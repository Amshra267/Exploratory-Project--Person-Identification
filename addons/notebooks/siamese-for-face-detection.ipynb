{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# PyTorch\n!pip install torchsummary\nfrom torchsummary import summary\nimport torch\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision.utils\nimport torchvision.datasets as dset\nfrom torch import optim\nfrom torch.utils.data import DataLoader,Dataset\nfrom torch.autograd import Variable\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom collections import defaultdict\n\nimport random\nfrom pathlib import Path\nimport sys\nfrom collections import OrderedDict\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport cv2\n","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### DATA LOADING AND PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"### here i will create the list of paths related to each one\n\ntrain_list = []\ntest_list = []\n\nroot = '../input/cleaned-lfw/cleaned_lfw'\nfor i in os.listdir(root):\n    imgs = glob(os.path.join(root, i, \"*\"))\n    length = len(imgs)\n    if (length==7):\n        ratio = 0.7\n    else:\n        ratio=0.8\n    train_div = int(ratio*length)\n    train_list.append(imgs[0:train_div])\n    test_list.append(imgs[train_div:])","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lenght(list_of_lists):\n    count = 0\n    for i in range(len(list_of_lists)):\n        count +=len(list_of_lists[i])\n    return count","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class trainingDataset(Dataset):#Get two images and whether they are related.\n    \n    def __init__(self, data_list, transform=None):\n        self.list = data_list\n        self.transform = transform\n        \n    def get_pair(self, data_list, positive):\n        pair = []\n        if positive:\n            value = random.randint(0,255)\n            id = [value, value]\n            label = 1\n        else:\n            label = 0\n            while True:\n                id = [random.randint(0,255), random.randint(0,255)]\n                if id[0] != id[1]:\n                    break\n        \n        for i in range(2):\n            filepath = ''\n            while True:\n                sub = self.list[id[i]]\n                filepath = random.choice(sub)\n                if not os.path.exists(filepath):\n                    continue\n                break\n            pair.append(filepath)\n        return pair, torch.tensor(label).long()\n  \n    def __getitem__(self,index):\n        #we need to make sure approx 50% of images are in the same class\n        should_get_same_class = random.randint(0,1) \n        path, label = self.get_pair(self.list, should_get_same_class)\n        img0 = cv2.imread(path[0])\n        img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n        img1 = cv2.imread(path[1])\n        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n\n\n        if self.transform is not None:\n            img0 = self.transform(image=img0)[\"image\"]\n            img1 = self.transform(image=img1)[\"image\"]\n        \n        img0 = img0/255.\n        img1 = img1/255.\n        return img0, img1, label \n    \n    def __len__(self):\n        return lenght(self.list)#essential for choose the num of data in one epoch","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 600\nIMAGE_WIDTH = 32\nIMAGE_HEIGHT = 32\n\ntrain_transform = A.Compose([\n    A.Resize(height=IMAGE_HEIGHT+2, width=IMAGE_WIDTH+4, p=1),\n    A.RandomCrop(width=IMAGE_WIDTH, height=IMAGE_HEIGHT,p=1),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=10),\n    A.OneOf([A.HueSaturationValue(p=0.4), A.RGBShift(p=0.4)], p=0.4),\n    A.RandomBrightnessContrast(p=0.2),\n    ToTensorV2()\n])\nval_transform = A.Compose([\n                            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, p=1),\n                            ToTensorV2()\n                        ])\n\n\n\ntrainset = trainingDataset(train_list , transform=train_transform)\ntrain_loader = DataLoader(trainset,\n                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n                        num_workers=8,\n                        batch_size=128)\n\nvalset = trainingDataset(test_list, transform=val_transform)\nvalidation_loader = DataLoader(valset,\n                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.\n                        num_workers=8,\n                        batch_size=128)\n","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VISUALISATION\n\nFor visulaisation batch size= 8 else 128"},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n    \ndataiter = iter(train_loader)\n\n\nexample_batch = next(dataiter)\nconcatenated = torch.cat((example_batch[0],example_batch[1]),0)\nimshow(torchvision.utils.make_grid(concatenated))\nprint(example_batch[2].numpy())","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":"[0 1 1 0 0 1 1 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn1 = nn.Sequential(\n            \n            nn.Conv2d(3, 64, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            \n\n            nn.Conv2d(64, 64, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            \n            nn.Conv2d(64, 32, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(32),\n\n            \n            nn.Conv2d(32, 32, kernel_size=3, stride = 2),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(32)\n        )\n        \n        self.fc1 = nn.Linear(32*12*12, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 2)\n\n\n    def forward_once(self, x):\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        output = torch.sub(output1, output2)\n        output = F.relu(output)\n        output = self.fc2(output)\n        output = F.relu(output)\n        output = self.fc3(output)\n        return output","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(SiameseNetwork().cuda(), [(3,32,32), (3,32,32)])","execution_count":20,"outputs":[{"output_type":"stream","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 30, 30]           1,792\n              ReLU-2           [-1, 64, 30, 30]               0\n       BatchNorm2d-3           [-1, 64, 30, 30]             128\n            Conv2d-4           [-1, 64, 28, 28]          36,928\n              ReLU-5           [-1, 64, 28, 28]               0\n       BatchNorm2d-6           [-1, 64, 28, 28]             128\n            Conv2d-7           [-1, 32, 26, 26]          18,464\n              ReLU-8           [-1, 32, 26, 26]               0\n       BatchNorm2d-9           [-1, 32, 26, 26]              64\n           Conv2d-10           [-1, 32, 12, 12]           9,248\n             ReLU-11           [-1, 32, 12, 12]               0\n      BatchNorm2d-12           [-1, 32, 12, 12]              64\n           Linear-13                  [-1, 512]       2,359,808\n           Conv2d-14           [-1, 64, 30, 30]           1,792\n             ReLU-15           [-1, 64, 30, 30]               0\n      BatchNorm2d-16           [-1, 64, 30, 30]             128\n           Conv2d-17           [-1, 64, 28, 28]          36,928\n             ReLU-18           [-1, 64, 28, 28]               0\n      BatchNorm2d-19           [-1, 64, 28, 28]             128\n           Conv2d-20           [-1, 32, 26, 26]          18,464\n             ReLU-21           [-1, 32, 26, 26]               0\n      BatchNorm2d-22           [-1, 32, 26, 26]              64\n           Conv2d-23           [-1, 32, 12, 12]           9,248\n             ReLU-24           [-1, 32, 12, 12]               0\n      BatchNorm2d-25           [-1, 32, 12, 12]              64\n           Linear-26                  [-1, 512]       2,359,808\n           Linear-27                  [-1, 128]          65,664\n           Linear-28                    [-1, 2]             258\n================================================================\nTotal params: 4,919,170\nTrainable params: 4,919,170\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 36.00\nForward/backward pass size (MB): 6.14\nParams size (MB): 18.77\nEstimated Total Size (MB): 60.91\n----------------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SiameseNetwork()\ndevice = torch.device('cuda:0')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss() # computes softmax and then the cross entropy\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay = 0.0005)\n\nlambda1 = lambda iteration: ((0.0001 * iteration + 1) ** -0.75)\n\nexp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n\n\niteration = 0\n\nif os.path.exists('logs'):\n    checkpoint = torch.load('logs')\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    epoch = checkpoint['epoch']\n    print('Restore model at epoch - ', epoch)\n\nhistory = defaultdict(list) ## for storing histories\nhistory['val_loss'].append(np.inf)\nfor i in range(epochs):\n    val_acc = []\n    val_loss = []\n    train_acc = []\n    train_loss = []\n    \n    \n    model.train() # setting for training\n    for batch_idx, data in enumerate(train_loader):\n        \n        \n        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]\n        img0, img1 , labels = img0.to(device), img1.to(device) , labels.to(device)#move to GPU\n        optimizer.zero_grad()\n        \n        logits = model(img0, img1)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n        _, preds = torch.max(logits, 1)\n        total = len(labels)\n        correct = torch.sum(preds==labels)\n        train_acc.append(correct.item()/total)\n        iteration +=1\n        print('Iteration: {}, learning rate: {:.5f}, Loss: {:.4f}, Accuracy:{:.3f}'.format(iteration, \n                                                                                       optimizer.param_groups[0][\"lr\"], \n                                                                                       loss.item(), correct.item()/total))\n        exp_lr_scheduler.step()\n    model.eval() # setting for training\n    \n    for batch_idx, data in enumerate(validation_loader):\n        \n        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]\n        img0, img1 , labels = img0.to(device), img1.to(device) , labels.to(device)#move to GPU\n        \n        logits = model(img0, img1)\n        loss = F.cross_entropy(logits, labels, reduction = 'sum')/len(img0)\n\n        val_loss.append(loss.item())\n        _, preds = torch.max(logits, 1)\n        total = len(labels)\n        correct = torch.sum(preds==labels)\n        val_acc.append(correct.item()/total)  \n    \n    epoch_t_loss = np.mean(train_loss)\n    epoch_t_acc = np.mean(train_acc)\n    epoch_v_loss = np.mean(val_loss)\n    epoch_v_acc = np.mean(val_acc)\n    print('Epoch: {}, Loss: {:.4f}, Accuracy:{:.3f}, Val Loss: {:.4f}, Val Accuracy: {:.3f}'.format(\n        i+1,  epoch_t_loss, epoch_t_acc , epoch_v_loss,  epoch_v_acc))\n    \n    history['loss'].append(epoch_t_loss)\n    history['val_loss'].append(epoch_v_loss)\n    history['acc'].append(epoch_t_acc)\n    history['val_acc'].append(epoch_v_acc)\n    if (history['val_loss'][-1]<min(history['val_loss'][:-1])):\n        print('val_loss_decreased from {:.4f} to {:.4f}, saving_checkpoint for epoch {}'.format(min(history['val_loss'][:-1]), \n                                                                                                history['val_loss'][-1], i+1))\n        torch.save({\n                'epoch': i+1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': exp_lr_scheduler.state_dict(),\n                }, 'logs')\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Iteration: 1, learning rate: 0.01000, Loss: 0.7390, Accuracy:0.406\nIteration: 2, learning rate: 0.01000, Loss: 0.7124, Accuracy:0.469\nIteration: 3, learning rate: 0.01000, Loss: 0.6838, Accuracy:0.523\nIteration: 4, learning rate: 0.01000, Loss: 0.6954, Accuracy:0.469\nIteration: 5, learning rate: 0.01000, Loss: 0.7014, Accuracy:0.445\nIteration: 6, learning rate: 0.01000, Loss: 0.6944, Accuracy:0.508\nIteration: 7, learning rate: 0.01000, Loss: 0.6971, Accuracy:0.445\nIteration: 8, learning rate: 0.00999, Loss: 0.6901, Accuracy:0.562\nIteration: 9, learning rate: 0.00999, Loss: 0.6966, Accuracy:0.469\nIteration: 10, learning rate: 0.00999, Loss: 0.6901, Accuracy:0.555\nIteration: 11, learning rate: 0.00999, Loss: 0.6954, Accuracy:0.531\nIteration: 12, learning rate: 0.00999, Loss: 0.6892, Accuracy:0.531\nIteration: 13, learning rate: 0.00999, Loss: 0.6913, Accuracy:0.508\nIteration: 14, learning rate: 0.00999, Loss: 0.6851, Accuracy:0.547\nIteration: 15, learning rate: 0.00999, Loss: 0.6861, Accuracy:0.562\nIteration: 16, learning rate: 0.00999, Loss: 0.6979, Accuracy:0.484\nIteration: 17, learning rate: 0.00999, Loss: 0.6923, Accuracy:0.523\nIteration: 18, learning rate: 0.00999, Loss: 0.6976, Accuracy:0.477\nIteration: 19, learning rate: 0.00999, Loss: 0.6965, Accuracy:0.539\nIteration: 20, learning rate: 0.00999, Loss: 0.6954, Accuracy:0.484\nIteration: 21, learning rate: 0.00999, Loss: 0.6930, Accuracy:0.539\nIteration: 22, learning rate: 0.00998, Loss: 0.6996, Accuracy:0.523\nIteration: 23, learning rate: 0.00998, Loss: 0.6923, Accuracy:0.531\nIteration: 24, learning rate: 0.00998, Loss: 0.6875, Accuracy:0.500\nIteration: 25, learning rate: 0.00998, Loss: 0.6865, Accuracy:0.562\nIteration: 26, learning rate: 0.00998, Loss: 0.7002, Accuracy:0.469\nIteration: 27, learning rate: 0.00998, Loss: 0.6808, Accuracy:0.578\nIteration: 28, learning rate: 0.00998, Loss: 0.7179, Accuracy:0.438\nIteration: 29, learning rate: 0.00998, Loss: 0.7027, Accuracy:0.492\nIteration: 30, learning rate: 0.00998, Loss: 0.6973, Accuracy:0.523\nIteration: 31, learning rate: 0.00998, Loss: 0.7015, Accuracy:0.473\nEpoch: 1, Loss: 0.6963, Accuracy:0.505, Val Loss: 0.6847, Val Accuracy: 0.519\nval_loss_decreased from inf to 0.6847, saving_checkpoint for epoch 1\nIteration: 32, learning rate: 0.00998, Loss: 0.7113, Accuracy:0.445\nIteration: 33, learning rate: 0.00998, Loss: 0.6822, Accuracy:0.586\nIteration: 34, learning rate: 0.00998, Loss: 0.6784, Accuracy:0.594\nIteration: 35, learning rate: 0.00997, Loss: 0.6901, Accuracy:0.539\nIteration: 36, learning rate: 0.00997, Loss: 0.6984, Accuracy:0.508\nIteration: 37, learning rate: 0.00997, Loss: 0.6868, Accuracy:0.500\nIteration: 38, learning rate: 0.00997, Loss: 0.6941, Accuracy:0.508\nIteration: 39, learning rate: 0.00997, Loss: 0.6829, Accuracy:0.570\nIteration: 40, learning rate: 0.00997, Loss: 0.6909, Accuracy:0.547\nIteration: 41, learning rate: 0.00997, Loss: 0.6972, Accuracy:0.492\nIteration: 42, learning rate: 0.00997, Loss: 0.6868, Accuracy:0.508\nIteration: 43, learning rate: 0.00997, Loss: 0.6792, Accuracy:0.578\nIteration: 44, learning rate: 0.00997, Loss: 0.6846, Accuracy:0.508\nIteration: 45, learning rate: 0.00997, Loss: 0.6893, Accuracy:0.555\nIteration: 46, learning rate: 0.00997, Loss: 0.7084, Accuracy:0.508\nIteration: 47, learning rate: 0.00997, Loss: 0.6893, Accuracy:0.562\nIteration: 48, learning rate: 0.00996, Loss: 0.7014, Accuracy:0.477\nIteration: 49, learning rate: 0.00996, Loss: 0.7001, Accuracy:0.477\nIteration: 50, learning rate: 0.00996, Loss: 0.6820, Accuracy:0.539\nIteration: 51, learning rate: 0.00996, Loss: 0.6808, Accuracy:0.586\nIteration: 52, learning rate: 0.00996, Loss: 0.6787, Accuracy:0.586\nIteration: 53, learning rate: 0.00996, Loss: 0.6747, Accuracy:0.586\nIteration: 54, learning rate: 0.00996, Loss: 0.6813, Accuracy:0.602\nIteration: 55, learning rate: 0.00996, Loss: 0.6942, Accuracy:0.539\nIteration: 56, learning rate: 0.00996, Loss: 0.6781, Accuracy:0.617\nIteration: 57, learning rate: 0.00996, Loss: 0.6758, Accuracy:0.602\nIteration: 58, learning rate: 0.00996, Loss: 0.6748, Accuracy:0.602\nIteration: 59, learning rate: 0.00996, Loss: 0.6643, Accuracy:0.578\nIteration: 60, learning rate: 0.00996, Loss: 0.6700, Accuracy:0.578\nIteration: 61, learning rate: 0.00996, Loss: 0.6844, Accuracy:0.523\nIteration: 62, learning rate: 0.00995, Loss: 0.6697, Accuracy:0.613\nEpoch: 2, Loss: 0.6858, Accuracy:0.549, Val Loss: 0.6580, Val Accuracy: 0.675\nval_loss_decreased from 0.6847 to 0.6580, saving_checkpoint for epoch 2\nIteration: 63, learning rate: 0.00995, Loss: 0.6707, Accuracy:0.578\nIteration: 64, learning rate: 0.00995, Loss: 0.6546, Accuracy:0.609\nIteration: 65, learning rate: 0.00995, Loss: 0.6726, Accuracy:0.625\nIteration: 66, learning rate: 0.00995, Loss: 0.6804, Accuracy:0.578\nIteration: 67, learning rate: 0.00995, Loss: 0.6565, Accuracy:0.578\nIteration: 68, learning rate: 0.00995, Loss: 0.6435, Accuracy:0.633\nIteration: 69, learning rate: 0.00995, Loss: 0.6653, Accuracy:0.617\nIteration: 70, learning rate: 0.00995, Loss: 0.6547, Accuracy:0.617\nIteration: 71, learning rate: 0.00995, Loss: 0.6840, Accuracy:0.531\nIteration: 72, learning rate: 0.00995, Loss: 0.6671, Accuracy:0.523\nIteration: 73, learning rate: 0.00995, Loss: 0.6763, Accuracy:0.625\nIteration: 74, learning rate: 0.00995, Loss: 0.6632, Accuracy:0.609\nIteration: 75, learning rate: 0.00994, Loss: 0.6340, Accuracy:0.695\nIteration: 76, learning rate: 0.00994, Loss: 0.6626, Accuracy:0.617\nIteration: 77, learning rate: 0.00994, Loss: 0.6424, Accuracy:0.625\nIteration: 78, learning rate: 0.00994, Loss: 0.6491, Accuracy:0.633\nIteration: 79, learning rate: 0.00994, Loss: 0.6280, Accuracy:0.633\nIteration: 80, learning rate: 0.00994, Loss: 0.6340, Accuracy:0.625\nIteration: 81, learning rate: 0.00994, Loss: 0.6395, Accuracy:0.641\nIteration: 82, learning rate: 0.00994, Loss: 0.6362, Accuracy:0.633\nIteration: 83, learning rate: 0.00994, Loss: 0.6458, Accuracy:0.633\nIteration: 84, learning rate: 0.00994, Loss: 0.6519, Accuracy:0.656\nIteration: 85, learning rate: 0.00994, Loss: 0.6012, Accuracy:0.672\nIteration: 86, learning rate: 0.00994, Loss: 0.7180, Accuracy:0.508\nIteration: 87, learning rate: 0.00994, Loss: 0.6605, Accuracy:0.594\nIteration: 88, learning rate: 0.00994, Loss: 0.6189, Accuracy:0.664\nIteration: 89, learning rate: 0.00993, Loss: 0.6184, Accuracy:0.609\nIteration: 90, learning rate: 0.00993, Loss: 0.5972, Accuracy:0.672\nIteration: 91, learning rate: 0.00993, Loss: 0.5931, Accuracy:0.703\nIteration: 92, learning rate: 0.00993, Loss: 0.6486, Accuracy:0.586\nIteration: 93, learning rate: 0.00993, Loss: 0.7123, Accuracy:0.581\nEpoch: 3, Loss: 0.6510, Accuracy:0.616, Val Loss: 0.6091, Val Accuracy: 0.706\nval_loss_decreased from 0.6580 to 0.6091, saving_checkpoint for epoch 3\nIteration: 94, learning rate: 0.00993, Loss: 0.6659, Accuracy:0.555\nIteration: 95, learning rate: 0.00993, Loss: 0.6237, Accuracy:0.641\nIteration: 96, learning rate: 0.00993, Loss: 0.6287, Accuracy:0.641\nIteration: 97, learning rate: 0.00993, Loss: 0.6338, Accuracy:0.656\nIteration: 98, learning rate: 0.00993, Loss: 0.6719, Accuracy:0.570\nIteration: 99, learning rate: 0.00993, Loss: 0.6346, Accuracy:0.625\nIteration: 100, learning rate: 0.00993, Loss: 0.6256, Accuracy:0.641\nIteration: 101, learning rate: 0.00993, Loss: 0.6042, Accuracy:0.695\nIteration: 102, learning rate: 0.00992, Loss: 0.6319, Accuracy:0.672\nIteration: 103, learning rate: 0.00992, Loss: 0.6106, Accuracy:0.648\nIteration: 104, learning rate: 0.00992, Loss: 0.6493, Accuracy:0.648\nIteration: 105, learning rate: 0.00992, Loss: 0.6828, Accuracy:0.570\nIteration: 106, learning rate: 0.00992, Loss: 0.6281, Accuracy:0.641\nIteration: 107, learning rate: 0.00992, Loss: 0.6124, Accuracy:0.672\nIteration: 108, learning rate: 0.00992, Loss: 0.6632, Accuracy:0.602\nIteration: 109, learning rate: 0.00992, Loss: 0.6008, Accuracy:0.688\nIteration: 110, learning rate: 0.00992, Loss: 0.6143, Accuracy:0.680\nIteration: 111, learning rate: 0.00992, Loss: 0.6512, Accuracy:0.617\nIteration: 112, learning rate: 0.00992, Loss: 0.6523, Accuracy:0.633\nIteration: 113, learning rate: 0.00992, Loss: 0.5679, Accuracy:0.734\nIteration: 114, learning rate: 0.00992, Loss: 0.6143, Accuracy:0.609\nIteration: 115, learning rate: 0.00992, Loss: 0.6674, Accuracy:0.625\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 116, learning rate: 0.00991, Loss: 0.6145, Accuracy:0.625\nIteration: 117, learning rate: 0.00991, Loss: 0.6224, Accuracy:0.641\nIteration: 118, learning rate: 0.00991, Loss: 0.6714, Accuracy:0.594\nIteration: 119, learning rate: 0.00991, Loss: 0.6393, Accuracy:0.672\nIteration: 120, learning rate: 0.00991, Loss: 0.6191, Accuracy:0.648\nIteration: 121, learning rate: 0.00991, Loss: 0.6328, Accuracy:0.648\nIteration: 122, learning rate: 0.00991, Loss: 0.6039, Accuracy:0.703\nIteration: 123, learning rate: 0.00991, Loss: 0.6362, Accuracy:0.617\nIteration: 124, learning rate: 0.00991, Loss: 0.5650, Accuracy:0.667\nEpoch: 4, Loss: 0.6303, Accuracy:0.641, Val Loss: 0.5773, Val Accuracy: 0.730\nval_loss_decreased from 0.6091 to 0.5773, saving_checkpoint for epoch 4\nIteration: 125, learning rate: 0.00991, Loss: 0.5815, Accuracy:0.703\nIteration: 126, learning rate: 0.00991, Loss: 0.5604, Accuracy:0.711\nIteration: 127, learning rate: 0.00991, Loss: 0.6297, Accuracy:0.656\nIteration: 128, learning rate: 0.00991, Loss: 0.6418, Accuracy:0.633\nIteration: 129, learning rate: 0.00991, Loss: 0.6256, Accuracy:0.602\nIteration: 130, learning rate: 0.00990, Loss: 0.5999, Accuracy:0.648\nIteration: 131, learning rate: 0.00990, Loss: 0.6436, Accuracy:0.664\nIteration: 132, learning rate: 0.00990, Loss: 0.6115, Accuracy:0.641\nIteration: 133, learning rate: 0.00990, Loss: 0.6534, Accuracy:0.617\nIteration: 134, learning rate: 0.00990, Loss: 0.6502, Accuracy:0.602\nIteration: 135, learning rate: 0.00990, Loss: 0.6200, Accuracy:0.672\nIteration: 136, learning rate: 0.00990, Loss: 0.6293, Accuracy:0.617\nIteration: 137, learning rate: 0.00990, Loss: 0.6128, Accuracy:0.625\nIteration: 138, learning rate: 0.00990, Loss: 0.5756, Accuracy:0.695\nIteration: 139, learning rate: 0.00990, Loss: 0.5935, Accuracy:0.672\nIteration: 140, learning rate: 0.00990, Loss: 0.6262, Accuracy:0.672\nIteration: 141, learning rate: 0.00990, Loss: 0.5861, Accuracy:0.742\nIteration: 142, learning rate: 0.00990, Loss: 0.6081, Accuracy:0.641\nIteration: 143, learning rate: 0.00989, Loss: 0.6206, Accuracy:0.656\nIteration: 144, learning rate: 0.00989, Loss: 0.6127, Accuracy:0.656\nIteration: 145, learning rate: 0.00989, Loss: 0.5723, Accuracy:0.703\nIteration: 146, learning rate: 0.00989, Loss: 0.6372, Accuracy:0.656\nIteration: 147, learning rate: 0.00989, Loss: 0.6316, Accuracy:0.703\nIteration: 148, learning rate: 0.00989, Loss: 0.6201, Accuracy:0.695\nIteration: 149, learning rate: 0.00989, Loss: 0.6284, Accuracy:0.664\nIteration: 150, learning rate: 0.00989, Loss: 0.5766, Accuracy:0.695\nIteration: 151, learning rate: 0.00989, Loss: 0.5926, Accuracy:0.742\nIteration: 152, learning rate: 0.00989, Loss: 0.5572, Accuracy:0.750\nIteration: 153, learning rate: 0.00989, Loss: 0.5568, Accuracy:0.750\nIteration: 154, learning rate: 0.00989, Loss: 0.5895, Accuracy:0.719\nIteration: 155, learning rate: 0.00989, Loss: 0.6047, Accuracy:0.667\nEpoch: 5, Loss: 0.6080, Accuracy:0.673, Val Loss: 0.5899, Val Accuracy: 0.714\nIteration: 156, learning rate: 0.00989, Loss: 0.6599, Accuracy:0.648\nIteration: 157, learning rate: 0.00988, Loss: 0.6451, Accuracy:0.648\nIteration: 158, learning rate: 0.00988, Loss: 0.6059, Accuracy:0.672\nIteration: 159, learning rate: 0.00988, Loss: 0.5549, Accuracy:0.734\nIteration: 160, learning rate: 0.00988, Loss: 0.6862, Accuracy:0.617\nIteration: 161, learning rate: 0.00988, Loss: 0.5902, Accuracy:0.711\nIteration: 162, learning rate: 0.00988, Loss: 0.6214, Accuracy:0.641\nIteration: 163, learning rate: 0.00988, Loss: 0.6064, Accuracy:0.680\nIteration: 164, learning rate: 0.00988, Loss: 0.6347, Accuracy:0.641\nIteration: 165, learning rate: 0.00988, Loss: 0.5695, Accuracy:0.727\nIteration: 166, learning rate: 0.00988, Loss: 0.5866, Accuracy:0.695\nIteration: 167, learning rate: 0.00988, Loss: 0.5805, Accuracy:0.734\nIteration: 168, learning rate: 0.00988, Loss: 0.6265, Accuracy:0.633\nIteration: 169, learning rate: 0.00988, Loss: 0.6079, Accuracy:0.719\nIteration: 170, learning rate: 0.00988, Loss: 0.6026, Accuracy:0.656\nIteration: 171, learning rate: 0.00987, Loss: 0.5949, Accuracy:0.664\nIteration: 172, learning rate: 0.00987, Loss: 0.5823, Accuracy:0.688\nIteration: 173, learning rate: 0.00987, Loss: 0.5608, Accuracy:0.727\nIteration: 174, learning rate: 0.00987, Loss: 0.5918, Accuracy:0.625\nIteration: 175, learning rate: 0.00987, Loss: 0.5945, Accuracy:0.742\nIteration: 176, learning rate: 0.00987, Loss: 0.6704, Accuracy:0.602\nIteration: 177, learning rate: 0.00987, Loss: 0.6083, Accuracy:0.727\nIteration: 178, learning rate: 0.00987, Loss: 0.5896, Accuracy:0.656\nIteration: 179, learning rate: 0.00987, Loss: 0.6752, Accuracy:0.633\nIteration: 180, learning rate: 0.00987, Loss: 0.6383, Accuracy:0.609\nIteration: 181, learning rate: 0.00987, Loss: 0.6009, Accuracy:0.703\nIteration: 182, learning rate: 0.00987, Loss: 0.6066, Accuracy:0.680\nIteration: 183, learning rate: 0.00987, Loss: 0.6156, Accuracy:0.625\nIteration: 184, learning rate: 0.00986, Loss: 0.5407, Accuracy:0.695\nIteration: 185, learning rate: 0.00986, Loss: 0.5693, Accuracy:0.727\nIteration: 186, learning rate: 0.00986, Loss: 0.5402, Accuracy:0.720\nEpoch: 6, Loss: 0.6051, Accuracy:0.677, Val Loss: 0.5444, Val Accuracy: 0.753\nval_loss_decreased from 0.5773 to 0.5444, saving_checkpoint for epoch 6\nIteration: 187, learning rate: 0.00986, Loss: 0.6233, Accuracy:0.664\nIteration: 188, learning rate: 0.00986, Loss: 0.6328, Accuracy:0.625\nIteration: 189, learning rate: 0.00986, Loss: 0.6111, Accuracy:0.672\nIteration: 190, learning rate: 0.00986, Loss: 0.6844, Accuracy:0.594\nIteration: 191, learning rate: 0.00986, Loss: 0.6446, Accuracy:0.648\nIteration: 192, learning rate: 0.00986, Loss: 0.5726, Accuracy:0.711\nIteration: 193, learning rate: 0.00986, Loss: 0.5970, Accuracy:0.680\nIteration: 194, learning rate: 0.00986, Loss: 0.5813, Accuracy:0.688\nIteration: 195, learning rate: 0.00986, Loss: 0.6224, Accuracy:0.648\nIteration: 196, learning rate: 0.00986, Loss: 0.5924, Accuracy:0.711\nIteration: 197, learning rate: 0.00986, Loss: 0.5662, Accuracy:0.664\nIteration: 198, learning rate: 0.00985, Loss: 0.6191, Accuracy:0.680\nIteration: 199, learning rate: 0.00985, Loss: 0.5685, Accuracy:0.703\nIteration: 200, learning rate: 0.00985, Loss: 0.5790, Accuracy:0.695\nIteration: 201, learning rate: 0.00985, Loss: 0.5795, Accuracy:0.719\nIteration: 202, learning rate: 0.00985, Loss: 0.5831, Accuracy:0.711\nIteration: 203, learning rate: 0.00985, Loss: 0.6009, Accuracy:0.672\nIteration: 204, learning rate: 0.00985, Loss: 0.5896, Accuracy:0.680\nIteration: 205, learning rate: 0.00985, Loss: 0.6204, Accuracy:0.680\nIteration: 206, learning rate: 0.00985, Loss: 0.5394, Accuracy:0.703\nIteration: 207, learning rate: 0.00985, Loss: 0.5847, Accuracy:0.719\nIteration: 208, learning rate: 0.00985, Loss: 0.5676, Accuracy:0.695\nIteration: 209, learning rate: 0.00985, Loss: 0.5653, Accuracy:0.758\nIteration: 210, learning rate: 0.00985, Loss: 0.5890, Accuracy:0.711\nIteration: 211, learning rate: 0.00985, Loss: 0.5814, Accuracy:0.711\nIteration: 212, learning rate: 0.00984, Loss: 0.6475, Accuracy:0.641\nIteration: 213, learning rate: 0.00984, Loss: 0.5842, Accuracy:0.664\nIteration: 214, learning rate: 0.00984, Loss: 0.6074, Accuracy:0.664\nIteration: 215, learning rate: 0.00984, Loss: 0.5963, Accuracy:0.688\nIteration: 216, learning rate: 0.00984, Loss: 0.6156, Accuracy:0.602\nIteration: 217, learning rate: 0.00984, Loss: 0.4947, Accuracy:0.817\nEpoch: 7, Loss: 0.5949, Accuracy:0.684, Val Loss: 0.5512, Val Accuracy: 0.744\nIteration: 218, learning rate: 0.00984, Loss: 0.6074, Accuracy:0.664\nIteration: 219, learning rate: 0.00984, Loss: 0.6215, Accuracy:0.680\nIteration: 220, learning rate: 0.00984, Loss: 0.6263, Accuracy:0.648\nIteration: 221, learning rate: 0.00984, Loss: 0.6053, Accuracy:0.688\nIteration: 222, learning rate: 0.00984, Loss: 0.5907, Accuracy:0.688\nIteration: 223, learning rate: 0.00984, Loss: 0.6006, Accuracy:0.633\nIteration: 224, learning rate: 0.00984, Loss: 0.5423, Accuracy:0.719\nIteration: 225, learning rate: 0.00984, Loss: 0.6585, Accuracy:0.633\nIteration: 226, learning rate: 0.00983, Loss: 0.6508, Accuracy:0.648\nIteration: 227, learning rate: 0.00983, Loss: 0.6879, Accuracy:0.633\nIteration: 228, learning rate: 0.00983, Loss: 0.6025, Accuracy:0.711\nIteration: 229, learning rate: 0.00983, Loss: 0.5577, Accuracy:0.703\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 230, learning rate: 0.00983, Loss: 0.6011, Accuracy:0.680\nIteration: 231, learning rate: 0.00983, Loss: 0.5433, Accuracy:0.750\nIteration: 232, learning rate: 0.00983, Loss: 0.6171, Accuracy:0.648\nIteration: 233, learning rate: 0.00983, Loss: 0.6001, Accuracy:0.695\nIteration: 234, learning rate: 0.00983, Loss: 0.5165, Accuracy:0.758\nIteration: 235, learning rate: 0.00983, Loss: 0.6382, Accuracy:0.625\nIteration: 236, learning rate: 0.00983, Loss: 0.5868, Accuracy:0.688\nIteration: 237, learning rate: 0.00983, Loss: 0.5593, Accuracy:0.742\nIteration: 238, learning rate: 0.00983, Loss: 0.5768, Accuracy:0.711\nIteration: 239, learning rate: 0.00983, Loss: 0.6132, Accuracy:0.664\nIteration: 240, learning rate: 0.00982, Loss: 0.5283, Accuracy:0.789\nIteration: 241, learning rate: 0.00982, Loss: 0.5739, Accuracy:0.711\nIteration: 242, learning rate: 0.00982, Loss: 0.5489, Accuracy:0.688\nIteration: 243, learning rate: 0.00982, Loss: 0.5920, Accuracy:0.703\nIteration: 244, learning rate: 0.00982, Loss: 0.5781, Accuracy:0.750\nIteration: 245, learning rate: 0.00982, Loss: 0.6196, Accuracy:0.633\nIteration: 246, learning rate: 0.00982, Loss: 0.6018, Accuracy:0.688\nIteration: 247, learning rate: 0.00982, Loss: 0.5845, Accuracy:0.664\nIteration: 248, learning rate: 0.00982, Loss: 0.5918, Accuracy:0.720\nEpoch: 8, Loss: 0.5943, Accuracy:0.689, Val Loss: 0.5786, Val Accuracy: 0.700\nIteration: 249, learning rate: 0.00982, Loss: 0.5820, Accuracy:0.758\nIteration: 250, learning rate: 0.00982, Loss: 0.5750, Accuracy:0.727\nIteration: 251, learning rate: 0.00982, Loss: 0.6093, Accuracy:0.680\nIteration: 252, learning rate: 0.00982, Loss: 0.5326, Accuracy:0.727\nIteration: 253, learning rate: 0.00982, Loss: 0.5768, Accuracy:0.656\nIteration: 254, learning rate: 0.00981, Loss: 0.6405, Accuracy:0.648\nIteration: 255, learning rate: 0.00981, Loss: 0.6072, Accuracy:0.688\nIteration: 256, learning rate: 0.00981, Loss: 0.6191, Accuracy:0.719\nIteration: 257, learning rate: 0.00981, Loss: 0.5252, Accuracy:0.781\nIteration: 258, learning rate: 0.00981, Loss: 0.5700, Accuracy:0.695\nIteration: 259, learning rate: 0.00981, Loss: 0.5765, Accuracy:0.711\nIteration: 260, learning rate: 0.00981, Loss: 0.5467, Accuracy:0.711\nIteration: 261, learning rate: 0.00981, Loss: 0.5700, Accuracy:0.727\nIteration: 262, learning rate: 0.00981, Loss: 0.5822, Accuracy:0.648\nIteration: 263, learning rate: 0.00981, Loss: 0.5811, Accuracy:0.664\nIteration: 264, learning rate: 0.00981, Loss: 0.5795, Accuracy:0.688\nIteration: 265, learning rate: 0.00981, Loss: 0.5125, Accuracy:0.742\nIteration: 266, learning rate: 0.00981, Loss: 0.5255, Accuracy:0.773\nIteration: 267, learning rate: 0.00981, Loss: 0.5357, Accuracy:0.750\nIteration: 268, learning rate: 0.00980, Loss: 0.6354, Accuracy:0.633\nIteration: 269, learning rate: 0.00980, Loss: 0.5411, Accuracy:0.773\nIteration: 270, learning rate: 0.00980, Loss: 0.5919, Accuracy:0.664\nIteration: 271, learning rate: 0.00980, Loss: 0.5671, Accuracy:0.672\nIteration: 272, learning rate: 0.00980, Loss: 0.5700, Accuracy:0.688\nIteration: 273, learning rate: 0.00980, Loss: 0.6323, Accuracy:0.656\nIteration: 274, learning rate: 0.00980, Loss: 0.5925, Accuracy:0.703\nIteration: 275, learning rate: 0.00980, Loss: 0.5882, Accuracy:0.695\nIteration: 276, learning rate: 0.00980, Loss: 0.6382, Accuracy:0.648\nIteration: 277, learning rate: 0.00980, Loss: 0.5449, Accuracy:0.719\nIteration: 278, learning rate: 0.00980, Loss: 0.5805, Accuracy:0.695\nIteration: 279, learning rate: 0.00980, Loss: 0.5312, Accuracy:0.774\nEpoch: 9, Loss: 0.5761, Accuracy:0.704, Val Loss: 0.5758, Val Accuracy: 0.688\nIteration: 280, learning rate: 0.00980, Loss: 0.5052, Accuracy:0.742\nIteration: 281, learning rate: 0.00980, Loss: 0.5514, Accuracy:0.727\nIteration: 282, learning rate: 0.00979, Loss: 0.5330, Accuracy:0.750\nIteration: 283, learning rate: 0.00979, Loss: 0.6273, Accuracy:0.672\nIteration: 284, learning rate: 0.00979, Loss: 0.5046, Accuracy:0.766\nIteration: 285, learning rate: 0.00979, Loss: 0.5639, Accuracy:0.727\nIteration: 286, learning rate: 0.00979, Loss: 0.5322, Accuracy:0.742\nIteration: 287, learning rate: 0.00979, Loss: 0.5645, Accuracy:0.750\nIteration: 288, learning rate: 0.00979, Loss: 0.6425, Accuracy:0.578\nIteration: 289, learning rate: 0.00979, Loss: 0.5849, Accuracy:0.656\nIteration: 290, learning rate: 0.00979, Loss: 0.5782, Accuracy:0.695\nIteration: 291, learning rate: 0.00979, Loss: 0.5921, Accuracy:0.703\nIteration: 292, learning rate: 0.00979, Loss: 0.6253, Accuracy:0.625\nIteration: 293, learning rate: 0.00979, Loss: 0.5593, Accuracy:0.695\nIteration: 294, learning rate: 0.00979, Loss: 0.5374, Accuracy:0.742\nIteration: 295, learning rate: 0.00979, Loss: 0.6149, Accuracy:0.672\nIteration: 296, learning rate: 0.00978, Loss: 0.5793, Accuracy:0.727\nIteration: 297, learning rate: 0.00978, Loss: 0.6372, Accuracy:0.641\nIteration: 298, learning rate: 0.00978, Loss: 0.5859, Accuracy:0.695\nIteration: 299, learning rate: 0.00978, Loss: 0.5857, Accuracy:0.727\nIteration: 300, learning rate: 0.00978, Loss: 0.5720, Accuracy:0.727\nIteration: 301, learning rate: 0.00978, Loss: 0.5833, Accuracy:0.695\nIteration: 302, learning rate: 0.00978, Loss: 0.5255, Accuracy:0.766\nIteration: 303, learning rate: 0.00978, Loss: 0.5137, Accuracy:0.766\nIteration: 304, learning rate: 0.00978, Loss: 0.5731, Accuracy:0.688\nIteration: 305, learning rate: 0.00978, Loss: 0.5746, Accuracy:0.688\nIteration: 306, learning rate: 0.00978, Loss: 0.6309, Accuracy:0.680\nIteration: 307, learning rate: 0.00978, Loss: 0.5988, Accuracy:0.656\nIteration: 308, learning rate: 0.00978, Loss: 0.5579, Accuracy:0.742\nIteration: 309, learning rate: 0.00978, Loss: 0.5993, Accuracy:0.680\nIteration: 310, learning rate: 0.00977, Loss: 0.5831, Accuracy:0.710\nEpoch: 10, Loss: 0.5747, Accuracy:0.704, Val Loss: 0.5722, Val Accuracy: 0.698\nIteration: 311, learning rate: 0.00977, Loss: 0.5266, Accuracy:0.742\nIteration: 312, learning rate: 0.00977, Loss: 0.6020, Accuracy:0.648\nIteration: 313, learning rate: 0.00977, Loss: 0.6420, Accuracy:0.609\nIteration: 314, learning rate: 0.00977, Loss: 0.6378, Accuracy:0.680\nIteration: 315, learning rate: 0.00977, Loss: 0.5971, Accuracy:0.641\nIteration: 316, learning rate: 0.00977, Loss: 0.5067, Accuracy:0.766\nIteration: 317, learning rate: 0.00977, Loss: 0.5240, Accuracy:0.727\nIteration: 318, learning rate: 0.00977, Loss: 0.5359, Accuracy:0.719\nIteration: 319, learning rate: 0.00977, Loss: 0.5841, Accuracy:0.719\nIteration: 320, learning rate: 0.00977, Loss: 0.5713, Accuracy:0.672\nIteration: 321, learning rate: 0.00977, Loss: 0.5712, Accuracy:0.727\nIteration: 322, learning rate: 0.00977, Loss: 0.6275, Accuracy:0.672\nIteration: 323, learning rate: 0.00977, Loss: 0.5979, Accuracy:0.680\nIteration: 324, learning rate: 0.00976, Loss: 0.5782, Accuracy:0.711\nIteration: 325, learning rate: 0.00976, Loss: 0.5438, Accuracy:0.734\nIteration: 326, learning rate: 0.00976, Loss: 0.5541, Accuracy:0.703\nIteration: 327, learning rate: 0.00976, Loss: 0.5443, Accuracy:0.703\nIteration: 328, learning rate: 0.00976, Loss: 0.5788, Accuracy:0.672\nIteration: 329, learning rate: 0.00976, Loss: 0.5420, Accuracy:0.727\nIteration: 330, learning rate: 0.00976, Loss: 0.6085, Accuracy:0.688\nIteration: 331, learning rate: 0.00976, Loss: 0.5725, Accuracy:0.680\nIteration: 332, learning rate: 0.00976, Loss: 0.5683, Accuracy:0.711\nIteration: 333, learning rate: 0.00976, Loss: 0.5941, Accuracy:0.703\nIteration: 334, learning rate: 0.00976, Loss: 0.5259, Accuracy:0.758\nIteration: 335, learning rate: 0.00976, Loss: 0.5593, Accuracy:0.703\nIteration: 336, learning rate: 0.00976, Loss: 0.5745, Accuracy:0.688\nIteration: 337, learning rate: 0.00976, Loss: 0.5543, Accuracy:0.711\nIteration: 338, learning rate: 0.00975, Loss: 0.5988, Accuracy:0.703\nIteration: 339, learning rate: 0.00975, Loss: 0.5234, Accuracy:0.703\nIteration: 340, learning rate: 0.00975, Loss: 0.5585, Accuracy:0.742\nIteration: 341, learning rate: 0.00975, Loss: 0.5963, Accuracy:0.710\nEpoch: 11, Loss: 0.5710, Accuracy:0.702, Val Loss: 0.5054, Val Accuracy: 0.765\nval_loss_decreased from 0.5444 to 0.5054, saving_checkpoint for epoch 11\nIteration: 342, learning rate: 0.00975, Loss: 0.5822, Accuracy:0.695\nIteration: 343, learning rate: 0.00975, Loss: 0.6061, Accuracy:0.664\nIteration: 344, learning rate: 0.00975, Loss: 0.5900, Accuracy:0.664\nIteration: 345, learning rate: 0.00975, Loss: 0.5963, Accuracy:0.695\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 346, learning rate: 0.00975, Loss: 0.6217, Accuracy:0.648\nIteration: 347, learning rate: 0.00975, Loss: 0.6233, Accuracy:0.648\nIteration: 348, learning rate: 0.00975, Loss: 0.5832, Accuracy:0.664\nIteration: 349, learning rate: 0.00975, Loss: 0.5458, Accuracy:0.734\nIteration: 350, learning rate: 0.00975, Loss: 0.5243, Accuracy:0.750\nIteration: 351, learning rate: 0.00975, Loss: 0.5453, Accuracy:0.719\nIteration: 352, learning rate: 0.00974, Loss: 0.5872, Accuracy:0.695\nIteration: 353, learning rate: 0.00974, Loss: 0.5377, Accuracy:0.719\nIteration: 354, learning rate: 0.00974, Loss: 0.5985, Accuracy:0.656\nIteration: 355, learning rate: 0.00974, Loss: 0.5646, Accuracy:0.734\nIteration: 356, learning rate: 0.00974, Loss: 0.5187, Accuracy:0.727\nIteration: 357, learning rate: 0.00974, Loss: 0.5946, Accuracy:0.648\nIteration: 358, learning rate: 0.00974, Loss: 0.5858, Accuracy:0.695\nIteration: 359, learning rate: 0.00974, Loss: 0.5330, Accuracy:0.742\nIteration: 360, learning rate: 0.00974, Loss: 0.5745, Accuracy:0.703\nIteration: 361, learning rate: 0.00974, Loss: 0.6024, Accuracy:0.648\nIteration: 362, learning rate: 0.00974, Loss: 0.5333, Accuracy:0.711\nIteration: 363, learning rate: 0.00974, Loss: 0.6231, Accuracy:0.633\nIteration: 364, learning rate: 0.00974, Loss: 0.5675, Accuracy:0.703\nIteration: 365, learning rate: 0.00974, Loss: 0.5760, Accuracy:0.695\nIteration: 366, learning rate: 0.00973, Loss: 0.5620, Accuracy:0.734\nIteration: 367, learning rate: 0.00973, Loss: 0.5744, Accuracy:0.703\nIteration: 368, learning rate: 0.00973, Loss: 0.5344, Accuracy:0.750\nIteration: 369, learning rate: 0.00973, Loss: 0.5491, Accuracy:0.719\nIteration: 370, learning rate: 0.00973, Loss: 0.5983, Accuracy:0.695\nIteration: 371, learning rate: 0.00973, Loss: 0.5638, Accuracy:0.703\nIteration: 372, learning rate: 0.00973, Loss: 0.5545, Accuracy:0.710\nEpoch: 12, Loss: 0.5726, Accuracy:0.697, Val Loss: 0.4898, Val Accuracy: 0.771\nval_loss_decreased from 0.5054 to 0.4898, saving_checkpoint for epoch 12\nIteration: 373, learning rate: 0.00973, Loss: 0.5571, Accuracy:0.727\nIteration: 374, learning rate: 0.00973, Loss: 0.6071, Accuracy:0.641\nIteration: 375, learning rate: 0.00973, Loss: 0.5215, Accuracy:0.758\nIteration: 376, learning rate: 0.00973, Loss: 0.6019, Accuracy:0.633\nIteration: 377, learning rate: 0.00973, Loss: 0.6478, Accuracy:0.617\nIteration: 378, learning rate: 0.00973, Loss: 0.5579, Accuracy:0.711\nIteration: 379, learning rate: 0.00973, Loss: 0.5444, Accuracy:0.719\nIteration: 380, learning rate: 0.00972, Loss: 0.5822, Accuracy:0.656\nIteration: 381, learning rate: 0.00972, Loss: 0.5314, Accuracy:0.727\nIteration: 382, learning rate: 0.00972, Loss: 0.6432, Accuracy:0.703\nIteration: 383, learning rate: 0.00972, Loss: 0.5651, Accuracy:0.742\nIteration: 384, learning rate: 0.00972, Loss: 0.5648, Accuracy:0.734\nIteration: 385, learning rate: 0.00972, Loss: 0.5430, Accuracy:0.734\nIteration: 386, learning rate: 0.00972, Loss: 0.5424, Accuracy:0.734\nIteration: 387, learning rate: 0.00972, Loss: 0.5916, Accuracy:0.648\nIteration: 388, learning rate: 0.00972, Loss: 0.5271, Accuracy:0.750\nIteration: 389, learning rate: 0.00972, Loss: 0.5073, Accuracy:0.773\nIteration: 390, learning rate: 0.00972, Loss: 0.5507, Accuracy:0.695\nIteration: 391, learning rate: 0.00972, Loss: 0.5071, Accuracy:0.742\nIteration: 392, learning rate: 0.00972, Loss: 0.5055, Accuracy:0.766\nIteration: 393, learning rate: 0.00972, Loss: 0.5634, Accuracy:0.750\nIteration: 394, learning rate: 0.00972, Loss: 0.5350, Accuracy:0.773\nIteration: 395, learning rate: 0.00971, Loss: 0.5892, Accuracy:0.664\nIteration: 396, learning rate: 0.00971, Loss: 0.5328, Accuracy:0.727\nIteration: 397, learning rate: 0.00971, Loss: 0.5319, Accuracy:0.750\nIteration: 398, learning rate: 0.00971, Loss: 0.6209, Accuracy:0.672\nIteration: 399, learning rate: 0.00971, Loss: 0.4942, Accuracy:0.773\nIteration: 400, learning rate: 0.00971, Loss: 0.6075, Accuracy:0.680\nIteration: 401, learning rate: 0.00971, Loss: 0.5620, Accuracy:0.734\nIteration: 402, learning rate: 0.00971, Loss: 0.5259, Accuracy:0.758\nIteration: 403, learning rate: 0.00971, Loss: 0.5362, Accuracy:0.753\nEpoch: 13, Loss: 0.5580, Accuracy:0.718, Val Loss: 0.5325, Val Accuracy: 0.724\nIteration: 404, learning rate: 0.00971, Loss: 0.5784, Accuracy:0.656\nIteration: 405, learning rate: 0.00971, Loss: 0.5808, Accuracy:0.641\nIteration: 406, learning rate: 0.00971, Loss: 0.4766, Accuracy:0.805\nIteration: 407, learning rate: 0.00971, Loss: 0.5741, Accuracy:0.680\nIteration: 408, learning rate: 0.00971, Loss: 0.5973, Accuracy:0.641\nIteration: 409, learning rate: 0.00970, Loss: 0.5652, Accuracy:0.695\nIteration: 410, learning rate: 0.00970, Loss: 0.4849, Accuracy:0.805\nIteration: 411, learning rate: 0.00970, Loss: 0.6219, Accuracy:0.680\nIteration: 412, learning rate: 0.00970, Loss: 0.5525, Accuracy:0.734\nIteration: 413, learning rate: 0.00970, Loss: 0.5200, Accuracy:0.703\nIteration: 414, learning rate: 0.00970, Loss: 0.5991, Accuracy:0.672\nIteration: 415, learning rate: 0.00970, Loss: 0.6110, Accuracy:0.688\nIteration: 416, learning rate: 0.00970, Loss: 0.5486, Accuracy:0.742\nIteration: 417, learning rate: 0.00970, Loss: 0.5436, Accuracy:0.734\nIteration: 418, learning rate: 0.00970, Loss: 0.5884, Accuracy:0.703\nIteration: 419, learning rate: 0.00970, Loss: 0.5539, Accuracy:0.719\nIteration: 420, learning rate: 0.00970, Loss: 0.5375, Accuracy:0.766\nIteration: 421, learning rate: 0.00970, Loss: 0.5943, Accuracy:0.695\nIteration: 422, learning rate: 0.00970, Loss: 0.4739, Accuracy:0.797\nIteration: 423, learning rate: 0.00969, Loss: 0.5985, Accuracy:0.664\nIteration: 424, learning rate: 0.00969, Loss: 0.5613, Accuracy:0.688\nIteration: 425, learning rate: 0.00969, Loss: 0.5763, Accuracy:0.688\nIteration: 426, learning rate: 0.00969, Loss: 0.4977, Accuracy:0.758\nIteration: 427, learning rate: 0.00969, Loss: 0.5472, Accuracy:0.789\nIteration: 428, learning rate: 0.00969, Loss: 0.5093, Accuracy:0.742\nIteration: 429, learning rate: 0.00969, Loss: 0.5032, Accuracy:0.758\nIteration: 430, learning rate: 0.00969, Loss: 0.5519, Accuracy:0.742\nIteration: 431, learning rate: 0.00969, Loss: 0.5437, Accuracy:0.750\nIteration: 432, learning rate: 0.00969, Loss: 0.5128, Accuracy:0.766\nIteration: 433, learning rate: 0.00969, Loss: 0.4841, Accuracy:0.852\nIteration: 434, learning rate: 0.00969, Loss: 0.5071, Accuracy:0.753\nEpoch: 14, Loss: 0.5482, Accuracy:0.726, Val Loss: 0.5081, Val Accuracy: 0.758\nIteration: 435, learning rate: 0.00969, Loss: 0.5574, Accuracy:0.703\nIteration: 436, learning rate: 0.00969, Loss: 0.5012, Accuracy:0.742\nIteration: 437, learning rate: 0.00968, Loss: 0.4415, Accuracy:0.844\nIteration: 438, learning rate: 0.00968, Loss: 0.4323, Accuracy:0.766\nIteration: 439, learning rate: 0.00968, Loss: 0.5077, Accuracy:0.758\nIteration: 440, learning rate: 0.00968, Loss: 0.4815, Accuracy:0.773\nIteration: 441, learning rate: 0.00968, Loss: 0.5421, Accuracy:0.703\nIteration: 442, learning rate: 0.00968, Loss: 0.5149, Accuracy:0.727\nIteration: 443, learning rate: 0.00968, Loss: 0.5640, Accuracy:0.664\nIteration: 444, learning rate: 0.00968, Loss: 0.6066, Accuracy:0.672\nIteration: 445, learning rate: 0.00968, Loss: 0.5178, Accuracy:0.789\nIteration: 446, learning rate: 0.00968, Loss: 0.5231, Accuracy:0.703\nIteration: 447, learning rate: 0.00968, Loss: 0.5385, Accuracy:0.711\nIteration: 448, learning rate: 0.00968, Loss: 0.5379, Accuracy:0.773\nIteration: 449, learning rate: 0.00968, Loss: 0.5438, Accuracy:0.688\nIteration: 450, learning rate: 0.00968, Loss: 0.6386, Accuracy:0.703\nIteration: 451, learning rate: 0.00968, Loss: 0.5481, Accuracy:0.773\nIteration: 452, learning rate: 0.00967, Loss: 0.6476, Accuracy:0.633\nIteration: 453, learning rate: 0.00967, Loss: 0.4656, Accuracy:0.812\nIteration: 454, learning rate: 0.00967, Loss: 0.5616, Accuracy:0.680\nIteration: 455, learning rate: 0.00967, Loss: 0.5221, Accuracy:0.727\nIteration: 456, learning rate: 0.00967, Loss: 0.5094, Accuracy:0.758\nIteration: 457, learning rate: 0.00967, Loss: 0.4927, Accuracy:0.766\nIteration: 458, learning rate: 0.00967, Loss: 0.5338, Accuracy:0.711\nIteration: 459, learning rate: 0.00967, Loss: 0.4664, Accuracy:0.773\nIteration: 460, learning rate: 0.00967, Loss: 0.5928, Accuracy:0.656\nIteration: 461, learning rate: 0.00967, Loss: 0.4754, Accuracy:0.789\nIteration: 462, learning rate: 0.00967, Loss: 0.4701, Accuracy:0.773\nIteration: 463, learning rate: 0.00967, Loss: 0.5971, Accuracy:0.695\nIteration: 464, learning rate: 0.00967, Loss: 0.5032, Accuracy:0.742\nIteration: 465, learning rate: 0.00967, Loss: 0.6038, Accuracy:0.645\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 15, Loss: 0.5303, Accuracy:0.731, Val Loss: 0.5235, Val Accuracy: 0.721\nIteration: 466, learning rate: 0.00966, Loss: 0.5231, Accuracy:0.734\nIteration: 467, learning rate: 0.00966, Loss: 0.5800, Accuracy:0.688\nIteration: 468, learning rate: 0.00966, Loss: 0.6187, Accuracy:0.688\nIteration: 469, learning rate: 0.00966, Loss: 0.5346, Accuracy:0.719\nIteration: 470, learning rate: 0.00966, Loss: 0.5041, Accuracy:0.727\nIteration: 471, learning rate: 0.00966, Loss: 0.6127, Accuracy:0.672\nIteration: 472, learning rate: 0.00966, Loss: 0.4853, Accuracy:0.797\nIteration: 473, learning rate: 0.00966, Loss: 0.5519, Accuracy:0.703\nIteration: 474, learning rate: 0.00966, Loss: 0.5756, Accuracy:0.688\nIteration: 475, learning rate: 0.00966, Loss: 0.5977, Accuracy:0.680\nIteration: 476, learning rate: 0.00966, Loss: 0.5849, Accuracy:0.680\nIteration: 477, learning rate: 0.00966, Loss: 0.5491, Accuracy:0.734\nIteration: 478, learning rate: 0.00966, Loss: 0.5948, Accuracy:0.680\nIteration: 479, learning rate: 0.00966, Loss: 0.5040, Accuracy:0.758\nIteration: 480, learning rate: 0.00966, Loss: 0.5963, Accuracy:0.680\nIteration: 481, learning rate: 0.00965, Loss: 0.5482, Accuracy:0.758\nIteration: 482, learning rate: 0.00965, Loss: 0.5688, Accuracy:0.688\nIteration: 483, learning rate: 0.00965, Loss: 0.5631, Accuracy:0.648\nIteration: 484, learning rate: 0.00965, Loss: 0.5958, Accuracy:0.672\nIteration: 485, learning rate: 0.00965, Loss: 0.5794, Accuracy:0.695\nIteration: 486, learning rate: 0.00965, Loss: 0.5619, Accuracy:0.695\nIteration: 487, learning rate: 0.00965, Loss: 0.5293, Accuracy:0.773\nIteration: 488, learning rate: 0.00965, Loss: 0.5466, Accuracy:0.695\nIteration: 489, learning rate: 0.00965, Loss: 0.4991, Accuracy:0.773\nIteration: 490, learning rate: 0.00965, Loss: 0.5567, Accuracy:0.703\nIteration: 491, learning rate: 0.00965, Loss: 0.5784, Accuracy:0.641\nIteration: 492, learning rate: 0.00965, Loss: 0.5363, Accuracy:0.695\nIteration: 493, learning rate: 0.00965, Loss: 0.5591, Accuracy:0.695\nIteration: 494, learning rate: 0.00965, Loss: 0.5643, Accuracy:0.664\nIteration: 495, learning rate: 0.00964, Loss: 0.5309, Accuracy:0.703\nIteration: 496, learning rate: 0.00964, Loss: 0.5378, Accuracy:0.731\nEpoch: 16, Loss: 0.5570, Accuracy:0.705, Val Loss: 0.5118, Val Accuracy: 0.749\nIteration: 497, learning rate: 0.00964, Loss: 0.4969, Accuracy:0.781\nIteration: 498, learning rate: 0.00964, Loss: 0.5783, Accuracy:0.688\nIteration: 499, learning rate: 0.00964, Loss: 0.5467, Accuracy:0.719\nIteration: 500, learning rate: 0.00964, Loss: 0.5335, Accuracy:0.727\nIteration: 501, learning rate: 0.00964, Loss: 0.5055, Accuracy:0.742\nIteration: 502, learning rate: 0.00964, Loss: 0.4680, Accuracy:0.805\nIteration: 503, learning rate: 0.00964, Loss: 0.5848, Accuracy:0.656\nIteration: 504, learning rate: 0.00964, Loss: 0.5622, Accuracy:0.680\nIteration: 505, learning rate: 0.00964, Loss: 0.5102, Accuracy:0.734\nIteration: 506, learning rate: 0.00964, Loss: 0.5546, Accuracy:0.688\nIteration: 507, learning rate: 0.00964, Loss: 0.4995, Accuracy:0.773\nIteration: 508, learning rate: 0.00964, Loss: 0.5141, Accuracy:0.758\nIteration: 509, learning rate: 0.00964, Loss: 0.5506, Accuracy:0.742\nIteration: 510, learning rate: 0.00963, Loss: 0.4994, Accuracy:0.773\nIteration: 511, learning rate: 0.00963, Loss: 0.5348, Accuracy:0.773\nIteration: 512, learning rate: 0.00963, Loss: 0.5354, Accuracy:0.773\nIteration: 513, learning rate: 0.00963, Loss: 0.5016, Accuracy:0.773\nIteration: 514, learning rate: 0.00963, Loss: 0.6194, Accuracy:0.617\nIteration: 515, learning rate: 0.00963, Loss: 0.5897, Accuracy:0.672\nIteration: 516, learning rate: 0.00963, Loss: 0.5262, Accuracy:0.727\nIteration: 517, learning rate: 0.00963, Loss: 0.4950, Accuracy:0.766\nIteration: 518, learning rate: 0.00963, Loss: 0.5116, Accuracy:0.703\nIteration: 519, learning rate: 0.00963, Loss: 0.5166, Accuracy:0.797\nIteration: 520, learning rate: 0.00963, Loss: 0.5328, Accuracy:0.727\nIteration: 521, learning rate: 0.00963, Loss: 0.5455, Accuracy:0.695\nIteration: 522, learning rate: 0.00963, Loss: 0.5482, Accuracy:0.750\nIteration: 523, learning rate: 0.00963, Loss: 0.4740, Accuracy:0.742\nIteration: 524, learning rate: 0.00962, Loss: 0.6105, Accuracy:0.695\nIteration: 525, learning rate: 0.00962, Loss: 0.5891, Accuracy:0.711\nIteration: 526, learning rate: 0.00962, Loss: 0.5235, Accuracy:0.750\nIteration: 527, learning rate: 0.00962, Loss: 0.5165, Accuracy:0.731\nEpoch: 17, Loss: 0.5347, Accuracy:0.731, Val Loss: 0.4526, Val Accuracy: 0.806\nval_loss_decreased from 0.4898 to 0.4526, saving_checkpoint for epoch 17\nIteration: 528, learning rate: 0.00962, Loss: 0.4830, Accuracy:0.781\nIteration: 529, learning rate: 0.00962, Loss: 0.5673, Accuracy:0.727\nIteration: 530, learning rate: 0.00962, Loss: 0.5939, Accuracy:0.680\nIteration: 531, learning rate: 0.00962, Loss: 0.5349, Accuracy:0.719\nIteration: 532, learning rate: 0.00962, Loss: 0.5354, Accuracy:0.711\nIteration: 533, learning rate: 0.00962, Loss: 0.5461, Accuracy:0.719\nIteration: 534, learning rate: 0.00962, Loss: 0.5965, Accuracy:0.656\nIteration: 535, learning rate: 0.00962, Loss: 0.5827, Accuracy:0.695\nIteration: 536, learning rate: 0.00962, Loss: 0.5462, Accuracy:0.766\nIteration: 537, learning rate: 0.00962, Loss: 0.4854, Accuracy:0.805\nIteration: 538, learning rate: 0.00962, Loss: 0.5810, Accuracy:0.656\nIteration: 539, learning rate: 0.00961, Loss: 0.5110, Accuracy:0.758\nIteration: 540, learning rate: 0.00961, Loss: 0.4969, Accuracy:0.773\nIteration: 541, learning rate: 0.00961, Loss: 0.5431, Accuracy:0.727\nIteration: 542, learning rate: 0.00961, Loss: 0.5686, Accuracy:0.680\nIteration: 543, learning rate: 0.00961, Loss: 0.5754, Accuracy:0.703\nIteration: 544, learning rate: 0.00961, Loss: 0.5437, Accuracy:0.750\nIteration: 545, learning rate: 0.00961, Loss: 0.5747, Accuracy:0.672\nIteration: 546, learning rate: 0.00961, Loss: 0.5445, Accuracy:0.711\nIteration: 547, learning rate: 0.00961, Loss: 0.5266, Accuracy:0.742\nIteration: 548, learning rate: 0.00961, Loss: 0.5589, Accuracy:0.734\nIteration: 549, learning rate: 0.00961, Loss: 0.4616, Accuracy:0.789\nIteration: 550, learning rate: 0.00961, Loss: 0.5900, Accuracy:0.734\nIteration: 551, learning rate: 0.00961, Loss: 0.6017, Accuracy:0.680\nIteration: 552, learning rate: 0.00961, Loss: 0.5002, Accuracy:0.750\nIteration: 553, learning rate: 0.00961, Loss: 0.6070, Accuracy:0.680\nIteration: 554, learning rate: 0.00960, Loss: 0.4988, Accuracy:0.766\nIteration: 555, learning rate: 0.00960, Loss: 0.5205, Accuracy:0.758\nIteration: 556, learning rate: 0.00960, Loss: 0.5267, Accuracy:0.703\nIteration: 557, learning rate: 0.00960, Loss: 0.5573, Accuracy:0.711\nIteration: 558, learning rate: 0.00960, Loss: 0.4680, Accuracy:0.796\nEpoch: 18, Loss: 0.5428, Accuracy:0.727, Val Loss: 0.4763, Val Accuracy: 0.788\nIteration: 559, learning rate: 0.00960, Loss: 0.4986, Accuracy:0.781\nIteration: 560, learning rate: 0.00960, Loss: 0.5400, Accuracy:0.672\nIteration: 561, learning rate: 0.00960, Loss: 0.5754, Accuracy:0.695\nIteration: 562, learning rate: 0.00960, Loss: 0.5487, Accuracy:0.680\nIteration: 563, learning rate: 0.00960, Loss: 0.5280, Accuracy:0.695\nIteration: 564, learning rate: 0.00960, Loss: 0.5581, Accuracy:0.727\nIteration: 565, learning rate: 0.00960, Loss: 0.6014, Accuracy:0.680\nIteration: 566, learning rate: 0.00960, Loss: 0.5532, Accuracy:0.742\nIteration: 567, learning rate: 0.00960, Loss: 0.5295, Accuracy:0.719\nIteration: 568, learning rate: 0.00959, Loss: 0.4995, Accuracy:0.742\nIteration: 569, learning rate: 0.00959, Loss: 0.4815, Accuracy:0.766\nIteration: 570, learning rate: 0.00959, Loss: 0.5329, Accuracy:0.680\nIteration: 571, learning rate: 0.00959, Loss: 0.5940, Accuracy:0.672\nIteration: 572, learning rate: 0.00959, Loss: 0.4809, Accuracy:0.805\nIteration: 573, learning rate: 0.00959, Loss: 0.5703, Accuracy:0.703\nIteration: 574, learning rate: 0.00959, Loss: 0.4745, Accuracy:0.766\nIteration: 575, learning rate: 0.00959, Loss: 0.4429, Accuracy:0.797\nIteration: 576, learning rate: 0.00959, Loss: 0.5351, Accuracy:0.781\nIteration: 577, learning rate: 0.00959, Loss: 0.5320, Accuracy:0.773\nIteration: 578, learning rate: 0.00959, Loss: 0.4844, Accuracy:0.742\nIteration: 579, learning rate: 0.00959, Loss: 0.5380, Accuracy:0.688\nIteration: 580, learning rate: 0.00959, Loss: 0.5181, Accuracy:0.766\nIteration: 581, learning rate: 0.00959, Loss: 0.4805, Accuracy:0.805\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 582, learning rate: 0.00959, Loss: 0.4969, Accuracy:0.742\nIteration: 583, learning rate: 0.00958, Loss: 0.5325, Accuracy:0.742\nIteration: 584, learning rate: 0.00958, Loss: 0.5415, Accuracy:0.695\nIteration: 585, learning rate: 0.00958, Loss: 0.5043, Accuracy:0.789\nIteration: 586, learning rate: 0.00958, Loss: 0.5002, Accuracy:0.734\nIteration: 587, learning rate: 0.00958, Loss: 0.5495, Accuracy:0.766\nIteration: 588, learning rate: 0.00958, Loss: 0.4495, Accuracy:0.867\nIteration: 589, learning rate: 0.00958, Loss: 0.5559, Accuracy:0.742\nEpoch: 19, Loss: 0.5235, Accuracy:0.740, Val Loss: 0.4705, Val Accuracy: 0.751\nIteration: 590, learning rate: 0.00958, Loss: 0.5025, Accuracy:0.758\nIteration: 591, learning rate: 0.00958, Loss: 0.5668, Accuracy:0.688\nIteration: 592, learning rate: 0.00958, Loss: 0.4587, Accuracy:0.766\nIteration: 593, learning rate: 0.00958, Loss: 0.4612, Accuracy:0.820\nIteration: 594, learning rate: 0.00958, Loss: 0.4903, Accuracy:0.781\nIteration: 595, learning rate: 0.00958, Loss: 0.5566, Accuracy:0.711\nIteration: 596, learning rate: 0.00958, Loss: 0.5120, Accuracy:0.727\nIteration: 597, learning rate: 0.00958, Loss: 0.4939, Accuracy:0.781\nIteration: 598, learning rate: 0.00957, Loss: 0.4351, Accuracy:0.805\nIteration: 599, learning rate: 0.00957, Loss: 0.4909, Accuracy:0.727\nIteration: 600, learning rate: 0.00957, Loss: 0.4607, Accuracy:0.758\nIteration: 601, learning rate: 0.00957, Loss: 0.4888, Accuracy:0.812\nIteration: 602, learning rate: 0.00957, Loss: 0.5747, Accuracy:0.672\nIteration: 603, learning rate: 0.00957, Loss: 0.5301, Accuracy:0.766\nIteration: 604, learning rate: 0.00957, Loss: 0.5444, Accuracy:0.758\nIteration: 605, learning rate: 0.00957, Loss: 0.5131, Accuracy:0.742\nIteration: 606, learning rate: 0.00957, Loss: 0.5159, Accuracy:0.703\nIteration: 607, learning rate: 0.00957, Loss: 0.4914, Accuracy:0.758\nIteration: 608, learning rate: 0.00957, Loss: 0.4991, Accuracy:0.750\nIteration: 609, learning rate: 0.00957, Loss: 0.5196, Accuracy:0.719\nIteration: 610, learning rate: 0.00957, Loss: 0.5316, Accuracy:0.727\nIteration: 611, learning rate: 0.00957, Loss: 0.6004, Accuracy:0.688\nIteration: 612, learning rate: 0.00956, Loss: 0.5139, Accuracy:0.711\nIteration: 613, learning rate: 0.00956, Loss: 0.4937, Accuracy:0.773\nIteration: 614, learning rate: 0.00956, Loss: 0.5358, Accuracy:0.727\nIteration: 615, learning rate: 0.00956, Loss: 0.4697, Accuracy:0.781\nIteration: 616, learning rate: 0.00956, Loss: 0.5487, Accuracy:0.750\nIteration: 617, learning rate: 0.00956, Loss: 0.4748, Accuracy:0.758\nIteration: 618, learning rate: 0.00956, Loss: 0.4986, Accuracy:0.781\nIteration: 619, learning rate: 0.00956, Loss: 0.5308, Accuracy:0.727\nIteration: 620, learning rate: 0.00956, Loss: 0.6157, Accuracy:0.731\nEpoch: 20, Loss: 0.5135, Accuracy:0.747, Val Loss: 0.4679, Val Accuracy: 0.763\nIteration: 621, learning rate: 0.00956, Loss: 0.5232, Accuracy:0.727\nIteration: 622, learning rate: 0.00956, Loss: 0.5343, Accuracy:0.734\nIteration: 623, learning rate: 0.00956, Loss: 0.5318, Accuracy:0.711\nIteration: 624, learning rate: 0.00956, Loss: 0.6131, Accuracy:0.711\nIteration: 625, learning rate: 0.00956, Loss: 0.5544, Accuracy:0.719\nIteration: 626, learning rate: 0.00956, Loss: 0.5432, Accuracy:0.711\nIteration: 627, learning rate: 0.00955, Loss: 0.5108, Accuracy:0.719\nIteration: 628, learning rate: 0.00955, Loss: 0.4727, Accuracy:0.789\nIteration: 629, learning rate: 0.00955, Loss: 0.5249, Accuracy:0.719\nIteration: 630, learning rate: 0.00955, Loss: 0.5087, Accuracy:0.742\nIteration: 631, learning rate: 0.00955, Loss: 0.5447, Accuracy:0.734\nIteration: 632, learning rate: 0.00955, Loss: 0.4790, Accuracy:0.750\nIteration: 633, learning rate: 0.00955, Loss: 0.5188, Accuracy:0.758\nIteration: 634, learning rate: 0.00955, Loss: 0.5417, Accuracy:0.727\nIteration: 635, learning rate: 0.00955, Loss: 0.4599, Accuracy:0.742\nIteration: 636, learning rate: 0.00955, Loss: 0.5024, Accuracy:0.742\nIteration: 637, learning rate: 0.00955, Loss: 0.5685, Accuracy:0.711\nIteration: 638, learning rate: 0.00955, Loss: 0.5635, Accuracy:0.734\nIteration: 639, learning rate: 0.00955, Loss: 0.5296, Accuracy:0.734\nIteration: 640, learning rate: 0.00955, Loss: 0.4910, Accuracy:0.773\nIteration: 641, learning rate: 0.00955, Loss: 0.5352, Accuracy:0.727\nIteration: 642, learning rate: 0.00954, Loss: 0.5347, Accuracy:0.688\nIteration: 643, learning rate: 0.00954, Loss: 0.5176, Accuracy:0.727\nIteration: 644, learning rate: 0.00954, Loss: 0.4865, Accuracy:0.781\nIteration: 645, learning rate: 0.00954, Loss: 0.5747, Accuracy:0.703\nIteration: 646, learning rate: 0.00954, Loss: 0.5641, Accuracy:0.711\nIteration: 647, learning rate: 0.00954, Loss: 0.4809, Accuracy:0.750\nIteration: 648, learning rate: 0.00954, Loss: 0.5921, Accuracy:0.680\nIteration: 649, learning rate: 0.00954, Loss: 0.4972, Accuracy:0.812\nIteration: 650, learning rate: 0.00954, Loss: 0.5950, Accuracy:0.680\nIteration: 651, learning rate: 0.00954, Loss: 0.4838, Accuracy:0.753\nEpoch: 21, Loss: 0.5283, Accuracy:0.732, Val Loss: 0.4606, Val Accuracy: 0.779\nIteration: 652, learning rate: 0.00954, Loss: 0.5142, Accuracy:0.734\nIteration: 653, learning rate: 0.00954, Loss: 0.4589, Accuracy:0.781\nIteration: 654, learning rate: 0.00954, Loss: 0.5601, Accuracy:0.703\nIteration: 655, learning rate: 0.00954, Loss: 0.5577, Accuracy:0.672\nIteration: 656, learning rate: 0.00954, Loss: 0.5368, Accuracy:0.711\nIteration: 657, learning rate: 0.00953, Loss: 0.5139, Accuracy:0.742\nIteration: 658, learning rate: 0.00953, Loss: 0.4814, Accuracy:0.758\nIteration: 659, learning rate: 0.00953, Loss: 0.4579, Accuracy:0.789\nIteration: 660, learning rate: 0.00953, Loss: 0.4690, Accuracy:0.789\nIteration: 661, learning rate: 0.00953, Loss: 0.4909, Accuracy:0.789\nIteration: 662, learning rate: 0.00953, Loss: 0.4716, Accuracy:0.766\nIteration: 663, learning rate: 0.00953, Loss: 0.5774, Accuracy:0.727\nIteration: 664, learning rate: 0.00953, Loss: 0.5522, Accuracy:0.719\nIteration: 665, learning rate: 0.00953, Loss: 0.5151, Accuracy:0.766\nIteration: 666, learning rate: 0.00953, Loss: 0.4638, Accuracy:0.781\nIteration: 667, learning rate: 0.00953, Loss: 0.5063, Accuracy:0.758\nIteration: 668, learning rate: 0.00953, Loss: 0.6078, Accuracy:0.688\nIteration: 669, learning rate: 0.00953, Loss: 0.5075, Accuracy:0.758\nIteration: 670, learning rate: 0.00953, Loss: 0.5232, Accuracy:0.742\nIteration: 671, learning rate: 0.00953, Loss: 0.4869, Accuracy:0.773\nIteration: 672, learning rate: 0.00952, Loss: 0.5168, Accuracy:0.727\nIteration: 673, learning rate: 0.00952, Loss: 0.5181, Accuracy:0.719\nIteration: 674, learning rate: 0.00952, Loss: 0.4646, Accuracy:0.805\nIteration: 675, learning rate: 0.00952, Loss: 0.4790, Accuracy:0.758\nIteration: 676, learning rate: 0.00952, Loss: 0.5776, Accuracy:0.734\nIteration: 677, learning rate: 0.00952, Loss: 0.5169, Accuracy:0.711\nIteration: 678, learning rate: 0.00952, Loss: 0.5929, Accuracy:0.703\nIteration: 679, learning rate: 0.00952, Loss: 0.4769, Accuracy:0.812\nIteration: 680, learning rate: 0.00952, Loss: 0.5300, Accuracy:0.742\nIteration: 681, learning rate: 0.00952, Loss: 0.4735, Accuracy:0.773\nIteration: 682, learning rate: 0.00952, Loss: 0.5660, Accuracy:0.667\nEpoch: 22, Loss: 0.5150, Accuracy:0.745, Val Loss: 0.4617, Val Accuracy: 0.771\nIteration: 683, learning rate: 0.00952, Loss: 0.4596, Accuracy:0.828\nIteration: 684, learning rate: 0.00952, Loss: 0.4775, Accuracy:0.781\nIteration: 685, learning rate: 0.00952, Loss: 0.5228, Accuracy:0.766\nIteration: 686, learning rate: 0.00952, Loss: 0.4680, Accuracy:0.781\nIteration: 687, learning rate: 0.00951, Loss: 0.4906, Accuracy:0.789\nIteration: 688, learning rate: 0.00951, Loss: 0.5398, Accuracy:0.750\nIteration: 689, learning rate: 0.00951, Loss: 0.5363, Accuracy:0.695\nIteration: 690, learning rate: 0.00951, Loss: 0.4277, Accuracy:0.781\nIteration: 691, learning rate: 0.00951, Loss: 0.4813, Accuracy:0.727\nIteration: 692, learning rate: 0.00951, Loss: 0.4721, Accuracy:0.781\nIteration: 693, learning rate: 0.00951, Loss: 0.5522, Accuracy:0.711\nIteration: 694, learning rate: 0.00951, Loss: 0.5359, Accuracy:0.727\nIteration: 695, learning rate: 0.00951, Loss: 0.4930, Accuracy:0.750\nIteration: 696, learning rate: 0.00951, Loss: 0.5255, Accuracy:0.688\nIteration: 697, learning rate: 0.00951, Loss: 0.5140, Accuracy:0.750\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 698, learning rate: 0.00951, Loss: 0.4334, Accuracy:0.836\nIteration: 699, learning rate: 0.00951, Loss: 0.5037, Accuracy:0.773\nIteration: 700, learning rate: 0.00951, Loss: 0.4889, Accuracy:0.766\nIteration: 701, learning rate: 0.00951, Loss: 0.4779, Accuracy:0.773\nIteration: 702, learning rate: 0.00950, Loss: 0.5226, Accuracy:0.742\nIteration: 703, learning rate: 0.00950, Loss: 0.4709, Accuracy:0.758\nIteration: 704, learning rate: 0.00950, Loss: 0.5729, Accuracy:0.727\nIteration: 705, learning rate: 0.00950, Loss: 0.5028, Accuracy:0.750\nIteration: 706, learning rate: 0.00950, Loss: 0.4773, Accuracy:0.797\nIteration: 707, learning rate: 0.00950, Loss: 0.4951, Accuracy:0.727\nIteration: 708, learning rate: 0.00950, Loss: 0.5274, Accuracy:0.742\nIteration: 709, learning rate: 0.00950, Loss: 0.3971, Accuracy:0.852\nIteration: 710, learning rate: 0.00950, Loss: 0.5498, Accuracy:0.664\nIteration: 711, learning rate: 0.00950, Loss: 0.4736, Accuracy:0.789\nIteration: 712, learning rate: 0.00950, Loss: 0.5070, Accuracy:0.766\nIteration: 713, learning rate: 0.00950, Loss: 0.4420, Accuracy:0.839\nEpoch: 23, Loss: 0.4948, Accuracy:0.761, Val Loss: 0.5026, Val Accuracy: 0.764\nIteration: 714, learning rate: 0.00950, Loss: 0.4546, Accuracy:0.812\nIteration: 715, learning rate: 0.00950, Loss: 0.4552, Accuracy:0.781\nIteration: 716, learning rate: 0.00950, Loss: 0.5736, Accuracy:0.664\nIteration: 717, learning rate: 0.00949, Loss: 0.4599, Accuracy:0.789\nIteration: 718, learning rate: 0.00949, Loss: 0.5270, Accuracy:0.711\nIteration: 719, learning rate: 0.00949, Loss: 0.5133, Accuracy:0.750\nIteration: 720, learning rate: 0.00949, Loss: 0.4942, Accuracy:0.766\nIteration: 721, learning rate: 0.00949, Loss: 0.4864, Accuracy:0.773\nIteration: 722, learning rate: 0.00949, Loss: 0.5115, Accuracy:0.773\nIteration: 723, learning rate: 0.00949, Loss: 0.4696, Accuracy:0.766\nIteration: 724, learning rate: 0.00949, Loss: 0.4816, Accuracy:0.758\nIteration: 725, learning rate: 0.00949, Loss: 0.5276, Accuracy:0.703\nIteration: 726, learning rate: 0.00949, Loss: 0.5161, Accuracy:0.727\nIteration: 727, learning rate: 0.00949, Loss: 0.5095, Accuracy:0.719\nIteration: 728, learning rate: 0.00949, Loss: 0.5118, Accuracy:0.758\nIteration: 729, learning rate: 0.00949, Loss: 0.5274, Accuracy:0.758\nIteration: 730, learning rate: 0.00949, Loss: 0.4940, Accuracy:0.797\nIteration: 731, learning rate: 0.00949, Loss: 0.5224, Accuracy:0.680\nIteration: 732, learning rate: 0.00948, Loss: 0.4475, Accuracy:0.805\nIteration: 733, learning rate: 0.00948, Loss: 0.4560, Accuracy:0.797\nIteration: 734, learning rate: 0.00948, Loss: 0.4878, Accuracy:0.773\nIteration: 735, learning rate: 0.00948, Loss: 0.5298, Accuracy:0.789\nIteration: 736, learning rate: 0.00948, Loss: 0.5512, Accuracy:0.703\nIteration: 737, learning rate: 0.00948, Loss: 0.5605, Accuracy:0.672\nIteration: 738, learning rate: 0.00948, Loss: 0.4641, Accuracy:0.766\nIteration: 739, learning rate: 0.00948, Loss: 0.5276, Accuracy:0.742\nIteration: 740, learning rate: 0.00948, Loss: 0.5303, Accuracy:0.750\nIteration: 741, learning rate: 0.00948, Loss: 0.4868, Accuracy:0.773\nIteration: 742, learning rate: 0.00948, Loss: 0.5346, Accuracy:0.750\nIteration: 743, learning rate: 0.00948, Loss: 0.4965, Accuracy:0.758\nIteration: 744, learning rate: 0.00948, Loss: 0.5703, Accuracy:0.688\nEpoch: 24, Loss: 0.5058, Accuracy:0.750, Val Loss: 0.4658, Val Accuracy: 0.765\nIteration: 745, learning rate: 0.00948, Loss: 0.5614, Accuracy:0.711\nIteration: 746, learning rate: 0.00948, Loss: 0.5955, Accuracy:0.641\nIteration: 747, learning rate: 0.00947, Loss: 0.4490, Accuracy:0.797\nIteration: 748, learning rate: 0.00947, Loss: 0.5040, Accuracy:0.758\nIteration: 749, learning rate: 0.00947, Loss: 0.4834, Accuracy:0.773\nIteration: 750, learning rate: 0.00947, Loss: 0.4960, Accuracy:0.758\nIteration: 751, learning rate: 0.00947, Loss: 0.5475, Accuracy:0.734\nIteration: 752, learning rate: 0.00947, Loss: 0.5021, Accuracy:0.766\nIteration: 753, learning rate: 0.00947, Loss: 0.5035, Accuracy:0.742\nIteration: 754, learning rate: 0.00947, Loss: 0.5426, Accuracy:0.727\nIteration: 755, learning rate: 0.00947, Loss: 0.5079, Accuracy:0.789\nIteration: 756, learning rate: 0.00947, Loss: 0.5207, Accuracy:0.734\nIteration: 757, learning rate: 0.00947, Loss: 0.4422, Accuracy:0.797\nIteration: 758, learning rate: 0.00947, Loss: 0.4772, Accuracy:0.789\nIteration: 759, learning rate: 0.00947, Loss: 0.4513, Accuracy:0.758\nIteration: 760, learning rate: 0.00947, Loss: 0.4758, Accuracy:0.781\nIteration: 761, learning rate: 0.00947, Loss: 0.4684, Accuracy:0.789\nIteration: 762, learning rate: 0.00946, Loss: 0.5509, Accuracy:0.734\nIteration: 763, learning rate: 0.00946, Loss: 0.4538, Accuracy:0.812\nIteration: 764, learning rate: 0.00946, Loss: 0.4992, Accuracy:0.758\nIteration: 765, learning rate: 0.00946, Loss: 0.4366, Accuracy:0.781\nIteration: 766, learning rate: 0.00946, Loss: 0.4913, Accuracy:0.789\nIteration: 767, learning rate: 0.00946, Loss: 0.4792, Accuracy:0.773\nIteration: 768, learning rate: 0.00946, Loss: 0.4684, Accuracy:0.789\nIteration: 769, learning rate: 0.00946, Loss: 0.4826, Accuracy:0.773\nIteration: 770, learning rate: 0.00946, Loss: 0.5964, Accuracy:0.633\nIteration: 771, learning rate: 0.00946, Loss: 0.5350, Accuracy:0.734\nIteration: 772, learning rate: 0.00946, Loss: 0.4763, Accuracy:0.773\nIteration: 773, learning rate: 0.00946, Loss: 0.4191, Accuracy:0.836\nIteration: 774, learning rate: 0.00946, Loss: 0.5495, Accuracy:0.711\nIteration: 775, learning rate: 0.00946, Loss: 0.5508, Accuracy:0.710\nEpoch: 25, Loss: 0.5006, Accuracy:0.757, Val Loss: 0.4797, Val Accuracy: 0.758\nIteration: 776, learning rate: 0.00946, Loss: 0.4557, Accuracy:0.789\nIteration: 777, learning rate: 0.00945, Loss: 0.4377, Accuracy:0.828\nIteration: 778, learning rate: 0.00945, Loss: 0.4363, Accuracy:0.789\nIteration: 779, learning rate: 0.00945, Loss: 0.5223, Accuracy:0.766\nIteration: 780, learning rate: 0.00945, Loss: 0.5530, Accuracy:0.719\nIteration: 781, learning rate: 0.00945, Loss: 0.4660, Accuracy:0.766\nIteration: 782, learning rate: 0.00945, Loss: 0.5225, Accuracy:0.734\nIteration: 783, learning rate: 0.00945, Loss: 0.5239, Accuracy:0.734\nIteration: 784, learning rate: 0.00945, Loss: 0.4979, Accuracy:0.750\nIteration: 785, learning rate: 0.00945, Loss: 0.5228, Accuracy:0.766\nIteration: 786, learning rate: 0.00945, Loss: 0.4008, Accuracy:0.805\nIteration: 787, learning rate: 0.00945, Loss: 0.4281, Accuracy:0.805\nIteration: 788, learning rate: 0.00945, Loss: 0.5223, Accuracy:0.695\nIteration: 789, learning rate: 0.00945, Loss: 0.4411, Accuracy:0.812\nIteration: 790, learning rate: 0.00945, Loss: 0.4450, Accuracy:0.820\nIteration: 791, learning rate: 0.00945, Loss: 0.5188, Accuracy:0.758\nIteration: 792, learning rate: 0.00945, Loss: 0.5033, Accuracy:0.727\nIteration: 793, learning rate: 0.00944, Loss: 0.4332, Accuracy:0.828\nIteration: 794, learning rate: 0.00944, Loss: 0.5301, Accuracy:0.734\nIteration: 795, learning rate: 0.00944, Loss: 0.4245, Accuracy:0.820\nIteration: 796, learning rate: 0.00944, Loss: 0.5089, Accuracy:0.734\nIteration: 797, learning rate: 0.00944, Loss: 0.4486, Accuracy:0.789\nIteration: 798, learning rate: 0.00944, Loss: 0.4511, Accuracy:0.766\nIteration: 799, learning rate: 0.00944, Loss: 0.4497, Accuracy:0.789\nIteration: 800, learning rate: 0.00944, Loss: 0.5277, Accuracy:0.734\nIteration: 801, learning rate: 0.00944, Loss: 0.4487, Accuracy:0.758\nIteration: 802, learning rate: 0.00944, Loss: 0.4976, Accuracy:0.750\nIteration: 803, learning rate: 0.00944, Loss: 0.4688, Accuracy:0.750\nIteration: 804, learning rate: 0.00944, Loss: 0.6109, Accuracy:0.703\nIteration: 805, learning rate: 0.00944, Loss: 0.4380, Accuracy:0.805\nIteration: 806, learning rate: 0.00944, Loss: 0.4546, Accuracy:0.742\nEpoch: 26, Loss: 0.4803, Accuracy:0.767, Val Loss: 0.4519, Val Accuracy: 0.793\nval_loss_decreased from 0.4526 to 0.4519, saving_checkpoint for epoch 26\nIteration: 807, learning rate: 0.00944, Loss: 0.5699, Accuracy:0.719\nIteration: 808, learning rate: 0.00943, Loss: 0.5627, Accuracy:0.742\nIteration: 809, learning rate: 0.00943, Loss: 0.5631, Accuracy:0.742\nIteration: 810, learning rate: 0.00943, Loss: 0.4740, Accuracy:0.773\nIteration: 811, learning rate: 0.00943, Loss: 0.5378, Accuracy:0.727\nIteration: 812, learning rate: 0.00943, Loss: 0.4414, Accuracy:0.781\nIteration: 813, learning rate: 0.00943, Loss: 0.3907, Accuracy:0.820\nIteration: 814, learning rate: 0.00943, Loss: 0.4776, Accuracy:0.773\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 815, learning rate: 0.00943, Loss: 0.5574, Accuracy:0.688\nIteration: 816, learning rate: 0.00943, Loss: 0.4849, Accuracy:0.773\nIteration: 817, learning rate: 0.00943, Loss: 0.5032, Accuracy:0.781\nIteration: 818, learning rate: 0.00943, Loss: 0.4746, Accuracy:0.766\nIteration: 819, learning rate: 0.00943, Loss: 0.5100, Accuracy:0.758\nIteration: 820, learning rate: 0.00943, Loss: 0.5090, Accuracy:0.758\nIteration: 821, learning rate: 0.00943, Loss: 0.4956, Accuracy:0.750\nIteration: 822, learning rate: 0.00943, Loss: 0.5134, Accuracy:0.781\nIteration: 823, learning rate: 0.00942, Loss: 0.4822, Accuracy:0.742\nIteration: 824, learning rate: 0.00942, Loss: 0.5103, Accuracy:0.734\nIteration: 825, learning rate: 0.00942, Loss: 0.4816, Accuracy:0.781\nIteration: 826, learning rate: 0.00942, Loss: 0.5418, Accuracy:0.695\nIteration: 827, learning rate: 0.00942, Loss: 0.4382, Accuracy:0.797\nIteration: 828, learning rate: 0.00942, Loss: 0.4385, Accuracy:0.805\nIteration: 829, learning rate: 0.00942, Loss: 0.4802, Accuracy:0.797\nIteration: 830, learning rate: 0.00942, Loss: 0.5120, Accuracy:0.734\nIteration: 831, learning rate: 0.00942, Loss: 0.4985, Accuracy:0.711\nIteration: 832, learning rate: 0.00942, Loss: 0.5094, Accuracy:0.750\nIteration: 833, learning rate: 0.00942, Loss: 0.6113, Accuracy:0.688\nIteration: 834, learning rate: 0.00942, Loss: 0.4953, Accuracy:0.758\nIteration: 835, learning rate: 0.00942, Loss: 0.4315, Accuracy:0.812\nIteration: 836, learning rate: 0.00942, Loss: 0.5066, Accuracy:0.789\nIteration: 837, learning rate: 0.00942, Loss: 0.4756, Accuracy:0.742\nEpoch: 27, Loss: 0.4993, Accuracy:0.757, Val Loss: 0.4444, Val Accuracy: 0.792\nval_loss_decreased from 0.4519 to 0.4444, saving_checkpoint for epoch 27\nIteration: 838, learning rate: 0.00941, Loss: 0.5310, Accuracy:0.711\nIteration: 839, learning rate: 0.00941, Loss: 0.4808, Accuracy:0.789\nIteration: 840, learning rate: 0.00941, Loss: 0.4946, Accuracy:0.766\nIteration: 841, learning rate: 0.00941, Loss: 0.4377, Accuracy:0.797\nIteration: 842, learning rate: 0.00941, Loss: 0.4886, Accuracy:0.766\nIteration: 843, learning rate: 0.00941, Loss: 0.4280, Accuracy:0.820\nIteration: 844, learning rate: 0.00941, Loss: 0.5113, Accuracy:0.734\nIteration: 845, learning rate: 0.00941, Loss: 0.5551, Accuracy:0.695\nIteration: 846, learning rate: 0.00941, Loss: 0.4281, Accuracy:0.820\nIteration: 847, learning rate: 0.00941, Loss: 0.4643, Accuracy:0.750\nIteration: 848, learning rate: 0.00941, Loss: 0.3966, Accuracy:0.820\nIteration: 849, learning rate: 0.00941, Loss: 0.4919, Accuracy:0.727\nIteration: 850, learning rate: 0.00941, Loss: 0.4462, Accuracy:0.766\nIteration: 851, learning rate: 0.00941, Loss: 0.5118, Accuracy:0.727\nIteration: 852, learning rate: 0.00941, Loss: 0.4951, Accuracy:0.727\nIteration: 853, learning rate: 0.00941, Loss: 0.5393, Accuracy:0.750\nIteration: 854, learning rate: 0.00940, Loss: 0.5713, Accuracy:0.672\nIteration: 855, learning rate: 0.00940, Loss: 0.4903, Accuracy:0.758\nIteration: 856, learning rate: 0.00940, Loss: 0.4672, Accuracy:0.789\nIteration: 857, learning rate: 0.00940, Loss: 0.4592, Accuracy:0.797\nIteration: 858, learning rate: 0.00940, Loss: 0.5435, Accuracy:0.695\nIteration: 859, learning rate: 0.00940, Loss: 0.4287, Accuracy:0.820\nIteration: 860, learning rate: 0.00940, Loss: 0.5736, Accuracy:0.711\nIteration: 861, learning rate: 0.00940, Loss: 0.5273, Accuracy:0.719\nIteration: 862, learning rate: 0.00940, Loss: 0.4554, Accuracy:0.773\nIteration: 863, learning rate: 0.00940, Loss: 0.4842, Accuracy:0.750\nIteration: 864, learning rate: 0.00940, Loss: 0.4863, Accuracy:0.758\nIteration: 865, learning rate: 0.00940, Loss: 0.4653, Accuracy:0.773\nIteration: 866, learning rate: 0.00940, Loss: 0.5614, Accuracy:0.734\nIteration: 867, learning rate: 0.00940, Loss: 0.4777, Accuracy:0.742\nIteration: 868, learning rate: 0.00940, Loss: 0.4297, Accuracy:0.774\nEpoch: 28, Loss: 0.4878, Accuracy:0.756, Val Loss: 0.4193, Val Accuracy: 0.796\nval_loss_decreased from 0.4444 to 0.4193, saving_checkpoint for epoch 28\nIteration: 869, learning rate: 0.00939, Loss: 0.5397, Accuracy:0.711\nIteration: 870, learning rate: 0.00939, Loss: 0.5100, Accuracy:0.742\nIteration: 871, learning rate: 0.00939, Loss: 0.4846, Accuracy:0.758\nIteration: 872, learning rate: 0.00939, Loss: 0.4973, Accuracy:0.766\nIteration: 873, learning rate: 0.00939, Loss: 0.3882, Accuracy:0.867\nIteration: 874, learning rate: 0.00939, Loss: 0.4664, Accuracy:0.789\nIteration: 875, learning rate: 0.00939, Loss: 0.4403, Accuracy:0.805\nIteration: 876, learning rate: 0.00939, Loss: 0.4375, Accuracy:0.781\nIteration: 877, learning rate: 0.00939, Loss: 0.5493, Accuracy:0.727\nIteration: 878, learning rate: 0.00939, Loss: 0.4695, Accuracy:0.781\nIteration: 879, learning rate: 0.00939, Loss: 0.5602, Accuracy:0.734\nIteration: 880, learning rate: 0.00939, Loss: 0.5595, Accuracy:0.711\nIteration: 881, learning rate: 0.00939, Loss: 0.5324, Accuracy:0.766\nIteration: 882, learning rate: 0.00939, Loss: 0.5119, Accuracy:0.742\nIteration: 883, learning rate: 0.00939, Loss: 0.4919, Accuracy:0.773\nIteration: 884, learning rate: 0.00939, Loss: 0.4828, Accuracy:0.820\nIteration: 885, learning rate: 0.00938, Loss: 0.5157, Accuracy:0.766\nIteration: 886, learning rate: 0.00938, Loss: 0.4646, Accuracy:0.797\nIteration: 887, learning rate: 0.00938, Loss: 0.5160, Accuracy:0.758\nIteration: 888, learning rate: 0.00938, Loss: 0.4398, Accuracy:0.812\nIteration: 889, learning rate: 0.00938, Loss: 0.4483, Accuracy:0.805\nIteration: 890, learning rate: 0.00938, Loss: 0.5436, Accuracy:0.734\nIteration: 891, learning rate: 0.00938, Loss: 0.5020, Accuracy:0.766\nIteration: 892, learning rate: 0.00938, Loss: 0.4644, Accuracy:0.758\nIteration: 893, learning rate: 0.00938, Loss: 0.5203, Accuracy:0.766\nIteration: 894, learning rate: 0.00938, Loss: 0.4812, Accuracy:0.734\nIteration: 895, learning rate: 0.00938, Loss: 0.5086, Accuracy:0.766\nIteration: 896, learning rate: 0.00938, Loss: 0.4132, Accuracy:0.812\nIteration: 897, learning rate: 0.00938, Loss: 0.4789, Accuracy:0.805\nIteration: 898, learning rate: 0.00938, Loss: 0.4911, Accuracy:0.734\nIteration: 899, learning rate: 0.00938, Loss: 0.4797, Accuracy:0.774\nEpoch: 29, Loss: 0.4900, Accuracy:0.770, Val Loss: 0.4645, Val Accuracy: 0.776\nIteration: 900, learning rate: 0.00937, Loss: 0.5439, Accuracy:0.742\nIteration: 901, learning rate: 0.00937, Loss: 0.4873, Accuracy:0.797\nIteration: 902, learning rate: 0.00937, Loss: 0.5460, Accuracy:0.703\nIteration: 903, learning rate: 0.00937, Loss: 0.4896, Accuracy:0.758\nIteration: 904, learning rate: 0.00937, Loss: 0.6110, Accuracy:0.664\nIteration: 905, learning rate: 0.00937, Loss: 0.5079, Accuracy:0.750\nIteration: 906, learning rate: 0.00937, Loss: 0.5252, Accuracy:0.719\nIteration: 907, learning rate: 0.00937, Loss: 0.4519, Accuracy:0.766\nIteration: 908, learning rate: 0.00937, Loss: 0.4897, Accuracy:0.750\nIteration: 909, learning rate: 0.00937, Loss: 0.4928, Accuracy:0.758\nIteration: 910, learning rate: 0.00937, Loss: 0.4433, Accuracy:0.797\nIteration: 911, learning rate: 0.00937, Loss: 0.5415, Accuracy:0.719\nIteration: 912, learning rate: 0.00937, Loss: 0.5175, Accuracy:0.727\nIteration: 913, learning rate: 0.00937, Loss: 0.4918, Accuracy:0.742\nIteration: 914, learning rate: 0.00937, Loss: 0.4797, Accuracy:0.773\nIteration: 915, learning rate: 0.00937, Loss: 0.4897, Accuracy:0.773\nIteration: 916, learning rate: 0.00936, Loss: 0.4390, Accuracy:0.805\nIteration: 917, learning rate: 0.00936, Loss: 0.4767, Accuracy:0.805\nIteration: 918, learning rate: 0.00936, Loss: 0.5544, Accuracy:0.703\nIteration: 919, learning rate: 0.00936, Loss: 0.5049, Accuracy:0.695\nIteration: 920, learning rate: 0.00936, Loss: 0.4456, Accuracy:0.797\nIteration: 921, learning rate: 0.00936, Loss: 0.4778, Accuracy:0.797\nIteration: 922, learning rate: 0.00936, Loss: 0.3933, Accuracy:0.859\nIteration: 923, learning rate: 0.00936, Loss: 0.5136, Accuracy:0.711\nIteration: 924, learning rate: 0.00936, Loss: 0.4539, Accuracy:0.797\nIteration: 925, learning rate: 0.00936, Loss: 0.3920, Accuracy:0.836\nIteration: 926, learning rate: 0.00936, Loss: 0.5302, Accuracy:0.742\nIteration: 927, learning rate: 0.00936, Loss: 0.4765, Accuracy:0.766\nIteration: 928, learning rate: 0.00936, Loss: 0.4641, Accuracy:0.758\nIteration: 929, learning rate: 0.00936, Loss: 0.5489, Accuracy:0.711\nIteration: 930, learning rate: 0.00936, Loss: 0.4297, Accuracy:0.806\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 30, Loss: 0.4906, Accuracy:0.759, Val Loss: 0.4570, Val Accuracy: 0.769\nIteration: 931, learning rate: 0.00935, Loss: 0.5147, Accuracy:0.719\nIteration: 932, learning rate: 0.00935, Loss: 0.5303, Accuracy:0.734\nIteration: 933, learning rate: 0.00935, Loss: 0.5282, Accuracy:0.703\nIteration: 934, learning rate: 0.00935, Loss: 0.4153, Accuracy:0.828\nIteration: 935, learning rate: 0.00935, Loss: 0.4479, Accuracy:0.773\nIteration: 936, learning rate: 0.00935, Loss: 0.4900, Accuracy:0.758\nIteration: 937, learning rate: 0.00935, Loss: 0.5139, Accuracy:0.766\nIteration: 938, learning rate: 0.00935, Loss: 0.4683, Accuracy:0.797\nIteration: 939, learning rate: 0.00935, Loss: 0.4829, Accuracy:0.773\nIteration: 940, learning rate: 0.00935, Loss: 0.3682, Accuracy:0.867\nIteration: 941, learning rate: 0.00935, Loss: 0.4744, Accuracy:0.781\nIteration: 942, learning rate: 0.00935, Loss: 0.5173, Accuracy:0.742\nIteration: 943, learning rate: 0.00935, Loss: 0.4614, Accuracy:0.758\nIteration: 944, learning rate: 0.00935, Loss: 0.4235, Accuracy:0.805\nIteration: 945, learning rate: 0.00935, Loss: 0.4172, Accuracy:0.805\nIteration: 946, learning rate: 0.00935, Loss: 0.4852, Accuracy:0.750\nIteration: 947, learning rate: 0.00934, Loss: 0.4583, Accuracy:0.773\nIteration: 948, learning rate: 0.00934, Loss: 0.3606, Accuracy:0.852\nIteration: 949, learning rate: 0.00934, Loss: 0.5834, Accuracy:0.719\nIteration: 950, learning rate: 0.00934, Loss: 0.5346, Accuracy:0.727\nIteration: 951, learning rate: 0.00934, Loss: 0.4780, Accuracy:0.711\nIteration: 952, learning rate: 0.00934, Loss: 0.5145, Accuracy:0.750\nIteration: 953, learning rate: 0.00934, Loss: 0.5268, Accuracy:0.789\nIteration: 954, learning rate: 0.00934, Loss: 0.5071, Accuracy:0.773\nIteration: 955, learning rate: 0.00934, Loss: 0.4179, Accuracy:0.812\nIteration: 956, learning rate: 0.00934, Loss: 0.4239, Accuracy:0.820\nIteration: 957, learning rate: 0.00934, Loss: 0.4428, Accuracy:0.789\nIteration: 958, learning rate: 0.00934, Loss: 0.5044, Accuracy:0.758\nIteration: 959, learning rate: 0.00934, Loss: 0.4304, Accuracy:0.781\nIteration: 960, learning rate: 0.00934, Loss: 0.4474, Accuracy:0.781\nIteration: 961, learning rate: 0.00934, Loss: 0.5353, Accuracy:0.742\nEpoch: 31, Loss: 0.4743, Accuracy:0.772, Val Loss: 0.4334, Val Accuracy: 0.798\nIteration: 962, learning rate: 0.00933, Loss: 0.5706, Accuracy:0.703\nIteration: 963, learning rate: 0.00933, Loss: 0.4176, Accuracy:0.820\nIteration: 964, learning rate: 0.00933, Loss: 0.5158, Accuracy:0.719\nIteration: 965, learning rate: 0.00933, Loss: 0.4136, Accuracy:0.820\nIteration: 966, learning rate: 0.00933, Loss: 0.4717, Accuracy:0.781\nIteration: 967, learning rate: 0.00933, Loss: 0.4932, Accuracy:0.758\nIteration: 968, learning rate: 0.00933, Loss: 0.4895, Accuracy:0.727\nIteration: 969, learning rate: 0.00933, Loss: 0.4196, Accuracy:0.797\nIteration: 970, learning rate: 0.00933, Loss: 0.4911, Accuracy:0.766\nIteration: 971, learning rate: 0.00933, Loss: 0.4568, Accuracy:0.789\nIteration: 972, learning rate: 0.00933, Loss: 0.5169, Accuracy:0.773\nIteration: 973, learning rate: 0.00933, Loss: 0.4988, Accuracy:0.766\nIteration: 974, learning rate: 0.00933, Loss: 0.4928, Accuracy:0.766\nIteration: 975, learning rate: 0.00933, Loss: 0.4478, Accuracy:0.812\nIteration: 976, learning rate: 0.00933, Loss: 0.5249, Accuracy:0.719\nIteration: 977, learning rate: 0.00933, Loss: 0.5128, Accuracy:0.758\nIteration: 978, learning rate: 0.00932, Loss: 0.4932, Accuracy:0.734\nIteration: 979, learning rate: 0.00932, Loss: 0.4196, Accuracy:0.766\nIteration: 980, learning rate: 0.00932, Loss: 0.5088, Accuracy:0.711\nIteration: 981, learning rate: 0.00932, Loss: 0.5394, Accuracy:0.719\nIteration: 982, learning rate: 0.00932, Loss: 0.4254, Accuracy:0.812\nIteration: 983, learning rate: 0.00932, Loss: 0.4117, Accuracy:0.781\nIteration: 984, learning rate: 0.00932, Loss: 0.4169, Accuracy:0.828\nIteration: 985, learning rate: 0.00932, Loss: 0.5031, Accuracy:0.750\nIteration: 986, learning rate: 0.00932, Loss: 0.5397, Accuracy:0.727\nIteration: 987, learning rate: 0.00932, Loss: 0.4909, Accuracy:0.766\nIteration: 988, learning rate: 0.00932, Loss: 0.5741, Accuracy:0.734\nIteration: 989, learning rate: 0.00932, Loss: 0.4769, Accuracy:0.773\nIteration: 990, learning rate: 0.00932, Loss: 0.4447, Accuracy:0.773\nIteration: 991, learning rate: 0.00932, Loss: 0.4540, Accuracy:0.789\nIteration: 992, learning rate: 0.00932, Loss: 0.4236, Accuracy:0.828\nEpoch: 32, Loss: 0.4792, Accuracy:0.767, Val Loss: 0.4375, Val Accuracy: 0.788\nIteration: 993, learning rate: 0.00932, Loss: 0.4169, Accuracy:0.828\nIteration: 994, learning rate: 0.00931, Loss: 0.5472, Accuracy:0.711\nIteration: 995, learning rate: 0.00931, Loss: 0.5187, Accuracy:0.766\nIteration: 996, learning rate: 0.00931, Loss: 0.4841, Accuracy:0.734\nIteration: 997, learning rate: 0.00931, Loss: 0.4708, Accuracy:0.758\nIteration: 998, learning rate: 0.00931, Loss: 0.4874, Accuracy:0.734\nIteration: 999, learning rate: 0.00931, Loss: 0.4768, Accuracy:0.797\nIteration: 1000, learning rate: 0.00931, Loss: 0.4102, Accuracy:0.820\nIteration: 1001, learning rate: 0.00931, Loss: 0.4648, Accuracy:0.781\nIteration: 1002, learning rate: 0.00931, Loss: 0.4532, Accuracy:0.797\nIteration: 1003, learning rate: 0.00931, Loss: 0.4347, Accuracy:0.812\nIteration: 1004, learning rate: 0.00931, Loss: 0.4689, Accuracy:0.758\nIteration: 1005, learning rate: 0.00931, Loss: 0.4990, Accuracy:0.766\nIteration: 1006, learning rate: 0.00931, Loss: 0.4111, Accuracy:0.852\nIteration: 1007, learning rate: 0.00931, Loss: 0.4460, Accuracy:0.844\nIteration: 1008, learning rate: 0.00931, Loss: 0.4566, Accuracy:0.797\nIteration: 1009, learning rate: 0.00931, Loss: 0.5210, Accuracy:0.766\nIteration: 1010, learning rate: 0.00930, Loss: 0.4125, Accuracy:0.781\nIteration: 1011, learning rate: 0.00930, Loss: 0.4359, Accuracy:0.797\nIteration: 1012, learning rate: 0.00930, Loss: 0.4442, Accuracy:0.812\nIteration: 1013, learning rate: 0.00930, Loss: 0.5018, Accuracy:0.766\nIteration: 1014, learning rate: 0.00930, Loss: 0.4473, Accuracy:0.781\nIteration: 1015, learning rate: 0.00930, Loss: 0.5061, Accuracy:0.719\nIteration: 1016, learning rate: 0.00930, Loss: 0.4219, Accuracy:0.805\nIteration: 1017, learning rate: 0.00930, Loss: 0.4953, Accuracy:0.750\nIteration: 1018, learning rate: 0.00930, Loss: 0.4503, Accuracy:0.812\nIteration: 1019, learning rate: 0.00930, Loss: 0.5567, Accuracy:0.742\nIteration: 1020, learning rate: 0.00930, Loss: 0.4648, Accuracy:0.781\nIteration: 1021, learning rate: 0.00930, Loss: 0.5031, Accuracy:0.781\nIteration: 1022, learning rate: 0.00930, Loss: 0.4613, Accuracy:0.781\nIteration: 1023, learning rate: 0.00930, Loss: 0.4943, Accuracy:0.763\nEpoch: 33, Loss: 0.4698, Accuracy:0.780, Val Loss: 0.3917, Val Accuracy: 0.823\nval_loss_decreased from 0.4193 to 0.3917, saving_checkpoint for epoch 33\nIteration: 1024, learning rate: 0.00930, Loss: 0.4763, Accuracy:0.773\nIteration: 1025, learning rate: 0.00929, Loss: 0.4735, Accuracy:0.781\nIteration: 1026, learning rate: 0.00929, Loss: 0.4826, Accuracy:0.766\nIteration: 1027, learning rate: 0.00929, Loss: 0.5074, Accuracy:0.742\nIteration: 1028, learning rate: 0.00929, Loss: 0.4382, Accuracy:0.828\nIteration: 1029, learning rate: 0.00929, Loss: 0.4529, Accuracy:0.797\nIteration: 1030, learning rate: 0.00929, Loss: 0.4442, Accuracy:0.828\nIteration: 1031, learning rate: 0.00929, Loss: 0.4631, Accuracy:0.781\nIteration: 1032, learning rate: 0.00929, Loss: 0.3972, Accuracy:0.812\nIteration: 1033, learning rate: 0.00929, Loss: 0.4457, Accuracy:0.797\nIteration: 1034, learning rate: 0.00929, Loss: 0.5430, Accuracy:0.734\nIteration: 1035, learning rate: 0.00929, Loss: 0.5479, Accuracy:0.758\nIteration: 1036, learning rate: 0.00929, Loss: 0.4225, Accuracy:0.828\nIteration: 1037, learning rate: 0.00929, Loss: 0.4481, Accuracy:0.750\nIteration: 1038, learning rate: 0.00929, Loss: 0.4698, Accuracy:0.781\nIteration: 1039, learning rate: 0.00929, Loss: 0.4388, Accuracy:0.820\nIteration: 1040, learning rate: 0.00929, Loss: 0.4760, Accuracy:0.805\nIteration: 1041, learning rate: 0.00928, Loss: 0.4721, Accuracy:0.773\nIteration: 1042, learning rate: 0.00928, Loss: 0.5715, Accuracy:0.727\nIteration: 1043, learning rate: 0.00928, Loss: 0.4635, Accuracy:0.766\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1044, learning rate: 0.00928, Loss: 0.4712, Accuracy:0.758\nIteration: 1045, learning rate: 0.00928, Loss: 0.5073, Accuracy:0.766\nIteration: 1046, learning rate: 0.00928, Loss: 0.4578, Accuracy:0.758\nIteration: 1047, learning rate: 0.00928, Loss: 0.4075, Accuracy:0.820\nIteration: 1048, learning rate: 0.00928, Loss: 0.4394, Accuracy:0.844\nIteration: 1049, learning rate: 0.00928, Loss: 0.4758, Accuracy:0.758\nIteration: 1050, learning rate: 0.00928, Loss: 0.4281, Accuracy:0.781\nIteration: 1051, learning rate: 0.00928, Loss: 0.4739, Accuracy:0.797\nIteration: 1052, learning rate: 0.00928, Loss: 0.4751, Accuracy:0.703\nIteration: 1053, learning rate: 0.00928, Loss: 0.4686, Accuracy:0.773\nIteration: 1054, learning rate: 0.00928, Loss: 0.4664, Accuracy:0.774\nEpoch: 34, Loss: 0.4679, Accuracy:0.780, Val Loss: 0.4356, Val Accuracy: 0.772\nIteration: 1055, learning rate: 0.00928, Loss: 0.5552, Accuracy:0.719\nIteration: 1056, learning rate: 0.00928, Loss: 0.4143, Accuracy:0.805\nIteration: 1057, learning rate: 0.00927, Loss: 0.4407, Accuracy:0.805\nIteration: 1058, learning rate: 0.00927, Loss: 0.4937, Accuracy:0.766\nIteration: 1059, learning rate: 0.00927, Loss: 0.4621, Accuracy:0.789\nIteration: 1060, learning rate: 0.00927, Loss: 0.5370, Accuracy:0.703\nIteration: 1061, learning rate: 0.00927, Loss: 0.4532, Accuracy:0.781\nIteration: 1062, learning rate: 0.00927, Loss: 0.4248, Accuracy:0.781\nIteration: 1063, learning rate: 0.00927, Loss: 0.5823, Accuracy:0.680\nIteration: 1064, learning rate: 0.00927, Loss: 0.5300, Accuracy:0.750\nIteration: 1065, learning rate: 0.00927, Loss: 0.4823, Accuracy:0.781\nIteration: 1066, learning rate: 0.00927, Loss: 0.4580, Accuracy:0.781\nIteration: 1067, learning rate: 0.00927, Loss: 0.4061, Accuracy:0.828\nIteration: 1068, learning rate: 0.00927, Loss: 0.4355, Accuracy:0.812\nIteration: 1069, learning rate: 0.00927, Loss: 0.3764, Accuracy:0.867\nIteration: 1070, learning rate: 0.00927, Loss: 0.5419, Accuracy:0.711\nIteration: 1071, learning rate: 0.00927, Loss: 0.4007, Accuracy:0.836\nIteration: 1072, learning rate: 0.00927, Loss: 0.4060, Accuracy:0.812\nIteration: 1073, learning rate: 0.00926, Loss: 0.4891, Accuracy:0.805\nIteration: 1074, learning rate: 0.00926, Loss: 0.4439, Accuracy:0.797\nIteration: 1075, learning rate: 0.00926, Loss: 0.4448, Accuracy:0.812\nIteration: 1076, learning rate: 0.00926, Loss: 0.4519, Accuracy:0.781\nIteration: 1077, learning rate: 0.00926, Loss: 0.5117, Accuracy:0.758\nIteration: 1078, learning rate: 0.00926, Loss: 0.4675, Accuracy:0.766\nIteration: 1079, learning rate: 0.00926, Loss: 0.5150, Accuracy:0.727\nIteration: 1080, learning rate: 0.00926, Loss: 0.4554, Accuracy:0.797\nIteration: 1081, learning rate: 0.00926, Loss: 0.4379, Accuracy:0.805\nIteration: 1082, learning rate: 0.00926, Loss: 0.4588, Accuracy:0.781\nIteration: 1083, learning rate: 0.00926, Loss: 0.5495, Accuracy:0.703\nIteration: 1084, learning rate: 0.00926, Loss: 0.4636, Accuracy:0.789\nIteration: 1085, learning rate: 0.00926, Loss: 0.4746, Accuracy:0.742\nEpoch: 35, Loss: 0.4698, Accuracy:0.776, Val Loss: 0.5083, Val Accuracy: 0.778\nIteration: 1086, learning rate: 0.00926, Loss: 0.4675, Accuracy:0.781\nIteration: 1087, learning rate: 0.00926, Loss: 0.4575, Accuracy:0.797\nIteration: 1088, learning rate: 0.00926, Loss: 0.4700, Accuracy:0.773\nIteration: 1089, learning rate: 0.00925, Loss: 0.4079, Accuracy:0.789\nIteration: 1090, learning rate: 0.00925, Loss: 0.4613, Accuracy:0.766\nIteration: 1091, learning rate: 0.00925, Loss: 0.4983, Accuracy:0.773\nIteration: 1092, learning rate: 0.00925, Loss: 0.5096, Accuracy:0.711\nIteration: 1093, learning rate: 0.00925, Loss: 0.4043, Accuracy:0.805\nIteration: 1094, learning rate: 0.00925, Loss: 0.4761, Accuracy:0.758\nIteration: 1095, learning rate: 0.00925, Loss: 0.4449, Accuracy:0.812\nIteration: 1096, learning rate: 0.00925, Loss: 0.4873, Accuracy:0.766\nIteration: 1097, learning rate: 0.00925, Loss: 0.4110, Accuracy:0.820\nIteration: 1098, learning rate: 0.00925, Loss: 0.4723, Accuracy:0.797\nIteration: 1099, learning rate: 0.00925, Loss: 0.4718, Accuracy:0.773\nIteration: 1100, learning rate: 0.00925, Loss: 0.4909, Accuracy:0.766\nIteration: 1101, learning rate: 0.00925, Loss: 0.4499, Accuracy:0.805\nIteration: 1102, learning rate: 0.00925, Loss: 0.4730, Accuracy:0.750\nIteration: 1103, learning rate: 0.00925, Loss: 0.3993, Accuracy:0.828\nIteration: 1104, learning rate: 0.00925, Loss: 0.4365, Accuracy:0.766\nIteration: 1105, learning rate: 0.00924, Loss: 0.4352, Accuracy:0.820\nIteration: 1106, learning rate: 0.00924, Loss: 0.5285, Accuracy:0.703\nIteration: 1107, learning rate: 0.00924, Loss: 0.4814, Accuracy:0.797\nIteration: 1108, learning rate: 0.00924, Loss: 0.4295, Accuracy:0.781\nIteration: 1109, learning rate: 0.00924, Loss: 0.5306, Accuracy:0.742\nIteration: 1110, learning rate: 0.00924, Loss: 0.4569, Accuracy:0.781\nIteration: 1111, learning rate: 0.00924, Loss: 0.3944, Accuracy:0.828\nIteration: 1112, learning rate: 0.00924, Loss: 0.4065, Accuracy:0.836\nIteration: 1113, learning rate: 0.00924, Loss: 0.4240, Accuracy:0.859\nIteration: 1114, learning rate: 0.00924, Loss: 0.4799, Accuracy:0.758\nIteration: 1115, learning rate: 0.00924, Loss: 0.4616, Accuracy:0.750\nIteration: 1116, learning rate: 0.00924, Loss: 0.5556, Accuracy:0.731\nEpoch: 36, Loss: 0.4604, Accuracy:0.781, Val Loss: 0.4537, Val Accuracy: 0.785\nIteration: 1117, learning rate: 0.00924, Loss: 0.4864, Accuracy:0.742\nIteration: 1118, learning rate: 0.00924, Loss: 0.3927, Accuracy:0.836\nIteration: 1119, learning rate: 0.00924, Loss: 0.4302, Accuracy:0.805\nIteration: 1120, learning rate: 0.00924, Loss: 0.4128, Accuracy:0.844\nIteration: 1121, learning rate: 0.00923, Loss: 0.5216, Accuracy:0.742\nIteration: 1122, learning rate: 0.00923, Loss: 0.4742, Accuracy:0.773\nIteration: 1123, learning rate: 0.00923, Loss: 0.5066, Accuracy:0.750\nIteration: 1124, learning rate: 0.00923, Loss: 0.4847, Accuracy:0.797\nIteration: 1125, learning rate: 0.00923, Loss: 0.4721, Accuracy:0.758\nIteration: 1126, learning rate: 0.00923, Loss: 0.4530, Accuracy:0.789\nIteration: 1127, learning rate: 0.00923, Loss: 0.5074, Accuracy:0.727\nIteration: 1128, learning rate: 0.00923, Loss: 0.4423, Accuracy:0.773\nIteration: 1129, learning rate: 0.00923, Loss: 0.5180, Accuracy:0.758\nIteration: 1130, learning rate: 0.00923, Loss: 0.4290, Accuracy:0.828\nIteration: 1131, learning rate: 0.00923, Loss: 0.5237, Accuracy:0.727\nIteration: 1132, learning rate: 0.00923, Loss: 0.4983, Accuracy:0.766\nIteration: 1133, learning rate: 0.00923, Loss: 0.4348, Accuracy:0.766\nIteration: 1134, learning rate: 0.00923, Loss: 0.5117, Accuracy:0.734\nIteration: 1135, learning rate: 0.00923, Loss: 0.5740, Accuracy:0.680\nIteration: 1136, learning rate: 0.00923, Loss: 0.4001, Accuracy:0.812\nIteration: 1137, learning rate: 0.00922, Loss: 0.4276, Accuracy:0.828\nIteration: 1138, learning rate: 0.00922, Loss: 0.4518, Accuracy:0.773\nIteration: 1139, learning rate: 0.00922, Loss: 0.4798, Accuracy:0.805\nIteration: 1140, learning rate: 0.00922, Loss: 0.4611, Accuracy:0.789\nIteration: 1141, learning rate: 0.00922, Loss: 0.4538, Accuracy:0.781\nIteration: 1142, learning rate: 0.00922, Loss: 0.3963, Accuracy:0.828\nIteration: 1143, learning rate: 0.00922, Loss: 0.4197, Accuracy:0.828\nIteration: 1144, learning rate: 0.00922, Loss: 0.4133, Accuracy:0.828\nIteration: 1145, learning rate: 0.00922, Loss: 0.5079, Accuracy:0.742\nIteration: 1146, learning rate: 0.00922, Loss: 0.4204, Accuracy:0.828\nIteration: 1147, learning rate: 0.00922, Loss: 0.5638, Accuracy:0.720\nEpoch: 37, Loss: 0.4667, Accuracy:0.779, Val Loss: 0.4565, Val Accuracy: 0.783\nIteration: 1148, learning rate: 0.00922, Loss: 0.4832, Accuracy:0.781\nIteration: 1149, learning rate: 0.00922, Loss: 0.4613, Accuracy:0.766\nIteration: 1150, learning rate: 0.00922, Loss: 0.4380, Accuracy:0.805\nIteration: 1151, learning rate: 0.00922, Loss: 0.3549, Accuracy:0.836\nIteration: 1152, learning rate: 0.00922, Loss: 0.4500, Accuracy:0.789\nIteration: 1153, learning rate: 0.00921, Loss: 0.4477, Accuracy:0.781\nIteration: 1154, learning rate: 0.00921, Loss: 0.5409, Accuracy:0.789\nIteration: 1155, learning rate: 0.00921, Loss: 0.4870, Accuracy:0.797\nIteration: 1156, learning rate: 0.00921, Loss: 0.5008, Accuracy:0.758\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1157, learning rate: 0.00921, Loss: 0.4481, Accuracy:0.797\nIteration: 1158, learning rate: 0.00921, Loss: 0.4523, Accuracy:0.805\nIteration: 1159, learning rate: 0.00921, Loss: 0.4818, Accuracy:0.734\nIteration: 1160, learning rate: 0.00921, Loss: 0.4405, Accuracy:0.812\nIteration: 1161, learning rate: 0.00921, Loss: 0.4075, Accuracy:0.812\nIteration: 1162, learning rate: 0.00921, Loss: 0.4723, Accuracy:0.805\nIteration: 1163, learning rate: 0.00921, Loss: 0.4343, Accuracy:0.766\nIteration: 1164, learning rate: 0.00921, Loss: 0.3939, Accuracy:0.812\nIteration: 1165, learning rate: 0.00921, Loss: 0.3610, Accuracy:0.867\nIteration: 1166, learning rate: 0.00921, Loss: 0.5100, Accuracy:0.781\nIteration: 1167, learning rate: 0.00921, Loss: 0.4581, Accuracy:0.773\nIteration: 1168, learning rate: 0.00921, Loss: 0.4687, Accuracy:0.781\nIteration: 1169, learning rate: 0.00920, Loss: 0.4370, Accuracy:0.797\nIteration: 1170, learning rate: 0.00920, Loss: 0.4086, Accuracy:0.836\nIteration: 1171, learning rate: 0.00920, Loss: 0.5085, Accuracy:0.727\nIteration: 1172, learning rate: 0.00920, Loss: 0.4575, Accuracy:0.773\nIteration: 1173, learning rate: 0.00920, Loss: 0.3636, Accuracy:0.859\nIteration: 1174, learning rate: 0.00920, Loss: 0.4899, Accuracy:0.766\nIteration: 1175, learning rate: 0.00920, Loss: 0.4114, Accuracy:0.812\nIteration: 1176, learning rate: 0.00920, Loss: 0.4514, Accuracy:0.750\nIteration: 1177, learning rate: 0.00920, Loss: 0.4406, Accuracy:0.773\nIteration: 1178, learning rate: 0.00920, Loss: 0.4374, Accuracy:0.753\nEpoch: 38, Loss: 0.4483, Accuracy:0.790, Val Loss: 0.4036, Val Accuracy: 0.808\nIteration: 1179, learning rate: 0.00920, Loss: 0.3985, Accuracy:0.844\nIteration: 1180, learning rate: 0.00920, Loss: 0.4576, Accuracy:0.789\nIteration: 1181, learning rate: 0.00920, Loss: 0.4023, Accuracy:0.805\nIteration: 1182, learning rate: 0.00920, Loss: 0.4501, Accuracy:0.789\nIteration: 1183, learning rate: 0.00920, Loss: 0.4246, Accuracy:0.812\nIteration: 1184, learning rate: 0.00920, Loss: 0.4056, Accuracy:0.820\nIteration: 1185, learning rate: 0.00920, Loss: 0.4285, Accuracy:0.797\nIteration: 1186, learning rate: 0.00919, Loss: 0.4432, Accuracy:0.750\nIteration: 1187, learning rate: 0.00919, Loss: 0.4116, Accuracy:0.781\nIteration: 1188, learning rate: 0.00919, Loss: 0.4808, Accuracy:0.773\nIteration: 1189, learning rate: 0.00919, Loss: 0.3920, Accuracy:0.852\nIteration: 1190, learning rate: 0.00919, Loss: 0.4411, Accuracy:0.812\nIteration: 1191, learning rate: 0.00919, Loss: 0.4419, Accuracy:0.789\nIteration: 1192, learning rate: 0.00919, Loss: 0.3465, Accuracy:0.875\nIteration: 1193, learning rate: 0.00919, Loss: 0.5063, Accuracy:0.758\nIteration: 1194, learning rate: 0.00919, Loss: 0.4953, Accuracy:0.773\nIteration: 1195, learning rate: 0.00919, Loss: 0.5265, Accuracy:0.742\nIteration: 1196, learning rate: 0.00919, Loss: 0.5042, Accuracy:0.758\nIteration: 1197, learning rate: 0.00919, Loss: 0.4712, Accuracy:0.781\nIteration: 1198, learning rate: 0.00919, Loss: 0.4571, Accuracy:0.805\nIteration: 1199, learning rate: 0.00919, Loss: 0.4545, Accuracy:0.773\nIteration: 1200, learning rate: 0.00919, Loss: 0.4014, Accuracy:0.797\nIteration: 1201, learning rate: 0.00919, Loss: 0.4725, Accuracy:0.758\nIteration: 1202, learning rate: 0.00918, Loss: 0.3838, Accuracy:0.875\nIteration: 1203, learning rate: 0.00918, Loss: 0.3840, Accuracy:0.828\nIteration: 1204, learning rate: 0.00918, Loss: 0.4755, Accuracy:0.781\nIteration: 1205, learning rate: 0.00918, Loss: 0.5465, Accuracy:0.703\nIteration: 1206, learning rate: 0.00918, Loss: 0.4443, Accuracy:0.773\nIteration: 1207, learning rate: 0.00918, Loss: 0.3956, Accuracy:0.867\nIteration: 1208, learning rate: 0.00918, Loss: 0.4398, Accuracy:0.789\nIteration: 1209, learning rate: 0.00918, Loss: 0.4001, Accuracy:0.839\nEpoch: 39, Loss: 0.4414, Accuracy:0.796, Val Loss: 0.3929, Val Accuracy: 0.818\nIteration: 1210, learning rate: 0.00918, Loss: 0.4373, Accuracy:0.773\nIteration: 1211, learning rate: 0.00918, Loss: 0.4824, Accuracy:0.781\nIteration: 1212, learning rate: 0.00918, Loss: 0.5098, Accuracy:0.758\nIteration: 1213, learning rate: 0.00918, Loss: 0.4339, Accuracy:0.797\nIteration: 1214, learning rate: 0.00918, Loss: 0.4833, Accuracy:0.781\nIteration: 1215, learning rate: 0.00918, Loss: 0.4359, Accuracy:0.773\nIteration: 1216, learning rate: 0.00918, Loss: 0.4690, Accuracy:0.805\nIteration: 1217, learning rate: 0.00918, Loss: 0.5016, Accuracy:0.758\nIteration: 1218, learning rate: 0.00917, Loss: 0.4601, Accuracy:0.797\nIteration: 1219, learning rate: 0.00917, Loss: 0.4309, Accuracy:0.820\nIteration: 1220, learning rate: 0.00917, Loss: 0.4488, Accuracy:0.789\nIteration: 1221, learning rate: 0.00917, Loss: 0.4474, Accuracy:0.766\nIteration: 1222, learning rate: 0.00917, Loss: 0.4290, Accuracy:0.820\nIteration: 1223, learning rate: 0.00917, Loss: 0.4045, Accuracy:0.828\nIteration: 1224, learning rate: 0.00917, Loss: 0.4458, Accuracy:0.805\nIteration: 1225, learning rate: 0.00917, Loss: 0.4414, Accuracy:0.828\nIteration: 1226, learning rate: 0.00917, Loss: 0.4483, Accuracy:0.781\nIteration: 1227, learning rate: 0.00917, Loss: 0.4129, Accuracy:0.820\nIteration: 1228, learning rate: 0.00917, Loss: 0.4227, Accuracy:0.836\nIteration: 1229, learning rate: 0.00917, Loss: 0.5004, Accuracy:0.758\nIteration: 1230, learning rate: 0.00917, Loss: 0.4672, Accuracy:0.789\nIteration: 1231, learning rate: 0.00917, Loss: 0.4572, Accuracy:0.773\nIteration: 1232, learning rate: 0.00917, Loss: 0.4494, Accuracy:0.797\nIteration: 1233, learning rate: 0.00917, Loss: 0.4378, Accuracy:0.781\nIteration: 1234, learning rate: 0.00916, Loss: 0.4136, Accuracy:0.844\nIteration: 1235, learning rate: 0.00916, Loss: 0.3973, Accuracy:0.805\nIteration: 1236, learning rate: 0.00916, Loss: 0.4745, Accuracy:0.750\nIteration: 1237, learning rate: 0.00916, Loss: 0.4175, Accuracy:0.766\nIteration: 1238, learning rate: 0.00916, Loss: 0.4387, Accuracy:0.797\nIteration: 1239, learning rate: 0.00916, Loss: 0.4789, Accuracy:0.781\nIteration: 1240, learning rate: 0.00916, Loss: 0.5176, Accuracy:0.763\nEpoch: 40, Loss: 0.4514, Accuracy:0.791, Val Loss: 0.4275, Val Accuracy: 0.788\nIteration: 1241, learning rate: 0.00916, Loss: 0.4152, Accuracy:0.812\nIteration: 1242, learning rate: 0.00916, Loss: 0.4607, Accuracy:0.812\nIteration: 1243, learning rate: 0.00916, Loss: 0.4066, Accuracy:0.828\nIteration: 1244, learning rate: 0.00916, Loss: 0.4073, Accuracy:0.828\nIteration: 1245, learning rate: 0.00916, Loss: 0.4194, Accuracy:0.734\nIteration: 1246, learning rate: 0.00916, Loss: 0.4864, Accuracy:0.773\nIteration: 1247, learning rate: 0.00916, Loss: 0.4924, Accuracy:0.789\nIteration: 1248, learning rate: 0.00916, Loss: 0.4440, Accuracy:0.789\nIteration: 1249, learning rate: 0.00916, Loss: 0.4481, Accuracy:0.828\nIteration: 1250, learning rate: 0.00916, Loss: 0.4822, Accuracy:0.727\nIteration: 1251, learning rate: 0.00915, Loss: 0.3722, Accuracy:0.805\nIteration: 1252, learning rate: 0.00915, Loss: 0.4109, Accuracy:0.812\nIteration: 1253, learning rate: 0.00915, Loss: 0.4609, Accuracy:0.797\nIteration: 1254, learning rate: 0.00915, Loss: 0.4261, Accuracy:0.836\nIteration: 1255, learning rate: 0.00915, Loss: 0.4490, Accuracy:0.797\nIteration: 1256, learning rate: 0.00915, Loss: 0.4588, Accuracy:0.773\nIteration: 1257, learning rate: 0.00915, Loss: 0.4417, Accuracy:0.797\nIteration: 1258, learning rate: 0.00915, Loss: 0.4781, Accuracy:0.781\nIteration: 1259, learning rate: 0.00915, Loss: 0.3720, Accuracy:0.852\nIteration: 1260, learning rate: 0.00915, Loss: 0.4324, Accuracy:0.742\nIteration: 1261, learning rate: 0.00915, Loss: 0.4858, Accuracy:0.750\nIteration: 1262, learning rate: 0.00915, Loss: 0.3610, Accuracy:0.828\nIteration: 1263, learning rate: 0.00915, Loss: 0.3995, Accuracy:0.789\nIteration: 1264, learning rate: 0.00915, Loss: 0.4211, Accuracy:0.812\nIteration: 1265, learning rate: 0.00915, Loss: 0.4000, Accuracy:0.789\nIteration: 1266, learning rate: 0.00915, Loss: 0.4617, Accuracy:0.773\nIteration: 1267, learning rate: 0.00914, Loss: 0.4664, Accuracy:0.750\nIteration: 1268, learning rate: 0.00914, Loss: 0.4340, Accuracy:0.797\nIteration: 1269, learning rate: 0.00914, Loss: 0.4820, Accuracy:0.750\nIteration: 1270, learning rate: 0.00914, Loss: 0.5188, Accuracy:0.734\nIteration: 1271, learning rate: 0.00914, Loss: 0.4603, Accuracy:0.763\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 41, Loss: 0.4405, Accuracy:0.789, Val Loss: 0.4233, Val Accuracy: 0.790\nIteration: 1272, learning rate: 0.00914, Loss: 0.4777, Accuracy:0.750\nIteration: 1273, learning rate: 0.00914, Loss: 0.4796, Accuracy:0.781\nIteration: 1274, learning rate: 0.00914, Loss: 0.4746, Accuracy:0.797\nIteration: 1275, learning rate: 0.00914, Loss: 0.4473, Accuracy:0.766\nIteration: 1276, learning rate: 0.00914, Loss: 0.5532, Accuracy:0.734\nIteration: 1277, learning rate: 0.00914, Loss: 0.4871, Accuracy:0.750\nIteration: 1278, learning rate: 0.00914, Loss: 0.4756, Accuracy:0.742\nIteration: 1279, learning rate: 0.00914, Loss: 0.4642, Accuracy:0.773\nIteration: 1280, learning rate: 0.00914, Loss: 0.3849, Accuracy:0.852\nIteration: 1281, learning rate: 0.00914, Loss: 0.5272, Accuracy:0.734\nIteration: 1282, learning rate: 0.00914, Loss: 0.4043, Accuracy:0.812\nIteration: 1283, learning rate: 0.00914, Loss: 0.5137, Accuracy:0.742\nIteration: 1284, learning rate: 0.00913, Loss: 0.4817, Accuracy:0.734\nIteration: 1285, learning rate: 0.00913, Loss: 0.4698, Accuracy:0.758\nIteration: 1286, learning rate: 0.00913, Loss: 0.5445, Accuracy:0.711\nIteration: 1287, learning rate: 0.00913, Loss: 0.4542, Accuracy:0.797\nIteration: 1288, learning rate: 0.00913, Loss: 0.5451, Accuracy:0.719\nIteration: 1289, learning rate: 0.00913, Loss: 0.4702, Accuracy:0.805\nIteration: 1290, learning rate: 0.00913, Loss: 0.4495, Accuracy:0.789\nIteration: 1291, learning rate: 0.00913, Loss: 0.4163, Accuracy:0.828\nIteration: 1292, learning rate: 0.00913, Loss: 0.3720, Accuracy:0.828\nIteration: 1293, learning rate: 0.00913, Loss: 0.5008, Accuracy:0.734\nIteration: 1294, learning rate: 0.00913, Loss: 0.4607, Accuracy:0.742\nIteration: 1295, learning rate: 0.00913, Loss: 0.4467, Accuracy:0.781\nIteration: 1296, learning rate: 0.00913, Loss: 0.5025, Accuracy:0.750\nIteration: 1297, learning rate: 0.00913, Loss: 0.3852, Accuracy:0.789\nIteration: 1298, learning rate: 0.00913, Loss: 0.3746, Accuracy:0.836\nIteration: 1299, learning rate: 0.00913, Loss: 0.3706, Accuracy:0.891\nIteration: 1300, learning rate: 0.00912, Loss: 0.4343, Accuracy:0.805\nIteration: 1301, learning rate: 0.00912, Loss: 0.4482, Accuracy:0.789\nIteration: 1302, learning rate: 0.00912, Loss: 0.3553, Accuracy:0.839\nEpoch: 42, Loss: 0.4571, Accuracy:0.779, Val Loss: 0.3904, Val Accuracy: 0.817\nval_loss_decreased from 0.3917 to 0.3904, saving_checkpoint for epoch 42\nIteration: 1303, learning rate: 0.00912, Loss: 0.4567, Accuracy:0.766\nIteration: 1304, learning rate: 0.00912, Loss: 0.3952, Accuracy:0.867\nIteration: 1305, learning rate: 0.00912, Loss: 0.5200, Accuracy:0.750\nIteration: 1306, learning rate: 0.00912, Loss: 0.4928, Accuracy:0.727\nIteration: 1307, learning rate: 0.00912, Loss: 0.5069, Accuracy:0.758\nIteration: 1308, learning rate: 0.00912, Loss: 0.3706, Accuracy:0.859\nIteration: 1309, learning rate: 0.00912, Loss: 0.3804, Accuracy:0.812\nIteration: 1310, learning rate: 0.00912, Loss: 0.4240, Accuracy:0.781\nIteration: 1311, learning rate: 0.00912, Loss: 0.4236, Accuracy:0.805\nIteration: 1312, learning rate: 0.00912, Loss: 0.4439, Accuracy:0.805\nIteration: 1313, learning rate: 0.00912, Loss: 0.5243, Accuracy:0.695\nIteration: 1314, learning rate: 0.00912, Loss: 0.4036, Accuracy:0.805\nIteration: 1315, learning rate: 0.00912, Loss: 0.4050, Accuracy:0.820\nIteration: 1316, learning rate: 0.00912, Loss: 0.4907, Accuracy:0.758\nIteration: 1317, learning rate: 0.00911, Loss: 0.3851, Accuracy:0.828\nIteration: 1318, learning rate: 0.00911, Loss: 0.4352, Accuracy:0.812\nIteration: 1319, learning rate: 0.00911, Loss: 0.4207, Accuracy:0.844\nIteration: 1320, learning rate: 0.00911, Loss: 0.4505, Accuracy:0.805\nIteration: 1321, learning rate: 0.00911, Loss: 0.4503, Accuracy:0.773\nIteration: 1322, learning rate: 0.00911, Loss: 0.4253, Accuracy:0.828\nIteration: 1323, learning rate: 0.00911, Loss: 0.4569, Accuracy:0.758\nIteration: 1324, learning rate: 0.00911, Loss: 0.5069, Accuracy:0.758\nIteration: 1325, learning rate: 0.00911, Loss: 0.4921, Accuracy:0.766\nIteration: 1326, learning rate: 0.00911, Loss: 0.3504, Accuracy:0.852\nIteration: 1327, learning rate: 0.00911, Loss: 0.5363, Accuracy:0.789\nIteration: 1328, learning rate: 0.00911, Loss: 0.5215, Accuracy:0.742\nIteration: 1329, learning rate: 0.00911, Loss: 0.4967, Accuracy:0.766\nIteration: 1330, learning rate: 0.00911, Loss: 0.4350, Accuracy:0.812\nIteration: 1331, learning rate: 0.00911, Loss: 0.4597, Accuracy:0.766\nIteration: 1332, learning rate: 0.00911, Loss: 0.4317, Accuracy:0.812\nIteration: 1333, learning rate: 0.00910, Loss: 0.5185, Accuracy:0.785\nEpoch: 43, Loss: 0.4520, Accuracy:0.790, Val Loss: 0.4249, Val Accuracy: 0.784\nIteration: 1334, learning rate: 0.00910, Loss: 0.4159, Accuracy:0.828\nIteration: 1335, learning rate: 0.00910, Loss: 0.4094, Accuracy:0.812\nIteration: 1336, learning rate: 0.00910, Loss: 0.3821, Accuracy:0.867\nIteration: 1337, learning rate: 0.00910, Loss: 0.4642, Accuracy:0.797\nIteration: 1338, learning rate: 0.00910, Loss: 0.4039, Accuracy:0.836\nIteration: 1339, learning rate: 0.00910, Loss: 0.4639, Accuracy:0.766\nIteration: 1340, learning rate: 0.00910, Loss: 0.3944, Accuracy:0.812\nIteration: 1341, learning rate: 0.00910, Loss: 0.5079, Accuracy:0.727\nIteration: 1342, learning rate: 0.00910, Loss: 0.4507, Accuracy:0.773\nIteration: 1343, learning rate: 0.00910, Loss: 0.4197, Accuracy:0.844\nIteration: 1344, learning rate: 0.00910, Loss: 0.4243, Accuracy:0.766\nIteration: 1345, learning rate: 0.00910, Loss: 0.4050, Accuracy:0.797\nIteration: 1346, learning rate: 0.00910, Loss: 0.4332, Accuracy:0.781\nIteration: 1347, learning rate: 0.00910, Loss: 0.3951, Accuracy:0.820\nIteration: 1348, learning rate: 0.00910, Loss: 0.5127, Accuracy:0.773\nIteration: 1349, learning rate: 0.00910, Loss: 0.3880, Accuracy:0.820\nIteration: 1350, learning rate: 0.00909, Loss: 0.4778, Accuracy:0.734\nIteration: 1351, learning rate: 0.00909, Loss: 0.4089, Accuracy:0.797\nIteration: 1352, learning rate: 0.00909, Loss: 0.4426, Accuracy:0.781\nIteration: 1353, learning rate: 0.00909, Loss: 0.4288, Accuracy:0.812\nIteration: 1354, learning rate: 0.00909, Loss: 0.4880, Accuracy:0.750\nIteration: 1355, learning rate: 0.00909, Loss: 0.4764, Accuracy:0.766\nIteration: 1356, learning rate: 0.00909, Loss: 0.3942, Accuracy:0.797\nIteration: 1357, learning rate: 0.00909, Loss: 0.4020, Accuracy:0.844\nIteration: 1358, learning rate: 0.00909, Loss: 0.4537, Accuracy:0.773\nIteration: 1359, learning rate: 0.00909, Loss: 0.4222, Accuracy:0.773\nIteration: 1360, learning rate: 0.00909, Loss: 0.4502, Accuracy:0.766\nIteration: 1361, learning rate: 0.00909, Loss: 0.3807, Accuracy:0.828\nIteration: 1362, learning rate: 0.00909, Loss: 0.3576, Accuracy:0.836\nIteration: 1363, learning rate: 0.00909, Loss: 0.4893, Accuracy:0.758\nIteration: 1364, learning rate: 0.00909, Loss: 0.3550, Accuracy:0.892\nEpoch: 44, Loss: 0.4290, Accuracy:0.798, Val Loss: 0.4064, Val Accuracy: 0.810\nIteration: 1365, learning rate: 0.00909, Loss: 0.4844, Accuracy:0.750\nIteration: 1366, learning rate: 0.00908, Loss: 0.4739, Accuracy:0.797\nIteration: 1367, learning rate: 0.00908, Loss: 0.3890, Accuracy:0.844\nIteration: 1368, learning rate: 0.00908, Loss: 0.4655, Accuracy:0.766\nIteration: 1369, learning rate: 0.00908, Loss: 0.4602, Accuracy:0.773\nIteration: 1370, learning rate: 0.00908, Loss: 0.4768, Accuracy:0.820\nIteration: 1371, learning rate: 0.00908, Loss: 0.4919, Accuracy:0.742\nIteration: 1372, learning rate: 0.00908, Loss: 0.4112, Accuracy:0.789\nIteration: 1373, learning rate: 0.00908, Loss: 0.4477, Accuracy:0.766\nIteration: 1374, learning rate: 0.00908, Loss: 0.4865, Accuracy:0.797\nIteration: 1375, learning rate: 0.00908, Loss: 0.4530, Accuracy:0.773\nIteration: 1376, learning rate: 0.00908, Loss: 0.5065, Accuracy:0.766\nIteration: 1377, learning rate: 0.00908, Loss: 0.4608, Accuracy:0.781\nIteration: 1378, learning rate: 0.00908, Loss: 0.3996, Accuracy:0.852\nIteration: 1379, learning rate: 0.00908, Loss: 0.4213, Accuracy:0.805\nIteration: 1380, learning rate: 0.00908, Loss: 0.3454, Accuracy:0.859\nIteration: 1381, learning rate: 0.00908, Loss: 0.4665, Accuracy:0.766\nIteration: 1382, learning rate: 0.00908, Loss: 0.4466, Accuracy:0.805\nIteration: 1383, learning rate: 0.00907, Loss: 0.5063, Accuracy:0.766\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1384, learning rate: 0.00907, Loss: 0.4375, Accuracy:0.805\nIteration: 1385, learning rate: 0.00907, Loss: 0.4392, Accuracy:0.781\nIteration: 1386, learning rate: 0.00907, Loss: 0.3496, Accuracy:0.883\nIteration: 1387, learning rate: 0.00907, Loss: 0.4770, Accuracy:0.750\nIteration: 1388, learning rate: 0.00907, Loss: 0.4264, Accuracy:0.773\nIteration: 1389, learning rate: 0.00907, Loss: 0.4182, Accuracy:0.812\nIteration: 1390, learning rate: 0.00907, Loss: 0.4276, Accuracy:0.797\nIteration: 1391, learning rate: 0.00907, Loss: 0.4468, Accuracy:0.750\nIteration: 1392, learning rate: 0.00907, Loss: 0.3793, Accuracy:0.836\nIteration: 1393, learning rate: 0.00907, Loss: 0.3992, Accuracy:0.844\nIteration: 1394, learning rate: 0.00907, Loss: 0.4043, Accuracy:0.836\nIteration: 1395, learning rate: 0.00907, Loss: 0.5346, Accuracy:0.731\nEpoch: 45, Loss: 0.4430, Accuracy:0.794, Val Loss: 0.3834, Val Accuracy: 0.823\nval_loss_decreased from 0.3904 to 0.3834, saving_checkpoint for epoch 45\nIteration: 1396, learning rate: 0.00907, Loss: 0.3989, Accuracy:0.805\nIteration: 1397, learning rate: 0.00907, Loss: 0.4206, Accuracy:0.789\nIteration: 1398, learning rate: 0.00907, Loss: 0.4656, Accuracy:0.773\nIteration: 1399, learning rate: 0.00907, Loss: 0.4040, Accuracy:0.828\nIteration: 1400, learning rate: 0.00906, Loss: 0.4433, Accuracy:0.766\nIteration: 1401, learning rate: 0.00906, Loss: 0.4013, Accuracy:0.820\nIteration: 1402, learning rate: 0.00906, Loss: 0.4583, Accuracy:0.820\nIteration: 1403, learning rate: 0.00906, Loss: 0.4850, Accuracy:0.789\nIteration: 1404, learning rate: 0.00906, Loss: 0.4433, Accuracy:0.789\nIteration: 1405, learning rate: 0.00906, Loss: 0.4083, Accuracy:0.836\nIteration: 1406, learning rate: 0.00906, Loss: 0.4408, Accuracy:0.812\nIteration: 1407, learning rate: 0.00906, Loss: 0.4274, Accuracy:0.781\nIteration: 1408, learning rate: 0.00906, Loss: 0.4998, Accuracy:0.727\nIteration: 1409, learning rate: 0.00906, Loss: 0.3070, Accuracy:0.875\nIteration: 1410, learning rate: 0.00906, Loss: 0.4091, Accuracy:0.812\nIteration: 1411, learning rate: 0.00906, Loss: 0.4086, Accuracy:0.828\nIteration: 1412, learning rate: 0.00906, Loss: 0.3337, Accuracy:0.875\nIteration: 1413, learning rate: 0.00906, Loss: 0.4529, Accuracy:0.797\nIteration: 1414, learning rate: 0.00906, Loss: 0.4060, Accuracy:0.805\nIteration: 1415, learning rate: 0.00906, Loss: 0.4878, Accuracy:0.742\nIteration: 1416, learning rate: 0.00906, Loss: 0.4124, Accuracy:0.820\nIteration: 1417, learning rate: 0.00905, Loss: 0.4758, Accuracy:0.781\nIteration: 1418, learning rate: 0.00905, Loss: 0.4374, Accuracy:0.789\nIteration: 1419, learning rate: 0.00905, Loss: 0.4113, Accuracy:0.828\nIteration: 1420, learning rate: 0.00905, Loss: 0.4510, Accuracy:0.812\nIteration: 1421, learning rate: 0.00905, Loss: 0.4478, Accuracy:0.805\nIteration: 1422, learning rate: 0.00905, Loss: 0.4261, Accuracy:0.805\nIteration: 1423, learning rate: 0.00905, Loss: 0.4106, Accuracy:0.812\nIteration: 1424, learning rate: 0.00905, Loss: 0.4324, Accuracy:0.758\nIteration: 1425, learning rate: 0.00905, Loss: 0.4213, Accuracy:0.812\nIteration: 1426, learning rate: 0.00905, Loss: 0.4255, Accuracy:0.817\nEpoch: 46, Loss: 0.4275, Accuracy:0.804, Val Loss: 0.4109, Val Accuracy: 0.802\nIteration: 1427, learning rate: 0.00905, Loss: 0.5133, Accuracy:0.734\nIteration: 1428, learning rate: 0.00905, Loss: 0.4506, Accuracy:0.773\nIteration: 1429, learning rate: 0.00905, Loss: 0.3943, Accuracy:0.812\nIteration: 1430, learning rate: 0.00905, Loss: 0.5008, Accuracy:0.742\nIteration: 1431, learning rate: 0.00905, Loss: 0.4106, Accuracy:0.812\nIteration: 1432, learning rate: 0.00905, Loss: 0.4194, Accuracy:0.820\nIteration: 1433, learning rate: 0.00904, Loss: 0.4173, Accuracy:0.812\nIteration: 1434, learning rate: 0.00904, Loss: 0.4213, Accuracy:0.812\nIteration: 1435, learning rate: 0.00904, Loss: 0.3887, Accuracy:0.836\nIteration: 1436, learning rate: 0.00904, Loss: 0.3261, Accuracy:0.852\nIteration: 1437, learning rate: 0.00904, Loss: 0.4837, Accuracy:0.766\nIteration: 1438, learning rate: 0.00904, Loss: 0.3787, Accuracy:0.812\nIteration: 1439, learning rate: 0.00904, Loss: 0.4516, Accuracy:0.766\nIteration: 1440, learning rate: 0.00904, Loss: 0.3874, Accuracy:0.797\nIteration: 1441, learning rate: 0.00904, Loss: 0.4360, Accuracy:0.781\nIteration: 1442, learning rate: 0.00904, Loss: 0.3992, Accuracy:0.789\nIteration: 1443, learning rate: 0.00904, Loss: 0.4246, Accuracy:0.805\nIteration: 1444, learning rate: 0.00904, Loss: 0.3619, Accuracy:0.859\nIteration: 1445, learning rate: 0.00904, Loss: 0.4490, Accuracy:0.805\nIteration: 1446, learning rate: 0.00904, Loss: 0.4360, Accuracy:0.781\nIteration: 1447, learning rate: 0.00904, Loss: 0.4804, Accuracy:0.766\nIteration: 1448, learning rate: 0.00904, Loss: 0.4548, Accuracy:0.812\nIteration: 1449, learning rate: 0.00904, Loss: 0.4250, Accuracy:0.820\nIteration: 1450, learning rate: 0.00903, Loss: 0.4682, Accuracy:0.750\nIteration: 1451, learning rate: 0.00903, Loss: 0.4672, Accuracy:0.758\nIteration: 1452, learning rate: 0.00903, Loss: 0.5160, Accuracy:0.758\nIteration: 1453, learning rate: 0.00903, Loss: 0.4734, Accuracy:0.781\nIteration: 1454, learning rate: 0.00903, Loss: 0.4647, Accuracy:0.750\nIteration: 1455, learning rate: 0.00903, Loss: 0.4323, Accuracy:0.805\nIteration: 1456, learning rate: 0.00903, Loss: 0.3780, Accuracy:0.836\nIteration: 1457, learning rate: 0.00903, Loss: 0.3517, Accuracy:0.839\nEpoch: 47, Loss: 0.4310, Accuracy:0.795, Val Loss: 0.4195, Val Accuracy: 0.802\nIteration: 1458, learning rate: 0.00903, Loss: 0.4559, Accuracy:0.766\nIteration: 1459, learning rate: 0.00903, Loss: 0.4257, Accuracy:0.797\nIteration: 1460, learning rate: 0.00903, Loss: 0.4990, Accuracy:0.734\nIteration: 1461, learning rate: 0.00903, Loss: 0.4599, Accuracy:0.805\nIteration: 1462, learning rate: 0.00903, Loss: 0.4316, Accuracy:0.773\nIteration: 1463, learning rate: 0.00903, Loss: 0.4429, Accuracy:0.781\nIteration: 1464, learning rate: 0.00903, Loss: 0.4137, Accuracy:0.805\nIteration: 1465, learning rate: 0.00903, Loss: 0.5029, Accuracy:0.734\nIteration: 1466, learning rate: 0.00903, Loss: 0.3690, Accuracy:0.820\nIteration: 1467, learning rate: 0.00902, Loss: 0.4839, Accuracy:0.781\nIteration: 1468, learning rate: 0.00902, Loss: 0.4296, Accuracy:0.789\nIteration: 1469, learning rate: 0.00902, Loss: 0.4063, Accuracy:0.820\nIteration: 1470, learning rate: 0.00902, Loss: 0.4537, Accuracy:0.789\nIteration: 1471, learning rate: 0.00902, Loss: 0.4848, Accuracy:0.750\nIteration: 1472, learning rate: 0.00902, Loss: 0.4327, Accuracy:0.836\nIteration: 1473, learning rate: 0.00902, Loss: 0.3959, Accuracy:0.836\nIteration: 1474, learning rate: 0.00902, Loss: 0.4046, Accuracy:0.820\nIteration: 1475, learning rate: 0.00902, Loss: 0.3698, Accuracy:0.836\nIteration: 1476, learning rate: 0.00902, Loss: 0.4390, Accuracy:0.820\nIteration: 1477, learning rate: 0.00902, Loss: 0.4721, Accuracy:0.750\nIteration: 1478, learning rate: 0.00902, Loss: 0.4797, Accuracy:0.750\nIteration: 1479, learning rate: 0.00902, Loss: 0.4736, Accuracy:0.766\nIteration: 1480, learning rate: 0.00902, Loss: 0.3686, Accuracy:0.844\nIteration: 1481, learning rate: 0.00902, Loss: 0.3610, Accuracy:0.875\nIteration: 1482, learning rate: 0.00902, Loss: 0.4445, Accuracy:0.789\nIteration: 1483, learning rate: 0.00902, Loss: 0.4555, Accuracy:0.766\nIteration: 1484, learning rate: 0.00901, Loss: 0.4599, Accuracy:0.797\nIteration: 1485, learning rate: 0.00901, Loss: 0.4859, Accuracy:0.750\nIteration: 1486, learning rate: 0.00901, Loss: 0.4413, Accuracy:0.789\nIteration: 1487, learning rate: 0.00901, Loss: 0.3891, Accuracy:0.820\nIteration: 1488, learning rate: 0.00901, Loss: 0.4314, Accuracy:0.796\nEpoch: 48, Loss: 0.4375, Accuracy:0.793, Val Loss: 0.3722, Val Accuracy: 0.828\nval_loss_decreased from 0.3834 to 0.3722, saving_checkpoint for epoch 48\nIteration: 1489, learning rate: 0.00901, Loss: 0.3853, Accuracy:0.820\nIteration: 1490, learning rate: 0.00901, Loss: 0.4019, Accuracy:0.844\nIteration: 1491, learning rate: 0.00901, Loss: 0.4779, Accuracy:0.773\nIteration: 1492, learning rate: 0.00901, Loss: 0.4446, Accuracy:0.781\nIteration: 1493, learning rate: 0.00901, Loss: 0.4385, Accuracy:0.789\nIteration: 1494, learning rate: 0.00901, Loss: 0.4469, Accuracy:0.812\nIteration: 1495, learning rate: 0.00901, Loss: 0.4461, Accuracy:0.781\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1496, learning rate: 0.00901, Loss: 0.3893, Accuracy:0.805\nIteration: 1497, learning rate: 0.00901, Loss: 0.4415, Accuracy:0.781\nIteration: 1498, learning rate: 0.00901, Loss: 0.4123, Accuracy:0.820\nIteration: 1499, learning rate: 0.00901, Loss: 0.4309, Accuracy:0.812\nIteration: 1500, learning rate: 0.00901, Loss: 0.4108, Accuracy:0.805\nIteration: 1501, learning rate: 0.00900, Loss: 0.4244, Accuracy:0.797\nIteration: 1502, learning rate: 0.00900, Loss: 0.4598, Accuracy:0.766\nIteration: 1503, learning rate: 0.00900, Loss: 0.4388, Accuracy:0.805\nIteration: 1504, learning rate: 0.00900, Loss: 0.3310, Accuracy:0.867\nIteration: 1505, learning rate: 0.00900, Loss: 0.3773, Accuracy:0.820\nIteration: 1506, learning rate: 0.00900, Loss: 0.4225, Accuracy:0.781\nIteration: 1507, learning rate: 0.00900, Loss: 0.4647, Accuracy:0.773\nIteration: 1508, learning rate: 0.00900, Loss: 0.3747, Accuracy:0.852\nIteration: 1509, learning rate: 0.00900, Loss: 0.3749, Accuracy:0.844\nIteration: 1510, learning rate: 0.00900, Loss: 0.3533, Accuracy:0.891\nIteration: 1511, learning rate: 0.00900, Loss: 0.4203, Accuracy:0.852\nIteration: 1512, learning rate: 0.00900, Loss: 0.4034, Accuracy:0.852\nIteration: 1513, learning rate: 0.00900, Loss: 0.4023, Accuracy:0.812\nIteration: 1514, learning rate: 0.00900, Loss: 0.4503, Accuracy:0.750\nIteration: 1515, learning rate: 0.00900, Loss: 0.4205, Accuracy:0.789\nIteration: 1516, learning rate: 0.00900, Loss: 0.5005, Accuracy:0.734\nIteration: 1517, learning rate: 0.00900, Loss: 0.3890, Accuracy:0.836\nIteration: 1518, learning rate: 0.00899, Loss: 0.4070, Accuracy:0.836\nIteration: 1519, learning rate: 0.00899, Loss: 0.4438, Accuracy:0.774\nEpoch: 49, Loss: 0.4188, Accuracy:0.808, Val Loss: 0.3756, Val Accuracy: 0.823\nIteration: 1520, learning rate: 0.00899, Loss: 0.4826, Accuracy:0.727\nIteration: 1521, learning rate: 0.00899, Loss: 0.4176, Accuracy:0.773\nIteration: 1522, learning rate: 0.00899, Loss: 0.5116, Accuracy:0.734\nIteration: 1523, learning rate: 0.00899, Loss: 0.4062, Accuracy:0.773\nIteration: 1524, learning rate: 0.00899, Loss: 0.4161, Accuracy:0.758\nIteration: 1525, learning rate: 0.00899, Loss: 0.4025, Accuracy:0.828\nIteration: 1526, learning rate: 0.00899, Loss: 0.3029, Accuracy:0.891\nIteration: 1527, learning rate: 0.00899, Loss: 0.3438, Accuracy:0.867\nIteration: 1528, learning rate: 0.00899, Loss: 0.3639, Accuracy:0.820\nIteration: 1529, learning rate: 0.00899, Loss: 0.4700, Accuracy:0.781\nIteration: 1530, learning rate: 0.00899, Loss: 0.4871, Accuracy:0.805\nIteration: 1531, learning rate: 0.00899, Loss: 0.4361, Accuracy:0.773\nIteration: 1532, learning rate: 0.00899, Loss: 0.4501, Accuracy:0.797\nIteration: 1533, learning rate: 0.00899, Loss: 0.4214, Accuracy:0.844\nIteration: 1534, learning rate: 0.00899, Loss: 0.4003, Accuracy:0.797\nIteration: 1535, learning rate: 0.00898, Loss: 0.3495, Accuracy:0.875\nIteration: 1536, learning rate: 0.00898, Loss: 0.4206, Accuracy:0.789\nIteration: 1537, learning rate: 0.00898, Loss: 0.4360, Accuracy:0.844\nIteration: 1538, learning rate: 0.00898, Loss: 0.3862, Accuracy:0.805\nIteration: 1539, learning rate: 0.00898, Loss: 0.4154, Accuracy:0.789\nIteration: 1540, learning rate: 0.00898, Loss: 0.4171, Accuracy:0.820\nIteration: 1541, learning rate: 0.00898, Loss: 0.4029, Accuracy:0.820\nIteration: 1542, learning rate: 0.00898, Loss: 0.4631, Accuracy:0.734\nIteration: 1543, learning rate: 0.00898, Loss: 0.3201, Accuracy:0.859\nIteration: 1544, learning rate: 0.00898, Loss: 0.4499, Accuracy:0.797\nIteration: 1545, learning rate: 0.00898, Loss: 0.4502, Accuracy:0.797\nIteration: 1546, learning rate: 0.00898, Loss: 0.4432, Accuracy:0.773\nIteration: 1547, learning rate: 0.00898, Loss: 0.4084, Accuracy:0.805\nIteration: 1548, learning rate: 0.00898, Loss: 0.4346, Accuracy:0.812\nIteration: 1549, learning rate: 0.00898, Loss: 0.3517, Accuracy:0.820\nIteration: 1550, learning rate: 0.00898, Loss: 0.3553, Accuracy:0.839\nEpoch: 50, Loss: 0.4134, Accuracy:0.805, Val Loss: 0.4553, Val Accuracy: 0.777\nIteration: 1551, learning rate: 0.00898, Loss: 0.4568, Accuracy:0.727\nIteration: 1552, learning rate: 0.00898, Loss: 0.4646, Accuracy:0.812\nIteration: 1553, learning rate: 0.00897, Loss: 0.4264, Accuracy:0.805\nIteration: 1554, learning rate: 0.00897, Loss: 0.4314, Accuracy:0.781\nIteration: 1555, learning rate: 0.00897, Loss: 0.4431, Accuracy:0.781\nIteration: 1556, learning rate: 0.00897, Loss: 0.4853, Accuracy:0.766\nIteration: 1557, learning rate: 0.00897, Loss: 0.3942, Accuracy:0.828\nIteration: 1558, learning rate: 0.00897, Loss: 0.4584, Accuracy:0.758\nIteration: 1559, learning rate: 0.00897, Loss: 0.4248, Accuracy:0.797\nIteration: 1560, learning rate: 0.00897, Loss: 0.4828, Accuracy:0.797\nIteration: 1561, learning rate: 0.00897, Loss: 0.4110, Accuracy:0.828\nIteration: 1562, learning rate: 0.00897, Loss: 0.3920, Accuracy:0.820\nIteration: 1563, learning rate: 0.00897, Loss: 0.4087, Accuracy:0.812\nIteration: 1564, learning rate: 0.00897, Loss: 0.3892, Accuracy:0.812\nIteration: 1565, learning rate: 0.00897, Loss: 0.3820, Accuracy:0.812\nIteration: 1566, learning rate: 0.00897, Loss: 0.4636, Accuracy:0.789\nIteration: 1567, learning rate: 0.00897, Loss: 0.3663, Accuracy:0.867\nIteration: 1568, learning rate: 0.00897, Loss: 0.4706, Accuracy:0.773\nIteration: 1569, learning rate: 0.00897, Loss: 0.4378, Accuracy:0.812\nIteration: 1570, learning rate: 0.00896, Loss: 0.4271, Accuracy:0.797\nIteration: 1571, learning rate: 0.00896, Loss: 0.3812, Accuracy:0.828\nIteration: 1572, learning rate: 0.00896, Loss: 0.3686, Accuracy:0.836\nIteration: 1573, learning rate: 0.00896, Loss: 0.3799, Accuracy:0.805\nIteration: 1574, learning rate: 0.00896, Loss: 0.3719, Accuracy:0.844\nIteration: 1575, learning rate: 0.00896, Loss: 0.3772, Accuracy:0.859\nIteration: 1576, learning rate: 0.00896, Loss: 0.4054, Accuracy:0.828\nIteration: 1577, learning rate: 0.00896, Loss: 0.4646, Accuracy:0.797\nIteration: 1578, learning rate: 0.00896, Loss: 0.4076, Accuracy:0.828\nIteration: 1579, learning rate: 0.00896, Loss: 0.3424, Accuracy:0.859\nIteration: 1580, learning rate: 0.00896, Loss: 0.3346, Accuracy:0.867\nIteration: 1581, learning rate: 0.00896, Loss: 0.4899, Accuracy:0.753\nEpoch: 51, Loss: 0.4174, Accuracy:0.809, Val Loss: 0.4055, Val Accuracy: 0.803\nIteration: 1582, learning rate: 0.00896, Loss: 0.4286, Accuracy:0.797\nIteration: 1583, learning rate: 0.00896, Loss: 0.3897, Accuracy:0.805\nIteration: 1584, learning rate: 0.00896, Loss: 0.3520, Accuracy:0.844\nIteration: 1585, learning rate: 0.00896, Loss: 0.4181, Accuracy:0.805\nIteration: 1586, learning rate: 0.00896, Loss: 0.4198, Accuracy:0.812\nIteration: 1587, learning rate: 0.00895, Loss: 0.4563, Accuracy:0.742\nIteration: 1588, learning rate: 0.00895, Loss: 0.3946, Accuracy:0.828\nIteration: 1589, learning rate: 0.00895, Loss: 0.4874, Accuracy:0.742\nIteration: 1590, learning rate: 0.00895, Loss: 0.4220, Accuracy:0.773\nIteration: 1591, learning rate: 0.00895, Loss: 0.4223, Accuracy:0.750\nIteration: 1592, learning rate: 0.00895, Loss: 0.4140, Accuracy:0.820\nIteration: 1593, learning rate: 0.00895, Loss: 0.3693, Accuracy:0.836\nIteration: 1594, learning rate: 0.00895, Loss: 0.4808, Accuracy:0.789\nIteration: 1595, learning rate: 0.00895, Loss: 0.4340, Accuracy:0.789\nIteration: 1596, learning rate: 0.00895, Loss: 0.4926, Accuracy:0.758\nIteration: 1597, learning rate: 0.00895, Loss: 0.4693, Accuracy:0.734\nIteration: 1598, learning rate: 0.00895, Loss: 0.3377, Accuracy:0.883\nIteration: 1599, learning rate: 0.00895, Loss: 0.3991, Accuracy:0.820\nIteration: 1600, learning rate: 0.00895, Loss: 0.4160, Accuracy:0.812\nIteration: 1601, learning rate: 0.00895, Loss: 0.4367, Accuracy:0.812\nIteration: 1602, learning rate: 0.00895, Loss: 0.4381, Accuracy:0.773\nIteration: 1603, learning rate: 0.00895, Loss: 0.4033, Accuracy:0.781\nIteration: 1604, learning rate: 0.00894, Loss: 0.4086, Accuracy:0.820\nIteration: 1605, learning rate: 0.00894, Loss: 0.4495, Accuracy:0.797\nIteration: 1606, learning rate: 0.00894, Loss: 0.4297, Accuracy:0.820\nIteration: 1607, learning rate: 0.00894, Loss: 0.4266, Accuracy:0.789\nIteration: 1608, learning rate: 0.00894, Loss: 0.3368, Accuracy:0.852\nIteration: 1609, learning rate: 0.00894, Loss: 0.3616, Accuracy:0.828\nIteration: 1610, learning rate: 0.00894, Loss: 0.4414, Accuracy:0.805\nIteration: 1611, learning rate: 0.00894, Loss: 0.4719, Accuracy:0.750\nIteration: 1612, learning rate: 0.00894, Loss: 0.4127, Accuracy:0.806\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 52, Loss: 0.4200, Accuracy:0.799, Val Loss: 0.3542, Val Accuracy: 0.833\nval_loss_decreased from 0.3722 to 0.3542, saving_checkpoint for epoch 52\nIteration: 1613, learning rate: 0.00894, Loss: 0.4991, Accuracy:0.758\nIteration: 1614, learning rate: 0.00894, Loss: 0.3840, Accuracy:0.844\nIteration: 1615, learning rate: 0.00894, Loss: 0.4408, Accuracy:0.766\nIteration: 1616, learning rate: 0.00894, Loss: 0.3073, Accuracy:0.867\nIteration: 1617, learning rate: 0.00894, Loss: 0.4502, Accuracy:0.781\nIteration: 1618, learning rate: 0.00894, Loss: 0.4238, Accuracy:0.781\nIteration: 1619, learning rate: 0.00894, Loss: 0.4662, Accuracy:0.789\nIteration: 1620, learning rate: 0.00894, Loss: 0.4359, Accuracy:0.812\nIteration: 1621, learning rate: 0.00894, Loss: 0.4310, Accuracy:0.789\nIteration: 1622, learning rate: 0.00893, Loss: 0.3854, Accuracy:0.852\nIteration: 1623, learning rate: 0.00893, Loss: 0.4174, Accuracy:0.828\nIteration: 1624, learning rate: 0.00893, Loss: 0.3331, Accuracy:0.828\nIteration: 1625, learning rate: 0.00893, Loss: 0.5045, Accuracy:0.695\nIteration: 1626, learning rate: 0.00893, Loss: 0.3420, Accuracy:0.859\nIteration: 1627, learning rate: 0.00893, Loss: 0.3866, Accuracy:0.828\nIteration: 1628, learning rate: 0.00893, Loss: 0.3889, Accuracy:0.797\nIteration: 1629, learning rate: 0.00893, Loss: 0.4524, Accuracy:0.781\nIteration: 1630, learning rate: 0.00893, Loss: 0.3836, Accuracy:0.820\nIteration: 1631, learning rate: 0.00893, Loss: 0.3935, Accuracy:0.812\nIteration: 1632, learning rate: 0.00893, Loss: 0.3931, Accuracy:0.844\nIteration: 1633, learning rate: 0.00893, Loss: 0.4285, Accuracy:0.805\nIteration: 1634, learning rate: 0.00893, Loss: 0.3510, Accuracy:0.852\nIteration: 1635, learning rate: 0.00893, Loss: 0.4222, Accuracy:0.828\nIteration: 1636, learning rate: 0.00893, Loss: 0.3596, Accuracy:0.875\nIteration: 1637, learning rate: 0.00893, Loss: 0.3718, Accuracy:0.867\nIteration: 1638, learning rate: 0.00893, Loss: 0.3784, Accuracy:0.820\nIteration: 1639, learning rate: 0.00892, Loss: 0.4578, Accuracy:0.773\nIteration: 1640, learning rate: 0.00892, Loss: 0.4601, Accuracy:0.797\nIteration: 1641, learning rate: 0.00892, Loss: 0.4096, Accuracy:0.836\nIteration: 1642, learning rate: 0.00892, Loss: 0.3886, Accuracy:0.828\nIteration: 1643, learning rate: 0.00892, Loss: 0.3782, Accuracy:0.828\nEpoch: 53, Loss: 0.4072, Accuracy:0.814, Val Loss: 0.3628, Val Accuracy: 0.823\nIteration: 1644, learning rate: 0.00892, Loss: 0.3587, Accuracy:0.883\nIteration: 1645, learning rate: 0.00892, Loss: 0.3777, Accuracy:0.797\nIteration: 1646, learning rate: 0.00892, Loss: 0.4658, Accuracy:0.758\nIteration: 1647, learning rate: 0.00892, Loss: 0.3786, Accuracy:0.836\nIteration: 1648, learning rate: 0.00892, Loss: 0.4165, Accuracy:0.812\nIteration: 1649, learning rate: 0.00892, Loss: 0.4678, Accuracy:0.781\nIteration: 1650, learning rate: 0.00892, Loss: 0.3716, Accuracy:0.812\nIteration: 1651, learning rate: 0.00892, Loss: 0.4112, Accuracy:0.812\nIteration: 1652, learning rate: 0.00892, Loss: 0.2967, Accuracy:0.867\nIteration: 1653, learning rate: 0.00892, Loss: 0.4617, Accuracy:0.797\nIteration: 1654, learning rate: 0.00892, Loss: 0.4428, Accuracy:0.812\nIteration: 1655, learning rate: 0.00892, Loss: 0.4808, Accuracy:0.766\nIteration: 1656, learning rate: 0.00891, Loss: 0.3465, Accuracy:0.867\nIteration: 1657, learning rate: 0.00891, Loss: 0.3918, Accuracy:0.828\nIteration: 1658, learning rate: 0.00891, Loss: 0.4427, Accuracy:0.797\nIteration: 1659, learning rate: 0.00891, Loss: 0.5355, Accuracy:0.742\nIteration: 1660, learning rate: 0.00891, Loss: 0.4439, Accuracy:0.789\nIteration: 1661, learning rate: 0.00891, Loss: 0.3878, Accuracy:0.820\nIteration: 1662, learning rate: 0.00891, Loss: 0.3226, Accuracy:0.852\nIteration: 1663, learning rate: 0.00891, Loss: 0.3714, Accuracy:0.859\nIteration: 1664, learning rate: 0.00891, Loss: 0.3791, Accuracy:0.805\nIteration: 1665, learning rate: 0.00891, Loss: 0.4829, Accuracy:0.750\nIteration: 1666, learning rate: 0.00891, Loss: 0.4571, Accuracy:0.766\nIteration: 1667, learning rate: 0.00891, Loss: 0.3785, Accuracy:0.859\nIteration: 1668, learning rate: 0.00891, Loss: 0.3922, Accuracy:0.797\nIteration: 1669, learning rate: 0.00891, Loss: 0.4723, Accuracy:0.773\nIteration: 1670, learning rate: 0.00891, Loss: 0.3656, Accuracy:0.828\nIteration: 1671, learning rate: 0.00891, Loss: 0.4009, Accuracy:0.805\nIteration: 1672, learning rate: 0.00891, Loss: 0.2866, Accuracy:0.914\nIteration: 1673, learning rate: 0.00891, Loss: 0.3887, Accuracy:0.820\nIteration: 1674, learning rate: 0.00890, Loss: 0.4642, Accuracy:0.774\nEpoch: 54, Loss: 0.4078, Accuracy:0.812, Val Loss: 0.3698, Val Accuracy: 0.817\nIteration: 1675, learning rate: 0.00890, Loss: 0.3969, Accuracy:0.812\nIteration: 1676, learning rate: 0.00890, Loss: 0.3366, Accuracy:0.875\nIteration: 1677, learning rate: 0.00890, Loss: 0.4355, Accuracy:0.789\nIteration: 1678, learning rate: 0.00890, Loss: 0.3820, Accuracy:0.789\nIteration: 1679, learning rate: 0.00890, Loss: 0.3849, Accuracy:0.844\nIteration: 1680, learning rate: 0.00890, Loss: 0.3949, Accuracy:0.820\nIteration: 1681, learning rate: 0.00890, Loss: 0.3760, Accuracy:0.805\nIteration: 1682, learning rate: 0.00890, Loss: 0.5430, Accuracy:0.750\nIteration: 1683, learning rate: 0.00890, Loss: 0.4648, Accuracy:0.758\nIteration: 1684, learning rate: 0.00890, Loss: 0.4027, Accuracy:0.836\nIteration: 1685, learning rate: 0.00890, Loss: 0.4311, Accuracy:0.797\nIteration: 1686, learning rate: 0.00890, Loss: 0.4023, Accuracy:0.805\nIteration: 1687, learning rate: 0.00890, Loss: 0.3810, Accuracy:0.875\nIteration: 1688, learning rate: 0.00890, Loss: 0.3445, Accuracy:0.828\nIteration: 1689, learning rate: 0.00890, Loss: 0.4913, Accuracy:0.758\nIteration: 1690, learning rate: 0.00890, Loss: 0.4563, Accuracy:0.750\nIteration: 1691, learning rate: 0.00889, Loss: 0.4417, Accuracy:0.797\nIteration: 1692, learning rate: 0.00889, Loss: 0.4395, Accuracy:0.781\nIteration: 1693, learning rate: 0.00889, Loss: 0.4358, Accuracy:0.805\nIteration: 1694, learning rate: 0.00889, Loss: 0.4363, Accuracy:0.805\nIteration: 1695, learning rate: 0.00889, Loss: 0.3800, Accuracy:0.820\nIteration: 1696, learning rate: 0.00889, Loss: 0.4415, Accuracy:0.797\nIteration: 1697, learning rate: 0.00889, Loss: 0.4137, Accuracy:0.805\nIteration: 1698, learning rate: 0.00889, Loss: 0.4617, Accuracy:0.750\nIteration: 1699, learning rate: 0.00889, Loss: 0.3529, Accuracy:0.883\nIteration: 1700, learning rate: 0.00889, Loss: 0.3810, Accuracy:0.812\nIteration: 1701, learning rate: 0.00889, Loss: 0.3951, Accuracy:0.820\nIteration: 1702, learning rate: 0.00889, Loss: 0.4193, Accuracy:0.789\nIteration: 1703, learning rate: 0.00889, Loss: 0.4549, Accuracy:0.773\nIteration: 1704, learning rate: 0.00889, Loss: 0.3799, Accuracy:0.867\nIteration: 1705, learning rate: 0.00889, Loss: 0.4539, Accuracy:0.742\nEpoch: 55, Loss: 0.4165, Accuracy:0.804, Val Loss: 0.3836, Val Accuracy: 0.815\nIteration: 1706, learning rate: 0.00889, Loss: 0.4404, Accuracy:0.828\nIteration: 1707, learning rate: 0.00889, Loss: 0.3520, Accuracy:0.867\nIteration: 1708, learning rate: 0.00889, Loss: 0.3626, Accuracy:0.805\nIteration: 1709, learning rate: 0.00888, Loss: 0.4292, Accuracy:0.781\nIteration: 1710, learning rate: 0.00888, Loss: 0.4538, Accuracy:0.781\nIteration: 1711, learning rate: 0.00888, Loss: 0.4613, Accuracy:0.750\nIteration: 1712, learning rate: 0.00888, Loss: 0.4989, Accuracy:0.766\nIteration: 1713, learning rate: 0.00888, Loss: 0.4276, Accuracy:0.789\nIteration: 1714, learning rate: 0.00888, Loss: 0.3962, Accuracy:0.859\nIteration: 1715, learning rate: 0.00888, Loss: 0.3639, Accuracy:0.859\nIteration: 1716, learning rate: 0.00888, Loss: 0.3798, Accuracy:0.836\nIteration: 1717, learning rate: 0.00888, Loss: 0.4537, Accuracy:0.797\nIteration: 1718, learning rate: 0.00888, Loss: 0.4379, Accuracy:0.812\nIteration: 1719, learning rate: 0.00888, Loss: 0.3352, Accuracy:0.820\nIteration: 1720, learning rate: 0.00888, Loss: 0.3885, Accuracy:0.828\nIteration: 1721, learning rate: 0.00888, Loss: 0.4512, Accuracy:0.789\nIteration: 1722, learning rate: 0.00888, Loss: 0.3784, Accuracy:0.820\nIteration: 1723, learning rate: 0.00888, Loss: 0.3321, Accuracy:0.867\nIteration: 1724, learning rate: 0.00888, Loss: 0.3733, Accuracy:0.812\nIteration: 1725, learning rate: 0.00888, Loss: 0.3862, Accuracy:0.836\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1726, learning rate: 0.00887, Loss: 0.3823, Accuracy:0.844\nIteration: 1727, learning rate: 0.00887, Loss: 0.3762, Accuracy:0.844\nIteration: 1728, learning rate: 0.00887, Loss: 0.4414, Accuracy:0.797\nIteration: 1729, learning rate: 0.00887, Loss: 0.4229, Accuracy:0.773\nIteration: 1730, learning rate: 0.00887, Loss: 0.3545, Accuracy:0.852\nIteration: 1731, learning rate: 0.00887, Loss: 0.4213, Accuracy:0.805\nIteration: 1732, learning rate: 0.00887, Loss: 0.4202, Accuracy:0.812\nIteration: 1733, learning rate: 0.00887, Loss: 0.4741, Accuracy:0.766\nIteration: 1734, learning rate: 0.00887, Loss: 0.4181, Accuracy:0.820\nIteration: 1735, learning rate: 0.00887, Loss: 0.4332, Accuracy:0.773\nIteration: 1736, learning rate: 0.00887, Loss: 0.3246, Accuracy:0.871\nEpoch: 56, Loss: 0.4055, Accuracy:0.815, Val Loss: 0.3918, Val Accuracy: 0.806\nIteration: 1737, learning rate: 0.00887, Loss: 0.3990, Accuracy:0.828\nIteration: 1738, learning rate: 0.00887, Loss: 0.3831, Accuracy:0.805\nIteration: 1739, learning rate: 0.00887, Loss: 0.4362, Accuracy:0.805\nIteration: 1740, learning rate: 0.00887, Loss: 0.3720, Accuracy:0.828\nIteration: 1741, learning rate: 0.00887, Loss: 0.3872, Accuracy:0.805\nIteration: 1742, learning rate: 0.00887, Loss: 0.3232, Accuracy:0.883\nIteration: 1743, learning rate: 0.00887, Loss: 0.3316, Accuracy:0.844\nIteration: 1744, learning rate: 0.00886, Loss: 0.4262, Accuracy:0.797\nIteration: 1745, learning rate: 0.00886, Loss: 0.4279, Accuracy:0.805\nIteration: 1746, learning rate: 0.00886, Loss: 0.3778, Accuracy:0.820\nIteration: 1747, learning rate: 0.00886, Loss: 0.4576, Accuracy:0.797\nIteration: 1748, learning rate: 0.00886, Loss: 0.4610, Accuracy:0.773\nIteration: 1749, learning rate: 0.00886, Loss: 0.4947, Accuracy:0.781\nIteration: 1750, learning rate: 0.00886, Loss: 0.4352, Accuracy:0.805\nIteration: 1751, learning rate: 0.00886, Loss: 0.3677, Accuracy:0.828\nIteration: 1752, learning rate: 0.00886, Loss: 0.4616, Accuracy:0.805\nIteration: 1753, learning rate: 0.00886, Loss: 0.4912, Accuracy:0.742\nIteration: 1754, learning rate: 0.00886, Loss: 0.4688, Accuracy:0.805\nIteration: 1755, learning rate: 0.00886, Loss: 0.3664, Accuracy:0.828\nIteration: 1756, learning rate: 0.00886, Loss: 0.4070, Accuracy:0.828\nIteration: 1757, learning rate: 0.00886, Loss: 0.3674, Accuracy:0.859\nIteration: 1758, learning rate: 0.00886, Loss: 0.4183, Accuracy:0.789\nIteration: 1759, learning rate: 0.00886, Loss: 0.4157, Accuracy:0.797\nIteration: 1760, learning rate: 0.00886, Loss: 0.3713, Accuracy:0.844\nIteration: 1761, learning rate: 0.00886, Loss: 0.5127, Accuracy:0.742\nIteration: 1762, learning rate: 0.00885, Loss: 0.4013, Accuracy:0.828\nIteration: 1763, learning rate: 0.00885, Loss: 0.4724, Accuracy:0.781\nIteration: 1764, learning rate: 0.00885, Loss: 0.3592, Accuracy:0.828\nIteration: 1765, learning rate: 0.00885, Loss: 0.3687, Accuracy:0.844\nIteration: 1766, learning rate: 0.00885, Loss: 0.3514, Accuracy:0.836\nIteration: 1767, learning rate: 0.00885, Loss: 0.3990, Accuracy:0.785\nEpoch: 57, Loss: 0.4101, Accuracy:0.811, Val Loss: 0.3829, Val Accuracy: 0.818\nIteration: 1768, learning rate: 0.00885, Loss: 0.4171, Accuracy:0.797\nIteration: 1769, learning rate: 0.00885, Loss: 0.4242, Accuracy:0.844\nIteration: 1770, learning rate: 0.00885, Loss: 0.3584, Accuracy:0.844\nIteration: 1771, learning rate: 0.00885, Loss: 0.3800, Accuracy:0.789\nIteration: 1772, learning rate: 0.00885, Loss: 0.4060, Accuracy:0.852\nIteration: 1773, learning rate: 0.00885, Loss: 0.4046, Accuracy:0.797\nIteration: 1774, learning rate: 0.00885, Loss: 0.4384, Accuracy:0.812\nIteration: 1775, learning rate: 0.00885, Loss: 0.3879, Accuracy:0.820\nIteration: 1776, learning rate: 0.00885, Loss: 0.4139, Accuracy:0.781\nIteration: 1777, learning rate: 0.00885, Loss: 0.4166, Accuracy:0.789\nIteration: 1778, learning rate: 0.00885, Loss: 0.3900, Accuracy:0.828\nIteration: 1779, learning rate: 0.00884, Loss: 0.4224, Accuracy:0.805\nIteration: 1780, learning rate: 0.00884, Loss: 0.4850, Accuracy:0.766\nIteration: 1781, learning rate: 0.00884, Loss: 0.4074, Accuracy:0.836\nIteration: 1782, learning rate: 0.00884, Loss: 0.3472, Accuracy:0.844\nIteration: 1783, learning rate: 0.00884, Loss: 0.5257, Accuracy:0.742\nIteration: 1784, learning rate: 0.00884, Loss: 0.3589, Accuracy:0.859\nIteration: 1785, learning rate: 0.00884, Loss: 0.3526, Accuracy:0.828\nIteration: 1786, learning rate: 0.00884, Loss: 0.4291, Accuracy:0.781\nIteration: 1787, learning rate: 0.00884, Loss: 0.3986, Accuracy:0.820\nIteration: 1788, learning rate: 0.00884, Loss: 0.4138, Accuracy:0.797\nIteration: 1789, learning rate: 0.00884, Loss: 0.4074, Accuracy:0.812\nIteration: 1790, learning rate: 0.00884, Loss: 0.3984, Accuracy:0.828\nIteration: 1791, learning rate: 0.00884, Loss: 0.3962, Accuracy:0.805\nIteration: 1792, learning rate: 0.00884, Loss: 0.3952, Accuracy:0.844\nIteration: 1793, learning rate: 0.00884, Loss: 0.3946, Accuracy:0.820\nIteration: 1794, learning rate: 0.00884, Loss: 0.4358, Accuracy:0.789\nIteration: 1795, learning rate: 0.00884, Loss: 0.3956, Accuracy:0.812\nIteration: 1796, learning rate: 0.00884, Loss: 0.3814, Accuracy:0.828\nIteration: 1797, learning rate: 0.00883, Loss: 0.4179, Accuracy:0.812\nIteration: 1798, learning rate: 0.00883, Loss: 0.3294, Accuracy:0.828\nEpoch: 58, Loss: 0.4042, Accuracy:0.813, Val Loss: 0.4156, Val Accuracy: 0.819\nIteration: 1799, learning rate: 0.00883, Loss: 0.3098, Accuracy:0.844\nIteration: 1800, learning rate: 0.00883, Loss: 0.4427, Accuracy:0.812\nIteration: 1801, learning rate: 0.00883, Loss: 0.4242, Accuracy:0.805\nIteration: 1802, learning rate: 0.00883, Loss: 0.3487, Accuracy:0.867\nIteration: 1803, learning rate: 0.00883, Loss: 0.5096, Accuracy:0.727\nIteration: 1804, learning rate: 0.00883, Loss: 0.4665, Accuracy:0.828\nIteration: 1805, learning rate: 0.00883, Loss: 0.4088, Accuracy:0.805\nIteration: 1806, learning rate: 0.00883, Loss: 0.4154, Accuracy:0.828\nIteration: 1807, learning rate: 0.00883, Loss: 0.4283, Accuracy:0.797\nIteration: 1808, learning rate: 0.00883, Loss: 0.4283, Accuracy:0.758\nIteration: 1809, learning rate: 0.00883, Loss: 0.3755, Accuracy:0.844\nIteration: 1810, learning rate: 0.00883, Loss: 0.3748, Accuracy:0.828\nIteration: 1811, learning rate: 0.00883, Loss: 0.4295, Accuracy:0.797\nIteration: 1812, learning rate: 0.00883, Loss: 0.3896, Accuracy:0.789\nIteration: 1813, learning rate: 0.00883, Loss: 0.3099, Accuracy:0.867\nIteration: 1814, learning rate: 0.00883, Loss: 0.3850, Accuracy:0.805\nIteration: 1815, learning rate: 0.00882, Loss: 0.3950, Accuracy:0.859\nIteration: 1816, learning rate: 0.00882, Loss: 0.2637, Accuracy:0.891\nIteration: 1817, learning rate: 0.00882, Loss: 0.3216, Accuracy:0.891\nIteration: 1818, learning rate: 0.00882, Loss: 0.4825, Accuracy:0.812\nIteration: 1819, learning rate: 0.00882, Loss: 0.3395, Accuracy:0.867\nIteration: 1820, learning rate: 0.00882, Loss: 0.4035, Accuracy:0.766\nIteration: 1821, learning rate: 0.00882, Loss: 0.4410, Accuracy:0.812\nIteration: 1822, learning rate: 0.00882, Loss: 0.3582, Accuracy:0.867\nIteration: 1823, learning rate: 0.00882, Loss: 0.3749, Accuracy:0.852\nIteration: 1824, learning rate: 0.00882, Loss: 0.3479, Accuracy:0.875\nIteration: 1825, learning rate: 0.00882, Loss: 0.3714, Accuracy:0.867\nIteration: 1826, learning rate: 0.00882, Loss: 0.3743, Accuracy:0.828\nIteration: 1827, learning rate: 0.00882, Loss: 0.4168, Accuracy:0.797\nIteration: 1828, learning rate: 0.00882, Loss: 0.3430, Accuracy:0.844\nIteration: 1829, learning rate: 0.00882, Loss: 0.4130, Accuracy:0.774\nEpoch: 59, Loss: 0.3901, Accuracy:0.826, Val Loss: 0.3956, Val Accuracy: 0.814\nIteration: 1830, learning rate: 0.00882, Loss: 0.4009, Accuracy:0.812\nIteration: 1831, learning rate: 0.00882, Loss: 0.4182, Accuracy:0.828\nIteration: 1832, learning rate: 0.00882, Loss: 0.3920, Accuracy:0.828\nIteration: 1833, learning rate: 0.00881, Loss: 0.4127, Accuracy:0.789\nIteration: 1834, learning rate: 0.00881, Loss: 0.3374, Accuracy:0.859\nIteration: 1835, learning rate: 0.00881, Loss: 0.3660, Accuracy:0.820\nIteration: 1836, learning rate: 0.00881, Loss: 0.3863, Accuracy:0.781\nIteration: 1837, learning rate: 0.00881, Loss: 0.3738, Accuracy:0.844\nIteration: 1838, learning rate: 0.00881, Loss: 0.3237, Accuracy:0.852\nIteration: 1839, learning rate: 0.00881, Loss: 0.3285, Accuracy:0.867\nIteration: 1840, learning rate: 0.00881, Loss: 0.3602, Accuracy:0.867\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1841, learning rate: 0.00881, Loss: 0.3550, Accuracy:0.844\nIteration: 1842, learning rate: 0.00881, Loss: 0.4059, Accuracy:0.781\nIteration: 1843, learning rate: 0.00881, Loss: 0.3731, Accuracy:0.859\nIteration: 1844, learning rate: 0.00881, Loss: 0.4345, Accuracy:0.828\nIteration: 1845, learning rate: 0.00881, Loss: 0.5301, Accuracy:0.766\nIteration: 1846, learning rate: 0.00881, Loss: 0.3727, Accuracy:0.844\nIteration: 1847, learning rate: 0.00881, Loss: 0.3943, Accuracy:0.844\nIteration: 1848, learning rate: 0.00881, Loss: 0.4396, Accuracy:0.828\nIteration: 1849, learning rate: 0.00881, Loss: 0.3939, Accuracy:0.852\nIteration: 1850, learning rate: 0.00881, Loss: 0.4106, Accuracy:0.805\nIteration: 1851, learning rate: 0.00880, Loss: 0.3871, Accuracy:0.820\nIteration: 1852, learning rate: 0.00880, Loss: 0.4962, Accuracy:0.711\nIteration: 1853, learning rate: 0.00880, Loss: 0.3259, Accuracy:0.883\nIteration: 1854, learning rate: 0.00880, Loss: 0.4089, Accuracy:0.789\nIteration: 1855, learning rate: 0.00880, Loss: 0.3718, Accuracy:0.852\nIteration: 1856, learning rate: 0.00880, Loss: 0.3622, Accuracy:0.852\nIteration: 1857, learning rate: 0.00880, Loss: 0.3646, Accuracy:0.859\nIteration: 1858, learning rate: 0.00880, Loss: 0.4187, Accuracy:0.797\nIteration: 1859, learning rate: 0.00880, Loss: 0.3733, Accuracy:0.836\nIteration: 1860, learning rate: 0.00880, Loss: 0.4163, Accuracy:0.806\nEpoch: 60, Loss: 0.3914, Accuracy:0.826, Val Loss: 0.3901, Val Accuracy: 0.801\nIteration: 1861, learning rate: 0.00880, Loss: 0.3941, Accuracy:0.820\nIteration: 1862, learning rate: 0.00880, Loss: 0.3433, Accuracy:0.875\nIteration: 1863, learning rate: 0.00880, Loss: 0.2977, Accuracy:0.883\nIteration: 1864, learning rate: 0.00880, Loss: 0.3399, Accuracy:0.875\nIteration: 1865, learning rate: 0.00880, Loss: 0.4206, Accuracy:0.773\nIteration: 1866, learning rate: 0.00880, Loss: 0.4086, Accuracy:0.844\nIteration: 1867, learning rate: 0.00880, Loss: 0.3019, Accuracy:0.867\nIteration: 1868, learning rate: 0.00880, Loss: 0.3601, Accuracy:0.852\nIteration: 1869, learning rate: 0.00879, Loss: 0.4707, Accuracy:0.766\nIteration: 1870, learning rate: 0.00879, Loss: 0.3612, Accuracy:0.836\nIteration: 1871, learning rate: 0.00879, Loss: 0.3849, Accuracy:0.805\nIteration: 1872, learning rate: 0.00879, Loss: 0.3825, Accuracy:0.836\nIteration: 1873, learning rate: 0.00879, Loss: 0.3916, Accuracy:0.812\nIteration: 1874, learning rate: 0.00879, Loss: 0.3328, Accuracy:0.852\nIteration: 1875, learning rate: 0.00879, Loss: 0.3786, Accuracy:0.828\nIteration: 1876, learning rate: 0.00879, Loss: 0.4999, Accuracy:0.758\nIteration: 1877, learning rate: 0.00879, Loss: 0.4994, Accuracy:0.719\nIteration: 1878, learning rate: 0.00879, Loss: 0.5304, Accuracy:0.750\nIteration: 1879, learning rate: 0.00879, Loss: 0.5351, Accuracy:0.719\nIteration: 1880, learning rate: 0.00879, Loss: 0.4092, Accuracy:0.812\nIteration: 1881, learning rate: 0.00879, Loss: 0.3351, Accuracy:0.859\nIteration: 1882, learning rate: 0.00879, Loss: 0.4115, Accuracy:0.820\nIteration: 1883, learning rate: 0.00879, Loss: 0.4258, Accuracy:0.789\nIteration: 1884, learning rate: 0.00879, Loss: 0.4667, Accuracy:0.766\nIteration: 1885, learning rate: 0.00879, Loss: 0.4326, Accuracy:0.820\nIteration: 1886, learning rate: 0.00879, Loss: 0.3889, Accuracy:0.852\nIteration: 1887, learning rate: 0.00878, Loss: 0.4105, Accuracy:0.836\nIteration: 1888, learning rate: 0.00878, Loss: 0.3513, Accuracy:0.852\nIteration: 1889, learning rate: 0.00878, Loss: 0.3964, Accuracy:0.836\nIteration: 1890, learning rate: 0.00878, Loss: 0.3505, Accuracy:0.836\nIteration: 1891, learning rate: 0.00878, Loss: 0.4107, Accuracy:0.849\nEpoch: 61, Loss: 0.4007, Accuracy:0.819, Val Loss: 0.3835, Val Accuracy: 0.824\nIteration: 1892, learning rate: 0.00878, Loss: 0.3764, Accuracy:0.836\nIteration: 1893, learning rate: 0.00878, Loss: 0.3454, Accuracy:0.875\nIteration: 1894, learning rate: 0.00878, Loss: 0.4313, Accuracy:0.805\nIteration: 1895, learning rate: 0.00878, Loss: 0.3721, Accuracy:0.828\nIteration: 1896, learning rate: 0.00878, Loss: 0.4093, Accuracy:0.773\nIteration: 1897, learning rate: 0.00878, Loss: 0.4583, Accuracy:0.781\nIteration: 1898, learning rate: 0.00878, Loss: 0.3447, Accuracy:0.836\nIteration: 1899, learning rate: 0.00878, Loss: 0.3703, Accuracy:0.820\nIteration: 1900, learning rate: 0.00878, Loss: 0.4103, Accuracy:0.805\nIteration: 1901, learning rate: 0.00878, Loss: 0.3478, Accuracy:0.844\nIteration: 1902, learning rate: 0.00878, Loss: 0.4658, Accuracy:0.773\nIteration: 1903, learning rate: 0.00878, Loss: 0.3713, Accuracy:0.797\nIteration: 1904, learning rate: 0.00878, Loss: 0.3409, Accuracy:0.867\nIteration: 1905, learning rate: 0.00877, Loss: 0.3819, Accuracy:0.805\nIteration: 1906, learning rate: 0.00877, Loss: 0.4099, Accuracy:0.805\nIteration: 1907, learning rate: 0.00877, Loss: 0.4327, Accuracy:0.797\nIteration: 1908, learning rate: 0.00877, Loss: 0.3529, Accuracy:0.867\nIteration: 1909, learning rate: 0.00877, Loss: 0.3634, Accuracy:0.844\nIteration: 1910, learning rate: 0.00877, Loss: 0.4134, Accuracy:0.805\nIteration: 1911, learning rate: 0.00877, Loss: 0.3224, Accuracy:0.867\nIteration: 1912, learning rate: 0.00877, Loss: 0.4189, Accuracy:0.836\nIteration: 1913, learning rate: 0.00877, Loss: 0.4113, Accuracy:0.789\nIteration: 1914, learning rate: 0.00877, Loss: 0.3496, Accuracy:0.820\nIteration: 1915, learning rate: 0.00877, Loss: 0.4228, Accuracy:0.805\nIteration: 1916, learning rate: 0.00877, Loss: 0.3291, Accuracy:0.875\nIteration: 1917, learning rate: 0.00877, Loss: 0.3093, Accuracy:0.891\nIteration: 1918, learning rate: 0.00877, Loss: 0.3661, Accuracy:0.805\nIteration: 1919, learning rate: 0.00877, Loss: 0.3637, Accuracy:0.812\nIteration: 1920, learning rate: 0.00877, Loss: 0.3772, Accuracy:0.836\nIteration: 1921, learning rate: 0.00877, Loss: 0.4238, Accuracy:0.805\nIteration: 1922, learning rate: 0.00877, Loss: 0.3894, Accuracy:0.806\nEpoch: 62, Loss: 0.3833, Accuracy:0.823, Val Loss: 0.3753, Val Accuracy: 0.817\nIteration: 1923, learning rate: 0.00876, Loss: 0.3426, Accuracy:0.867\nIteration: 1924, learning rate: 0.00876, Loss: 0.4079, Accuracy:0.812\nIteration: 1925, learning rate: 0.00876, Loss: 0.3924, Accuracy:0.797\nIteration: 1926, learning rate: 0.00876, Loss: 0.2712, Accuracy:0.891\nIteration: 1927, learning rate: 0.00876, Loss: 0.4100, Accuracy:0.820\nIteration: 1928, learning rate: 0.00876, Loss: 0.3384, Accuracy:0.867\nIteration: 1929, learning rate: 0.00876, Loss: 0.3864, Accuracy:0.820\nIteration: 1930, learning rate: 0.00876, Loss: 0.4353, Accuracy:0.789\nIteration: 1931, learning rate: 0.00876, Loss: 0.3269, Accuracy:0.820\nIteration: 1932, learning rate: 0.00876, Loss: 0.3792, Accuracy:0.852\nIteration: 1933, learning rate: 0.00876, Loss: 0.3777, Accuracy:0.812\nIteration: 1934, learning rate: 0.00876, Loss: 0.3678, Accuracy:0.805\nIteration: 1935, learning rate: 0.00876, Loss: 0.4980, Accuracy:0.742\nIteration: 1936, learning rate: 0.00876, Loss: 0.3594, Accuracy:0.820\nIteration: 1937, learning rate: 0.00876, Loss: 0.4124, Accuracy:0.844\nIteration: 1938, learning rate: 0.00876, Loss: 0.4801, Accuracy:0.719\nIteration: 1939, learning rate: 0.00876, Loss: 0.4147, Accuracy:0.766\nIteration: 1940, learning rate: 0.00876, Loss: 0.3259, Accuracy:0.867\nIteration: 1941, learning rate: 0.00875, Loss: 0.3907, Accuracy:0.836\nIteration: 1942, learning rate: 0.00875, Loss: 0.3404, Accuracy:0.859\nIteration: 1943, learning rate: 0.00875, Loss: 0.3905, Accuracy:0.828\nIteration: 1944, learning rate: 0.00875, Loss: 0.2692, Accuracy:0.898\nIteration: 1945, learning rate: 0.00875, Loss: 0.3708, Accuracy:0.844\nIteration: 1946, learning rate: 0.00875, Loss: 0.3579, Accuracy:0.828\nIteration: 1947, learning rate: 0.00875, Loss: 0.3807, Accuracy:0.820\nIteration: 1948, learning rate: 0.00875, Loss: 0.3782, Accuracy:0.812\nIteration: 1949, learning rate: 0.00875, Loss: 0.3718, Accuracy:0.844\nIteration: 1950, learning rate: 0.00875, Loss: 0.3905, Accuracy:0.844\nIteration: 1951, learning rate: 0.00875, Loss: 0.3931, Accuracy:0.852\nIteration: 1952, learning rate: 0.00875, Loss: 0.4536, Accuracy:0.781\nIteration: 1953, learning rate: 0.00875, Loss: 0.3828, Accuracy:0.774\nEpoch: 63, Loss: 0.3805, Accuracy:0.824, Val Loss: 0.3468, Val Accuracy: 0.842\nval_loss_decreased from 0.3542 to 0.3468, saving_checkpoint for epoch 63\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1954, learning rate: 0.00875, Loss: 0.4512, Accuracy:0.836\nIteration: 1955, learning rate: 0.00875, Loss: 0.4400, Accuracy:0.781\nIteration: 1956, learning rate: 0.00875, Loss: 0.4120, Accuracy:0.820\nIteration: 1957, learning rate: 0.00875, Loss: 0.3891, Accuracy:0.852\nIteration: 1958, learning rate: 0.00875, Loss: 0.3027, Accuracy:0.867\nIteration: 1959, learning rate: 0.00874, Loss: 0.4745, Accuracy:0.789\nIteration: 1960, learning rate: 0.00874, Loss: 0.4070, Accuracy:0.805\nIteration: 1961, learning rate: 0.00874, Loss: 0.3446, Accuracy:0.812\nIteration: 1962, learning rate: 0.00874, Loss: 0.3417, Accuracy:0.867\nIteration: 1963, learning rate: 0.00874, Loss: 0.3704, Accuracy:0.828\nIteration: 1964, learning rate: 0.00874, Loss: 0.3508, Accuracy:0.844\nIteration: 1965, learning rate: 0.00874, Loss: 0.3849, Accuracy:0.820\nIteration: 1966, learning rate: 0.00874, Loss: 0.3621, Accuracy:0.852\nIteration: 1967, learning rate: 0.00874, Loss: 0.4307, Accuracy:0.789\nIteration: 1968, learning rate: 0.00874, Loss: 0.3792, Accuracy:0.797\nIteration: 1969, learning rate: 0.00874, Loss: 0.3996, Accuracy:0.797\nIteration: 1970, learning rate: 0.00874, Loss: 0.4163, Accuracy:0.828\nIteration: 1971, learning rate: 0.00874, Loss: 0.3021, Accuracy:0.883\nIteration: 1972, learning rate: 0.00874, Loss: 0.3988, Accuracy:0.828\nIteration: 1973, learning rate: 0.00874, Loss: 0.4022, Accuracy:0.820\nIteration: 1974, learning rate: 0.00874, Loss: 0.3736, Accuracy:0.859\nIteration: 1975, learning rate: 0.00874, Loss: 0.3018, Accuracy:0.898\nIteration: 1976, learning rate: 0.00874, Loss: 0.2964, Accuracy:0.875\nIteration: 1977, learning rate: 0.00874, Loss: 0.3960, Accuracy:0.820\nIteration: 1978, learning rate: 0.00873, Loss: 0.4141, Accuracy:0.828\nIteration: 1979, learning rate: 0.00873, Loss: 0.3604, Accuracy:0.844\nIteration: 1980, learning rate: 0.00873, Loss: 0.4028, Accuracy:0.836\nIteration: 1981, learning rate: 0.00873, Loss: 0.4404, Accuracy:0.812\nIteration: 1982, learning rate: 0.00873, Loss: 0.3831, Accuracy:0.812\nIteration: 1983, learning rate: 0.00873, Loss: 0.4320, Accuracy:0.805\nIteration: 1984, learning rate: 0.00873, Loss: 0.4091, Accuracy:0.839\nEpoch: 64, Loss: 0.3861, Accuracy:0.830, Val Loss: 0.4174, Val Accuracy: 0.798\nIteration: 1985, learning rate: 0.00873, Loss: 0.3639, Accuracy:0.820\nIteration: 1986, learning rate: 0.00873, Loss: 0.4304, Accuracy:0.773\nIteration: 1987, learning rate: 0.00873, Loss: 0.3683, Accuracy:0.859\nIteration: 1988, learning rate: 0.00873, Loss: 0.3683, Accuracy:0.859\nIteration: 1989, learning rate: 0.00873, Loss: 0.3683, Accuracy:0.852\nIteration: 1990, learning rate: 0.00873, Loss: 0.3381, Accuracy:0.859\nIteration: 1991, learning rate: 0.00873, Loss: 0.3993, Accuracy:0.836\nIteration: 1992, learning rate: 0.00873, Loss: 0.3236, Accuracy:0.844\nIteration: 1993, learning rate: 0.00873, Loss: 0.4237, Accuracy:0.812\nIteration: 1994, learning rate: 0.00873, Loss: 0.3881, Accuracy:0.828\nIteration: 1995, learning rate: 0.00873, Loss: 0.4421, Accuracy:0.766\nIteration: 1996, learning rate: 0.00872, Loss: 0.3878, Accuracy:0.852\nIteration: 1997, learning rate: 0.00872, Loss: 0.3702, Accuracy:0.820\nIteration: 1998, learning rate: 0.00872, Loss: 0.3786, Accuracy:0.805\nIteration: 1999, learning rate: 0.00872, Loss: 0.3166, Accuracy:0.891\nIteration: 2000, learning rate: 0.00872, Loss: 0.4350, Accuracy:0.781\nIteration: 2001, learning rate: 0.00872, Loss: 0.3555, Accuracy:0.805\nIteration: 2002, learning rate: 0.00872, Loss: 0.3013, Accuracy:0.852\nIteration: 2003, learning rate: 0.00872, Loss: 0.3294, Accuracy:0.859\nIteration: 2004, learning rate: 0.00872, Loss: 0.4430, Accuracy:0.805\nIteration: 2005, learning rate: 0.00872, Loss: 0.4274, Accuracy:0.805\nIteration: 2006, learning rate: 0.00872, Loss: 0.4087, Accuracy:0.812\nIteration: 2007, learning rate: 0.00872, Loss: 0.3811, Accuracy:0.836\nIteration: 2008, learning rate: 0.00872, Loss: 0.3717, Accuracy:0.852\nIteration: 2009, learning rate: 0.00872, Loss: 0.3356, Accuracy:0.883\nIteration: 2010, learning rate: 0.00872, Loss: 0.3474, Accuracy:0.852\nIteration: 2011, learning rate: 0.00872, Loss: 0.3712, Accuracy:0.844\nIteration: 2012, learning rate: 0.00872, Loss: 0.3941, Accuracy:0.812\nIteration: 2013, learning rate: 0.00872, Loss: 0.4045, Accuracy:0.773\nIteration: 2014, learning rate: 0.00871, Loss: 0.4601, Accuracy:0.758\nIteration: 2015, learning rate: 0.00871, Loss: 0.3603, Accuracy:0.882\nEpoch: 65, Loss: 0.3804, Accuracy:0.829, Val Loss: 0.3752, Val Accuracy: 0.823\nIteration: 2016, learning rate: 0.00871, Loss: 0.3981, Accuracy:0.836\nIteration: 2017, learning rate: 0.00871, Loss: 0.3662, Accuracy:0.828\nIteration: 2018, learning rate: 0.00871, Loss: 0.4112, Accuracy:0.820\nIteration: 2019, learning rate: 0.00871, Loss: 0.3169, Accuracy:0.867\nIteration: 2020, learning rate: 0.00871, Loss: 0.3622, Accuracy:0.812\nIteration: 2021, learning rate: 0.00871, Loss: 0.3587, Accuracy:0.875\nIteration: 2022, learning rate: 0.00871, Loss: 0.3906, Accuracy:0.828\nIteration: 2023, learning rate: 0.00871, Loss: 0.3887, Accuracy:0.812\nIteration: 2024, learning rate: 0.00871, Loss: 0.3695, Accuracy:0.828\nIteration: 2025, learning rate: 0.00871, Loss: 0.3148, Accuracy:0.883\nIteration: 2026, learning rate: 0.00871, Loss: 0.3370, Accuracy:0.820\nIteration: 2027, learning rate: 0.00871, Loss: 0.4215, Accuracy:0.820\nIteration: 2028, learning rate: 0.00871, Loss: 0.3854, Accuracy:0.852\nIteration: 2029, learning rate: 0.00871, Loss: 0.4352, Accuracy:0.781\nIteration: 2030, learning rate: 0.00871, Loss: 0.3618, Accuracy:0.883\nIteration: 2031, learning rate: 0.00871, Loss: 0.3247, Accuracy:0.852\nIteration: 2032, learning rate: 0.00871, Loss: 0.3679, Accuracy:0.812\nIteration: 2033, learning rate: 0.00870, Loss: 0.4105, Accuracy:0.820\nIteration: 2034, learning rate: 0.00870, Loss: 0.3893, Accuracy:0.859\nIteration: 2035, learning rate: 0.00870, Loss: 0.3049, Accuracy:0.844\nIteration: 2036, learning rate: 0.00870, Loss: 0.3972, Accuracy:0.820\nIteration: 2037, learning rate: 0.00870, Loss: 0.3882, Accuracy:0.852\nIteration: 2038, learning rate: 0.00870, Loss: 0.3886, Accuracy:0.836\nIteration: 2039, learning rate: 0.00870, Loss: 0.3963, Accuracy:0.836\nIteration: 2040, learning rate: 0.00870, Loss: 0.3410, Accuracy:0.859\nIteration: 2041, learning rate: 0.00870, Loss: 0.3630, Accuracy:0.812\nIteration: 2042, learning rate: 0.00870, Loss: 0.4081, Accuracy:0.812\nIteration: 2043, learning rate: 0.00870, Loss: 0.3800, Accuracy:0.812\nIteration: 2044, learning rate: 0.00870, Loss: 0.3503, Accuracy:0.852\nIteration: 2045, learning rate: 0.00870, Loss: 0.3485, Accuracy:0.844\nIteration: 2046, learning rate: 0.00870, Loss: 0.4170, Accuracy:0.828\nEpoch: 66, Loss: 0.3740, Accuracy:0.835, Val Loss: 0.4213, Val Accuracy: 0.791\nIteration: 2047, learning rate: 0.00870, Loss: 0.3404, Accuracy:0.859\nIteration: 2048, learning rate: 0.00870, Loss: 0.3204, Accuracy:0.867\nIteration: 2049, learning rate: 0.00870, Loss: 0.4811, Accuracy:0.773\nIteration: 2050, learning rate: 0.00870, Loss: 0.3208, Accuracy:0.836\nIteration: 2051, learning rate: 0.00869, Loss: 0.3469, Accuracy:0.844\nIteration: 2052, learning rate: 0.00869, Loss: 0.4207, Accuracy:0.805\nIteration: 2053, learning rate: 0.00869, Loss: 0.2927, Accuracy:0.875\nIteration: 2054, learning rate: 0.00869, Loss: 0.3307, Accuracy:0.852\nIteration: 2055, learning rate: 0.00869, Loss: 0.3500, Accuracy:0.836\nIteration: 2056, learning rate: 0.00869, Loss: 0.4206, Accuracy:0.797\nIteration: 2057, learning rate: 0.00869, Loss: 0.2427, Accuracy:0.922\nIteration: 2058, learning rate: 0.00869, Loss: 0.4229, Accuracy:0.820\nIteration: 2059, learning rate: 0.00869, Loss: 0.3713, Accuracy:0.859\nIteration: 2060, learning rate: 0.00869, Loss: 0.4708, Accuracy:0.750\nIteration: 2061, learning rate: 0.00869, Loss: 0.3364, Accuracy:0.836\nIteration: 2062, learning rate: 0.00869, Loss: 0.3583, Accuracy:0.852\nIteration: 2063, learning rate: 0.00869, Loss: 0.3348, Accuracy:0.867\nIteration: 2064, learning rate: 0.00869, Loss: 0.4579, Accuracy:0.773\nIteration: 2065, learning rate: 0.00869, Loss: 0.3560, Accuracy:0.836\nIteration: 2066, learning rate: 0.00869, Loss: 0.3928, Accuracy:0.852\nIteration: 2067, learning rate: 0.00869, Loss: 0.3483, Accuracy:0.844\nIteration: 2068, learning rate: 0.00869, Loss: 0.4149, Accuracy:0.781\nIteration: 2069, learning rate: 0.00869, Loss: 0.3710, Accuracy:0.828\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2070, learning rate: 0.00868, Loss: 0.4369, Accuracy:0.781\nIteration: 2071, learning rate: 0.00868, Loss: 0.3576, Accuracy:0.844\nIteration: 2072, learning rate: 0.00868, Loss: 0.3540, Accuracy:0.844\nIteration: 2073, learning rate: 0.00868, Loss: 0.3998, Accuracy:0.805\nIteration: 2074, learning rate: 0.00868, Loss: 0.2944, Accuracy:0.875\nIteration: 2075, learning rate: 0.00868, Loss: 0.4044, Accuracy:0.812\nIteration: 2076, learning rate: 0.00868, Loss: 0.3128, Accuracy:0.867\nIteration: 2077, learning rate: 0.00868, Loss: 0.3283, Accuracy:0.871\nEpoch: 67, Loss: 0.3674, Accuracy:0.834, Val Loss: 0.3885, Val Accuracy: 0.821\nIteration: 2078, learning rate: 0.00868, Loss: 0.3085, Accuracy:0.875\nIteration: 2079, learning rate: 0.00868, Loss: 0.3176, Accuracy:0.852\nIteration: 2080, learning rate: 0.00868, Loss: 0.3064, Accuracy:0.891\nIteration: 2081, learning rate: 0.00868, Loss: 0.3688, Accuracy:0.859\nIteration: 2082, learning rate: 0.00868, Loss: 0.3773, Accuracy:0.820\nIteration: 2083, learning rate: 0.00868, Loss: 0.4180, Accuracy:0.805\nIteration: 2084, learning rate: 0.00868, Loss: 0.4320, Accuracy:0.797\nIteration: 2085, learning rate: 0.00868, Loss: 0.3413, Accuracy:0.852\nIteration: 2086, learning rate: 0.00868, Loss: 0.3459, Accuracy:0.828\nIteration: 2087, learning rate: 0.00868, Loss: 0.4140, Accuracy:0.820\nIteration: 2088, learning rate: 0.00867, Loss: 0.4086, Accuracy:0.805\nIteration: 2089, learning rate: 0.00867, Loss: 0.3709, Accuracy:0.844\nIteration: 2090, learning rate: 0.00867, Loss: 0.4851, Accuracy:0.750\nIteration: 2091, learning rate: 0.00867, Loss: 0.3318, Accuracy:0.867\nIteration: 2092, learning rate: 0.00867, Loss: 0.3141, Accuracy:0.867\nIteration: 2093, learning rate: 0.00867, Loss: 0.3636, Accuracy:0.828\nIteration: 2094, learning rate: 0.00867, Loss: 0.4002, Accuracy:0.797\nIteration: 2095, learning rate: 0.00867, Loss: 0.3975, Accuracy:0.750\nIteration: 2096, learning rate: 0.00867, Loss: 0.3526, Accuracy:0.836\nIteration: 2097, learning rate: 0.00867, Loss: 0.3775, Accuracy:0.820\nIteration: 2098, learning rate: 0.00867, Loss: 0.3359, Accuracy:0.875\nIteration: 2099, learning rate: 0.00867, Loss: 0.3606, Accuracy:0.828\nIteration: 2100, learning rate: 0.00867, Loss: 0.3617, Accuracy:0.852\nIteration: 2101, learning rate: 0.00867, Loss: 0.4201, Accuracy:0.812\nIteration: 2102, learning rate: 0.00867, Loss: 0.3972, Accuracy:0.797\nIteration: 2103, learning rate: 0.00867, Loss: 0.3656, Accuracy:0.828\nIteration: 2104, learning rate: 0.00867, Loss: 0.3292, Accuracy:0.852\nIteration: 2105, learning rate: 0.00867, Loss: 0.3663, Accuracy:0.883\nIteration: 2106, learning rate: 0.00867, Loss: 0.3905, Accuracy:0.820\nIteration: 2107, learning rate: 0.00866, Loss: 0.3823, Accuracy:0.820\nIteration: 2108, learning rate: 0.00866, Loss: 0.4221, Accuracy:0.817\nEpoch: 68, Loss: 0.3730, Accuracy:0.831, Val Loss: 0.3607, Val Accuracy: 0.820\nIteration: 2109, learning rate: 0.00866, Loss: 0.4026, Accuracy:0.852\nIteration: 2110, learning rate: 0.00866, Loss: 0.3597, Accuracy:0.844\nIteration: 2111, learning rate: 0.00866, Loss: 0.3943, Accuracy:0.805\nIteration: 2112, learning rate: 0.00866, Loss: 0.3874, Accuracy:0.828\nIteration: 2113, learning rate: 0.00866, Loss: 0.3857, Accuracy:0.789\nIteration: 2114, learning rate: 0.00866, Loss: 0.3882, Accuracy:0.805\nIteration: 2115, learning rate: 0.00866, Loss: 0.3855, Accuracy:0.797\nIteration: 2116, learning rate: 0.00866, Loss: 0.4038, Accuracy:0.844\nIteration: 2117, learning rate: 0.00866, Loss: 0.3917, Accuracy:0.859\nIteration: 2118, learning rate: 0.00866, Loss: 0.3641, Accuracy:0.836\nIteration: 2119, learning rate: 0.00866, Loss: 0.4311, Accuracy:0.805\nIteration: 2120, learning rate: 0.00866, Loss: 0.4531, Accuracy:0.773\nIteration: 2121, learning rate: 0.00866, Loss: 0.3732, Accuracy:0.836\nIteration: 2122, learning rate: 0.00866, Loss: 0.5409, Accuracy:0.719\nIteration: 2123, learning rate: 0.00866, Loss: 0.4600, Accuracy:0.742\nIteration: 2124, learning rate: 0.00866, Loss: 0.3494, Accuracy:0.859\nIteration: 2125, learning rate: 0.00865, Loss: 0.3939, Accuracy:0.828\nIteration: 2126, learning rate: 0.00865, Loss: 0.3543, Accuracy:0.844\nIteration: 2127, learning rate: 0.00865, Loss: 0.3779, Accuracy:0.812\nIteration: 2128, learning rate: 0.00865, Loss: 0.3750, Accuracy:0.844\nIteration: 2129, learning rate: 0.00865, Loss: 0.4087, Accuracy:0.805\nIteration: 2130, learning rate: 0.00865, Loss: 0.4320, Accuracy:0.758\nIteration: 2131, learning rate: 0.00865, Loss: 0.3601, Accuracy:0.820\nIteration: 2132, learning rate: 0.00865, Loss: 0.3230, Accuracy:0.891\nIteration: 2133, learning rate: 0.00865, Loss: 0.3168, Accuracy:0.883\nIteration: 2134, learning rate: 0.00865, Loss: 0.4377, Accuracy:0.789\nIteration: 2135, learning rate: 0.00865, Loss: 0.4465, Accuracy:0.820\nIteration: 2136, learning rate: 0.00865, Loss: 0.4584, Accuracy:0.789\nIteration: 2137, learning rate: 0.00865, Loss: 0.4033, Accuracy:0.773\nIteration: 2138, learning rate: 0.00865, Loss: 0.3666, Accuracy:0.852\nIteration: 2139, learning rate: 0.00865, Loss: 0.3853, Accuracy:0.860\nEpoch: 69, Loss: 0.3971, Accuracy:0.818, Val Loss: 0.3721, Val Accuracy: 0.830\nIteration: 2140, learning rate: 0.00865, Loss: 0.3860, Accuracy:0.812\nIteration: 2141, learning rate: 0.00865, Loss: 0.2821, Accuracy:0.906\nIteration: 2142, learning rate: 0.00865, Loss: 0.4493, Accuracy:0.789\nIteration: 2143, learning rate: 0.00865, Loss: 0.3562, Accuracy:0.852\nIteration: 2144, learning rate: 0.00864, Loss: 0.4725, Accuracy:0.758\nIteration: 2145, learning rate: 0.00864, Loss: 0.4189, Accuracy:0.805\nIteration: 2146, learning rate: 0.00864, Loss: 0.4407, Accuracy:0.797\nIteration: 2147, learning rate: 0.00864, Loss: 0.3713, Accuracy:0.820\nIteration: 2148, learning rate: 0.00864, Loss: 0.3649, Accuracy:0.859\nIteration: 2149, learning rate: 0.00864, Loss: 0.2843, Accuracy:0.859\nIteration: 2150, learning rate: 0.00864, Loss: 0.4015, Accuracy:0.820\nIteration: 2151, learning rate: 0.00864, Loss: 0.4526, Accuracy:0.789\nIteration: 2152, learning rate: 0.00864, Loss: 0.3900, Accuracy:0.812\nIteration: 2153, learning rate: 0.00864, Loss: 0.3618, Accuracy:0.875\nIteration: 2154, learning rate: 0.00864, Loss: 0.3747, Accuracy:0.844\nIteration: 2155, learning rate: 0.00864, Loss: 0.3103, Accuracy:0.883\nIteration: 2156, learning rate: 0.00864, Loss: 0.4796, Accuracy:0.781\nIteration: 2157, learning rate: 0.00864, Loss: 0.3426, Accuracy:0.844\nIteration: 2158, learning rate: 0.00864, Loss: 0.3526, Accuracy:0.852\nIteration: 2159, learning rate: 0.00864, Loss: 0.3208, Accuracy:0.867\nIteration: 2160, learning rate: 0.00864, Loss: 0.3345, Accuracy:0.875\nIteration: 2161, learning rate: 0.00864, Loss: 0.3253, Accuracy:0.867\nIteration: 2162, learning rate: 0.00864, Loss: 0.3076, Accuracy:0.875\nIteration: 2163, learning rate: 0.00863, Loss: 0.4503, Accuracy:0.781\nIteration: 2164, learning rate: 0.00863, Loss: 0.4012, Accuracy:0.797\nIteration: 2165, learning rate: 0.00863, Loss: 0.3422, Accuracy:0.844\nIteration: 2166, learning rate: 0.00863, Loss: 0.3292, Accuracy:0.852\nIteration: 2167, learning rate: 0.00863, Loss: 0.3214, Accuracy:0.867\nIteration: 2168, learning rate: 0.00863, Loss: 0.3601, Accuracy:0.867\nIteration: 2169, learning rate: 0.00863, Loss: 0.3072, Accuracy:0.859\nIteration: 2170, learning rate: 0.00863, Loss: 0.3524, Accuracy:0.860\nEpoch: 70, Loss: 0.3692, Accuracy:0.838, Val Loss: 0.3995, Val Accuracy: 0.828\nIteration: 2171, learning rate: 0.00863, Loss: 0.2974, Accuracy:0.852\nIteration: 2172, learning rate: 0.00863, Loss: 0.3367, Accuracy:0.812\nIteration: 2173, learning rate: 0.00863, Loss: 0.4182, Accuracy:0.812\nIteration: 2174, learning rate: 0.00863, Loss: 0.3267, Accuracy:0.883\nIteration: 2175, learning rate: 0.00863, Loss: 0.4494, Accuracy:0.789\nIteration: 2176, learning rate: 0.00863, Loss: 0.3506, Accuracy:0.828\nIteration: 2177, learning rate: 0.00863, Loss: 0.3368, Accuracy:0.859\nIteration: 2178, learning rate: 0.00863, Loss: 0.3589, Accuracy:0.867\nIteration: 2179, learning rate: 0.00863, Loss: 0.3348, Accuracy:0.820\nIteration: 2180, learning rate: 0.00863, Loss: 0.3612, Accuracy:0.812\nIteration: 2181, learning rate: 0.00863, Loss: 0.3894, Accuracy:0.812\nIteration: 2182, learning rate: 0.00862, Loss: 0.3892, Accuracy:0.812\nIteration: 2183, learning rate: 0.00862, Loss: 0.3188, Accuracy:0.844\nIteration: 2184, learning rate: 0.00862, Loss: 0.3893, Accuracy:0.812\nIteration: 2185, learning rate: 0.00862, Loss: 0.3494, Accuracy:0.844\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2186, learning rate: 0.00862, Loss: 0.4487, Accuracy:0.758\nIteration: 2187, learning rate: 0.00862, Loss: 0.3181, Accuracy:0.836\nIteration: 2188, learning rate: 0.00862, Loss: 0.2920, Accuracy:0.867\nIteration: 2189, learning rate: 0.00862, Loss: 0.4405, Accuracy:0.797\nIteration: 2190, learning rate: 0.00862, Loss: 0.3957, Accuracy:0.828\nIteration: 2191, learning rate: 0.00862, Loss: 0.3936, Accuracy:0.797\nIteration: 2192, learning rate: 0.00862, Loss: 0.3626, Accuracy:0.812\nIteration: 2193, learning rate: 0.00862, Loss: 0.2916, Accuracy:0.867\nIteration: 2194, learning rate: 0.00862, Loss: 0.3791, Accuracy:0.852\nIteration: 2195, learning rate: 0.00862, Loss: 0.4313, Accuracy:0.781\nIteration: 2196, learning rate: 0.00862, Loss: 0.3053, Accuracy:0.852\nIteration: 2197, learning rate: 0.00862, Loss: 0.3470, Accuracy:0.820\nIteration: 2198, learning rate: 0.00862, Loss: 0.4131, Accuracy:0.820\nIteration: 2199, learning rate: 0.00862, Loss: 0.3511, Accuracy:0.812\nIteration: 2200, learning rate: 0.00862, Loss: 0.3210, Accuracy:0.875\nIteration: 2201, learning rate: 0.00861, Loss: 0.3848, Accuracy:0.839\nEpoch: 71, Loss: 0.3639, Accuracy:0.828, Val Loss: 0.3491, Val Accuracy: 0.839\nIteration: 2202, learning rate: 0.00861, Loss: 0.4232, Accuracy:0.820\nIteration: 2203, learning rate: 0.00861, Loss: 0.2986, Accuracy:0.867\nIteration: 2204, learning rate: 0.00861, Loss: 0.4278, Accuracy:0.781\nIteration: 2205, learning rate: 0.00861, Loss: 0.4215, Accuracy:0.805\nIteration: 2206, learning rate: 0.00861, Loss: 0.3174, Accuracy:0.867\nIteration: 2207, learning rate: 0.00861, Loss: 0.3254, Accuracy:0.859\nIteration: 2208, learning rate: 0.00861, Loss: 0.4245, Accuracy:0.797\nIteration: 2209, learning rate: 0.00861, Loss: 0.3780, Accuracy:0.820\nIteration: 2210, learning rate: 0.00861, Loss: 0.3836, Accuracy:0.836\nIteration: 2211, learning rate: 0.00861, Loss: 0.4118, Accuracy:0.820\nIteration: 2212, learning rate: 0.00861, Loss: 0.4627, Accuracy:0.773\nIteration: 2213, learning rate: 0.00861, Loss: 0.3723, Accuracy:0.820\nIteration: 2214, learning rate: 0.00861, Loss: 0.4045, Accuracy:0.789\nIteration: 2215, learning rate: 0.00861, Loss: 0.3415, Accuracy:0.844\nIteration: 2216, learning rate: 0.00861, Loss: 0.4060, Accuracy:0.812\nIteration: 2217, learning rate: 0.00861, Loss: 0.4480, Accuracy:0.805\nIteration: 2218, learning rate: 0.00861, Loss: 0.4390, Accuracy:0.766\nIteration: 2219, learning rate: 0.00860, Loss: 0.3557, Accuracy:0.859\nIteration: 2220, learning rate: 0.00860, Loss: 0.3916, Accuracy:0.797\nIteration: 2221, learning rate: 0.00860, Loss: 0.3321, Accuracy:0.859\nIteration: 2222, learning rate: 0.00860, Loss: 0.4277, Accuracy:0.758\nIteration: 2223, learning rate: 0.00860, Loss: 0.3457, Accuracy:0.812\nIteration: 2224, learning rate: 0.00860, Loss: 0.3934, Accuracy:0.766\nIteration: 2225, learning rate: 0.00860, Loss: 0.3679, Accuracy:0.844\nIteration: 2226, learning rate: 0.00860, Loss: 0.3655, Accuracy:0.820\nIteration: 2227, learning rate: 0.00860, Loss: 0.3928, Accuracy:0.820\nIteration: 2228, learning rate: 0.00860, Loss: 0.3737, Accuracy:0.812\nIteration: 2229, learning rate: 0.00860, Loss: 0.4237, Accuracy:0.812\nIteration: 2230, learning rate: 0.00860, Loss: 0.4189, Accuracy:0.828\nIteration: 2231, learning rate: 0.00860, Loss: 0.4394, Accuracy:0.789\nIteration: 2232, learning rate: 0.00860, Loss: 0.3688, Accuracy:0.806\nEpoch: 72, Loss: 0.3898, Accuracy:0.815, Val Loss: 0.3808, Val Accuracy: 0.825\nIteration: 2233, learning rate: 0.00860, Loss: 0.4046, Accuracy:0.812\nIteration: 2234, learning rate: 0.00860, Loss: 0.3846, Accuracy:0.812\nIteration: 2235, learning rate: 0.00860, Loss: 0.3595, Accuracy:0.867\nIteration: 2236, learning rate: 0.00860, Loss: 0.4171, Accuracy:0.789\nIteration: 2237, learning rate: 0.00860, Loss: 0.4577, Accuracy:0.781\nIteration: 2238, learning rate: 0.00859, Loss: 0.3904, Accuracy:0.867\nIteration: 2239, learning rate: 0.00859, Loss: 0.4773, Accuracy:0.797\nIteration: 2240, learning rate: 0.00859, Loss: 0.4295, Accuracy:0.789\nIteration: 2241, learning rate: 0.00859, Loss: 0.3418, Accuracy:0.836\nIteration: 2242, learning rate: 0.00859, Loss: 0.3649, Accuracy:0.828\nIteration: 2243, learning rate: 0.00859, Loss: 0.3947, Accuracy:0.805\nIteration: 2244, learning rate: 0.00859, Loss: 0.3530, Accuracy:0.859\nIteration: 2245, learning rate: 0.00859, Loss: 0.4004, Accuracy:0.797\nIteration: 2246, learning rate: 0.00859, Loss: 0.3609, Accuracy:0.859\nIteration: 2247, learning rate: 0.00859, Loss: 0.2665, Accuracy:0.906\nIteration: 2248, learning rate: 0.00859, Loss: 0.3262, Accuracy:0.875\nIteration: 2249, learning rate: 0.00859, Loss: 0.3530, Accuracy:0.836\nIteration: 2250, learning rate: 0.00859, Loss: 0.3674, Accuracy:0.812\nIteration: 2251, learning rate: 0.00859, Loss: 0.3929, Accuracy:0.820\nIteration: 2252, learning rate: 0.00859, Loss: 0.3491, Accuracy:0.852\nIteration: 2253, learning rate: 0.00859, Loss: 0.4591, Accuracy:0.750\nIteration: 2254, learning rate: 0.00859, Loss: 0.3025, Accuracy:0.859\nIteration: 2255, learning rate: 0.00859, Loss: 0.3674, Accuracy:0.844\nIteration: 2256, learning rate: 0.00859, Loss: 0.4065, Accuracy:0.828\nIteration: 2257, learning rate: 0.00858, Loss: 0.4049, Accuracy:0.828\nIteration: 2258, learning rate: 0.00858, Loss: 0.4256, Accuracy:0.852\nIteration: 2259, learning rate: 0.00858, Loss: 0.3715, Accuracy:0.797\nIteration: 2260, learning rate: 0.00858, Loss: 0.3164, Accuracy:0.898\nIteration: 2261, learning rate: 0.00858, Loss: 0.2973, Accuracy:0.883\nIteration: 2262, learning rate: 0.00858, Loss: 0.3192, Accuracy:0.883\nIteration: 2263, learning rate: 0.00858, Loss: 0.3318, Accuracy:0.882\nEpoch: 73, Loss: 0.3740, Accuracy:0.836, Val Loss: 0.3552, Val Accuracy: 0.847\nIteration: 2264, learning rate: 0.00858, Loss: 0.3832, Accuracy:0.812\nIteration: 2265, learning rate: 0.00858, Loss: 0.3403, Accuracy:0.875\nIteration: 2266, learning rate: 0.00858, Loss: 0.4055, Accuracy:0.805\nIteration: 2267, learning rate: 0.00858, Loss: 0.3687, Accuracy:0.812\nIteration: 2268, learning rate: 0.00858, Loss: 0.3733, Accuracy:0.820\nIteration: 2269, learning rate: 0.00858, Loss: 0.3730, Accuracy:0.859\nIteration: 2270, learning rate: 0.00858, Loss: 0.3479, Accuracy:0.852\nIteration: 2271, learning rate: 0.00858, Loss: 0.4156, Accuracy:0.820\nIteration: 2272, learning rate: 0.00858, Loss: 0.2990, Accuracy:0.867\nIteration: 2273, learning rate: 0.00858, Loss: 0.3602, Accuracy:0.836\nIteration: 2274, learning rate: 0.00858, Loss: 0.3312, Accuracy:0.812\nIteration: 2275, learning rate: 0.00858, Loss: 0.3911, Accuracy:0.820\nIteration: 2276, learning rate: 0.00857, Loss: 0.3997, Accuracy:0.828\nIteration: 2277, learning rate: 0.00857, Loss: 0.4005, Accuracy:0.859\nIteration: 2278, learning rate: 0.00857, Loss: 0.4075, Accuracy:0.828\nIteration: 2279, learning rate: 0.00857, Loss: 0.3974, Accuracy:0.836\nIteration: 2280, learning rate: 0.00857, Loss: 0.4161, Accuracy:0.820\nIteration: 2281, learning rate: 0.00857, Loss: 0.3441, Accuracy:0.805\nIteration: 2282, learning rate: 0.00857, Loss: 0.4198, Accuracy:0.820\nIteration: 2283, learning rate: 0.00857, Loss: 0.3853, Accuracy:0.812\nIteration: 2284, learning rate: 0.00857, Loss: 0.3316, Accuracy:0.867\nIteration: 2285, learning rate: 0.00857, Loss: 0.3815, Accuracy:0.852\nIteration: 2286, learning rate: 0.00857, Loss: 0.3945, Accuracy:0.797\nIteration: 2287, learning rate: 0.00857, Loss: 0.4209, Accuracy:0.781\nIteration: 2288, learning rate: 0.00857, Loss: 0.3336, Accuracy:0.867\nIteration: 2289, learning rate: 0.00857, Loss: 0.3449, Accuracy:0.867\nIteration: 2290, learning rate: 0.00857, Loss: 0.3238, Accuracy:0.891\nIteration: 2291, learning rate: 0.00857, Loss: 0.3535, Accuracy:0.844\nIteration: 2292, learning rate: 0.00857, Loss: 0.3914, Accuracy:0.781\nIteration: 2293, learning rate: 0.00857, Loss: 0.4088, Accuracy:0.820\nIteration: 2294, learning rate: 0.00857, Loss: 0.4107, Accuracy:0.817\nEpoch: 74, Loss: 0.3760, Accuracy:0.832, Val Loss: 0.4042, Val Accuracy: 0.810\nIteration: 2295, learning rate: 0.00857, Loss: 0.3909, Accuracy:0.789\nIteration: 2296, learning rate: 0.00856, Loss: 0.3641, Accuracy:0.820\nIteration: 2297, learning rate: 0.00856, Loss: 0.3289, Accuracy:0.883\nIteration: 2298, learning rate: 0.00856, Loss: 0.3604, Accuracy:0.820\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2299, learning rate: 0.00856, Loss: 0.4672, Accuracy:0.758\nIteration: 2300, learning rate: 0.00856, Loss: 0.4288, Accuracy:0.789\nIteration: 2301, learning rate: 0.00856, Loss: 0.3874, Accuracy:0.836\nIteration: 2302, learning rate: 0.00856, Loss: 0.2679, Accuracy:0.875\nIteration: 2303, learning rate: 0.00856, Loss: 0.3246, Accuracy:0.859\nIteration: 2304, learning rate: 0.00856, Loss: 0.3895, Accuracy:0.836\nIteration: 2305, learning rate: 0.00856, Loss: 0.3065, Accuracy:0.859\nIteration: 2306, learning rate: 0.00856, Loss: 0.3973, Accuracy:0.828\nIteration: 2307, learning rate: 0.00856, Loss: 0.3650, Accuracy:0.836\nIteration: 2308, learning rate: 0.00856, Loss: 0.3760, Accuracy:0.836\nIteration: 2309, learning rate: 0.00856, Loss: 0.4317, Accuracy:0.812\nIteration: 2310, learning rate: 0.00856, Loss: 0.3158, Accuracy:0.867\nIteration: 2311, learning rate: 0.00856, Loss: 0.3603, Accuracy:0.852\nIteration: 2312, learning rate: 0.00856, Loss: 0.3084, Accuracy:0.867\nIteration: 2313, learning rate: 0.00856, Loss: 0.4361, Accuracy:0.820\nIteration: 2314, learning rate: 0.00856, Loss: 0.4219, Accuracy:0.867\nIteration: 2315, learning rate: 0.00855, Loss: 0.3254, Accuracy:0.875\nIteration: 2316, learning rate: 0.00855, Loss: 0.3189, Accuracy:0.859\nIteration: 2317, learning rate: 0.00855, Loss: 0.3290, Accuracy:0.852\nIteration: 2318, learning rate: 0.00855, Loss: 0.3435, Accuracy:0.883\nIteration: 2319, learning rate: 0.00855, Loss: 0.3697, Accuracy:0.820\nIteration: 2320, learning rate: 0.00855, Loss: 0.3604, Accuracy:0.875\nIteration: 2321, learning rate: 0.00855, Loss: 0.3576, Accuracy:0.867\nIteration: 2322, learning rate: 0.00855, Loss: 0.4220, Accuracy:0.836\nIteration: 2323, learning rate: 0.00855, Loss: 0.3772, Accuracy:0.836\nIteration: 2324, learning rate: 0.00855, Loss: 0.3361, Accuracy:0.836\nIteration: 2325, learning rate: 0.00855, Loss: 0.3584, Accuracy:0.806\nEpoch: 75, Loss: 0.3654, Accuracy:0.841, Val Loss: 0.3322, Val Accuracy: 0.852\nval_loss_decreased from 0.3468 to 0.3322, saving_checkpoint for epoch 75\nIteration: 2326, learning rate: 0.00855, Loss: 0.3906, Accuracy:0.844\nIteration: 2327, learning rate: 0.00855, Loss: 0.3469, Accuracy:0.836\nIteration: 2328, learning rate: 0.00855, Loss: 0.3017, Accuracy:0.859\nIteration: 2329, learning rate: 0.00855, Loss: 0.3448, Accuracy:0.867\nIteration: 2330, learning rate: 0.00855, Loss: 0.3836, Accuracy:0.812\nIteration: 2331, learning rate: 0.00855, Loss: 0.3363, Accuracy:0.852\nIteration: 2332, learning rate: 0.00855, Loss: 0.3632, Accuracy:0.852\nIteration: 2333, learning rate: 0.00855, Loss: 0.4189, Accuracy:0.828\nIteration: 2334, learning rate: 0.00854, Loss: 0.3175, Accuracy:0.852\nIteration: 2335, learning rate: 0.00854, Loss: 0.3668, Accuracy:0.852\nIteration: 2336, learning rate: 0.00854, Loss: 0.3489, Accuracy:0.836\nIteration: 2337, learning rate: 0.00854, Loss: 0.3466, Accuracy:0.852\nIteration: 2338, learning rate: 0.00854, Loss: 0.3826, Accuracy:0.844\nIteration: 2339, learning rate: 0.00854, Loss: 0.3331, Accuracy:0.797\nIteration: 2340, learning rate: 0.00854, Loss: 0.3248, Accuracy:0.828\nIteration: 2341, learning rate: 0.00854, Loss: 0.3930, Accuracy:0.812\nIteration: 2342, learning rate: 0.00854, Loss: 0.3916, Accuracy:0.805\nIteration: 2343, learning rate: 0.00854, Loss: 0.4359, Accuracy:0.773\nIteration: 2344, learning rate: 0.00854, Loss: 0.2784, Accuracy:0.898\nIteration: 2345, learning rate: 0.00854, Loss: 0.3854, Accuracy:0.828\nIteration: 2346, learning rate: 0.00854, Loss: 0.4128, Accuracy:0.781\nIteration: 2347, learning rate: 0.00854, Loss: 0.3541, Accuracy:0.836\nIteration: 2348, learning rate: 0.00854, Loss: 0.3920, Accuracy:0.836\nIteration: 2349, learning rate: 0.00854, Loss: 0.3242, Accuracy:0.859\nIteration: 2350, learning rate: 0.00854, Loss: 0.2771, Accuracy:0.875\nIteration: 2351, learning rate: 0.00854, Loss: 0.3661, Accuracy:0.836\nIteration: 2352, learning rate: 0.00854, Loss: 0.3717, Accuracy:0.836\nIteration: 2353, learning rate: 0.00853, Loss: 0.4439, Accuracy:0.805\nIteration: 2354, learning rate: 0.00853, Loss: 0.3802, Accuracy:0.828\nIteration: 2355, learning rate: 0.00853, Loss: 0.4724, Accuracy:0.773\nIteration: 2356, learning rate: 0.00853, Loss: 0.4215, Accuracy:0.763\nEpoch: 76, Loss: 0.3680, Accuracy:0.831, Val Loss: 0.3627, Val Accuracy: 0.828\nIteration: 2357, learning rate: 0.00853, Loss: 0.3690, Accuracy:0.852\nIteration: 2358, learning rate: 0.00853, Loss: 0.4382, Accuracy:0.836\nIteration: 2359, learning rate: 0.00853, Loss: 0.5154, Accuracy:0.773\nIteration: 2360, learning rate: 0.00853, Loss: 0.3771, Accuracy:0.859\nIteration: 2361, learning rate: 0.00853, Loss: 0.3722, Accuracy:0.852\nIteration: 2362, learning rate: 0.00853, Loss: 0.3251, Accuracy:0.859\nIteration: 2363, learning rate: 0.00853, Loss: 0.3912, Accuracy:0.812\nIteration: 2364, learning rate: 0.00853, Loss: 0.3197, Accuracy:0.875\nIteration: 2365, learning rate: 0.00853, Loss: 0.3520, Accuracy:0.883\nIteration: 2366, learning rate: 0.00853, Loss: 0.3503, Accuracy:0.828\nIteration: 2367, learning rate: 0.00853, Loss: 0.3908, Accuracy:0.805\nIteration: 2368, learning rate: 0.00853, Loss: 0.4564, Accuracy:0.812\nIteration: 2369, learning rate: 0.00853, Loss: 0.3568, Accuracy:0.852\nIteration: 2370, learning rate: 0.00853, Loss: 0.4164, Accuracy:0.797\nIteration: 2371, learning rate: 0.00853, Loss: 0.3464, Accuracy:0.852\nIteration: 2372, learning rate: 0.00853, Loss: 0.3334, Accuracy:0.836\nIteration: 2373, learning rate: 0.00852, Loss: 0.3179, Accuracy:0.836\nIteration: 2374, learning rate: 0.00852, Loss: 0.2969, Accuracy:0.875\nIteration: 2375, learning rate: 0.00852, Loss: 0.4015, Accuracy:0.805\nIteration: 2376, learning rate: 0.00852, Loss: 0.2794, Accuracy:0.875\nIteration: 2377, learning rate: 0.00852, Loss: 0.2733, Accuracy:0.852\nIteration: 2378, learning rate: 0.00852, Loss: 0.3307, Accuracy:0.875\nIteration: 2379, learning rate: 0.00852, Loss: 0.4190, Accuracy:0.789\nIteration: 2380, learning rate: 0.00852, Loss: 0.3578, Accuracy:0.875\nIteration: 2381, learning rate: 0.00852, Loss: 0.3686, Accuracy:0.805\nIteration: 2382, learning rate: 0.00852, Loss: 0.3974, Accuracy:0.812\nIteration: 2383, learning rate: 0.00852, Loss: 0.3508, Accuracy:0.812\nIteration: 2384, learning rate: 0.00852, Loss: 0.3166, Accuracy:0.852\nIteration: 2385, learning rate: 0.00852, Loss: 0.3943, Accuracy:0.836\nIteration: 2386, learning rate: 0.00852, Loss: 0.3095, Accuracy:0.875\nIteration: 2387, learning rate: 0.00852, Loss: 0.2946, Accuracy:0.871\nEpoch: 77, Loss: 0.3619, Accuracy:0.840, Val Loss: 0.3859, Val Accuracy: 0.817\nIteration: 2388, learning rate: 0.00852, Loss: 0.3284, Accuracy:0.844\nIteration: 2389, learning rate: 0.00852, Loss: 0.3543, Accuracy:0.820\nIteration: 2390, learning rate: 0.00852, Loss: 0.3342, Accuracy:0.875\nIteration: 2391, learning rate: 0.00852, Loss: 0.3137, Accuracy:0.883\nIteration: 2392, learning rate: 0.00851, Loss: 0.3747, Accuracy:0.812\nIteration: 2393, learning rate: 0.00851, Loss: 0.2723, Accuracy:0.875\nIteration: 2394, learning rate: 0.00851, Loss: 0.3859, Accuracy:0.852\nIteration: 2395, learning rate: 0.00851, Loss: 0.3372, Accuracy:0.852\nIteration: 2396, learning rate: 0.00851, Loss: 0.3274, Accuracy:0.867\nIteration: 2397, learning rate: 0.00851, Loss: 0.3922, Accuracy:0.805\nIteration: 2398, learning rate: 0.00851, Loss: 0.3912, Accuracy:0.828\nIteration: 2399, learning rate: 0.00851, Loss: 0.3716, Accuracy:0.820\nIteration: 2400, learning rate: 0.00851, Loss: 0.4487, Accuracy:0.797\nIteration: 2401, learning rate: 0.00851, Loss: 0.3726, Accuracy:0.836\nIteration: 2402, learning rate: 0.00851, Loss: 0.4017, Accuracy:0.812\nIteration: 2403, learning rate: 0.00851, Loss: 0.3931, Accuracy:0.859\nIteration: 2404, learning rate: 0.00851, Loss: 0.3598, Accuracy:0.844\nIteration: 2405, learning rate: 0.00851, Loss: 0.3888, Accuracy:0.828\nIteration: 2406, learning rate: 0.00851, Loss: 0.3809, Accuracy:0.836\nIteration: 2407, learning rate: 0.00851, Loss: 0.2963, Accuracy:0.867\nIteration: 2408, learning rate: 0.00851, Loss: 0.3599, Accuracy:0.844\nIteration: 2409, learning rate: 0.00851, Loss: 0.3582, Accuracy:0.852\nIteration: 2410, learning rate: 0.00851, Loss: 0.3941, Accuracy:0.828\nIteration: 2411, learning rate: 0.00850, Loss: 0.3833, Accuracy:0.820\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2412, learning rate: 0.00850, Loss: 0.3783, Accuracy:0.867\nIteration: 2413, learning rate: 0.00850, Loss: 0.3688, Accuracy:0.844\nIteration: 2414, learning rate: 0.00850, Loss: 0.3824, Accuracy:0.844\nIteration: 2415, learning rate: 0.00850, Loss: 0.5100, Accuracy:0.766\nIteration: 2416, learning rate: 0.00850, Loss: 0.3310, Accuracy:0.844\nIteration: 2417, learning rate: 0.00850, Loss: 0.3360, Accuracy:0.852\nIteration: 2418, learning rate: 0.00850, Loss: 0.4351, Accuracy:0.796\nEpoch: 78, Loss: 0.3697, Accuracy:0.838, Val Loss: 0.4034, Val Accuracy: 0.813\nIteration: 2419, learning rate: 0.00850, Loss: 0.3377, Accuracy:0.828\nIteration: 2420, learning rate: 0.00850, Loss: 0.3580, Accuracy:0.797\nIteration: 2421, learning rate: 0.00850, Loss: 0.3450, Accuracy:0.836\nIteration: 2422, learning rate: 0.00850, Loss: 0.2965, Accuracy:0.859\nIteration: 2423, learning rate: 0.00850, Loss: 0.3663, Accuracy:0.836\nIteration: 2424, learning rate: 0.00850, Loss: 0.3755, Accuracy:0.812\nIteration: 2425, learning rate: 0.00850, Loss: 0.3992, Accuracy:0.828\nIteration: 2426, learning rate: 0.00850, Loss: 0.3498, Accuracy:0.844\nIteration: 2427, learning rate: 0.00850, Loss: 0.3245, Accuracy:0.859\nIteration: 2428, learning rate: 0.00850, Loss: 0.3050, Accuracy:0.898\nIteration: 2429, learning rate: 0.00850, Loss: 0.2768, Accuracy:0.898\nIteration: 2430, learning rate: 0.00850, Loss: 0.3466, Accuracy:0.844\nIteration: 2431, learning rate: 0.00849, Loss: 0.3788, Accuracy:0.781\nIteration: 2432, learning rate: 0.00849, Loss: 0.3358, Accuracy:0.883\nIteration: 2433, learning rate: 0.00849, Loss: 0.4765, Accuracy:0.781\nIteration: 2434, learning rate: 0.00849, Loss: 0.4520, Accuracy:0.781\nIteration: 2435, learning rate: 0.00849, Loss: 0.3258, Accuracy:0.852\nIteration: 2436, learning rate: 0.00849, Loss: 0.3451, Accuracy:0.812\nIteration: 2437, learning rate: 0.00849, Loss: 0.3847, Accuracy:0.836\nIteration: 2438, learning rate: 0.00849, Loss: 0.2928, Accuracy:0.891\nIteration: 2439, learning rate: 0.00849, Loss: 0.3653, Accuracy:0.852\nIteration: 2440, learning rate: 0.00849, Loss: 0.3145, Accuracy:0.852\nIteration: 2441, learning rate: 0.00849, Loss: 0.2882, Accuracy:0.883\nIteration: 2442, learning rate: 0.00849, Loss: 0.2881, Accuracy:0.867\nIteration: 2443, learning rate: 0.00849, Loss: 0.3564, Accuracy:0.844\nIteration: 2444, learning rate: 0.00849, Loss: 0.2755, Accuracy:0.898\nIteration: 2445, learning rate: 0.00849, Loss: 0.3296, Accuracy:0.859\nIteration: 2446, learning rate: 0.00849, Loss: 0.4333, Accuracy:0.805\nIteration: 2447, learning rate: 0.00849, Loss: 0.3256, Accuracy:0.891\nIteration: 2448, learning rate: 0.00849, Loss: 0.3054, Accuracy:0.867\nIteration: 2449, learning rate: 0.00849, Loss: 0.2135, Accuracy:0.892\nEpoch: 79, Loss: 0.3409, Accuracy:0.847, Val Loss: 0.4253, Val Accuracy: 0.794\nIteration: 2450, learning rate: 0.00848, Loss: 0.3090, Accuracy:0.844\nIteration: 2451, learning rate: 0.00848, Loss: 0.4201, Accuracy:0.805\nIteration: 2452, learning rate: 0.00848, Loss: 0.3260, Accuracy:0.828\nIteration: 2453, learning rate: 0.00848, Loss: 0.3339, Accuracy:0.828\nIteration: 2454, learning rate: 0.00848, Loss: 0.4475, Accuracy:0.750\nIteration: 2455, learning rate: 0.00848, Loss: 0.3957, Accuracy:0.828\nIteration: 2456, learning rate: 0.00848, Loss: 0.3657, Accuracy:0.812\nIteration: 2457, learning rate: 0.00848, Loss: 0.3872, Accuracy:0.844\nIteration: 2458, learning rate: 0.00848, Loss: 0.2786, Accuracy:0.906\nIteration: 2459, learning rate: 0.00848, Loss: 0.3493, Accuracy:0.836\nIteration: 2460, learning rate: 0.00848, Loss: 0.4800, Accuracy:0.758\nIteration: 2461, learning rate: 0.00848, Loss: 0.4798, Accuracy:0.750\nIteration: 2462, learning rate: 0.00848, Loss: 0.3059, Accuracy:0.859\nIteration: 2463, learning rate: 0.00848, Loss: 0.3197, Accuracy:0.883\nIteration: 2464, learning rate: 0.00848, Loss: 0.3689, Accuracy:0.820\nIteration: 2465, learning rate: 0.00848, Loss: 0.3194, Accuracy:0.875\nIteration: 2466, learning rate: 0.00848, Loss: 0.3456, Accuracy:0.859\nIteration: 2467, learning rate: 0.00848, Loss: 0.2779, Accuracy:0.883\nIteration: 2468, learning rate: 0.00848, Loss: 0.3259, Accuracy:0.898\nIteration: 2469, learning rate: 0.00848, Loss: 0.4155, Accuracy:0.812\nIteration: 2470, learning rate: 0.00847, Loss: 0.3862, Accuracy:0.852\nIteration: 2471, learning rate: 0.00847, Loss: 0.3340, Accuracy:0.875\nIteration: 2472, learning rate: 0.00847, Loss: 0.4218, Accuracy:0.781\nIteration: 2473, learning rate: 0.00847, Loss: 0.3390, Accuracy:0.852\nIteration: 2474, learning rate: 0.00847, Loss: 0.4028, Accuracy:0.812\nIteration: 2475, learning rate: 0.00847, Loss: 0.3116, Accuracy:0.875\nIteration: 2476, learning rate: 0.00847, Loss: 0.3368, Accuracy:0.859\nIteration: 2477, learning rate: 0.00847, Loss: 0.2693, Accuracy:0.891\nIteration: 2478, learning rate: 0.00847, Loss: 0.3289, Accuracy:0.875\nIteration: 2479, learning rate: 0.00847, Loss: 0.4288, Accuracy:0.789\nIteration: 2480, learning rate: 0.00847, Loss: 0.3868, Accuracy:0.806\nEpoch: 80, Loss: 0.3612, Accuracy:0.837, Val Loss: 0.3641, Val Accuracy: 0.830\nIteration: 2481, learning rate: 0.00847, Loss: 0.4244, Accuracy:0.812\nIteration: 2482, learning rate: 0.00847, Loss: 0.3832, Accuracy:0.844\nIteration: 2483, learning rate: 0.00847, Loss: 0.4228, Accuracy:0.773\nIteration: 2484, learning rate: 0.00847, Loss: 0.3167, Accuracy:0.852\nIteration: 2485, learning rate: 0.00847, Loss: 0.4024, Accuracy:0.828\nIteration: 2486, learning rate: 0.00847, Loss: 0.2279, Accuracy:0.914\nIteration: 2487, learning rate: 0.00847, Loss: 0.3275, Accuracy:0.859\nIteration: 2488, learning rate: 0.00847, Loss: 0.3660, Accuracy:0.828\nIteration: 2489, learning rate: 0.00847, Loss: 0.3176, Accuracy:0.891\nIteration: 2490, learning rate: 0.00846, Loss: 0.3081, Accuracy:0.883\nIteration: 2491, learning rate: 0.00846, Loss: 0.3245, Accuracy:0.859\nIteration: 2492, learning rate: 0.00846, Loss: 0.3580, Accuracy:0.820\nIteration: 2493, learning rate: 0.00846, Loss: 0.3814, Accuracy:0.836\nIteration: 2494, learning rate: 0.00846, Loss: 0.2616, Accuracy:0.898\nIteration: 2495, learning rate: 0.00846, Loss: 0.3581, Accuracy:0.836\nIteration: 2496, learning rate: 0.00846, Loss: 0.4449, Accuracy:0.766\nIteration: 2497, learning rate: 0.00846, Loss: 0.3913, Accuracy:0.812\nIteration: 2498, learning rate: 0.00846, Loss: 0.4059, Accuracy:0.812\nIteration: 2499, learning rate: 0.00846, Loss: 0.3276, Accuracy:0.906\nIteration: 2500, learning rate: 0.00846, Loss: 0.3227, Accuracy:0.883\nIteration: 2501, learning rate: 0.00846, Loss: 0.4883, Accuracy:0.805\nIteration: 2502, learning rate: 0.00846, Loss: 0.2474, Accuracy:0.914\nIteration: 2503, learning rate: 0.00846, Loss: 0.2861, Accuracy:0.898\nIteration: 2504, learning rate: 0.00846, Loss: 0.4420, Accuracy:0.805\nIteration: 2505, learning rate: 0.00846, Loss: 0.3536, Accuracy:0.859\nIteration: 2506, learning rate: 0.00846, Loss: 0.4216, Accuracy:0.797\nIteration: 2507, learning rate: 0.00846, Loss: 0.3245, Accuracy:0.820\nIteration: 2508, learning rate: 0.00846, Loss: 0.2874, Accuracy:0.898\nIteration: 2509, learning rate: 0.00845, Loss: 0.3647, Accuracy:0.836\nIteration: 2510, learning rate: 0.00845, Loss: 0.3961, Accuracy:0.844\nIteration: 2511, learning rate: 0.00845, Loss: 0.2470, Accuracy:0.871\nEpoch: 81, Loss: 0.3526, Accuracy:0.847, Val Loss: 0.3745, Val Accuracy: 0.829\nIteration: 2512, learning rate: 0.00845, Loss: 0.3336, Accuracy:0.867\nIteration: 2513, learning rate: 0.00845, Loss: 0.2972, Accuracy:0.852\nIteration: 2514, learning rate: 0.00845, Loss: 0.4000, Accuracy:0.836\nIteration: 2515, learning rate: 0.00845, Loss: 0.3551, Accuracy:0.852\nIteration: 2516, learning rate: 0.00845, Loss: 0.3732, Accuracy:0.820\nIteration: 2517, learning rate: 0.00845, Loss: 0.3193, Accuracy:0.867\nIteration: 2518, learning rate: 0.00845, Loss: 0.3356, Accuracy:0.859\nIteration: 2519, learning rate: 0.00845, Loss: 0.3432, Accuracy:0.828\nIteration: 2520, learning rate: 0.00845, Loss: 0.3164, Accuracy:0.875\nIteration: 2521, learning rate: 0.00845, Loss: 0.4117, Accuracy:0.820\nIteration: 2522, learning rate: 0.00845, Loss: 0.2981, Accuracy:0.867\nIteration: 2523, learning rate: 0.00845, Loss: 0.3560, Accuracy:0.867\nIteration: 2524, learning rate: 0.00845, Loss: 0.3482, Accuracy:0.875\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2525, learning rate: 0.00845, Loss: 0.3076, Accuracy:0.891\nIteration: 2526, learning rate: 0.00845, Loss: 0.3051, Accuracy:0.859\nIteration: 2527, learning rate: 0.00845, Loss: 0.3516, Accuracy:0.844\nIteration: 2528, learning rate: 0.00845, Loss: 0.2757, Accuracy:0.898\nIteration: 2529, learning rate: 0.00844, Loss: 0.3933, Accuracy:0.844\nIteration: 2530, learning rate: 0.00844, Loss: 0.3372, Accuracy:0.867\nIteration: 2531, learning rate: 0.00844, Loss: 0.2578, Accuracy:0.914\nIteration: 2532, learning rate: 0.00844, Loss: 0.3162, Accuracy:0.867\nIteration: 2533, learning rate: 0.00844, Loss: 0.4039, Accuracy:0.820\nIteration: 2534, learning rate: 0.00844, Loss: 0.3716, Accuracy:0.812\nIteration: 2535, learning rate: 0.00844, Loss: 0.3928, Accuracy:0.836\nIteration: 2536, learning rate: 0.00844, Loss: 0.4179, Accuracy:0.844\nIteration: 2537, learning rate: 0.00844, Loss: 0.2798, Accuracy:0.898\nIteration: 2538, learning rate: 0.00844, Loss: 0.2726, Accuracy:0.898\nIteration: 2539, learning rate: 0.00844, Loss: 0.3760, Accuracy:0.836\nIteration: 2540, learning rate: 0.00844, Loss: 0.2766, Accuracy:0.898\nIteration: 2541, learning rate: 0.00844, Loss: 0.4001, Accuracy:0.797\nIteration: 2542, learning rate: 0.00844, Loss: 0.4177, Accuracy:0.817\nEpoch: 82, Loss: 0.3433, Accuracy:0.856, Val Loss: 0.3287, Val Accuracy: 0.862\nval_loss_decreased from 0.3322 to 0.3287, saving_checkpoint for epoch 82\nIteration: 2543, learning rate: 0.00844, Loss: 0.3731, Accuracy:0.828\nIteration: 2544, learning rate: 0.00844, Loss: 0.3586, Accuracy:0.812\nIteration: 2545, learning rate: 0.00844, Loss: 0.3530, Accuracy:0.805\nIteration: 2546, learning rate: 0.00844, Loss: 0.4201, Accuracy:0.812\nIteration: 2547, learning rate: 0.00844, Loss: 0.3212, Accuracy:0.875\nIteration: 2548, learning rate: 0.00844, Loss: 0.3553, Accuracy:0.820\nIteration: 2549, learning rate: 0.00843, Loss: 0.3813, Accuracy:0.852\nIteration: 2550, learning rate: 0.00843, Loss: 0.3061, Accuracy:0.898\nIteration: 2551, learning rate: 0.00843, Loss: 0.3571, Accuracy:0.844\nIteration: 2552, learning rate: 0.00843, Loss: 0.4146, Accuracy:0.836\nIteration: 2553, learning rate: 0.00843, Loss: 0.3000, Accuracy:0.859\nIteration: 2554, learning rate: 0.00843, Loss: 0.3381, Accuracy:0.844\nIteration: 2555, learning rate: 0.00843, Loss: 0.2766, Accuracy:0.875\nIteration: 2556, learning rate: 0.00843, Loss: 0.2491, Accuracy:0.867\nIteration: 2557, learning rate: 0.00843, Loss: 0.2959, Accuracy:0.875\nIteration: 2558, learning rate: 0.00843, Loss: 0.3658, Accuracy:0.836\nIteration: 2559, learning rate: 0.00843, Loss: 0.3780, Accuracy:0.820\nIteration: 2560, learning rate: 0.00843, Loss: 0.3640, Accuracy:0.859\nIteration: 2561, learning rate: 0.00843, Loss: 0.3179, Accuracy:0.867\nIteration: 2562, learning rate: 0.00843, Loss: 0.3269, Accuracy:0.867\nIteration: 2563, learning rate: 0.00843, Loss: 0.4187, Accuracy:0.789\nIteration: 2564, learning rate: 0.00843, Loss: 0.3223, Accuracy:0.867\nIteration: 2565, learning rate: 0.00843, Loss: 0.3542, Accuracy:0.820\nIteration: 2566, learning rate: 0.00843, Loss: 0.3855, Accuracy:0.820\nIteration: 2567, learning rate: 0.00843, Loss: 0.3315, Accuracy:0.844\nIteration: 2568, learning rate: 0.00843, Loss: 0.3297, Accuracy:0.875\nIteration: 2569, learning rate: 0.00842, Loss: 0.3769, Accuracy:0.844\nIteration: 2570, learning rate: 0.00842, Loss: 0.3559, Accuracy:0.867\nIteration: 2571, learning rate: 0.00842, Loss: 0.4040, Accuracy:0.828\nIteration: 2572, learning rate: 0.00842, Loss: 0.3729, Accuracy:0.812\nIteration: 2573, learning rate: 0.00842, Loss: 0.3310, Accuracy:0.839\nEpoch: 83, Loss: 0.3495, Accuracy:0.844, Val Loss: 0.3468, Val Accuracy: 0.841\nIteration: 2574, learning rate: 0.00842, Loss: 0.3386, Accuracy:0.859\nIteration: 2575, learning rate: 0.00842, Loss: 0.3144, Accuracy:0.844\nIteration: 2576, learning rate: 0.00842, Loss: 0.3454, Accuracy:0.828\nIteration: 2577, learning rate: 0.00842, Loss: 0.3321, Accuracy:0.906\nIteration: 2578, learning rate: 0.00842, Loss: 0.3302, Accuracy:0.867\nIteration: 2579, learning rate: 0.00842, Loss: 0.3890, Accuracy:0.797\nIteration: 2580, learning rate: 0.00842, Loss: 0.3473, Accuracy:0.836\nIteration: 2581, learning rate: 0.00842, Loss: 0.3172, Accuracy:0.891\nIteration: 2582, learning rate: 0.00842, Loss: 0.3577, Accuracy:0.844\nIteration: 2583, learning rate: 0.00842, Loss: 0.3255, Accuracy:0.867\nIteration: 2584, learning rate: 0.00842, Loss: 0.2832, Accuracy:0.875\nIteration: 2585, learning rate: 0.00842, Loss: 0.3275, Accuracy:0.852\nIteration: 2586, learning rate: 0.00842, Loss: 0.3259, Accuracy:0.859\nIteration: 2587, learning rate: 0.00842, Loss: 0.3737, Accuracy:0.828\nIteration: 2588, learning rate: 0.00842, Loss: 0.3586, Accuracy:0.828\nIteration: 2589, learning rate: 0.00841, Loss: 0.2976, Accuracy:0.867\nIteration: 2590, learning rate: 0.00841, Loss: 0.3486, Accuracy:0.867\nIteration: 2591, learning rate: 0.00841, Loss: 0.3502, Accuracy:0.852\nIteration: 2592, learning rate: 0.00841, Loss: 0.3952, Accuracy:0.820\nIteration: 2593, learning rate: 0.00841, Loss: 0.2586, Accuracy:0.898\nIteration: 2594, learning rate: 0.00841, Loss: 0.3105, Accuracy:0.883\nIteration: 2595, learning rate: 0.00841, Loss: 0.3066, Accuracy:0.875\nIteration: 2596, learning rate: 0.00841, Loss: 0.3963, Accuracy:0.820\nIteration: 2597, learning rate: 0.00841, Loss: 0.3720, Accuracy:0.867\nIteration: 2598, learning rate: 0.00841, Loss: 0.3172, Accuracy:0.867\nIteration: 2599, learning rate: 0.00841, Loss: 0.4322, Accuracy:0.828\nIteration: 2600, learning rate: 0.00841, Loss: 0.3298, Accuracy:0.867\nIteration: 2601, learning rate: 0.00841, Loss: 0.3385, Accuracy:0.836\nIteration: 2602, learning rate: 0.00841, Loss: 0.3148, Accuracy:0.867\nIteration: 2603, learning rate: 0.00841, Loss: 0.3900, Accuracy:0.852\nIteration: 2604, learning rate: 0.00841, Loss: 0.3209, Accuracy:0.839\nEpoch: 84, Loss: 0.3402, Accuracy:0.854, Val Loss: 0.3571, Val Accuracy: 0.846\nIteration: 2605, learning rate: 0.00841, Loss: 0.3886, Accuracy:0.789\nIteration: 2606, learning rate: 0.00841, Loss: 0.3502, Accuracy:0.867\nIteration: 2607, learning rate: 0.00841, Loss: 0.3974, Accuracy:0.820\nIteration: 2608, learning rate: 0.00841, Loss: 0.4334, Accuracy:0.781\nIteration: 2609, learning rate: 0.00840, Loss: 0.4064, Accuracy:0.828\nIteration: 2610, learning rate: 0.00840, Loss: 0.2842, Accuracy:0.883\nIteration: 2611, learning rate: 0.00840, Loss: 0.3527, Accuracy:0.859\nIteration: 2612, learning rate: 0.00840, Loss: 0.3652, Accuracy:0.812\nIteration: 2613, learning rate: 0.00840, Loss: 0.3688, Accuracy:0.820\nIteration: 2614, learning rate: 0.00840, Loss: 0.3977, Accuracy:0.828\nIteration: 2615, learning rate: 0.00840, Loss: 0.2820, Accuracy:0.883\nIteration: 2616, learning rate: 0.00840, Loss: 0.3186, Accuracy:0.852\nIteration: 2617, learning rate: 0.00840, Loss: 0.2911, Accuracy:0.891\nIteration: 2618, learning rate: 0.00840, Loss: 0.3721, Accuracy:0.797\nIteration: 2619, learning rate: 0.00840, Loss: 0.3936, Accuracy:0.805\nIteration: 2620, learning rate: 0.00840, Loss: 0.3595, Accuracy:0.797\nIteration: 2621, learning rate: 0.00840, Loss: 0.3341, Accuracy:0.852\nIteration: 2622, learning rate: 0.00840, Loss: 0.3747, Accuracy:0.828\nIteration: 2623, learning rate: 0.00840, Loss: 0.3422, Accuracy:0.875\nIteration: 2624, learning rate: 0.00840, Loss: 0.3674, Accuracy:0.797\nIteration: 2625, learning rate: 0.00840, Loss: 0.3233, Accuracy:0.844\nIteration: 2626, learning rate: 0.00840, Loss: 0.3064, Accuracy:0.867\nIteration: 2627, learning rate: 0.00840, Loss: 0.3155, Accuracy:0.875\nIteration: 2628, learning rate: 0.00840, Loss: 0.3912, Accuracy:0.820\nIteration: 2629, learning rate: 0.00839, Loss: 0.3811, Accuracy:0.789\nIteration: 2630, learning rate: 0.00839, Loss: 0.3227, Accuracy:0.867\nIteration: 2631, learning rate: 0.00839, Loss: 0.3608, Accuracy:0.859\nIteration: 2632, learning rate: 0.00839, Loss: 0.2877, Accuracy:0.898\nIteration: 2633, learning rate: 0.00839, Loss: 0.3021, Accuracy:0.859\nIteration: 2634, learning rate: 0.00839, Loss: 0.3465, Accuracy:0.875\nIteration: 2635, learning rate: 0.00839, Loss: 0.3770, Accuracy:0.860\nEpoch: 85, Loss: 0.3514, Accuracy:0.841, Val Loss: 0.3915, Val Accuracy: 0.821\nIteration: 2636, learning rate: 0.00839, Loss: 0.3777, Accuracy:0.852\nIteration: 2637, learning rate: 0.00839, Loss: 0.3438, Accuracy:0.844\nIteration: 2638, learning rate: 0.00839, Loss: 0.2914, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2639, learning rate: 0.00839, Loss: 0.3571, Accuracy:0.859\nIteration: 2640, learning rate: 0.00839, Loss: 0.3063, Accuracy:0.852\nIteration: 2641, learning rate: 0.00839, Loss: 0.3523, Accuracy:0.828\nIteration: 2642, learning rate: 0.00839, Loss: 0.3499, Accuracy:0.844\nIteration: 2643, learning rate: 0.00839, Loss: 0.3242, Accuracy:0.883\nIteration: 2644, learning rate: 0.00839, Loss: 0.3390, Accuracy:0.875\nIteration: 2645, learning rate: 0.00839, Loss: 0.2832, Accuracy:0.883\nIteration: 2646, learning rate: 0.00839, Loss: 0.3411, Accuracy:0.828\nIteration: 2647, learning rate: 0.00839, Loss: 0.4367, Accuracy:0.797\nIteration: 2648, learning rate: 0.00839, Loss: 0.3658, Accuracy:0.836\nIteration: 2649, learning rate: 0.00838, Loss: 0.3196, Accuracy:0.883\nIteration: 2650, learning rate: 0.00838, Loss: 0.3021, Accuracy:0.852\nIteration: 2651, learning rate: 0.00838, Loss: 0.2893, Accuracy:0.875\nIteration: 2652, learning rate: 0.00838, Loss: 0.3246, Accuracy:0.836\nIteration: 2653, learning rate: 0.00838, Loss: 0.2493, Accuracy:0.883\nIteration: 2654, learning rate: 0.00838, Loss: 0.3509, Accuracy:0.820\nIteration: 2655, learning rate: 0.00838, Loss: 0.4098, Accuracy:0.789\nIteration: 2656, learning rate: 0.00838, Loss: 0.3923, Accuracy:0.781\nIteration: 2657, learning rate: 0.00838, Loss: 0.3763, Accuracy:0.859\nIteration: 2658, learning rate: 0.00838, Loss: 0.2208, Accuracy:0.922\nIteration: 2659, learning rate: 0.00838, Loss: 0.3095, Accuracy:0.883\nIteration: 2660, learning rate: 0.00838, Loss: 0.3577, Accuracy:0.852\nIteration: 2661, learning rate: 0.00838, Loss: 0.3753, Accuracy:0.852\nIteration: 2662, learning rate: 0.00838, Loss: 0.2800, Accuracy:0.906\nIteration: 2663, learning rate: 0.00838, Loss: 0.3390, Accuracy:0.852\nIteration: 2664, learning rate: 0.00838, Loss: 0.3066, Accuracy:0.898\nIteration: 2665, learning rate: 0.00838, Loss: 0.3169, Accuracy:0.891\nIteration: 2666, learning rate: 0.00838, Loss: 0.2571, Accuracy:0.903\nEpoch: 86, Loss: 0.3305, Accuracy:0.859, Val Loss: 0.3363, Val Accuracy: 0.846\nIteration: 2667, learning rate: 0.00838, Loss: 0.3432, Accuracy:0.828\nIteration: 2668, learning rate: 0.00838, Loss: 0.3402, Accuracy:0.852\nIteration: 2669, learning rate: 0.00837, Loss: 0.3225, Accuracy:0.883\nIteration: 2670, learning rate: 0.00837, Loss: 0.2822, Accuracy:0.898\nIteration: 2671, learning rate: 0.00837, Loss: 0.3675, Accuracy:0.836\nIteration: 2672, learning rate: 0.00837, Loss: 0.3265, Accuracy:0.875\nIteration: 2673, learning rate: 0.00837, Loss: 0.3865, Accuracy:0.828\nIteration: 2674, learning rate: 0.00837, Loss: 0.3175, Accuracy:0.875\nIteration: 2675, learning rate: 0.00837, Loss: 0.2591, Accuracy:0.898\nIteration: 2676, learning rate: 0.00837, Loss: 0.3040, Accuracy:0.875\nIteration: 2677, learning rate: 0.00837, Loss: 0.3494, Accuracy:0.844\nIteration: 2678, learning rate: 0.00837, Loss: 0.3409, Accuracy:0.844\nIteration: 2679, learning rate: 0.00837, Loss: 0.3606, Accuracy:0.852\nIteration: 2680, learning rate: 0.00837, Loss: 0.3142, Accuracy:0.852\nIteration: 2681, learning rate: 0.00837, Loss: 0.3198, Accuracy:0.867\nIteration: 2682, learning rate: 0.00837, Loss: 0.2735, Accuracy:0.852\nIteration: 2683, learning rate: 0.00837, Loss: 0.2878, Accuracy:0.875\nIteration: 2684, learning rate: 0.00837, Loss: 0.3298, Accuracy:0.852\nIteration: 2685, learning rate: 0.00837, Loss: 0.3123, Accuracy:0.859\nIteration: 2686, learning rate: 0.00837, Loss: 0.3614, Accuracy:0.859\nIteration: 2687, learning rate: 0.00837, Loss: 0.4542, Accuracy:0.781\nIteration: 2688, learning rate: 0.00837, Loss: 0.3678, Accuracy:0.844\nIteration: 2689, learning rate: 0.00836, Loss: 0.4291, Accuracy:0.820\nIteration: 2690, learning rate: 0.00836, Loss: 0.3737, Accuracy:0.820\nIteration: 2691, learning rate: 0.00836, Loss: 0.3382, Accuracy:0.852\nIteration: 2692, learning rate: 0.00836, Loss: 0.3401, Accuracy:0.820\nIteration: 2693, learning rate: 0.00836, Loss: 0.4065, Accuracy:0.781\nIteration: 2694, learning rate: 0.00836, Loss: 0.3101, Accuracy:0.859\nIteration: 2695, learning rate: 0.00836, Loss: 0.3039, Accuracy:0.859\nIteration: 2696, learning rate: 0.00836, Loss: 0.4376, Accuracy:0.805\nIteration: 2697, learning rate: 0.00836, Loss: 0.3368, Accuracy:0.860\nEpoch: 87, Loss: 0.3418, Accuracy:0.849, Val Loss: 0.3059, Val Accuracy: 0.861\nval_loss_decreased from 0.3287 to 0.3059, saving_checkpoint for epoch 87\nIteration: 2698, learning rate: 0.00836, Loss: 0.3515, Accuracy:0.875\nIteration: 2699, learning rate: 0.00836, Loss: 0.2772, Accuracy:0.898\nIteration: 2700, learning rate: 0.00836, Loss: 0.3303, Accuracy:0.867\nIteration: 2701, learning rate: 0.00836, Loss: 0.3108, Accuracy:0.891\nIteration: 2702, learning rate: 0.00836, Loss: 0.3058, Accuracy:0.859\nIteration: 2703, learning rate: 0.00836, Loss: 0.4062, Accuracy:0.828\nIteration: 2704, learning rate: 0.00836, Loss: 0.3555, Accuracy:0.844\nIteration: 2705, learning rate: 0.00836, Loss: 0.3157, Accuracy:0.883\nIteration: 2706, learning rate: 0.00836, Loss: 0.3966, Accuracy:0.797\nIteration: 2707, learning rate: 0.00836, Loss: 0.3614, Accuracy:0.844\nIteration: 2708, learning rate: 0.00836, Loss: 0.3060, Accuracy:0.859\nIteration: 2709, learning rate: 0.00835, Loss: 0.3070, Accuracy:0.867\nIteration: 2710, learning rate: 0.00835, Loss: 0.2403, Accuracy:0.891\nIteration: 2711, learning rate: 0.00835, Loss: 0.3773, Accuracy:0.844\nIteration: 2712, learning rate: 0.00835, Loss: 0.3668, Accuracy:0.820\nIteration: 2713, learning rate: 0.00835, Loss: 0.3317, Accuracy:0.859\nIteration: 2714, learning rate: 0.00835, Loss: 0.3567, Accuracy:0.828\nIteration: 2715, learning rate: 0.00835, Loss: 0.4389, Accuracy:0.773\nIteration: 2716, learning rate: 0.00835, Loss: 0.3493, Accuracy:0.852\nIteration: 2717, learning rate: 0.00835, Loss: 0.2472, Accuracy:0.875\nIteration: 2718, learning rate: 0.00835, Loss: 0.2953, Accuracy:0.852\nIteration: 2719, learning rate: 0.00835, Loss: 0.3004, Accuracy:0.891\nIteration: 2720, learning rate: 0.00835, Loss: 0.3081, Accuracy:0.898\nIteration: 2721, learning rate: 0.00835, Loss: 0.3068, Accuracy:0.859\nIteration: 2722, learning rate: 0.00835, Loss: 0.3972, Accuracy:0.820\nIteration: 2723, learning rate: 0.00835, Loss: 0.3186, Accuracy:0.859\nIteration: 2724, learning rate: 0.00835, Loss: 0.4259, Accuracy:0.812\nIteration: 2725, learning rate: 0.00835, Loss: 0.2819, Accuracy:0.836\nIteration: 2726, learning rate: 0.00835, Loss: 0.3394, Accuracy:0.836\nIteration: 2727, learning rate: 0.00835, Loss: 0.2611, Accuracy:0.891\nIteration: 2728, learning rate: 0.00835, Loss: 0.4063, Accuracy:0.785\nEpoch: 88, Loss: 0.3346, Accuracy:0.851, Val Loss: 0.3376, Val Accuracy: 0.846\nIteration: 2729, learning rate: 0.00835, Loss: 0.3833, Accuracy:0.828\nIteration: 2730, learning rate: 0.00834, Loss: 0.3958, Accuracy:0.828\nIteration: 2731, learning rate: 0.00834, Loss: 0.3369, Accuracy:0.867\nIteration: 2732, learning rate: 0.00834, Loss: 0.3017, Accuracy:0.836\nIteration: 2733, learning rate: 0.00834, Loss: 0.2968, Accuracy:0.875\nIteration: 2734, learning rate: 0.00834, Loss: 0.3833, Accuracy:0.844\nIteration: 2735, learning rate: 0.00834, Loss: 0.4091, Accuracy:0.805\nIteration: 2736, learning rate: 0.00834, Loss: 0.3219, Accuracy:0.898\nIteration: 2737, learning rate: 0.00834, Loss: 0.3008, Accuracy:0.906\nIteration: 2738, learning rate: 0.00834, Loss: 0.3608, Accuracy:0.820\nIteration: 2739, learning rate: 0.00834, Loss: 0.3211, Accuracy:0.875\nIteration: 2740, learning rate: 0.00834, Loss: 0.3794, Accuracy:0.828\nIteration: 2741, learning rate: 0.00834, Loss: 0.3032, Accuracy:0.867\nIteration: 2742, learning rate: 0.00834, Loss: 0.2943, Accuracy:0.891\nIteration: 2743, learning rate: 0.00834, Loss: 0.3832, Accuracy:0.836\nIteration: 2744, learning rate: 0.00834, Loss: 0.3696, Accuracy:0.828\nIteration: 2745, learning rate: 0.00834, Loss: 0.4239, Accuracy:0.820\nIteration: 2746, learning rate: 0.00834, Loss: 0.3651, Accuracy:0.828\nIteration: 2747, learning rate: 0.00834, Loss: 0.3877, Accuracy:0.836\nIteration: 2748, learning rate: 0.00834, Loss: 0.2397, Accuracy:0.906\nIteration: 2749, learning rate: 0.00834, Loss: 0.3368, Accuracy:0.859\nIteration: 2750, learning rate: 0.00833, Loss: 0.3626, Accuracy:0.836\nIteration: 2751, learning rate: 0.00833, Loss: 0.3670, Accuracy:0.805\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2752, learning rate: 0.00833, Loss: 0.3168, Accuracy:0.898\nIteration: 2753, learning rate: 0.00833, Loss: 0.3789, Accuracy:0.812\nIteration: 2754, learning rate: 0.00833, Loss: 0.3993, Accuracy:0.828\nIteration: 2755, learning rate: 0.00833, Loss: 0.3680, Accuracy:0.781\nIteration: 2756, learning rate: 0.00833, Loss: 0.2815, Accuracy:0.875\nIteration: 2757, learning rate: 0.00833, Loss: 0.4535, Accuracy:0.781\nIteration: 2758, learning rate: 0.00833, Loss: 0.3571, Accuracy:0.836\nIteration: 2759, learning rate: 0.00833, Loss: 0.3244, Accuracy:0.860\nEpoch: 89, Loss: 0.3517, Accuracy:0.845, Val Loss: 0.3375, Val Accuracy: 0.860\nIteration: 2760, learning rate: 0.00833, Loss: 0.2999, Accuracy:0.898\nIteration: 2761, learning rate: 0.00833, Loss: 0.3244, Accuracy:0.883\nIteration: 2762, learning rate: 0.00833, Loss: 0.3929, Accuracy:0.836\nIteration: 2763, learning rate: 0.00833, Loss: 0.3310, Accuracy:0.844\nIteration: 2764, learning rate: 0.00833, Loss: 0.2889, Accuracy:0.875\nIteration: 2765, learning rate: 0.00833, Loss: 0.3561, Accuracy:0.844\nIteration: 2766, learning rate: 0.00833, Loss: 0.3333, Accuracy:0.867\nIteration: 2767, learning rate: 0.00833, Loss: 0.4185, Accuracy:0.828\nIteration: 2768, learning rate: 0.00833, Loss: 0.2456, Accuracy:0.906\nIteration: 2769, learning rate: 0.00833, Loss: 0.3530, Accuracy:0.836\nIteration: 2770, learning rate: 0.00832, Loss: 0.3980, Accuracy:0.828\nIteration: 2771, learning rate: 0.00832, Loss: 0.3510, Accuracy:0.812\nIteration: 2772, learning rate: 0.00832, Loss: 0.3307, Accuracy:0.875\nIteration: 2773, learning rate: 0.00832, Loss: 0.3042, Accuracy:0.891\nIteration: 2774, learning rate: 0.00832, Loss: 0.4181, Accuracy:0.797\nIteration: 2775, learning rate: 0.00832, Loss: 0.2733, Accuracy:0.906\nIteration: 2776, learning rate: 0.00832, Loss: 0.3683, Accuracy:0.852\nIteration: 2777, learning rate: 0.00832, Loss: 0.3679, Accuracy:0.828\nIteration: 2778, learning rate: 0.00832, Loss: 0.4079, Accuracy:0.805\nIteration: 2779, learning rate: 0.00832, Loss: 0.3396, Accuracy:0.859\nIteration: 2780, learning rate: 0.00832, Loss: 0.3576, Accuracy:0.812\nIteration: 2781, learning rate: 0.00832, Loss: 0.3468, Accuracy:0.820\nIteration: 2782, learning rate: 0.00832, Loss: 0.3803, Accuracy:0.844\nIteration: 2783, learning rate: 0.00832, Loss: 0.4395, Accuracy:0.781\nIteration: 2784, learning rate: 0.00832, Loss: 0.3522, Accuracy:0.812\nIteration: 2785, learning rate: 0.00832, Loss: 0.4257, Accuracy:0.789\nIteration: 2786, learning rate: 0.00832, Loss: 0.3753, Accuracy:0.852\nIteration: 2787, learning rate: 0.00832, Loss: 0.3171, Accuracy:0.859\nIteration: 2788, learning rate: 0.00832, Loss: 0.3550, Accuracy:0.836\nIteration: 2789, learning rate: 0.00832, Loss: 0.3901, Accuracy:0.844\nIteration: 2790, learning rate: 0.00832, Loss: 0.3651, Accuracy:0.839\nEpoch: 90, Loss: 0.3551, Accuracy:0.844, Val Loss: 0.3843, Val Accuracy: 0.822\nIteration: 2791, learning rate: 0.00831, Loss: 0.3591, Accuracy:0.836\nIteration: 2792, learning rate: 0.00831, Loss: 0.3355, Accuracy:0.844\nIteration: 2793, learning rate: 0.00831, Loss: 0.3587, Accuracy:0.828\nIteration: 2794, learning rate: 0.00831, Loss: 0.3184, Accuracy:0.859\nIteration: 2795, learning rate: 0.00831, Loss: 0.2703, Accuracy:0.883\nIteration: 2796, learning rate: 0.00831, Loss: 0.3876, Accuracy:0.859\nIteration: 2797, learning rate: 0.00831, Loss: 0.3083, Accuracy:0.859\nIteration: 2798, learning rate: 0.00831, Loss: 0.3586, Accuracy:0.836\nIteration: 2799, learning rate: 0.00831, Loss: 0.3256, Accuracy:0.867\nIteration: 2800, learning rate: 0.00831, Loss: 0.3528, Accuracy:0.836\nIteration: 2801, learning rate: 0.00831, Loss: 0.3795, Accuracy:0.828\nIteration: 2802, learning rate: 0.00831, Loss: 0.4818, Accuracy:0.750\nIteration: 2803, learning rate: 0.00831, Loss: 0.3610, Accuracy:0.812\nIteration: 2804, learning rate: 0.00831, Loss: 0.3325, Accuracy:0.867\nIteration: 2805, learning rate: 0.00831, Loss: 0.3370, Accuracy:0.852\nIteration: 2806, learning rate: 0.00831, Loss: 0.4041, Accuracy:0.812\nIteration: 2807, learning rate: 0.00831, Loss: 0.3521, Accuracy:0.820\nIteration: 2808, learning rate: 0.00831, Loss: 0.3029, Accuracy:0.867\nIteration: 2809, learning rate: 0.00831, Loss: 0.3925, Accuracy:0.859\nIteration: 2810, learning rate: 0.00831, Loss: 0.3498, Accuracy:0.828\nIteration: 2811, learning rate: 0.00830, Loss: 0.2855, Accuracy:0.891\nIteration: 2812, learning rate: 0.00830, Loss: 0.2886, Accuracy:0.875\nIteration: 2813, learning rate: 0.00830, Loss: 0.3054, Accuracy:0.859\nIteration: 2814, learning rate: 0.00830, Loss: 0.3592, Accuracy:0.805\nIteration: 2815, learning rate: 0.00830, Loss: 0.3006, Accuracy:0.836\nIteration: 2816, learning rate: 0.00830, Loss: 0.2606, Accuracy:0.891\nIteration: 2817, learning rate: 0.00830, Loss: 0.2563, Accuracy:0.898\nIteration: 2818, learning rate: 0.00830, Loss: 0.2443, Accuracy:0.914\nIteration: 2819, learning rate: 0.00830, Loss: 0.2899, Accuracy:0.875\nIteration: 2820, learning rate: 0.00830, Loss: 0.3774, Accuracy:0.828\nIteration: 2821, learning rate: 0.00830, Loss: 0.3319, Accuracy:0.892\nEpoch: 91, Loss: 0.3345, Accuracy:0.851, Val Loss: 0.3448, Val Accuracy: 0.833\nIteration: 2822, learning rate: 0.00830, Loss: 0.3570, Accuracy:0.867\nIteration: 2823, learning rate: 0.00830, Loss: 0.3658, Accuracy:0.852\nIteration: 2824, learning rate: 0.00830, Loss: 0.3088, Accuracy:0.867\nIteration: 2825, learning rate: 0.00830, Loss: 0.2570, Accuracy:0.914\nIteration: 2826, learning rate: 0.00830, Loss: 0.3548, Accuracy:0.828\nIteration: 2827, learning rate: 0.00830, Loss: 0.3095, Accuracy:0.852\nIteration: 2828, learning rate: 0.00830, Loss: 0.3786, Accuracy:0.820\nIteration: 2829, learning rate: 0.00830, Loss: 0.3415, Accuracy:0.844\nIteration: 2830, learning rate: 0.00830, Loss: 0.3172, Accuracy:0.883\nIteration: 2831, learning rate: 0.00830, Loss: 0.3050, Accuracy:0.867\nIteration: 2832, learning rate: 0.00829, Loss: 0.4013, Accuracy:0.812\nIteration: 2833, learning rate: 0.00829, Loss: 0.3349, Accuracy:0.852\nIteration: 2834, learning rate: 0.00829, Loss: 0.4078, Accuracy:0.789\nIteration: 2835, learning rate: 0.00829, Loss: 0.3254, Accuracy:0.883\nIteration: 2836, learning rate: 0.00829, Loss: 0.4091, Accuracy:0.812\nIteration: 2837, learning rate: 0.00829, Loss: 0.4300, Accuracy:0.805\nIteration: 2838, learning rate: 0.00829, Loss: 0.2931, Accuracy:0.891\nIteration: 2839, learning rate: 0.00829, Loss: 0.3640, Accuracy:0.844\nIteration: 2840, learning rate: 0.00829, Loss: 0.3122, Accuracy:0.867\nIteration: 2841, learning rate: 0.00829, Loss: 0.2991, Accuracy:0.867\nIteration: 2842, learning rate: 0.00829, Loss: 0.3193, Accuracy:0.836\nIteration: 2843, learning rate: 0.00829, Loss: 0.3155, Accuracy:0.875\nIteration: 2844, learning rate: 0.00829, Loss: 0.2968, Accuracy:0.867\nIteration: 2845, learning rate: 0.00829, Loss: 0.2580, Accuracy:0.898\nIteration: 2846, learning rate: 0.00829, Loss: 0.3237, Accuracy:0.867\nIteration: 2847, learning rate: 0.00829, Loss: 0.3471, Accuracy:0.852\nIteration: 2848, learning rate: 0.00829, Loss: 0.3598, Accuracy:0.820\nIteration: 2849, learning rate: 0.00829, Loss: 0.3844, Accuracy:0.820\nIteration: 2850, learning rate: 0.00829, Loss: 0.3086, Accuracy:0.852\nIteration: 2851, learning rate: 0.00829, Loss: 0.3729, Accuracy:0.859\nIteration: 2852, learning rate: 0.00829, Loss: 0.2502, Accuracy:0.903\nEpoch: 92, Loss: 0.3358, Accuracy:0.854, Val Loss: 0.3443, Val Accuracy: 0.829\nIteration: 2853, learning rate: 0.00828, Loss: 0.3014, Accuracy:0.867\nIteration: 2854, learning rate: 0.00828, Loss: 0.3786, Accuracy:0.789\nIteration: 2855, learning rate: 0.00828, Loss: 0.3096, Accuracy:0.852\nIteration: 2856, learning rate: 0.00828, Loss: 0.3114, Accuracy:0.859\nIteration: 2857, learning rate: 0.00828, Loss: 0.3011, Accuracy:0.867\nIteration: 2858, learning rate: 0.00828, Loss: 0.3135, Accuracy:0.852\nIteration: 2859, learning rate: 0.00828, Loss: 0.3745, Accuracy:0.828\nIteration: 2860, learning rate: 0.00828, Loss: 0.3355, Accuracy:0.836\nIteration: 2861, learning rate: 0.00828, Loss: 0.2485, Accuracy:0.914\nIteration: 2862, learning rate: 0.00828, Loss: 0.3320, Accuracy:0.836\nIteration: 2863, learning rate: 0.00828, Loss: 0.3391, Accuracy:0.836\nIteration: 2864, learning rate: 0.00828, Loss: 0.3361, Accuracy:0.844\nIteration: 2865, learning rate: 0.00828, Loss: 0.3939, Accuracy:0.828\nIteration: 2866, learning rate: 0.00828, Loss: 0.3421, Accuracy:0.852\nIteration: 2867, learning rate: 0.00828, Loss: 0.3480, Accuracy:0.844\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2868, learning rate: 0.00828, Loss: 0.2685, Accuracy:0.891\nIteration: 2869, learning rate: 0.00828, Loss: 0.3441, Accuracy:0.812\nIteration: 2870, learning rate: 0.00828, Loss: 0.3281, Accuracy:0.867\nIteration: 2871, learning rate: 0.00828, Loss: 0.3206, Accuracy:0.859\nIteration: 2872, learning rate: 0.00828, Loss: 0.3063, Accuracy:0.859\nIteration: 2873, learning rate: 0.00827, Loss: 0.2362, Accuracy:0.914\nIteration: 2874, learning rate: 0.00827, Loss: 0.2450, Accuracy:0.914\nIteration: 2875, learning rate: 0.00827, Loss: 0.2329, Accuracy:0.922\nIteration: 2876, learning rate: 0.00827, Loss: 0.3759, Accuracy:0.836\nIteration: 2877, learning rate: 0.00827, Loss: 0.3222, Accuracy:0.883\nIteration: 2878, learning rate: 0.00827, Loss: 0.3253, Accuracy:0.844\nIteration: 2879, learning rate: 0.00827, Loss: 0.2911, Accuracy:0.891\nIteration: 2880, learning rate: 0.00827, Loss: 0.3365, Accuracy:0.867\nIteration: 2881, learning rate: 0.00827, Loss: 0.2970, Accuracy:0.875\nIteration: 2882, learning rate: 0.00827, Loss: 0.3347, Accuracy:0.828\nIteration: 2883, learning rate: 0.00827, Loss: 0.3178, Accuracy:0.871\nEpoch: 93, Loss: 0.3177, Accuracy:0.859, Val Loss: 0.3738, Val Accuracy: 0.812\nIteration: 2884, learning rate: 0.00827, Loss: 0.2689, Accuracy:0.906\nIteration: 2885, learning rate: 0.00827, Loss: 0.3117, Accuracy:0.875\nIteration: 2886, learning rate: 0.00827, Loss: 0.3425, Accuracy:0.836\nIteration: 2887, learning rate: 0.00827, Loss: 0.3057, Accuracy:0.859\nIteration: 2888, learning rate: 0.00827, Loss: 0.3228, Accuracy:0.883\nIteration: 2889, learning rate: 0.00827, Loss: 0.4033, Accuracy:0.820\nIteration: 2890, learning rate: 0.00827, Loss: 0.3013, Accuracy:0.891\nIteration: 2891, learning rate: 0.00827, Loss: 0.3240, Accuracy:0.859\nIteration: 2892, learning rate: 0.00827, Loss: 0.3977, Accuracy:0.812\nIteration: 2893, learning rate: 0.00827, Loss: 0.3858, Accuracy:0.852\nIteration: 2894, learning rate: 0.00826, Loss: 0.3553, Accuracy:0.828\nIteration: 2895, learning rate: 0.00826, Loss: 0.3448, Accuracy:0.859\nIteration: 2896, learning rate: 0.00826, Loss: 0.3642, Accuracy:0.844\nIteration: 2897, learning rate: 0.00826, Loss: 0.3557, Accuracy:0.820\nIteration: 2898, learning rate: 0.00826, Loss: 0.3836, Accuracy:0.805\nIteration: 2899, learning rate: 0.00826, Loss: 0.3382, Accuracy:0.883\nIteration: 2900, learning rate: 0.00826, Loss: 0.4051, Accuracy:0.844\nIteration: 2901, learning rate: 0.00826, Loss: 0.3253, Accuracy:0.844\nIteration: 2902, learning rate: 0.00826, Loss: 0.2296, Accuracy:0.922\nIteration: 2903, learning rate: 0.00826, Loss: 0.3034, Accuracy:0.883\nIteration: 2904, learning rate: 0.00826, Loss: 0.4101, Accuracy:0.805\nIteration: 2905, learning rate: 0.00826, Loss: 0.3063, Accuracy:0.898\nIteration: 2906, learning rate: 0.00826, Loss: 0.3590, Accuracy:0.836\nIteration: 2907, learning rate: 0.00826, Loss: 0.2976, Accuracy:0.891\nIteration: 2908, learning rate: 0.00826, Loss: 0.3806, Accuracy:0.836\nIteration: 2909, learning rate: 0.00826, Loss: 0.3093, Accuracy:0.891\nIteration: 2910, learning rate: 0.00826, Loss: 0.2918, Accuracy:0.836\nIteration: 2911, learning rate: 0.00826, Loss: 0.4139, Accuracy:0.797\nIteration: 2912, learning rate: 0.00826, Loss: 0.2641, Accuracy:0.875\nIteration: 2913, learning rate: 0.00826, Loss: 0.3282, Accuracy:0.828\nIteration: 2914, learning rate: 0.00826, Loss: 0.3348, Accuracy:0.849\nEpoch: 94, Loss: 0.3376, Accuracy:0.854, Val Loss: 0.3363, Val Accuracy: 0.849\nIteration: 2915, learning rate: 0.00825, Loss: 0.2333, Accuracy:0.906\nIteration: 2916, learning rate: 0.00825, Loss: 0.3807, Accuracy:0.805\nIteration: 2917, learning rate: 0.00825, Loss: 0.3274, Accuracy:0.891\nIteration: 2918, learning rate: 0.00825, Loss: 0.2604, Accuracy:0.930\nIteration: 2919, learning rate: 0.00825, Loss: 0.2877, Accuracy:0.883\nIteration: 2920, learning rate: 0.00825, Loss: 0.4356, Accuracy:0.805\nIteration: 2921, learning rate: 0.00825, Loss: 0.3941, Accuracy:0.812\nIteration: 2922, learning rate: 0.00825, Loss: 0.3103, Accuracy:0.844\nIteration: 2923, learning rate: 0.00825, Loss: 0.1895, Accuracy:0.930\nIteration: 2924, learning rate: 0.00825, Loss: 0.2679, Accuracy:0.867\nIteration: 2925, learning rate: 0.00825, Loss: 0.4183, Accuracy:0.805\nIteration: 2926, learning rate: 0.00825, Loss: 0.3404, Accuracy:0.836\nIteration: 2927, learning rate: 0.00825, Loss: 0.3753, Accuracy:0.812\nIteration: 2928, learning rate: 0.00825, Loss: 0.3911, Accuracy:0.836\nIteration: 2929, learning rate: 0.00825, Loss: 0.3427, Accuracy:0.844\nIteration: 2930, learning rate: 0.00825, Loss: 0.3047, Accuracy:0.859\nIteration: 2931, learning rate: 0.00825, Loss: 0.3020, Accuracy:0.891\nIteration: 2932, learning rate: 0.00825, Loss: 0.3892, Accuracy:0.812\nIteration: 2933, learning rate: 0.00825, Loss: 0.3737, Accuracy:0.812\nIteration: 2934, learning rate: 0.00825, Loss: 0.2717, Accuracy:0.891\nIteration: 2935, learning rate: 0.00825, Loss: 0.3225, Accuracy:0.859\nIteration: 2936, learning rate: 0.00824, Loss: 0.2846, Accuracy:0.883\nIteration: 2937, learning rate: 0.00824, Loss: 0.2968, Accuracy:0.859\nIteration: 2938, learning rate: 0.00824, Loss: 0.3495, Accuracy:0.820\nIteration: 2939, learning rate: 0.00824, Loss: 0.3236, Accuracy:0.820\nIteration: 2940, learning rate: 0.00824, Loss: 0.2449, Accuracy:0.930\nIteration: 2941, learning rate: 0.00824, Loss: 0.3496, Accuracy:0.852\nIteration: 2942, learning rate: 0.00824, Loss: 0.3311, Accuracy:0.844\nIteration: 2943, learning rate: 0.00824, Loss: 0.3098, Accuracy:0.875\nIteration: 2944, learning rate: 0.00824, Loss: 0.3253, Accuracy:0.844\nIteration: 2945, learning rate: 0.00824, Loss: 0.3162, Accuracy:0.839\nEpoch: 95, Loss: 0.3242, Accuracy:0.855, Val Loss: 0.3622, Val Accuracy: 0.828\nIteration: 2946, learning rate: 0.00824, Loss: 0.2696, Accuracy:0.914\nIteration: 2947, learning rate: 0.00824, Loss: 0.3187, Accuracy:0.867\nIteration: 2948, learning rate: 0.00824, Loss: 0.3238, Accuracy:0.852\nIteration: 2949, learning rate: 0.00824, Loss: 0.3143, Accuracy:0.844\nIteration: 2950, learning rate: 0.00824, Loss: 0.2381, Accuracy:0.906\nIteration: 2951, learning rate: 0.00824, Loss: 0.3510, Accuracy:0.836\nIteration: 2952, learning rate: 0.00824, Loss: 0.3151, Accuracy:0.859\nIteration: 2953, learning rate: 0.00824, Loss: 0.2729, Accuracy:0.922\nIteration: 2954, learning rate: 0.00824, Loss: 0.3296, Accuracy:0.859\nIteration: 2955, learning rate: 0.00824, Loss: 0.3652, Accuracy:0.867\nIteration: 2956, learning rate: 0.00824, Loss: 0.2327, Accuracy:0.922\nIteration: 2957, learning rate: 0.00823, Loss: 0.3701, Accuracy:0.859\nIteration: 2958, learning rate: 0.00823, Loss: 0.3402, Accuracy:0.859\nIteration: 2959, learning rate: 0.00823, Loss: 0.3689, Accuracy:0.828\nIteration: 2960, learning rate: 0.00823, Loss: 0.3624, Accuracy:0.867\nIteration: 2961, learning rate: 0.00823, Loss: 0.3556, Accuracy:0.797\nIteration: 2962, learning rate: 0.00823, Loss: 0.3445, Accuracy:0.844\nIteration: 2963, learning rate: 0.00823, Loss: 0.3446, Accuracy:0.836\nIteration: 2964, learning rate: 0.00823, Loss: 0.2972, Accuracy:0.875\nIteration: 2965, learning rate: 0.00823, Loss: 0.2703, Accuracy:0.875\nIteration: 2966, learning rate: 0.00823, Loss: 0.2801, Accuracy:0.906\nIteration: 2967, learning rate: 0.00823, Loss: 0.2981, Accuracy:0.906\nIteration: 2968, learning rate: 0.00823, Loss: 0.2574, Accuracy:0.906\nIteration: 2969, learning rate: 0.00823, Loss: 0.3121, Accuracy:0.859\nIteration: 2970, learning rate: 0.00823, Loss: 0.3093, Accuracy:0.867\nIteration: 2971, learning rate: 0.00823, Loss: 0.3158, Accuracy:0.883\nIteration: 2972, learning rate: 0.00823, Loss: 0.3583, Accuracy:0.812\nIteration: 2973, learning rate: 0.00823, Loss: 0.3204, Accuracy:0.852\nIteration: 2974, learning rate: 0.00823, Loss: 0.2914, Accuracy:0.875\nIteration: 2975, learning rate: 0.00823, Loss: 0.3236, Accuracy:0.867\nIteration: 2976, learning rate: 0.00823, Loss: 0.2824, Accuracy:0.882\nEpoch: 96, Loss: 0.3140, Accuracy:0.868, Val Loss: 0.3185, Val Accuracy: 0.842\nIteration: 2977, learning rate: 0.00823, Loss: 0.3150, Accuracy:0.844\nIteration: 2978, learning rate: 0.00822, Loss: 0.3609, Accuracy:0.852\nIteration: 2979, learning rate: 0.00822, Loss: 0.3802, Accuracy:0.812\nIteration: 2980, learning rate: 0.00822, Loss: 0.4061, Accuracy:0.805\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 2981, learning rate: 0.00822, Loss: 0.3392, Accuracy:0.852\nIteration: 2982, learning rate: 0.00822, Loss: 0.3117, Accuracy:0.859\nIteration: 2983, learning rate: 0.00822, Loss: 0.3424, Accuracy:0.852\nIteration: 2984, learning rate: 0.00822, Loss: 0.3280, Accuracy:0.883\nIteration: 2985, learning rate: 0.00822, Loss: 0.3368, Accuracy:0.859\nIteration: 2986, learning rate: 0.00822, Loss: 0.3271, Accuracy:0.867\nIteration: 2987, learning rate: 0.00822, Loss: 0.3464, Accuracy:0.867\nIteration: 2988, learning rate: 0.00822, Loss: 0.3778, Accuracy:0.844\nIteration: 2989, learning rate: 0.00822, Loss: 0.3622, Accuracy:0.836\nIteration: 2990, learning rate: 0.00822, Loss: 0.3139, Accuracy:0.867\nIteration: 2991, learning rate: 0.00822, Loss: 0.3067, Accuracy:0.859\nIteration: 2992, learning rate: 0.00822, Loss: 0.3190, Accuracy:0.867\nIteration: 2993, learning rate: 0.00822, Loss: 0.3404, Accuracy:0.836\nIteration: 2994, learning rate: 0.00822, Loss: 0.3780, Accuracy:0.844\nIteration: 2995, learning rate: 0.00822, Loss: 0.3910, Accuracy:0.828\nIteration: 2996, learning rate: 0.00822, Loss: 0.2797, Accuracy:0.898\nIteration: 2997, learning rate: 0.00822, Loss: 0.3521, Accuracy:0.844\nIteration: 2998, learning rate: 0.00822, Loss: 0.3130, Accuracy:0.844\nIteration: 2999, learning rate: 0.00821, Loss: 0.3637, Accuracy:0.859\nIteration: 3000, learning rate: 0.00821, Loss: 0.3480, Accuracy:0.828\nIteration: 3001, learning rate: 0.00821, Loss: 0.2909, Accuracy:0.883\nIteration: 3002, learning rate: 0.00821, Loss: 0.3275, Accuracy:0.859\nIteration: 3003, learning rate: 0.00821, Loss: 0.3632, Accuracy:0.828\nIteration: 3004, learning rate: 0.00821, Loss: 0.4085, Accuracy:0.797\nIteration: 3005, learning rate: 0.00821, Loss: 0.3505, Accuracy:0.812\nIteration: 3006, learning rate: 0.00821, Loss: 0.3746, Accuracy:0.859\nIteration: 3007, learning rate: 0.00821, Loss: 0.3160, Accuracy:0.860\nEpoch: 97, Loss: 0.3442, Accuracy:0.849, Val Loss: 0.3397, Val Accuracy: 0.858\nIteration: 3008, learning rate: 0.00821, Loss: 0.2848, Accuracy:0.883\nIteration: 3009, learning rate: 0.00821, Loss: 0.4018, Accuracy:0.836\nIteration: 3010, learning rate: 0.00821, Loss: 0.3087, Accuracy:0.859\nIteration: 3011, learning rate: 0.00821, Loss: 0.2898, Accuracy:0.859\nIteration: 3012, learning rate: 0.00821, Loss: 0.2829, Accuracy:0.891\nIteration: 3013, learning rate: 0.00821, Loss: 0.3669, Accuracy:0.836\nIteration: 3014, learning rate: 0.00821, Loss: 0.3638, Accuracy:0.867\nIteration: 3015, learning rate: 0.00821, Loss: 0.4472, Accuracy:0.820\nIteration: 3016, learning rate: 0.00821, Loss: 0.2656, Accuracy:0.875\nIteration: 3017, learning rate: 0.00821, Loss: 0.3299, Accuracy:0.852\nIteration: 3018, learning rate: 0.00821, Loss: 0.2847, Accuracy:0.891\nIteration: 3019, learning rate: 0.00821, Loss: 0.2112, Accuracy:0.930\nIteration: 3020, learning rate: 0.00820, Loss: 0.3094, Accuracy:0.867\nIteration: 3021, learning rate: 0.00820, Loss: 0.3415, Accuracy:0.859\nIteration: 3022, learning rate: 0.00820, Loss: 0.2618, Accuracy:0.859\nIteration: 3023, learning rate: 0.00820, Loss: 0.3383, Accuracy:0.844\nIteration: 3024, learning rate: 0.00820, Loss: 0.3453, Accuracy:0.828\nIteration: 3025, learning rate: 0.00820, Loss: 0.2906, Accuracy:0.883\nIteration: 3026, learning rate: 0.00820, Loss: 0.3061, Accuracy:0.891\nIteration: 3027, learning rate: 0.00820, Loss: 0.3367, Accuracy:0.875\nIteration: 3028, learning rate: 0.00820, Loss: 0.2812, Accuracy:0.859\nIteration: 3029, learning rate: 0.00820, Loss: 0.3570, Accuracy:0.836\nIteration: 3030, learning rate: 0.00820, Loss: 0.3004, Accuracy:0.836\nIteration: 3031, learning rate: 0.00820, Loss: 0.2639, Accuracy:0.891\nIteration: 3032, learning rate: 0.00820, Loss: 0.3427, Accuracy:0.867\nIteration: 3033, learning rate: 0.00820, Loss: 0.2821, Accuracy:0.891\nIteration: 3034, learning rate: 0.00820, Loss: 0.3664, Accuracy:0.836\nIteration: 3035, learning rate: 0.00820, Loss: 0.3533, Accuracy:0.844\nIteration: 3036, learning rate: 0.00820, Loss: 0.3051, Accuracy:0.875\nIteration: 3037, learning rate: 0.00820, Loss: 0.4097, Accuracy:0.828\nIteration: 3038, learning rate: 0.00820, Loss: 0.2502, Accuracy:0.892\nEpoch: 98, Loss: 0.3187, Accuracy:0.863, Val Loss: 0.2887, Val Accuracy: 0.873\nval_loss_decreased from 0.3059 to 0.2887, saving_checkpoint for epoch 98\nIteration: 3039, learning rate: 0.00820, Loss: 0.2627, Accuracy:0.891\nIteration: 3040, learning rate: 0.00820, Loss: 0.3114, Accuracy:0.844\nIteration: 3041, learning rate: 0.00819, Loss: 0.2924, Accuracy:0.859\nIteration: 3042, learning rate: 0.00819, Loss: 0.2891, Accuracy:0.867\nIteration: 3043, learning rate: 0.00819, Loss: 0.3956, Accuracy:0.828\nIteration: 3044, learning rate: 0.00819, Loss: 0.3228, Accuracy:0.867\nIteration: 3045, learning rate: 0.00819, Loss: 0.3066, Accuracy:0.883\nIteration: 3046, learning rate: 0.00819, Loss: 0.3248, Accuracy:0.867\nIteration: 3047, learning rate: 0.00819, Loss: 0.2481, Accuracy:0.875\nIteration: 3048, learning rate: 0.00819, Loss: 0.2336, Accuracy:0.898\nIteration: 3049, learning rate: 0.00819, Loss: 0.3140, Accuracy:0.867\nIteration: 3050, learning rate: 0.00819, Loss: 0.3264, Accuracy:0.844\nIteration: 3051, learning rate: 0.00819, Loss: 0.3260, Accuracy:0.875\nIteration: 3052, learning rate: 0.00819, Loss: 0.3107, Accuracy:0.852\nIteration: 3053, learning rate: 0.00819, Loss: 0.3287, Accuracy:0.836\nIteration: 3054, learning rate: 0.00819, Loss: 0.3548, Accuracy:0.867\nIteration: 3055, learning rate: 0.00819, Loss: 0.2980, Accuracy:0.883\nIteration: 3056, learning rate: 0.00819, Loss: 0.3194, Accuracy:0.867\nIteration: 3057, learning rate: 0.00819, Loss: 0.3001, Accuracy:0.852\nIteration: 3058, learning rate: 0.00819, Loss: 0.2880, Accuracy:0.898\nIteration: 3059, learning rate: 0.00819, Loss: 0.3399, Accuracy:0.836\nIteration: 3060, learning rate: 0.00819, Loss: 0.3675, Accuracy:0.859\nIteration: 3061, learning rate: 0.00819, Loss: 0.2811, Accuracy:0.875\nIteration: 3062, learning rate: 0.00818, Loss: 0.3793, Accuracy:0.852\nIteration: 3063, learning rate: 0.00818, Loss: 0.3214, Accuracy:0.859\nIteration: 3064, learning rate: 0.00818, Loss: 0.3328, Accuracy:0.883\nIteration: 3065, learning rate: 0.00818, Loss: 0.2637, Accuracy:0.883\nIteration: 3066, learning rate: 0.00818, Loss: 0.3184, Accuracy:0.852\nIteration: 3067, learning rate: 0.00818, Loss: 0.3065, Accuracy:0.867\nIteration: 3068, learning rate: 0.00818, Loss: 0.3555, Accuracy:0.859\nIteration: 3069, learning rate: 0.00818, Loss: 0.3574, Accuracy:0.828\nEpoch: 99, Loss: 0.3154, Accuracy:0.864, Val Loss: 0.3485, Val Accuracy: 0.842\nIteration: 3070, learning rate: 0.00818, Loss: 0.3173, Accuracy:0.883\nIteration: 3071, learning rate: 0.00818, Loss: 0.2760, Accuracy:0.883\nIteration: 3072, learning rate: 0.00818, Loss: 0.4180, Accuracy:0.781\nIteration: 3073, learning rate: 0.00818, Loss: 0.3160, Accuracy:0.844\nIteration: 3074, learning rate: 0.00818, Loss: 0.3598, Accuracy:0.828\nIteration: 3075, learning rate: 0.00818, Loss: 0.3390, Accuracy:0.859\nIteration: 3076, learning rate: 0.00818, Loss: 0.2777, Accuracy:0.867\nIteration: 3077, learning rate: 0.00818, Loss: 0.3085, Accuracy:0.805\nIteration: 3078, learning rate: 0.00818, Loss: 0.3312, Accuracy:0.867\nIteration: 3079, learning rate: 0.00818, Loss: 0.2953, Accuracy:0.867\nIteration: 3080, learning rate: 0.00818, Loss: 0.2207, Accuracy:0.914\nIteration: 3081, learning rate: 0.00818, Loss: 0.3812, Accuracy:0.797\nIteration: 3082, learning rate: 0.00818, Loss: 0.2690, Accuracy:0.875\nIteration: 3083, learning rate: 0.00818, Loss: 0.3139, Accuracy:0.867\nIteration: 3084, learning rate: 0.00817, Loss: 0.2571, Accuracy:0.914\nIteration: 3085, learning rate: 0.00817, Loss: 0.3072, Accuracy:0.844\nIteration: 3086, learning rate: 0.00817, Loss: 0.3133, Accuracy:0.836\nIteration: 3087, learning rate: 0.00817, Loss: 0.4129, Accuracy:0.805\nIteration: 3088, learning rate: 0.00817, Loss: 0.3864, Accuracy:0.859\nIteration: 3089, learning rate: 0.00817, Loss: 0.3204, Accuracy:0.883\nIteration: 3090, learning rate: 0.00817, Loss: 0.3362, Accuracy:0.844\nIteration: 3091, learning rate: 0.00817, Loss: 0.2744, Accuracy:0.875\nIteration: 3092, learning rate: 0.00817, Loss: 0.4080, Accuracy:0.812\nIteration: 3093, learning rate: 0.00817, Loss: 0.2486, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3094, learning rate: 0.00817, Loss: 0.3126, Accuracy:0.898\nIteration: 3095, learning rate: 0.00817, Loss: 0.3510, Accuracy:0.867\nIteration: 3096, learning rate: 0.00817, Loss: 0.3186, Accuracy:0.891\nIteration: 3097, learning rate: 0.00817, Loss: 0.2692, Accuracy:0.844\nIteration: 3098, learning rate: 0.00817, Loss: 0.3013, Accuracy:0.859\nIteration: 3099, learning rate: 0.00817, Loss: 0.3161, Accuracy:0.852\nIteration: 3100, learning rate: 0.00817, Loss: 0.3737, Accuracy:0.839\nEpoch: 100, Loss: 0.3203, Accuracy:0.857, Val Loss: 0.3087, Val Accuracy: 0.873\nIteration: 3101, learning rate: 0.00817, Loss: 0.3377, Accuracy:0.844\nIteration: 3102, learning rate: 0.00817, Loss: 0.4070, Accuracy:0.812\nIteration: 3103, learning rate: 0.00817, Loss: 0.3862, Accuracy:0.820\nIteration: 3104, learning rate: 0.00817, Loss: 0.3796, Accuracy:0.812\nIteration: 3105, learning rate: 0.00816, Loss: 0.3328, Accuracy:0.844\nIteration: 3106, learning rate: 0.00816, Loss: 0.4411, Accuracy:0.797\nIteration: 3107, learning rate: 0.00816, Loss: 0.3115, Accuracy:0.828\nIteration: 3108, learning rate: 0.00816, Loss: 0.2706, Accuracy:0.859\nIteration: 3109, learning rate: 0.00816, Loss: 0.3211, Accuracy:0.867\nIteration: 3110, learning rate: 0.00816, Loss: 0.2521, Accuracy:0.875\nIteration: 3111, learning rate: 0.00816, Loss: 0.3484, Accuracy:0.867\nIteration: 3112, learning rate: 0.00816, Loss: 0.3451, Accuracy:0.852\nIteration: 3113, learning rate: 0.00816, Loss: 0.3658, Accuracy:0.836\nIteration: 3114, learning rate: 0.00816, Loss: 0.3202, Accuracy:0.852\nIteration: 3115, learning rate: 0.00816, Loss: 0.3412, Accuracy:0.883\nIteration: 3116, learning rate: 0.00816, Loss: 0.3589, Accuracy:0.828\nIteration: 3117, learning rate: 0.00816, Loss: 0.2548, Accuracy:0.875\nIteration: 3118, learning rate: 0.00816, Loss: 0.2256, Accuracy:0.922\nIteration: 3119, learning rate: 0.00816, Loss: 0.3289, Accuracy:0.867\nIteration: 3120, learning rate: 0.00816, Loss: 0.3847, Accuracy:0.875\nIteration: 3121, learning rate: 0.00816, Loss: 0.2928, Accuracy:0.883\nIteration: 3122, learning rate: 0.00816, Loss: 0.4030, Accuracy:0.812\nIteration: 3123, learning rate: 0.00816, Loss: 0.3025, Accuracy:0.867\nIteration: 3124, learning rate: 0.00816, Loss: 0.2742, Accuracy:0.914\nIteration: 3125, learning rate: 0.00816, Loss: 0.3202, Accuracy:0.852\nIteration: 3126, learning rate: 0.00816, Loss: 0.3188, Accuracy:0.875\nIteration: 3127, learning rate: 0.00815, Loss: 0.2891, Accuracy:0.875\nIteration: 3128, learning rate: 0.00815, Loss: 0.3083, Accuracy:0.859\nIteration: 3129, learning rate: 0.00815, Loss: 0.3464, Accuracy:0.844\nIteration: 3130, learning rate: 0.00815, Loss: 0.2587, Accuracy:0.898\nIteration: 3131, learning rate: 0.00815, Loss: 0.2473, Accuracy:0.925\nEpoch: 101, Loss: 0.3250, Accuracy:0.859, Val Loss: 0.3446, Val Accuracy: 0.839\nIteration: 3132, learning rate: 0.00815, Loss: 0.3768, Accuracy:0.812\nIteration: 3133, learning rate: 0.00815, Loss: 0.3382, Accuracy:0.867\nIteration: 3134, learning rate: 0.00815, Loss: 0.3977, Accuracy:0.828\nIteration: 3135, learning rate: 0.00815, Loss: 0.2639, Accuracy:0.875\nIteration: 3136, learning rate: 0.00815, Loss: 0.3406, Accuracy:0.859\nIteration: 3137, learning rate: 0.00815, Loss: 0.4332, Accuracy:0.820\nIteration: 3138, learning rate: 0.00815, Loss: 0.3586, Accuracy:0.836\nIteration: 3139, learning rate: 0.00815, Loss: 0.3977, Accuracy:0.805\nIteration: 3140, learning rate: 0.00815, Loss: 0.4331, Accuracy:0.773\nIteration: 3141, learning rate: 0.00815, Loss: 0.2877, Accuracy:0.867\nIteration: 3142, learning rate: 0.00815, Loss: 0.3234, Accuracy:0.852\nIteration: 3143, learning rate: 0.00815, Loss: 0.2428, Accuracy:0.898\nIteration: 3144, learning rate: 0.00815, Loss: 0.3023, Accuracy:0.852\nIteration: 3145, learning rate: 0.00815, Loss: 0.2973, Accuracy:0.875\nIteration: 3146, learning rate: 0.00815, Loss: 0.3125, Accuracy:0.859\nIteration: 3147, learning rate: 0.00815, Loss: 0.2619, Accuracy:0.906\nIteration: 3148, learning rate: 0.00814, Loss: 0.3331, Accuracy:0.875\nIteration: 3149, learning rate: 0.00814, Loss: 0.3124, Accuracy:0.891\nIteration: 3150, learning rate: 0.00814, Loss: 0.4042, Accuracy:0.805\nIteration: 3151, learning rate: 0.00814, Loss: 0.2788, Accuracy:0.883\nIteration: 3152, learning rate: 0.00814, Loss: 0.2823, Accuracy:0.875\nIteration: 3153, learning rate: 0.00814, Loss: 0.3974, Accuracy:0.844\nIteration: 3154, learning rate: 0.00814, Loss: 0.3482, Accuracy:0.836\nIteration: 3155, learning rate: 0.00814, Loss: 0.3234, Accuracy:0.883\nIteration: 3156, learning rate: 0.00814, Loss: 0.3506, Accuracy:0.844\nIteration: 3157, learning rate: 0.00814, Loss: 0.3802, Accuracy:0.836\nIteration: 3158, learning rate: 0.00814, Loss: 0.3143, Accuracy:0.859\nIteration: 3159, learning rate: 0.00814, Loss: 0.2701, Accuracy:0.875\nIteration: 3160, learning rate: 0.00814, Loss: 0.2618, Accuracy:0.898\nIteration: 3161, learning rate: 0.00814, Loss: 0.3053, Accuracy:0.867\nIteration: 3162, learning rate: 0.00814, Loss: 0.3389, Accuracy:0.903\nEpoch: 102, Loss: 0.3312, Accuracy:0.857, Val Loss: 0.3168, Val Accuracy: 0.859\nIteration: 3163, learning rate: 0.00814, Loss: 0.3046, Accuracy:0.867\nIteration: 3164, learning rate: 0.00814, Loss: 0.2482, Accuracy:0.914\nIteration: 3165, learning rate: 0.00814, Loss: 0.3465, Accuracy:0.859\nIteration: 3166, learning rate: 0.00814, Loss: 0.3012, Accuracy:0.867\nIteration: 3167, learning rate: 0.00814, Loss: 0.2907, Accuracy:0.844\nIteration: 3168, learning rate: 0.00814, Loss: 0.3628, Accuracy:0.867\nIteration: 3169, learning rate: 0.00814, Loss: 0.2581, Accuracy:0.891\nIteration: 3170, learning rate: 0.00813, Loss: 0.3154, Accuracy:0.875\nIteration: 3171, learning rate: 0.00813, Loss: 0.2356, Accuracy:0.914\nIteration: 3172, learning rate: 0.00813, Loss: 0.3318, Accuracy:0.828\nIteration: 3173, learning rate: 0.00813, Loss: 0.3085, Accuracy:0.875\nIteration: 3174, learning rate: 0.00813, Loss: 0.2805, Accuracy:0.883\nIteration: 3175, learning rate: 0.00813, Loss: 0.2647, Accuracy:0.898\nIteration: 3176, learning rate: 0.00813, Loss: 0.2918, Accuracy:0.898\nIteration: 3177, learning rate: 0.00813, Loss: 0.2695, Accuracy:0.883\nIteration: 3178, learning rate: 0.00813, Loss: 0.3765, Accuracy:0.797\nIteration: 3179, learning rate: 0.00813, Loss: 0.3204, Accuracy:0.883\nIteration: 3180, learning rate: 0.00813, Loss: 0.3605, Accuracy:0.867\nIteration: 3181, learning rate: 0.00813, Loss: 0.3399, Accuracy:0.867\nIteration: 3182, learning rate: 0.00813, Loss: 0.2725, Accuracy:0.867\nIteration: 3183, learning rate: 0.00813, Loss: 0.3375, Accuracy:0.828\nIteration: 3184, learning rate: 0.00813, Loss: 0.2517, Accuracy:0.906\nIteration: 3185, learning rate: 0.00813, Loss: 0.3742, Accuracy:0.836\nIteration: 3186, learning rate: 0.00813, Loss: 0.2314, Accuracy:0.922\nIteration: 3187, learning rate: 0.00813, Loss: 0.3073, Accuracy:0.891\nIteration: 3188, learning rate: 0.00813, Loss: 0.3057, Accuracy:0.891\nIteration: 3189, learning rate: 0.00813, Loss: 0.3751, Accuracy:0.805\nIteration: 3190, learning rate: 0.00813, Loss: 0.2999, Accuracy:0.867\nIteration: 3191, learning rate: 0.00812, Loss: 0.2731, Accuracy:0.930\nIteration: 3192, learning rate: 0.00812, Loss: 0.3732, Accuracy:0.797\nIteration: 3193, learning rate: 0.00812, Loss: 0.2861, Accuracy:0.871\nEpoch: 103, Loss: 0.3063, Accuracy:0.871, Val Loss: 0.3439, Val Accuracy: 0.830\nIteration: 3194, learning rate: 0.00812, Loss: 0.2976, Accuracy:0.891\nIteration: 3195, learning rate: 0.00812, Loss: 0.3749, Accuracy:0.828\nIteration: 3196, learning rate: 0.00812, Loss: 0.2656, Accuracy:0.875\nIteration: 3197, learning rate: 0.00812, Loss: 0.2761, Accuracy:0.891\nIteration: 3198, learning rate: 0.00812, Loss: 0.2928, Accuracy:0.859\nIteration: 3199, learning rate: 0.00812, Loss: 0.3355, Accuracy:0.828\nIteration: 3200, learning rate: 0.00812, Loss: 0.3011, Accuracy:0.859\nIteration: 3201, learning rate: 0.00812, Loss: 0.3754, Accuracy:0.820\nIteration: 3202, learning rate: 0.00812, Loss: 0.3468, Accuracy:0.828\nIteration: 3203, learning rate: 0.00812, Loss: 0.3042, Accuracy:0.844\nIteration: 3204, learning rate: 0.00812, Loss: 0.3333, Accuracy:0.852\nIteration: 3205, learning rate: 0.00812, Loss: 0.3604, Accuracy:0.867\nIteration: 3206, learning rate: 0.00812, Loss: 0.2593, Accuracy:0.891\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3207, learning rate: 0.00812, Loss: 0.2736, Accuracy:0.906\nIteration: 3208, learning rate: 0.00812, Loss: 0.3847, Accuracy:0.836\nIteration: 3209, learning rate: 0.00812, Loss: 0.2823, Accuracy:0.906\nIteration: 3210, learning rate: 0.00812, Loss: 0.2288, Accuracy:0.922\nIteration: 3211, learning rate: 0.00812, Loss: 0.3124, Accuracy:0.867\nIteration: 3212, learning rate: 0.00812, Loss: 0.3536, Accuracy:0.875\nIteration: 3213, learning rate: 0.00811, Loss: 0.3651, Accuracy:0.859\nIteration: 3214, learning rate: 0.00811, Loss: 0.3332, Accuracy:0.852\nIteration: 3215, learning rate: 0.00811, Loss: 0.2832, Accuracy:0.898\nIteration: 3216, learning rate: 0.00811, Loss: 0.3029, Accuracy:0.891\nIteration: 3217, learning rate: 0.00811, Loss: 0.3071, Accuracy:0.883\nIteration: 3218, learning rate: 0.00811, Loss: 0.3681, Accuracy:0.820\nIteration: 3219, learning rate: 0.00811, Loss: 0.2966, Accuracy:0.859\nIteration: 3220, learning rate: 0.00811, Loss: 0.3319, Accuracy:0.836\nIteration: 3221, learning rate: 0.00811, Loss: 0.3285, Accuracy:0.867\nIteration: 3222, learning rate: 0.00811, Loss: 0.4130, Accuracy:0.812\nIteration: 3223, learning rate: 0.00811, Loss: 0.3170, Accuracy:0.867\nIteration: 3224, learning rate: 0.00811, Loss: 0.3418, Accuracy:0.849\nEpoch: 104, Loss: 0.3209, Accuracy:0.863, Val Loss: 0.3208, Val Accuracy: 0.838\nIteration: 3225, learning rate: 0.00811, Loss: 0.3245, Accuracy:0.852\nIteration: 3226, learning rate: 0.00811, Loss: 0.3030, Accuracy:0.891\nIteration: 3227, learning rate: 0.00811, Loss: 0.2570, Accuracy:0.930\nIteration: 3228, learning rate: 0.00811, Loss: 0.3155, Accuracy:0.836\nIteration: 3229, learning rate: 0.00811, Loss: 0.3449, Accuracy:0.836\nIteration: 3230, learning rate: 0.00811, Loss: 0.3417, Accuracy:0.867\nIteration: 3231, learning rate: 0.00811, Loss: 0.2897, Accuracy:0.867\nIteration: 3232, learning rate: 0.00811, Loss: 0.4082, Accuracy:0.844\nIteration: 3233, learning rate: 0.00811, Loss: 0.2341, Accuracy:0.914\nIteration: 3234, learning rate: 0.00811, Loss: 0.3710, Accuracy:0.836\nIteration: 3235, learning rate: 0.00810, Loss: 0.3126, Accuracy:0.859\nIteration: 3236, learning rate: 0.00810, Loss: 0.2663, Accuracy:0.867\nIteration: 3237, learning rate: 0.00810, Loss: 0.3499, Accuracy:0.852\nIteration: 3238, learning rate: 0.00810, Loss: 0.2883, Accuracy:0.875\nIteration: 3239, learning rate: 0.00810, Loss: 0.3871, Accuracy:0.836\nIteration: 3240, learning rate: 0.00810, Loss: 0.3431, Accuracy:0.852\nIteration: 3241, learning rate: 0.00810, Loss: 0.3215, Accuracy:0.812\nIteration: 3242, learning rate: 0.00810, Loss: 0.2585, Accuracy:0.906\nIteration: 3243, learning rate: 0.00810, Loss: 0.3528, Accuracy:0.836\nIteration: 3244, learning rate: 0.00810, Loss: 0.3086, Accuracy:0.891\nIteration: 3245, learning rate: 0.00810, Loss: 0.2676, Accuracy:0.875\nIteration: 3246, learning rate: 0.00810, Loss: 0.3441, Accuracy:0.867\nIteration: 3247, learning rate: 0.00810, Loss: 0.3660, Accuracy:0.805\nIteration: 3248, learning rate: 0.00810, Loss: 0.2890, Accuracy:0.891\nIteration: 3249, learning rate: 0.00810, Loss: 0.3328, Accuracy:0.891\nIteration: 3250, learning rate: 0.00810, Loss: 0.2995, Accuracy:0.875\nIteration: 3251, learning rate: 0.00810, Loss: 0.3088, Accuracy:0.852\nIteration: 3252, learning rate: 0.00810, Loss: 0.2276, Accuracy:0.930\nIteration: 3253, learning rate: 0.00810, Loss: 0.2861, Accuracy:0.867\nIteration: 3254, learning rate: 0.00810, Loss: 0.2612, Accuracy:0.914\nIteration: 3255, learning rate: 0.00810, Loss: 0.2141, Accuracy:0.935\nEpoch: 105, Loss: 0.3089, Accuracy:0.870, Val Loss: 0.3409, Val Accuracy: 0.826\nIteration: 3256, learning rate: 0.00809, Loss: 0.2444, Accuracy:0.906\nIteration: 3257, learning rate: 0.00809, Loss: 0.2142, Accuracy:0.930\nIteration: 3258, learning rate: 0.00809, Loss: 0.3211, Accuracy:0.859\nIteration: 3259, learning rate: 0.00809, Loss: 0.3417, Accuracy:0.852\nIteration: 3260, learning rate: 0.00809, Loss: 0.3003, Accuracy:0.859\nIteration: 3261, learning rate: 0.00809, Loss: 0.3299, Accuracy:0.828\nIteration: 3262, learning rate: 0.00809, Loss: 0.2814, Accuracy:0.898\nIteration: 3263, learning rate: 0.00809, Loss: 0.3480, Accuracy:0.875\nIteration: 3264, learning rate: 0.00809, Loss: 0.2627, Accuracy:0.891\nIteration: 3265, learning rate: 0.00809, Loss: 0.2516, Accuracy:0.906\nIteration: 3266, learning rate: 0.00809, Loss: 0.3047, Accuracy:0.852\nIteration: 3267, learning rate: 0.00809, Loss: 0.2897, Accuracy:0.875\nIteration: 3268, learning rate: 0.00809, Loss: 0.3029, Accuracy:0.883\nIteration: 3269, learning rate: 0.00809, Loss: 0.3020, Accuracy:0.859\nIteration: 3270, learning rate: 0.00809, Loss: 0.3301, Accuracy:0.875\nIteration: 3271, learning rate: 0.00809, Loss: 0.3307, Accuracy:0.852\nIteration: 3272, learning rate: 0.00809, Loss: 0.3257, Accuracy:0.867\nIteration: 3273, learning rate: 0.00809, Loss: 0.3455, Accuracy:0.852\nIteration: 3274, learning rate: 0.00809, Loss: 0.4274, Accuracy:0.820\nIteration: 3275, learning rate: 0.00809, Loss: 0.2759, Accuracy:0.867\nIteration: 3276, learning rate: 0.00809, Loss: 0.3271, Accuracy:0.859\nIteration: 3277, learning rate: 0.00809, Loss: 0.3536, Accuracy:0.805\nIteration: 3278, learning rate: 0.00808, Loss: 0.2841, Accuracy:0.867\nIteration: 3279, learning rate: 0.00808, Loss: 0.3083, Accuracy:0.875\nIteration: 3280, learning rate: 0.00808, Loss: 0.2454, Accuracy:0.875\nIteration: 3281, learning rate: 0.00808, Loss: 0.2967, Accuracy:0.852\nIteration: 3282, learning rate: 0.00808, Loss: 0.3163, Accuracy:0.859\nIteration: 3283, learning rate: 0.00808, Loss: 0.2867, Accuracy:0.852\nIteration: 3284, learning rate: 0.00808, Loss: 0.2839, Accuracy:0.891\nIteration: 3285, learning rate: 0.00808, Loss: 0.2735, Accuracy:0.867\nIteration: 3286, learning rate: 0.00808, Loss: 0.3604, Accuracy:0.817\nEpoch: 106, Loss: 0.3053, Accuracy:0.865, Val Loss: 0.3464, Val Accuracy: 0.851\nIteration: 3287, learning rate: 0.00808, Loss: 0.2460, Accuracy:0.875\nIteration: 3288, learning rate: 0.00808, Loss: 0.2695, Accuracy:0.875\nIteration: 3289, learning rate: 0.00808, Loss: 0.3465, Accuracy:0.852\nIteration: 3290, learning rate: 0.00808, Loss: 0.4361, Accuracy:0.789\nIteration: 3291, learning rate: 0.00808, Loss: 0.4064, Accuracy:0.820\nIteration: 3292, learning rate: 0.00808, Loss: 0.2358, Accuracy:0.898\nIteration: 3293, learning rate: 0.00808, Loss: 0.3187, Accuracy:0.875\nIteration: 3294, learning rate: 0.00808, Loss: 0.3293, Accuracy:0.859\nIteration: 3295, learning rate: 0.00808, Loss: 0.3216, Accuracy:0.867\nIteration: 3296, learning rate: 0.00808, Loss: 0.3944, Accuracy:0.852\nIteration: 3297, learning rate: 0.00808, Loss: 0.4179, Accuracy:0.797\nIteration: 3298, learning rate: 0.00808, Loss: 0.3063, Accuracy:0.906\nIteration: 3299, learning rate: 0.00808, Loss: 0.3037, Accuracy:0.867\nIteration: 3300, learning rate: 0.00807, Loss: 0.3162, Accuracy:0.859\nIteration: 3301, learning rate: 0.00807, Loss: 0.2933, Accuracy:0.891\nIteration: 3302, learning rate: 0.00807, Loss: 0.3131, Accuracy:0.844\nIteration: 3303, learning rate: 0.00807, Loss: 0.3090, Accuracy:0.852\nIteration: 3304, learning rate: 0.00807, Loss: 0.3604, Accuracy:0.828\nIteration: 3305, learning rate: 0.00807, Loss: 0.3498, Accuracy:0.820\nIteration: 3306, learning rate: 0.00807, Loss: 0.3345, Accuracy:0.883\nIteration: 3307, learning rate: 0.00807, Loss: 0.3054, Accuracy:0.875\nIteration: 3308, learning rate: 0.00807, Loss: 0.3298, Accuracy:0.852\nIteration: 3309, learning rate: 0.00807, Loss: 0.3660, Accuracy:0.836\nIteration: 3310, learning rate: 0.00807, Loss: 0.3481, Accuracy:0.828\nIteration: 3311, learning rate: 0.00807, Loss: 0.2183, Accuracy:0.930\nIteration: 3312, learning rate: 0.00807, Loss: 0.3037, Accuracy:0.875\nIteration: 3313, learning rate: 0.00807, Loss: 0.3027, Accuracy:0.859\nIteration: 3314, learning rate: 0.00807, Loss: 0.3267, Accuracy:0.844\nIteration: 3315, learning rate: 0.00807, Loss: 0.2828, Accuracy:0.867\nIteration: 3316, learning rate: 0.00807, Loss: 0.3731, Accuracy:0.812\nIteration: 3317, learning rate: 0.00807, Loss: 0.2993, Accuracy:0.839\nEpoch: 107, Loss: 0.3247, Accuracy:0.856, Val Loss: 0.3476, Val Accuracy: 0.840\nIteration: 3318, learning rate: 0.00807, Loss: 0.2653, Accuracy:0.891\nIteration: 3319, learning rate: 0.00807, Loss: 0.3553, Accuracy:0.844\nIteration: 3320, learning rate: 0.00807, Loss: 0.2516, Accuracy:0.891\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3321, learning rate: 0.00807, Loss: 0.2802, Accuracy:0.898\nIteration: 3322, learning rate: 0.00806, Loss: 0.3384, Accuracy:0.844\nIteration: 3323, learning rate: 0.00806, Loss: 0.3047, Accuracy:0.883\nIteration: 3324, learning rate: 0.00806, Loss: 0.3538, Accuracy:0.828\nIteration: 3325, learning rate: 0.00806, Loss: 0.3789, Accuracy:0.797\nIteration: 3326, learning rate: 0.00806, Loss: 0.2846, Accuracy:0.891\nIteration: 3327, learning rate: 0.00806, Loss: 0.3616, Accuracy:0.852\nIteration: 3328, learning rate: 0.00806, Loss: 0.2185, Accuracy:0.938\nIteration: 3329, learning rate: 0.00806, Loss: 0.3678, Accuracy:0.820\nIteration: 3330, learning rate: 0.00806, Loss: 0.2722, Accuracy:0.859\nIteration: 3331, learning rate: 0.00806, Loss: 0.2896, Accuracy:0.891\nIteration: 3332, learning rate: 0.00806, Loss: 0.3533, Accuracy:0.844\nIteration: 3333, learning rate: 0.00806, Loss: 0.3144, Accuracy:0.820\nIteration: 3334, learning rate: 0.00806, Loss: 0.2652, Accuracy:0.891\nIteration: 3335, learning rate: 0.00806, Loss: 0.2319, Accuracy:0.914\nIteration: 3336, learning rate: 0.00806, Loss: 0.1854, Accuracy:0.938\nIteration: 3337, learning rate: 0.00806, Loss: 0.3615, Accuracy:0.844\nIteration: 3338, learning rate: 0.00806, Loss: 0.3621, Accuracy:0.883\nIteration: 3339, learning rate: 0.00806, Loss: 0.3018, Accuracy:0.852\nIteration: 3340, learning rate: 0.00806, Loss: 0.3331, Accuracy:0.828\nIteration: 3341, learning rate: 0.00806, Loss: 0.3678, Accuracy:0.828\nIteration: 3342, learning rate: 0.00806, Loss: 0.3121, Accuracy:0.859\nIteration: 3343, learning rate: 0.00806, Loss: 0.3586, Accuracy:0.844\nIteration: 3344, learning rate: 0.00805, Loss: 0.2659, Accuracy:0.906\nIteration: 3345, learning rate: 0.00805, Loss: 0.3801, Accuracy:0.852\nIteration: 3346, learning rate: 0.00805, Loss: 0.3617, Accuracy:0.828\nIteration: 3347, learning rate: 0.00805, Loss: 0.3693, Accuracy:0.859\nIteration: 3348, learning rate: 0.00805, Loss: 0.4395, Accuracy:0.742\nEpoch: 108, Loss: 0.3189, Accuracy:0.860, Val Loss: 0.3362, Val Accuracy: 0.841\nIteration: 3349, learning rate: 0.00805, Loss: 0.3879, Accuracy:0.820\nIteration: 3350, learning rate: 0.00805, Loss: 0.2592, Accuracy:0.867\nIteration: 3351, learning rate: 0.00805, Loss: 0.3181, Accuracy:0.852\nIteration: 3352, learning rate: 0.00805, Loss: 0.2349, Accuracy:0.906\nIteration: 3353, learning rate: 0.00805, Loss: 0.2936, Accuracy:0.891\nIteration: 3354, learning rate: 0.00805, Loss: 0.2751, Accuracy:0.875\nIteration: 3355, learning rate: 0.00805, Loss: 0.2683, Accuracy:0.891\nIteration: 3356, learning rate: 0.00805, Loss: 0.3146, Accuracy:0.875\nIteration: 3357, learning rate: 0.00805, Loss: 0.2700, Accuracy:0.883\nIteration: 3358, learning rate: 0.00805, Loss: 0.3247, Accuracy:0.875\nIteration: 3359, learning rate: 0.00805, Loss: 0.4055, Accuracy:0.820\nIteration: 3360, learning rate: 0.00805, Loss: 0.3658, Accuracy:0.828\nIteration: 3361, learning rate: 0.00805, Loss: 0.3695, Accuracy:0.836\nIteration: 3362, learning rate: 0.00805, Loss: 0.2986, Accuracy:0.875\nIteration: 3363, learning rate: 0.00805, Loss: 0.2721, Accuracy:0.891\nIteration: 3364, learning rate: 0.00805, Loss: 0.2053, Accuracy:0.938\nIteration: 3365, learning rate: 0.00805, Loss: 0.3107, Accuracy:0.844\nIteration: 3366, learning rate: 0.00804, Loss: 0.3010, Accuracy:0.875\nIteration: 3367, learning rate: 0.00804, Loss: 0.2875, Accuracy:0.875\nIteration: 3368, learning rate: 0.00804, Loss: 0.2500, Accuracy:0.906\nIteration: 3369, learning rate: 0.00804, Loss: 0.3242, Accuracy:0.852\nIteration: 3370, learning rate: 0.00804, Loss: 0.2758, Accuracy:0.883\nIteration: 3371, learning rate: 0.00804, Loss: 0.2868, Accuracy:0.891\nIteration: 3372, learning rate: 0.00804, Loss: 0.3049, Accuracy:0.875\nIteration: 3373, learning rate: 0.00804, Loss: 0.3678, Accuracy:0.852\nIteration: 3374, learning rate: 0.00804, Loss: 0.2770, Accuracy:0.883\nIteration: 3375, learning rate: 0.00804, Loss: 0.3917, Accuracy:0.836\nIteration: 3376, learning rate: 0.00804, Loss: 0.2589, Accuracy:0.914\nIteration: 3377, learning rate: 0.00804, Loss: 0.3567, Accuracy:0.836\nIteration: 3378, learning rate: 0.00804, Loss: 0.3202, Accuracy:0.891\nIteration: 3379, learning rate: 0.00804, Loss: 0.3459, Accuracy:0.817\nEpoch: 109, Loss: 0.3072, Accuracy:0.869, Val Loss: 0.3457, Val Accuracy: 0.835\nIteration: 3380, learning rate: 0.00804, Loss: 0.3259, Accuracy:0.867\nIteration: 3381, learning rate: 0.00804, Loss: 0.3576, Accuracy:0.875\nIteration: 3382, learning rate: 0.00804, Loss: 0.3061, Accuracy:0.867\nIteration: 3383, learning rate: 0.00804, Loss: 0.2957, Accuracy:0.875\nIteration: 3384, learning rate: 0.00804, Loss: 0.2611, Accuracy:0.867\nIteration: 3385, learning rate: 0.00804, Loss: 0.4052, Accuracy:0.812\nIteration: 3386, learning rate: 0.00804, Loss: 0.2849, Accuracy:0.883\nIteration: 3387, learning rate: 0.00804, Loss: 0.2966, Accuracy:0.859\nIteration: 3388, learning rate: 0.00804, Loss: 0.3651, Accuracy:0.820\nIteration: 3389, learning rate: 0.00803, Loss: 0.3197, Accuracy:0.859\nIteration: 3390, learning rate: 0.00803, Loss: 0.2941, Accuracy:0.844\nIteration: 3391, learning rate: 0.00803, Loss: 0.2530, Accuracy:0.875\nIteration: 3392, learning rate: 0.00803, Loss: 0.2992, Accuracy:0.875\nIteration: 3393, learning rate: 0.00803, Loss: 0.3413, Accuracy:0.836\nIteration: 3394, learning rate: 0.00803, Loss: 0.3880, Accuracy:0.828\nIteration: 3395, learning rate: 0.00803, Loss: 0.2650, Accuracy:0.891\nIteration: 3396, learning rate: 0.00803, Loss: 0.3430, Accuracy:0.852\nIteration: 3397, learning rate: 0.00803, Loss: 0.2932, Accuracy:0.867\nIteration: 3398, learning rate: 0.00803, Loss: 0.2806, Accuracy:0.875\nIteration: 3399, learning rate: 0.00803, Loss: 0.3383, Accuracy:0.812\nIteration: 3400, learning rate: 0.00803, Loss: 0.3072, Accuracy:0.844\nIteration: 3401, learning rate: 0.00803, Loss: 0.3293, Accuracy:0.852\nIteration: 3402, learning rate: 0.00803, Loss: 0.4143, Accuracy:0.805\nIteration: 3403, learning rate: 0.00803, Loss: 0.2698, Accuracy:0.906\nIteration: 3404, learning rate: 0.00803, Loss: 0.3490, Accuracy:0.852\nIteration: 3405, learning rate: 0.00803, Loss: 0.2791, Accuracy:0.891\nIteration: 3406, learning rate: 0.00803, Loss: 0.3390, Accuracy:0.875\nIteration: 3407, learning rate: 0.00803, Loss: 0.3275, Accuracy:0.867\nIteration: 3408, learning rate: 0.00803, Loss: 0.3279, Accuracy:0.875\nIteration: 3409, learning rate: 0.00803, Loss: 0.4149, Accuracy:0.859\nIteration: 3410, learning rate: 0.00803, Loss: 0.3124, Accuracy:0.871\nEpoch: 110, Loss: 0.3221, Accuracy:0.859, Val Loss: 0.3362, Val Accuracy: 0.845\nIteration: 3411, learning rate: 0.00802, Loss: 0.3494, Accuracy:0.852\nIteration: 3412, learning rate: 0.00802, Loss: 0.2697, Accuracy:0.906\nIteration: 3413, learning rate: 0.00802, Loss: 0.3565, Accuracy:0.883\nIteration: 3414, learning rate: 0.00802, Loss: 0.3256, Accuracy:0.898\nIteration: 3415, learning rate: 0.00802, Loss: 0.3315, Accuracy:0.844\nIteration: 3416, learning rate: 0.00802, Loss: 0.3632, Accuracy:0.852\nIteration: 3417, learning rate: 0.00802, Loss: 0.2673, Accuracy:0.898\nIteration: 3418, learning rate: 0.00802, Loss: 0.2356, Accuracy:0.914\nIteration: 3419, learning rate: 0.00802, Loss: 0.3873, Accuracy:0.836\nIteration: 3420, learning rate: 0.00802, Loss: 0.2614, Accuracy:0.875\nIteration: 3421, learning rate: 0.00802, Loss: 0.3598, Accuracy:0.844\nIteration: 3422, learning rate: 0.00802, Loss: 0.4050, Accuracy:0.805\nIteration: 3423, learning rate: 0.00802, Loss: 0.3667, Accuracy:0.844\nIteration: 3424, learning rate: 0.00802, Loss: 0.2989, Accuracy:0.836\nIteration: 3425, learning rate: 0.00802, Loss: 0.2447, Accuracy:0.906\nIteration: 3426, learning rate: 0.00802, Loss: 0.3240, Accuracy:0.883\nIteration: 3427, learning rate: 0.00802, Loss: 0.3213, Accuracy:0.852\nIteration: 3428, learning rate: 0.00802, Loss: 0.3859, Accuracy:0.844\nIteration: 3429, learning rate: 0.00802, Loss: 0.3504, Accuracy:0.875\nIteration: 3430, learning rate: 0.00802, Loss: 0.2970, Accuracy:0.883\nIteration: 3431, learning rate: 0.00802, Loss: 0.2557, Accuracy:0.914\nIteration: 3432, learning rate: 0.00802, Loss: 0.3322, Accuracy:0.820\nIteration: 3433, learning rate: 0.00801, Loss: 0.3367, Accuracy:0.867\nIteration: 3434, learning rate: 0.00801, Loss: 0.3232, Accuracy:0.883\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3435, learning rate: 0.00801, Loss: 0.4092, Accuracy:0.789\nIteration: 3436, learning rate: 0.00801, Loss: 0.3017, Accuracy:0.875\nIteration: 3437, learning rate: 0.00801, Loss: 0.3246, Accuracy:0.867\nIteration: 3438, learning rate: 0.00801, Loss: 0.2598, Accuracy:0.867\nIteration: 3439, learning rate: 0.00801, Loss: 0.2921, Accuracy:0.898\nIteration: 3440, learning rate: 0.00801, Loss: 0.2677, Accuracy:0.906\nIteration: 3441, learning rate: 0.00801, Loss: 0.2882, Accuracy:0.892\nEpoch: 111, Loss: 0.3191, Accuracy:0.868, Val Loss: 0.3377, Val Accuracy: 0.848\nIteration: 3442, learning rate: 0.00801, Loss: 0.3456, Accuracy:0.812\nIteration: 3443, learning rate: 0.00801, Loss: 0.2409, Accuracy:0.898\nIteration: 3444, learning rate: 0.00801, Loss: 0.3638, Accuracy:0.852\nIteration: 3445, learning rate: 0.00801, Loss: 0.2195, Accuracy:0.922\nIteration: 3446, learning rate: 0.00801, Loss: 0.3283, Accuracy:0.844\nIteration: 3447, learning rate: 0.00801, Loss: 0.3772, Accuracy:0.820\nIteration: 3448, learning rate: 0.00801, Loss: 0.3463, Accuracy:0.844\nIteration: 3449, learning rate: 0.00801, Loss: 0.2985, Accuracy:0.875\nIteration: 3450, learning rate: 0.00801, Loss: 0.2857, Accuracy:0.867\nIteration: 3451, learning rate: 0.00801, Loss: 0.3385, Accuracy:0.844\nIteration: 3452, learning rate: 0.00801, Loss: 0.2876, Accuracy:0.898\nIteration: 3453, learning rate: 0.00801, Loss: 0.3053, Accuracy:0.891\nIteration: 3454, learning rate: 0.00801, Loss: 0.3696, Accuracy:0.820\nIteration: 3455, learning rate: 0.00801, Loss: 0.3160, Accuracy:0.852\nIteration: 3456, learning rate: 0.00800, Loss: 0.2959, Accuracy:0.883\nIteration: 3457, learning rate: 0.00800, Loss: 0.3789, Accuracy:0.844\nIteration: 3458, learning rate: 0.00800, Loss: 0.3135, Accuracy:0.867\nIteration: 3459, learning rate: 0.00800, Loss: 0.3113, Accuracy:0.875\nIteration: 3460, learning rate: 0.00800, Loss: 0.2288, Accuracy:0.930\nIteration: 3461, learning rate: 0.00800, Loss: 0.4240, Accuracy:0.773\nIteration: 3462, learning rate: 0.00800, Loss: 0.3361, Accuracy:0.828\nIteration: 3463, learning rate: 0.00800, Loss: 0.3127, Accuracy:0.859\nIteration: 3464, learning rate: 0.00800, Loss: 0.3346, Accuracy:0.828\nIteration: 3465, learning rate: 0.00800, Loss: 0.3558, Accuracy:0.852\nIteration: 3466, learning rate: 0.00800, Loss: 0.2901, Accuracy:0.891\nIteration: 3467, learning rate: 0.00800, Loss: 0.2255, Accuracy:0.930\nIteration: 3468, learning rate: 0.00800, Loss: 0.3605, Accuracy:0.875\nIteration: 3469, learning rate: 0.00800, Loss: 0.3097, Accuracy:0.867\nIteration: 3470, learning rate: 0.00800, Loss: 0.2697, Accuracy:0.859\nIteration: 3471, learning rate: 0.00800, Loss: 0.2667, Accuracy:0.883\nIteration: 3472, learning rate: 0.00800, Loss: 0.2775, Accuracy:0.882\nEpoch: 112, Loss: 0.3134, Accuracy:0.863, Val Loss: 0.3124, Val Accuracy: 0.869\nIteration: 3473, learning rate: 0.00800, Loss: 0.2601, Accuracy:0.859\nIteration: 3474, learning rate: 0.00800, Loss: 0.2405, Accuracy:0.898\nIteration: 3475, learning rate: 0.00800, Loss: 0.2686, Accuracy:0.906\nIteration: 3476, learning rate: 0.00800, Loss: 0.2187, Accuracy:0.914\nIteration: 3477, learning rate: 0.00800, Loss: 0.3674, Accuracy:0.852\nIteration: 3478, learning rate: 0.00799, Loss: 0.3212, Accuracy:0.852\nIteration: 3479, learning rate: 0.00799, Loss: 0.3620, Accuracy:0.836\nIteration: 3480, learning rate: 0.00799, Loss: 0.2674, Accuracy:0.891\nIteration: 3481, learning rate: 0.00799, Loss: 0.3574, Accuracy:0.836\nIteration: 3482, learning rate: 0.00799, Loss: 0.2196, Accuracy:0.930\nIteration: 3483, learning rate: 0.00799, Loss: 0.2681, Accuracy:0.906\nIteration: 3484, learning rate: 0.00799, Loss: 0.3233, Accuracy:0.859\nIteration: 3485, learning rate: 0.00799, Loss: 0.3233, Accuracy:0.859\nIteration: 3486, learning rate: 0.00799, Loss: 0.3115, Accuracy:0.852\nIteration: 3487, learning rate: 0.00799, Loss: 0.3037, Accuracy:0.891\nIteration: 3488, learning rate: 0.00799, Loss: 0.3366, Accuracy:0.820\nIteration: 3489, learning rate: 0.00799, Loss: 0.3099, Accuracy:0.859\nIteration: 3490, learning rate: 0.00799, Loss: 0.3778, Accuracy:0.836\nIteration: 3491, learning rate: 0.00799, Loss: 0.2985, Accuracy:0.859\nIteration: 3492, learning rate: 0.00799, Loss: 0.2094, Accuracy:0.930\nIteration: 3493, learning rate: 0.00799, Loss: 0.3034, Accuracy:0.859\nIteration: 3494, learning rate: 0.00799, Loss: 0.2981, Accuracy:0.891\nIteration: 3495, learning rate: 0.00799, Loss: 0.3064, Accuracy:0.891\nIteration: 3496, learning rate: 0.00799, Loss: 0.3239, Accuracy:0.875\nIteration: 3497, learning rate: 0.00799, Loss: 0.3142, Accuracy:0.867\nIteration: 3498, learning rate: 0.00799, Loss: 0.2549, Accuracy:0.930\nIteration: 3499, learning rate: 0.00799, Loss: 0.2979, Accuracy:0.867\nIteration: 3500, learning rate: 0.00798, Loss: 0.2522, Accuracy:0.867\nIteration: 3501, learning rate: 0.00798, Loss: 0.2883, Accuracy:0.883\nIteration: 3502, learning rate: 0.00798, Loss: 0.2591, Accuracy:0.867\nIteration: 3503, learning rate: 0.00798, Loss: 0.3229, Accuracy:0.849\nEpoch: 113, Loss: 0.2957, Accuracy:0.874, Val Loss: 0.3341, Val Accuracy: 0.858\nIteration: 3504, learning rate: 0.00798, Loss: 0.3341, Accuracy:0.828\nIteration: 3505, learning rate: 0.00798, Loss: 0.3678, Accuracy:0.852\nIteration: 3506, learning rate: 0.00798, Loss: 0.3396, Accuracy:0.844\nIteration: 3507, learning rate: 0.00798, Loss: 0.2606, Accuracy:0.875\nIteration: 3508, learning rate: 0.00798, Loss: 0.2783, Accuracy:0.898\nIteration: 3509, learning rate: 0.00798, Loss: 0.4106, Accuracy:0.812\nIteration: 3510, learning rate: 0.00798, Loss: 0.2738, Accuracy:0.875\nIteration: 3511, learning rate: 0.00798, Loss: 0.2914, Accuracy:0.859\nIteration: 3512, learning rate: 0.00798, Loss: 0.3358, Accuracy:0.875\nIteration: 3513, learning rate: 0.00798, Loss: 0.2391, Accuracy:0.914\nIteration: 3514, learning rate: 0.00798, Loss: 0.2527, Accuracy:0.898\nIteration: 3515, learning rate: 0.00798, Loss: 0.2707, Accuracy:0.859\nIteration: 3516, learning rate: 0.00798, Loss: 0.3193, Accuracy:0.852\nIteration: 3517, learning rate: 0.00798, Loss: 0.2513, Accuracy:0.891\nIteration: 3518, learning rate: 0.00798, Loss: 0.2927, Accuracy:0.891\nIteration: 3519, learning rate: 0.00798, Loss: 0.2607, Accuracy:0.922\nIteration: 3520, learning rate: 0.00798, Loss: 0.2525, Accuracy:0.914\nIteration: 3521, learning rate: 0.00798, Loss: 0.3363, Accuracy:0.867\nIteration: 3522, learning rate: 0.00798, Loss: 0.3016, Accuracy:0.867\nIteration: 3523, learning rate: 0.00797, Loss: 0.2310, Accuracy:0.906\nIteration: 3524, learning rate: 0.00797, Loss: 0.2957, Accuracy:0.875\nIteration: 3525, learning rate: 0.00797, Loss: 0.2825, Accuracy:0.867\nIteration: 3526, learning rate: 0.00797, Loss: 0.2155, Accuracy:0.922\nIteration: 3527, learning rate: 0.00797, Loss: 0.3382, Accuracy:0.828\nIteration: 3528, learning rate: 0.00797, Loss: 0.2834, Accuracy:0.898\nIteration: 3529, learning rate: 0.00797, Loss: 0.3015, Accuracy:0.867\nIteration: 3530, learning rate: 0.00797, Loss: 0.2411, Accuracy:0.875\nIteration: 3531, learning rate: 0.00797, Loss: 0.2761, Accuracy:0.859\nIteration: 3532, learning rate: 0.00797, Loss: 0.2533, Accuracy:0.883\nIteration: 3533, learning rate: 0.00797, Loss: 0.2310, Accuracy:0.906\nIteration: 3534, learning rate: 0.00797, Loss: 0.3150, Accuracy:0.882\nEpoch: 114, Loss: 0.2882, Accuracy:0.876, Val Loss: 0.3364, Val Accuracy: 0.846\nIteration: 3535, learning rate: 0.00797, Loss: 0.2856, Accuracy:0.906\nIteration: 3536, learning rate: 0.00797, Loss: 0.2857, Accuracy:0.875\nIteration: 3537, learning rate: 0.00797, Loss: 0.3114, Accuracy:0.852\nIteration: 3538, learning rate: 0.00797, Loss: 0.2515, Accuracy:0.914\nIteration: 3539, learning rate: 0.00797, Loss: 0.3313, Accuracy:0.875\nIteration: 3540, learning rate: 0.00797, Loss: 0.2701, Accuracy:0.875\nIteration: 3541, learning rate: 0.00797, Loss: 0.2920, Accuracy:0.859\nIteration: 3542, learning rate: 0.00797, Loss: 0.3083, Accuracy:0.859\nIteration: 3543, learning rate: 0.00797, Loss: 0.2410, Accuracy:0.914\nIteration: 3544, learning rate: 0.00797, Loss: 0.3414, Accuracy:0.852\nIteration: 3545, learning rate: 0.00797, Loss: 0.3015, Accuracy:0.883\nIteration: 3546, learning rate: 0.00796, Loss: 0.2313, Accuracy:0.898\nIteration: 3547, learning rate: 0.00796, Loss: 0.2445, Accuracy:0.875\nIteration: 3548, learning rate: 0.00796, Loss: 0.2314, Accuracy:0.938\nIteration: 3549, learning rate: 0.00796, Loss: 0.2510, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3550, learning rate: 0.00796, Loss: 0.3832, Accuracy:0.852\nIteration: 3551, learning rate: 0.00796, Loss: 0.2355, Accuracy:0.906\nIteration: 3552, learning rate: 0.00796, Loss: 0.3251, Accuracy:0.883\nIteration: 3553, learning rate: 0.00796, Loss: 0.3176, Accuracy:0.867\nIteration: 3554, learning rate: 0.00796, Loss: 0.2766, Accuracy:0.898\nIteration: 3555, learning rate: 0.00796, Loss: 0.3450, Accuracy:0.844\nIteration: 3556, learning rate: 0.00796, Loss: 0.3298, Accuracy:0.891\nIteration: 3557, learning rate: 0.00796, Loss: 0.3645, Accuracy:0.828\nIteration: 3558, learning rate: 0.00796, Loss: 0.3469, Accuracy:0.836\nIteration: 3559, learning rate: 0.00796, Loss: 0.3825, Accuracy:0.828\nIteration: 3560, learning rate: 0.00796, Loss: 0.2424, Accuracy:0.930\nIteration: 3561, learning rate: 0.00796, Loss: 0.2874, Accuracy:0.883\nIteration: 3562, learning rate: 0.00796, Loss: 0.3010, Accuracy:0.883\nIteration: 3563, learning rate: 0.00796, Loss: 0.3496, Accuracy:0.828\nIteration: 3564, learning rate: 0.00796, Loss: 0.3081, Accuracy:0.859\nIteration: 3565, learning rate: 0.00796, Loss: 0.2765, Accuracy:0.892\nEpoch: 115, Loss: 0.2984, Accuracy:0.877, Val Loss: 0.3530, Val Accuracy: 0.853\nIteration: 3566, learning rate: 0.00796, Loss: 0.3037, Accuracy:0.867\nIteration: 3567, learning rate: 0.00796, Loss: 0.3248, Accuracy:0.836\nIteration: 3568, learning rate: 0.00795, Loss: 0.4838, Accuracy:0.766\nIteration: 3569, learning rate: 0.00795, Loss: 0.3207, Accuracy:0.891\nIteration: 3570, learning rate: 0.00795, Loss: 0.2757, Accuracy:0.875\nIteration: 3571, learning rate: 0.00795, Loss: 0.2609, Accuracy:0.883\nIteration: 3572, learning rate: 0.00795, Loss: 0.4146, Accuracy:0.812\nIteration: 3573, learning rate: 0.00795, Loss: 0.3231, Accuracy:0.875\nIteration: 3574, learning rate: 0.00795, Loss: 0.2741, Accuracy:0.891\nIteration: 3575, learning rate: 0.00795, Loss: 0.2279, Accuracy:0.922\nIteration: 3576, learning rate: 0.00795, Loss: 0.2095, Accuracy:0.938\nIteration: 3577, learning rate: 0.00795, Loss: 0.3031, Accuracy:0.852\nIteration: 3578, learning rate: 0.00795, Loss: 0.2497, Accuracy:0.891\nIteration: 3579, learning rate: 0.00795, Loss: 0.2685, Accuracy:0.891\nIteration: 3580, learning rate: 0.00795, Loss: 0.3451, Accuracy:0.867\nIteration: 3581, learning rate: 0.00795, Loss: 0.3755, Accuracy:0.852\nIteration: 3582, learning rate: 0.00795, Loss: 0.3209, Accuracy:0.852\nIteration: 3583, learning rate: 0.00795, Loss: 0.3806, Accuracy:0.828\nIteration: 3584, learning rate: 0.00795, Loss: 0.2851, Accuracy:0.891\nIteration: 3585, learning rate: 0.00795, Loss: 0.3826, Accuracy:0.812\nIteration: 3586, learning rate: 0.00795, Loss: 0.3108, Accuracy:0.891\nIteration: 3587, learning rate: 0.00795, Loss: 0.4013, Accuracy:0.820\nIteration: 3588, learning rate: 0.00795, Loss: 0.3807, Accuracy:0.844\nIteration: 3589, learning rate: 0.00795, Loss: 0.3331, Accuracy:0.875\nIteration: 3590, learning rate: 0.00795, Loss: 0.3442, Accuracy:0.844\nIteration: 3591, learning rate: 0.00794, Loss: 0.3259, Accuracy:0.844\nIteration: 3592, learning rate: 0.00794, Loss: 0.2583, Accuracy:0.914\nIteration: 3593, learning rate: 0.00794, Loss: 0.2695, Accuracy:0.914\nIteration: 3594, learning rate: 0.00794, Loss: 0.2359, Accuracy:0.914\nIteration: 3595, learning rate: 0.00794, Loss: 0.3306, Accuracy:0.836\nIteration: 3596, learning rate: 0.00794, Loss: 0.2537, Accuracy:0.925\nEpoch: 116, Loss: 0.3153, Accuracy:0.868, Val Loss: 0.3893, Val Accuracy: 0.821\nIteration: 3597, learning rate: 0.00794, Loss: 0.2664, Accuracy:0.891\nIteration: 3598, learning rate: 0.00794, Loss: 0.2976, Accuracy:0.875\nIteration: 3599, learning rate: 0.00794, Loss: 0.2129, Accuracy:0.922\nIteration: 3600, learning rate: 0.00794, Loss: 0.2629, Accuracy:0.906\nIteration: 3601, learning rate: 0.00794, Loss: 0.3578, Accuracy:0.820\nIteration: 3602, learning rate: 0.00794, Loss: 0.1903, Accuracy:0.930\nIteration: 3603, learning rate: 0.00794, Loss: 0.2597, Accuracy:0.922\nIteration: 3604, learning rate: 0.00794, Loss: 0.2594, Accuracy:0.875\nIteration: 3605, learning rate: 0.00794, Loss: 0.3501, Accuracy:0.836\nIteration: 3606, learning rate: 0.00794, Loss: 0.3526, Accuracy:0.859\nIteration: 3607, learning rate: 0.00794, Loss: 0.3397, Accuracy:0.852\nIteration: 3608, learning rate: 0.00794, Loss: 0.3652, Accuracy:0.852\nIteration: 3609, learning rate: 0.00794, Loss: 0.2889, Accuracy:0.883\nIteration: 3610, learning rate: 0.00794, Loss: 0.3140, Accuracy:0.859\nIteration: 3611, learning rate: 0.00794, Loss: 0.2409, Accuracy:0.898\nIteration: 3612, learning rate: 0.00794, Loss: 0.2688, Accuracy:0.859\nIteration: 3613, learning rate: 0.00794, Loss: 0.2598, Accuracy:0.883\nIteration: 3614, learning rate: 0.00793, Loss: 0.2834, Accuracy:0.867\nIteration: 3615, learning rate: 0.00793, Loss: 0.3013, Accuracy:0.891\nIteration: 3616, learning rate: 0.00793, Loss: 0.1989, Accuracy:0.953\nIteration: 3617, learning rate: 0.00793, Loss: 0.2496, Accuracy:0.906\nIteration: 3618, learning rate: 0.00793, Loss: 0.3647, Accuracy:0.852\nIteration: 3619, learning rate: 0.00793, Loss: 0.2953, Accuracy:0.891\nIteration: 3620, learning rate: 0.00793, Loss: 0.3711, Accuracy:0.812\nIteration: 3621, learning rate: 0.00793, Loss: 0.2852, Accuracy:0.883\nIteration: 3622, learning rate: 0.00793, Loss: 0.2773, Accuracy:0.875\nIteration: 3623, learning rate: 0.00793, Loss: 0.2720, Accuracy:0.891\nIteration: 3624, learning rate: 0.00793, Loss: 0.3726, Accuracy:0.844\nIteration: 3625, learning rate: 0.00793, Loss: 0.2993, Accuracy:0.867\nIteration: 3626, learning rate: 0.00793, Loss: 0.3535, Accuracy:0.852\nIteration: 3627, learning rate: 0.00793, Loss: 0.2874, Accuracy:0.860\nEpoch: 117, Loss: 0.2935, Accuracy:0.876, Val Loss: 0.3441, Val Accuracy: 0.839\nIteration: 3628, learning rate: 0.00793, Loss: 0.2621, Accuracy:0.898\nIteration: 3629, learning rate: 0.00793, Loss: 0.2811, Accuracy:0.891\nIteration: 3630, learning rate: 0.00793, Loss: 0.3274, Accuracy:0.836\nIteration: 3631, learning rate: 0.00793, Loss: 0.3077, Accuracy:0.859\nIteration: 3632, learning rate: 0.00793, Loss: 0.2849, Accuracy:0.844\nIteration: 3633, learning rate: 0.00793, Loss: 0.2882, Accuracy:0.875\nIteration: 3634, learning rate: 0.00793, Loss: 0.2673, Accuracy:0.906\nIteration: 3635, learning rate: 0.00793, Loss: 0.2265, Accuracy:0.914\nIteration: 3636, learning rate: 0.00793, Loss: 0.3441, Accuracy:0.844\nIteration: 3637, learning rate: 0.00792, Loss: 0.3104, Accuracy:0.852\nIteration: 3638, learning rate: 0.00792, Loss: 0.2841, Accuracy:0.883\nIteration: 3639, learning rate: 0.00792, Loss: 0.3274, Accuracy:0.852\nIteration: 3640, learning rate: 0.00792, Loss: 0.2876, Accuracy:0.875\nIteration: 3641, learning rate: 0.00792, Loss: 0.3166, Accuracy:0.844\nIteration: 3642, learning rate: 0.00792, Loss: 0.3628, Accuracy:0.844\nIteration: 3643, learning rate: 0.00792, Loss: 0.2953, Accuracy:0.867\nIteration: 3644, learning rate: 0.00792, Loss: 0.3680, Accuracy:0.797\nIteration: 3645, learning rate: 0.00792, Loss: 0.3014, Accuracy:0.852\nIteration: 3646, learning rate: 0.00792, Loss: 0.3574, Accuracy:0.820\nIteration: 3647, learning rate: 0.00792, Loss: 0.3151, Accuracy:0.859\nIteration: 3648, learning rate: 0.00792, Loss: 0.2487, Accuracy:0.891\nIteration: 3649, learning rate: 0.00792, Loss: 0.2596, Accuracy:0.906\nIteration: 3650, learning rate: 0.00792, Loss: 0.2832, Accuracy:0.883\nIteration: 3651, learning rate: 0.00792, Loss: 0.1981, Accuracy:0.945\nIteration: 3652, learning rate: 0.00792, Loss: 0.2068, Accuracy:0.930\nIteration: 3653, learning rate: 0.00792, Loss: 0.2955, Accuracy:0.875\nIteration: 3654, learning rate: 0.00792, Loss: 0.3300, Accuracy:0.867\nIteration: 3655, learning rate: 0.00792, Loss: 0.4331, Accuracy:0.781\nIteration: 3656, learning rate: 0.00792, Loss: 0.2633, Accuracy:0.891\nIteration: 3657, learning rate: 0.00792, Loss: 0.2261, Accuracy:0.891\nIteration: 3658, learning rate: 0.00792, Loss: 0.2664, Accuracy:0.882\nEpoch: 118, Loss: 0.2944, Accuracy:0.869, Val Loss: 0.3255, Val Accuracy: 0.842\nIteration: 3659, learning rate: 0.00792, Loss: 0.1781, Accuracy:0.906\nIteration: 3660, learning rate: 0.00791, Loss: 0.2529, Accuracy:0.898\nIteration: 3661, learning rate: 0.00791, Loss: 0.2719, Accuracy:0.859\nIteration: 3662, learning rate: 0.00791, Loss: 0.3104, Accuracy:0.859\nIteration: 3663, learning rate: 0.00791, Loss: 0.2517, Accuracy:0.906\nIteration: 3664, learning rate: 0.00791, Loss: 0.3432, Accuracy:0.867\nIteration: 3665, learning rate: 0.00791, Loss: 0.2452, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3666, learning rate: 0.00791, Loss: 0.2600, Accuracy:0.883\nIteration: 3667, learning rate: 0.00791, Loss: 0.4470, Accuracy:0.820\nIteration: 3668, learning rate: 0.00791, Loss: 0.2814, Accuracy:0.891\nIteration: 3669, learning rate: 0.00791, Loss: 0.2601, Accuracy:0.898\nIteration: 3670, learning rate: 0.00791, Loss: 0.3052, Accuracy:0.875\nIteration: 3671, learning rate: 0.00791, Loss: 0.3020, Accuracy:0.883\nIteration: 3672, learning rate: 0.00791, Loss: 0.2942, Accuracy:0.906\nIteration: 3673, learning rate: 0.00791, Loss: 0.3192, Accuracy:0.836\nIteration: 3674, learning rate: 0.00791, Loss: 0.2272, Accuracy:0.898\nIteration: 3675, learning rate: 0.00791, Loss: 0.2975, Accuracy:0.883\nIteration: 3676, learning rate: 0.00791, Loss: 0.2364, Accuracy:0.914\nIteration: 3677, learning rate: 0.00791, Loss: 0.2935, Accuracy:0.852\nIteration: 3678, learning rate: 0.00791, Loss: 0.3266, Accuracy:0.844\nIteration: 3679, learning rate: 0.00791, Loss: 0.2804, Accuracy:0.883\nIteration: 3680, learning rate: 0.00791, Loss: 0.3128, Accuracy:0.844\nIteration: 3681, learning rate: 0.00791, Loss: 0.2239, Accuracy:0.914\nIteration: 3682, learning rate: 0.00791, Loss: 0.3064, Accuracy:0.859\nIteration: 3683, learning rate: 0.00790, Loss: 0.2075, Accuracy:0.914\nIteration: 3684, learning rate: 0.00790, Loss: 0.3563, Accuracy:0.836\nIteration: 3685, learning rate: 0.00790, Loss: 0.2775, Accuracy:0.867\nIteration: 3686, learning rate: 0.00790, Loss: 0.3382, Accuracy:0.859\nIteration: 3687, learning rate: 0.00790, Loss: 0.2620, Accuracy:0.867\nIteration: 3688, learning rate: 0.00790, Loss: 0.2028, Accuracy:0.945\nIteration: 3689, learning rate: 0.00790, Loss: 0.3195, Accuracy:0.882\nEpoch: 119, Loss: 0.2836, Accuracy:0.880, Val Loss: 0.3417, Val Accuracy: 0.829\nIteration: 3690, learning rate: 0.00790, Loss: 0.3225, Accuracy:0.859\nIteration: 3691, learning rate: 0.00790, Loss: 0.3030, Accuracy:0.875\nIteration: 3692, learning rate: 0.00790, Loss: 0.2631, Accuracy:0.898\nIteration: 3693, learning rate: 0.00790, Loss: 0.3556, Accuracy:0.844\nIteration: 3694, learning rate: 0.00790, Loss: 0.2908, Accuracy:0.844\nIteration: 3695, learning rate: 0.00790, Loss: 0.3469, Accuracy:0.867\nIteration: 3696, learning rate: 0.00790, Loss: 0.4169, Accuracy:0.836\nIteration: 3697, learning rate: 0.00790, Loss: 0.3303, Accuracy:0.852\nIteration: 3698, learning rate: 0.00790, Loss: 0.2893, Accuracy:0.891\nIteration: 3699, learning rate: 0.00790, Loss: 0.2550, Accuracy:0.898\nIteration: 3700, learning rate: 0.00790, Loss: 0.2579, Accuracy:0.898\nIteration: 3701, learning rate: 0.00790, Loss: 0.3174, Accuracy:0.836\nIteration: 3702, learning rate: 0.00790, Loss: 0.3445, Accuracy:0.883\nIteration: 3703, learning rate: 0.00790, Loss: 0.2996, Accuracy:0.867\nIteration: 3704, learning rate: 0.00790, Loss: 0.3026, Accuracy:0.867\nIteration: 3705, learning rate: 0.00790, Loss: 0.3823, Accuracy:0.820\nIteration: 3706, learning rate: 0.00789, Loss: 0.3482, Accuracy:0.836\nIteration: 3707, learning rate: 0.00789, Loss: 0.2899, Accuracy:0.914\nIteration: 3708, learning rate: 0.00789, Loss: 0.3535, Accuracy:0.812\nIteration: 3709, learning rate: 0.00789, Loss: 0.3338, Accuracy:0.852\nIteration: 3710, learning rate: 0.00789, Loss: 0.3128, Accuracy:0.852\nIteration: 3711, learning rate: 0.00789, Loss: 0.2773, Accuracy:0.914\nIteration: 3712, learning rate: 0.00789, Loss: 0.3693, Accuracy:0.844\nIteration: 3713, learning rate: 0.00789, Loss: 0.2393, Accuracy:0.906\nIteration: 3714, learning rate: 0.00789, Loss: 0.3098, Accuracy:0.859\nIteration: 3715, learning rate: 0.00789, Loss: 0.2893, Accuracy:0.883\nIteration: 3716, learning rate: 0.00789, Loss: 0.4149, Accuracy:0.820\nIteration: 3717, learning rate: 0.00789, Loss: 0.3973, Accuracy:0.828\nIteration: 3718, learning rate: 0.00789, Loss: 0.2788, Accuracy:0.859\nIteration: 3719, learning rate: 0.00789, Loss: 0.3541, Accuracy:0.836\nIteration: 3720, learning rate: 0.00789, Loss: 0.2755, Accuracy:0.871\nEpoch: 120, Loss: 0.3201, Accuracy:0.862, Val Loss: 0.3494, Val Accuracy: 0.828\nIteration: 3721, learning rate: 0.00789, Loss: 0.2803, Accuracy:0.906\nIteration: 3722, learning rate: 0.00789, Loss: 0.3028, Accuracy:0.883\nIteration: 3723, learning rate: 0.00789, Loss: 0.2994, Accuracy:0.891\nIteration: 3724, learning rate: 0.00789, Loss: 0.2735, Accuracy:0.891\nIteration: 3725, learning rate: 0.00789, Loss: 0.3188, Accuracy:0.844\nIteration: 3726, learning rate: 0.00789, Loss: 0.2665, Accuracy:0.852\nIteration: 3727, learning rate: 0.00789, Loss: 0.2693, Accuracy:0.883\nIteration: 3728, learning rate: 0.00789, Loss: 0.3229, Accuracy:0.852\nIteration: 3729, learning rate: 0.00788, Loss: 0.2798, Accuracy:0.883\nIteration: 3730, learning rate: 0.00788, Loss: 0.2785, Accuracy:0.883\nIteration: 3731, learning rate: 0.00788, Loss: 0.2877, Accuracy:0.875\nIteration: 3732, learning rate: 0.00788, Loss: 0.2768, Accuracy:0.891\nIteration: 3733, learning rate: 0.00788, Loss: 0.2586, Accuracy:0.898\nIteration: 3734, learning rate: 0.00788, Loss: 0.3595, Accuracy:0.859\nIteration: 3735, learning rate: 0.00788, Loss: 0.3128, Accuracy:0.875\nIteration: 3736, learning rate: 0.00788, Loss: 0.2693, Accuracy:0.867\nIteration: 3737, learning rate: 0.00788, Loss: 0.3879, Accuracy:0.812\nIteration: 3738, learning rate: 0.00788, Loss: 0.3135, Accuracy:0.875\nIteration: 3739, learning rate: 0.00788, Loss: 0.3096, Accuracy:0.852\nIteration: 3740, learning rate: 0.00788, Loss: 0.2042, Accuracy:0.922\nIteration: 3741, learning rate: 0.00788, Loss: 0.3660, Accuracy:0.836\nIteration: 3742, learning rate: 0.00788, Loss: 0.3409, Accuracy:0.875\nIteration: 3743, learning rate: 0.00788, Loss: 0.2987, Accuracy:0.914\nIteration: 3744, learning rate: 0.00788, Loss: 0.2703, Accuracy:0.898\nIteration: 3745, learning rate: 0.00788, Loss: 0.3238, Accuracy:0.859\nIteration: 3746, learning rate: 0.00788, Loss: 0.2218, Accuracy:0.898\nIteration: 3747, learning rate: 0.00788, Loss: 0.2924, Accuracy:0.875\nIteration: 3748, learning rate: 0.00788, Loss: 0.2983, Accuracy:0.867\nIteration: 3749, learning rate: 0.00788, Loss: 0.2615, Accuracy:0.891\nIteration: 3750, learning rate: 0.00788, Loss: 0.2558, Accuracy:0.914\nIteration: 3751, learning rate: 0.00788, Loss: 0.2376, Accuracy:0.860\nEpoch: 121, Loss: 0.2916, Accuracy:0.877, Val Loss: 0.3347, Val Accuracy: 0.856\nIteration: 3752, learning rate: 0.00787, Loss: 0.2950, Accuracy:0.875\nIteration: 3753, learning rate: 0.00787, Loss: 0.2648, Accuracy:0.875\nIteration: 3754, learning rate: 0.00787, Loss: 0.2954, Accuracy:0.859\nIteration: 3755, learning rate: 0.00787, Loss: 0.2739, Accuracy:0.906\nIteration: 3756, learning rate: 0.00787, Loss: 0.2798, Accuracy:0.875\nIteration: 3757, learning rate: 0.00787, Loss: 0.2744, Accuracy:0.875\nIteration: 3758, learning rate: 0.00787, Loss: 0.3594, Accuracy:0.828\nIteration: 3759, learning rate: 0.00787, Loss: 0.2958, Accuracy:0.883\nIteration: 3760, learning rate: 0.00787, Loss: 0.2340, Accuracy:0.898\nIteration: 3761, learning rate: 0.00787, Loss: 0.2799, Accuracy:0.891\nIteration: 3762, learning rate: 0.00787, Loss: 0.2751, Accuracy:0.906\nIteration: 3763, learning rate: 0.00787, Loss: 0.3384, Accuracy:0.859\nIteration: 3764, learning rate: 0.00787, Loss: 0.2310, Accuracy:0.875\nIteration: 3765, learning rate: 0.00787, Loss: 0.2510, Accuracy:0.891\nIteration: 3766, learning rate: 0.00787, Loss: 0.3368, Accuracy:0.875\nIteration: 3767, learning rate: 0.00787, Loss: 0.2919, Accuracy:0.883\nIteration: 3768, learning rate: 0.00787, Loss: 0.3300, Accuracy:0.844\nIteration: 3769, learning rate: 0.00787, Loss: 0.2808, Accuracy:0.898\nIteration: 3770, learning rate: 0.00787, Loss: 0.2033, Accuracy:0.930\nIteration: 3771, learning rate: 0.00787, Loss: 0.3106, Accuracy:0.875\nIteration: 3772, learning rate: 0.00787, Loss: 0.4551, Accuracy:0.828\nIteration: 3773, learning rate: 0.00787, Loss: 0.2815, Accuracy:0.891\nIteration: 3774, learning rate: 0.00787, Loss: 0.2590, Accuracy:0.883\nIteration: 3775, learning rate: 0.00787, Loss: 0.2918, Accuracy:0.867\nIteration: 3776, learning rate: 0.00786, Loss: 0.3077, Accuracy:0.867\nIteration: 3777, learning rate: 0.00786, Loss: 0.2941, Accuracy:0.883\nIteration: 3778, learning rate: 0.00786, Loss: 0.3043, Accuracy:0.836\nIteration: 3779, learning rate: 0.00786, Loss: 0.2965, Accuracy:0.883\nIteration: 3780, learning rate: 0.00786, Loss: 0.2494, Accuracy:0.914\nIteration: 3781, learning rate: 0.00786, Loss: 0.2672, Accuracy:0.852\nIteration: 3782, learning rate: 0.00786, Loss: 0.3394, Accuracy:0.806\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 122, Loss: 0.2918, Accuracy:0.875, Val Loss: 0.3051, Val Accuracy: 0.870\nIteration: 3783, learning rate: 0.00786, Loss: 0.4018, Accuracy:0.828\nIteration: 3784, learning rate: 0.00786, Loss: 0.3097, Accuracy:0.844\nIteration: 3785, learning rate: 0.00786, Loss: 0.3321, Accuracy:0.836\nIteration: 3786, learning rate: 0.00786, Loss: 0.3375, Accuracy:0.836\nIteration: 3787, learning rate: 0.00786, Loss: 0.2631, Accuracy:0.867\nIteration: 3788, learning rate: 0.00786, Loss: 0.3973, Accuracy:0.836\nIteration: 3789, learning rate: 0.00786, Loss: 0.2733, Accuracy:0.898\nIteration: 3790, learning rate: 0.00786, Loss: 0.3329, Accuracy:0.836\nIteration: 3791, learning rate: 0.00786, Loss: 0.2480, Accuracy:0.883\nIteration: 3792, learning rate: 0.00786, Loss: 0.3903, Accuracy:0.805\nIteration: 3793, learning rate: 0.00786, Loss: 0.4375, Accuracy:0.797\nIteration: 3794, learning rate: 0.00786, Loss: 0.3128, Accuracy:0.852\nIteration: 3795, learning rate: 0.00786, Loss: 0.3247, Accuracy:0.836\nIteration: 3796, learning rate: 0.00786, Loss: 0.3338, Accuracy:0.820\nIteration: 3797, learning rate: 0.00786, Loss: 0.2577, Accuracy:0.906\nIteration: 3798, learning rate: 0.00786, Loss: 0.2629, Accuracy:0.906\nIteration: 3799, learning rate: 0.00785, Loss: 0.2541, Accuracy:0.914\nIteration: 3800, learning rate: 0.00785, Loss: 0.2872, Accuracy:0.852\nIteration: 3801, learning rate: 0.00785, Loss: 0.3527, Accuracy:0.844\nIteration: 3802, learning rate: 0.00785, Loss: 0.2758, Accuracy:0.875\nIteration: 3803, learning rate: 0.00785, Loss: 0.3390, Accuracy:0.852\nIteration: 3804, learning rate: 0.00785, Loss: 0.3076, Accuracy:0.875\nIteration: 3805, learning rate: 0.00785, Loss: 0.2625, Accuracy:0.906\nIteration: 3806, learning rate: 0.00785, Loss: 0.2929, Accuracy:0.867\nIteration: 3807, learning rate: 0.00785, Loss: 0.2472, Accuracy:0.883\nIteration: 3808, learning rate: 0.00785, Loss: 0.2952, Accuracy:0.875\nIteration: 3809, learning rate: 0.00785, Loss: 0.2415, Accuracy:0.906\nIteration: 3810, learning rate: 0.00785, Loss: 0.2840, Accuracy:0.891\nIteration: 3811, learning rate: 0.00785, Loss: 0.2552, Accuracy:0.898\nIteration: 3812, learning rate: 0.00785, Loss: 0.3071, Accuracy:0.875\nIteration: 3813, learning rate: 0.00785, Loss: 0.3137, Accuracy:0.860\nEpoch: 123, Loss: 0.3075, Accuracy:0.863, Val Loss: 0.3083, Val Accuracy: 0.864\nIteration: 3814, learning rate: 0.00785, Loss: 0.3561, Accuracy:0.828\nIteration: 3815, learning rate: 0.00785, Loss: 0.2336, Accuracy:0.898\nIteration: 3816, learning rate: 0.00785, Loss: 0.2508, Accuracy:0.906\nIteration: 3817, learning rate: 0.00785, Loss: 0.2956, Accuracy:0.891\nIteration: 3818, learning rate: 0.00785, Loss: 0.2865, Accuracy:0.891\nIteration: 3819, learning rate: 0.00785, Loss: 0.2979, Accuracy:0.836\nIteration: 3820, learning rate: 0.00785, Loss: 0.3549, Accuracy:0.836\nIteration: 3821, learning rate: 0.00785, Loss: 0.2221, Accuracy:0.922\nIteration: 3822, learning rate: 0.00785, Loss: 0.3336, Accuracy:0.844\nIteration: 3823, learning rate: 0.00784, Loss: 0.2674, Accuracy:0.883\nIteration: 3824, learning rate: 0.00784, Loss: 0.2530, Accuracy:0.906\nIteration: 3825, learning rate: 0.00784, Loss: 0.2246, Accuracy:0.922\nIteration: 3826, learning rate: 0.00784, Loss: 0.2446, Accuracy:0.906\nIteration: 3827, learning rate: 0.00784, Loss: 0.2852, Accuracy:0.906\nIteration: 3828, learning rate: 0.00784, Loss: 0.2751, Accuracy:0.867\nIteration: 3829, learning rate: 0.00784, Loss: 0.2757, Accuracy:0.891\nIteration: 3830, learning rate: 0.00784, Loss: 0.2876, Accuracy:0.898\nIteration: 3831, learning rate: 0.00784, Loss: 0.3213, Accuracy:0.867\nIteration: 3832, learning rate: 0.00784, Loss: 0.2825, Accuracy:0.883\nIteration: 3833, learning rate: 0.00784, Loss: 0.3125, Accuracy:0.852\nIteration: 3834, learning rate: 0.00784, Loss: 0.3157, Accuracy:0.844\nIteration: 3835, learning rate: 0.00784, Loss: 0.2810, Accuracy:0.883\nIteration: 3836, learning rate: 0.00784, Loss: 0.2832, Accuracy:0.906\nIteration: 3837, learning rate: 0.00784, Loss: 0.2154, Accuracy:0.906\nIteration: 3838, learning rate: 0.00784, Loss: 0.3041, Accuracy:0.875\nIteration: 3839, learning rate: 0.00784, Loss: 0.2911, Accuracy:0.859\nIteration: 3840, learning rate: 0.00784, Loss: 0.2666, Accuracy:0.898\nIteration: 3841, learning rate: 0.00784, Loss: 0.2613, Accuracy:0.914\nIteration: 3842, learning rate: 0.00784, Loss: 0.3708, Accuracy:0.836\nIteration: 3843, learning rate: 0.00784, Loss: 0.2413, Accuracy:0.922\nIteration: 3844, learning rate: 0.00784, Loss: 0.2554, Accuracy:0.914\nEpoch: 124, Loss: 0.2822, Accuracy:0.884, Val Loss: 0.3507, Val Accuracy: 0.843\nIteration: 3845, learning rate: 0.00784, Loss: 0.2764, Accuracy:0.859\nIteration: 3846, learning rate: 0.00783, Loss: 0.2252, Accuracy:0.906\nIteration: 3847, learning rate: 0.00783, Loss: 0.3456, Accuracy:0.852\nIteration: 3848, learning rate: 0.00783, Loss: 0.3912, Accuracy:0.828\nIteration: 3849, learning rate: 0.00783, Loss: 0.2082, Accuracy:0.930\nIteration: 3850, learning rate: 0.00783, Loss: 0.3175, Accuracy:0.859\nIteration: 3851, learning rate: 0.00783, Loss: 0.2248, Accuracy:0.922\nIteration: 3852, learning rate: 0.00783, Loss: 0.2643, Accuracy:0.922\nIteration: 3853, learning rate: 0.00783, Loss: 0.2774, Accuracy:0.891\nIteration: 3854, learning rate: 0.00783, Loss: 0.2998, Accuracy:0.875\nIteration: 3855, learning rate: 0.00783, Loss: 0.2830, Accuracy:0.891\nIteration: 3856, learning rate: 0.00783, Loss: 0.3238, Accuracy:0.836\nIteration: 3857, learning rate: 0.00783, Loss: 0.3429, Accuracy:0.836\nIteration: 3858, learning rate: 0.00783, Loss: 0.2328, Accuracy:0.914\nIteration: 3859, learning rate: 0.00783, Loss: 0.2327, Accuracy:0.914\nIteration: 3860, learning rate: 0.00783, Loss: 0.2554, Accuracy:0.891\nIteration: 3861, learning rate: 0.00783, Loss: 0.2420, Accuracy:0.906\nIteration: 3862, learning rate: 0.00783, Loss: 0.3274, Accuracy:0.844\nIteration: 3863, learning rate: 0.00783, Loss: 0.3000, Accuracy:0.836\nIteration: 3864, learning rate: 0.00783, Loss: 0.3107, Accuracy:0.898\nIteration: 3865, learning rate: 0.00783, Loss: 0.3674, Accuracy:0.844\nIteration: 3866, learning rate: 0.00783, Loss: 0.2381, Accuracy:0.898\nIteration: 3867, learning rate: 0.00783, Loss: 0.3112, Accuracy:0.867\nIteration: 3868, learning rate: 0.00783, Loss: 0.3242, Accuracy:0.859\nIteration: 3869, learning rate: 0.00783, Loss: 0.3442, Accuracy:0.867\nIteration: 3870, learning rate: 0.00782, Loss: 0.2921, Accuracy:0.883\nIteration: 3871, learning rate: 0.00782, Loss: 0.2606, Accuracy:0.898\nIteration: 3872, learning rate: 0.00782, Loss: 0.2783, Accuracy:0.867\nIteration: 3873, learning rate: 0.00782, Loss: 0.3044, Accuracy:0.875\nIteration: 3874, learning rate: 0.00782, Loss: 0.3217, Accuracy:0.852\nIteration: 3875, learning rate: 0.00782, Loss: 0.2355, Accuracy:0.892\nEpoch: 125, Loss: 0.2890, Accuracy:0.878, Val Loss: 0.3155, Val Accuracy: 0.866\nIteration: 3876, learning rate: 0.00782, Loss: 0.2874, Accuracy:0.844\nIteration: 3877, learning rate: 0.00782, Loss: 0.3208, Accuracy:0.836\nIteration: 3878, learning rate: 0.00782, Loss: 0.2872, Accuracy:0.898\nIteration: 3879, learning rate: 0.00782, Loss: 0.2521, Accuracy:0.883\nIteration: 3880, learning rate: 0.00782, Loss: 0.3110, Accuracy:0.883\nIteration: 3881, learning rate: 0.00782, Loss: 0.2617, Accuracy:0.875\nIteration: 3882, learning rate: 0.00782, Loss: 0.2112, Accuracy:0.945\nIteration: 3883, learning rate: 0.00782, Loss: 0.2726, Accuracy:0.867\nIteration: 3884, learning rate: 0.00782, Loss: 0.2824, Accuracy:0.867\nIteration: 3885, learning rate: 0.00782, Loss: 0.2792, Accuracy:0.883\nIteration: 3886, learning rate: 0.00782, Loss: 0.2198, Accuracy:0.906\nIteration: 3887, learning rate: 0.00782, Loss: 0.2702, Accuracy:0.891\nIteration: 3888, learning rate: 0.00782, Loss: 0.2875, Accuracy:0.875\nIteration: 3889, learning rate: 0.00782, Loss: 0.3295, Accuracy:0.875\nIteration: 3890, learning rate: 0.00782, Loss: 0.3730, Accuracy:0.852\nIteration: 3891, learning rate: 0.00782, Loss: 0.2830, Accuracy:0.844\nIteration: 3892, learning rate: 0.00782, Loss: 0.3367, Accuracy:0.859\nIteration: 3893, learning rate: 0.00781, Loss: 0.2066, Accuracy:0.922\nIteration: 3894, learning rate: 0.00781, Loss: 0.3114, Accuracy:0.859\nIteration: 3895, learning rate: 0.00781, Loss: 0.3153, Accuracy:0.875\nIteration: 3896, learning rate: 0.00781, Loss: 0.3320, Accuracy:0.844\nIteration: 3897, learning rate: 0.00781, Loss: 0.3073, Accuracy:0.836\nIteration: 3898, learning rate: 0.00781, Loss: 0.2917, Accuracy:0.883\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 3899, learning rate: 0.00781, Loss: 0.4186, Accuracy:0.805\nIteration: 3900, learning rate: 0.00781, Loss: 0.2377, Accuracy:0.930\nIteration: 3901, learning rate: 0.00781, Loss: 0.3242, Accuracy:0.859\nIteration: 3902, learning rate: 0.00781, Loss: 0.2318, Accuracy:0.883\nIteration: 3903, learning rate: 0.00781, Loss: 0.2459, Accuracy:0.867\nIteration: 3904, learning rate: 0.00781, Loss: 0.2010, Accuracy:0.930\nIteration: 3905, learning rate: 0.00781, Loss: 0.2643, Accuracy:0.891\nIteration: 3906, learning rate: 0.00781, Loss: 0.2944, Accuracy:0.860\nEpoch: 126, Loss: 0.2854, Accuracy:0.875, Val Loss: 0.3643, Val Accuracy: 0.835\nIteration: 3907, learning rate: 0.00781, Loss: 0.2632, Accuracy:0.930\nIteration: 3908, learning rate: 0.00781, Loss: 0.3542, Accuracy:0.875\nIteration: 3909, learning rate: 0.00781, Loss: 0.2839, Accuracy:0.859\nIteration: 3910, learning rate: 0.00781, Loss: 0.2784, Accuracy:0.914\nIteration: 3911, learning rate: 0.00781, Loss: 0.2610, Accuracy:0.922\nIteration: 3912, learning rate: 0.00781, Loss: 0.3009, Accuracy:0.859\nIteration: 3913, learning rate: 0.00781, Loss: 0.2813, Accuracy:0.867\nIteration: 3914, learning rate: 0.00781, Loss: 0.3895, Accuracy:0.852\nIteration: 3915, learning rate: 0.00781, Loss: 0.3967, Accuracy:0.828\nIteration: 3916, learning rate: 0.00781, Loss: 0.3483, Accuracy:0.859\nIteration: 3917, learning rate: 0.00780, Loss: 0.2964, Accuracy:0.891\nIteration: 3918, learning rate: 0.00780, Loss: 0.2673, Accuracy:0.875\nIteration: 3919, learning rate: 0.00780, Loss: 0.2797, Accuracy:0.891\nIteration: 3920, learning rate: 0.00780, Loss: 0.3476, Accuracy:0.820\nIteration: 3921, learning rate: 0.00780, Loss: 0.2722, Accuracy:0.875\nIteration: 3922, learning rate: 0.00780, Loss: 0.2909, Accuracy:0.867\nIteration: 3923, learning rate: 0.00780, Loss: 0.2901, Accuracy:0.883\nIteration: 3924, learning rate: 0.00780, Loss: 0.3107, Accuracy:0.844\nIteration: 3925, learning rate: 0.00780, Loss: 0.3413, Accuracy:0.859\nIteration: 3926, learning rate: 0.00780, Loss: 0.2225, Accuracy:0.922\nIteration: 3927, learning rate: 0.00780, Loss: 0.3233, Accuracy:0.875\nIteration: 3928, learning rate: 0.00780, Loss: 0.2445, Accuracy:0.906\nIteration: 3929, learning rate: 0.00780, Loss: 0.2862, Accuracy:0.883\nIteration: 3930, learning rate: 0.00780, Loss: 0.3781, Accuracy:0.828\nIteration: 3931, learning rate: 0.00780, Loss: 0.3500, Accuracy:0.820\nIteration: 3932, learning rate: 0.00780, Loss: 0.2170, Accuracy:0.906\nIteration: 3933, learning rate: 0.00780, Loss: 0.2573, Accuracy:0.859\nIteration: 3934, learning rate: 0.00780, Loss: 0.2736, Accuracy:0.898\nIteration: 3935, learning rate: 0.00780, Loss: 0.2500, Accuracy:0.914\nIteration: 3936, learning rate: 0.00780, Loss: 0.2558, Accuracy:0.898\nIteration: 3937, learning rate: 0.00780, Loss: 0.2835, Accuracy:0.871\nEpoch: 127, Loss: 0.2966, Accuracy:0.876, Val Loss: 0.3261, Val Accuracy: 0.857\nIteration: 3938, learning rate: 0.00780, Loss: 0.4001, Accuracy:0.820\nIteration: 3939, learning rate: 0.00780, Loss: 0.2527, Accuracy:0.922\nIteration: 3940, learning rate: 0.00780, Loss: 0.2454, Accuracy:0.898\nIteration: 3941, learning rate: 0.00779, Loss: 0.3320, Accuracy:0.852\nIteration: 3942, learning rate: 0.00779, Loss: 0.2994, Accuracy:0.859\nIteration: 3943, learning rate: 0.00779, Loss: 0.3098, Accuracy:0.867\nIteration: 3944, learning rate: 0.00779, Loss: 0.2378, Accuracy:0.891\nIteration: 3945, learning rate: 0.00779, Loss: 0.3090, Accuracy:0.883\nIteration: 3946, learning rate: 0.00779, Loss: 0.2587, Accuracy:0.883\nIteration: 3947, learning rate: 0.00779, Loss: 0.1975, Accuracy:0.922\nIteration: 3948, learning rate: 0.00779, Loss: 0.2734, Accuracy:0.891\nIteration: 3949, learning rate: 0.00779, Loss: 0.2134, Accuracy:0.914\nIteration: 3950, learning rate: 0.00779, Loss: 0.2202, Accuracy:0.930\nIteration: 3951, learning rate: 0.00779, Loss: 0.3349, Accuracy:0.859\nIteration: 3952, learning rate: 0.00779, Loss: 0.2995, Accuracy:0.852\nIteration: 3953, learning rate: 0.00779, Loss: 0.3179, Accuracy:0.875\nIteration: 3954, learning rate: 0.00779, Loss: 0.2383, Accuracy:0.914\nIteration: 3955, learning rate: 0.00779, Loss: 0.2583, Accuracy:0.891\nIteration: 3956, learning rate: 0.00779, Loss: 0.3357, Accuracy:0.867\nIteration: 3957, learning rate: 0.00779, Loss: 0.2959, Accuracy:0.867\nIteration: 3958, learning rate: 0.00779, Loss: 0.2518, Accuracy:0.852\nIteration: 3959, learning rate: 0.00779, Loss: 0.4224, Accuracy:0.828\nIteration: 3960, learning rate: 0.00779, Loss: 0.3271, Accuracy:0.875\nIteration: 3961, learning rate: 0.00779, Loss: 0.3338, Accuracy:0.852\nIteration: 3962, learning rate: 0.00779, Loss: 0.3356, Accuracy:0.859\nIteration: 3963, learning rate: 0.00779, Loss: 0.2818, Accuracy:0.875\nIteration: 3964, learning rate: 0.00779, Loss: 0.3466, Accuracy:0.812\nIteration: 3965, learning rate: 0.00778, Loss: 0.2329, Accuracy:0.906\nIteration: 3966, learning rate: 0.00778, Loss: 0.2846, Accuracy:0.906\nIteration: 3967, learning rate: 0.00778, Loss: 0.2738, Accuracy:0.875\nIteration: 3968, learning rate: 0.00778, Loss: 0.1989, Accuracy:0.903\nEpoch: 128, Loss: 0.2877, Accuracy:0.877, Val Loss: 0.3093, Val Accuracy: 0.853\nIteration: 3969, learning rate: 0.00778, Loss: 0.3555, Accuracy:0.812\nIteration: 3970, learning rate: 0.00778, Loss: 0.2161, Accuracy:0.898\nIteration: 3971, learning rate: 0.00778, Loss: 0.2286, Accuracy:0.906\nIteration: 3972, learning rate: 0.00778, Loss: 0.2563, Accuracy:0.891\nIteration: 3973, learning rate: 0.00778, Loss: 0.2333, Accuracy:0.898\nIteration: 3974, learning rate: 0.00778, Loss: 0.3302, Accuracy:0.859\nIteration: 3975, learning rate: 0.00778, Loss: 0.2565, Accuracy:0.906\nIteration: 3976, learning rate: 0.00778, Loss: 0.2824, Accuracy:0.859\nIteration: 3977, learning rate: 0.00778, Loss: 0.3149, Accuracy:0.867\nIteration: 3978, learning rate: 0.00778, Loss: 0.3224, Accuracy:0.852\nIteration: 3979, learning rate: 0.00778, Loss: 0.2686, Accuracy:0.906\nIteration: 3980, learning rate: 0.00778, Loss: 0.3048, Accuracy:0.852\nIteration: 3981, learning rate: 0.00778, Loss: 0.2509, Accuracy:0.906\nIteration: 3982, learning rate: 0.00778, Loss: 0.3218, Accuracy:0.852\nIteration: 3983, learning rate: 0.00778, Loss: 0.2730, Accuracy:0.914\nIteration: 3984, learning rate: 0.00778, Loss: 0.2646, Accuracy:0.898\nIteration: 3985, learning rate: 0.00778, Loss: 0.3118, Accuracy:0.852\nIteration: 3986, learning rate: 0.00778, Loss: 0.2826, Accuracy:0.883\nIteration: 3987, learning rate: 0.00778, Loss: 0.2453, Accuracy:0.914\nIteration: 3988, learning rate: 0.00778, Loss: 0.3154, Accuracy:0.898\nIteration: 3989, learning rate: 0.00777, Loss: 0.2854, Accuracy:0.875\nIteration: 3990, learning rate: 0.00777, Loss: 0.2634, Accuracy:0.891\nIteration: 3991, learning rate: 0.00777, Loss: 0.2907, Accuracy:0.867\nIteration: 3992, learning rate: 0.00777, Loss: 0.2290, Accuracy:0.898\nIteration: 3993, learning rate: 0.00777, Loss: 0.3517, Accuracy:0.859\nIteration: 3994, learning rate: 0.00777, Loss: 0.3095, Accuracy:0.859\nIteration: 3995, learning rate: 0.00777, Loss: 0.2556, Accuracy:0.914\nIteration: 3996, learning rate: 0.00777, Loss: 0.3564, Accuracy:0.836\nIteration: 3997, learning rate: 0.00777, Loss: 0.3165, Accuracy:0.852\nIteration: 3998, learning rate: 0.00777, Loss: 0.3549, Accuracy:0.820\nIteration: 3999, learning rate: 0.00777, Loss: 0.2504, Accuracy:0.903\nEpoch: 129, Loss: 0.2870, Accuracy:0.877, Val Loss: 0.2685, Val Accuracy: 0.884\nval_loss_decreased from 0.2887 to 0.2685, saving_checkpoint for epoch 129\nIteration: 4000, learning rate: 0.00777, Loss: 0.2637, Accuracy:0.906\nIteration: 4001, learning rate: 0.00777, Loss: 0.2834, Accuracy:0.898\nIteration: 4002, learning rate: 0.00777, Loss: 0.3340, Accuracy:0.828\nIteration: 4003, learning rate: 0.00777, Loss: 0.2873, Accuracy:0.898\nIteration: 4004, learning rate: 0.00777, Loss: 0.2230, Accuracy:0.945\nIteration: 4005, learning rate: 0.00777, Loss: 0.3226, Accuracy:0.875\nIteration: 4006, learning rate: 0.00777, Loss: 0.3208, Accuracy:0.852\nIteration: 4007, learning rate: 0.00777, Loss: 0.3523, Accuracy:0.859\nIteration: 4008, learning rate: 0.00777, Loss: 0.2326, Accuracy:0.891\nIteration: 4009, learning rate: 0.00777, Loss: 0.2376, Accuracy:0.883\nIteration: 4010, learning rate: 0.00777, Loss: 0.1901, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4011, learning rate: 0.00777, Loss: 0.2721, Accuracy:0.875\nIteration: 4012, learning rate: 0.00777, Loss: 0.2560, Accuracy:0.898\nIteration: 4013, learning rate: 0.00776, Loss: 0.3221, Accuracy:0.820\nIteration: 4014, learning rate: 0.00776, Loss: 0.3046, Accuracy:0.852\nIteration: 4015, learning rate: 0.00776, Loss: 0.2248, Accuracy:0.930\nIteration: 4016, learning rate: 0.00776, Loss: 0.2342, Accuracy:0.906\nIteration: 4017, learning rate: 0.00776, Loss: 0.2411, Accuracy:0.914\nIteration: 4018, learning rate: 0.00776, Loss: 0.2793, Accuracy:0.891\nIteration: 4019, learning rate: 0.00776, Loss: 0.2290, Accuracy:0.914\nIteration: 4020, learning rate: 0.00776, Loss: 0.2561, Accuracy:0.898\nIteration: 4021, learning rate: 0.00776, Loss: 0.3452, Accuracy:0.883\nIteration: 4022, learning rate: 0.00776, Loss: 0.2822, Accuracy:0.906\nIteration: 4023, learning rate: 0.00776, Loss: 0.2467, Accuracy:0.891\nIteration: 4024, learning rate: 0.00776, Loss: 0.3085, Accuracy:0.875\nIteration: 4025, learning rate: 0.00776, Loss: 0.2535, Accuracy:0.898\nIteration: 4026, learning rate: 0.00776, Loss: 0.2587, Accuracy:0.914\nIteration: 4027, learning rate: 0.00776, Loss: 0.2176, Accuracy:0.891\nIteration: 4028, learning rate: 0.00776, Loss: 0.2612, Accuracy:0.891\nIteration: 4029, learning rate: 0.00776, Loss: 0.2720, Accuracy:0.891\nIteration: 4030, learning rate: 0.00776, Loss: 0.1825, Accuracy:0.925\nEpoch: 130, Loss: 0.2676, Accuracy:0.891, Val Loss: 0.3661, Val Accuracy: 0.851\nIteration: 4031, learning rate: 0.00776, Loss: 0.2051, Accuracy:0.938\nIteration: 4032, learning rate: 0.00776, Loss: 0.3083, Accuracy:0.883\nIteration: 4033, learning rate: 0.00776, Loss: 0.2343, Accuracy:0.930\nIteration: 4034, learning rate: 0.00776, Loss: 0.2451, Accuracy:0.891\nIteration: 4035, learning rate: 0.00776, Loss: 0.2797, Accuracy:0.883\nIteration: 4036, learning rate: 0.00776, Loss: 0.2638, Accuracy:0.891\nIteration: 4037, learning rate: 0.00775, Loss: 0.2595, Accuracy:0.898\nIteration: 4038, learning rate: 0.00775, Loss: 0.3108, Accuracy:0.859\nIteration: 4039, learning rate: 0.00775, Loss: 0.2794, Accuracy:0.883\nIteration: 4040, learning rate: 0.00775, Loss: 0.2294, Accuracy:0.906\nIteration: 4041, learning rate: 0.00775, Loss: 0.2571, Accuracy:0.891\nIteration: 4042, learning rate: 0.00775, Loss: 0.3436, Accuracy:0.859\nIteration: 4043, learning rate: 0.00775, Loss: 0.2175, Accuracy:0.906\nIteration: 4044, learning rate: 0.00775, Loss: 0.2328, Accuracy:0.906\nIteration: 4045, learning rate: 0.00775, Loss: 0.3027, Accuracy:0.859\nIteration: 4046, learning rate: 0.00775, Loss: 0.2342, Accuracy:0.883\nIteration: 4047, learning rate: 0.00775, Loss: 0.2553, Accuracy:0.906\nIteration: 4048, learning rate: 0.00775, Loss: 0.2552, Accuracy:0.891\nIteration: 4049, learning rate: 0.00775, Loss: 0.2621, Accuracy:0.906\nIteration: 4050, learning rate: 0.00775, Loss: 0.2741, Accuracy:0.906\nIteration: 4051, learning rate: 0.00775, Loss: 0.2578, Accuracy:0.898\nIteration: 4052, learning rate: 0.00775, Loss: 0.4039, Accuracy:0.836\nIteration: 4053, learning rate: 0.00775, Loss: 0.2803, Accuracy:0.891\nIteration: 4054, learning rate: 0.00775, Loss: 0.2727, Accuracy:0.891\nIteration: 4055, learning rate: 0.00775, Loss: 0.3279, Accuracy:0.859\nIteration: 4056, learning rate: 0.00775, Loss: 0.3212, Accuracy:0.898\nIteration: 4057, learning rate: 0.00775, Loss: 0.2723, Accuracy:0.883\nIteration: 4058, learning rate: 0.00775, Loss: 0.1664, Accuracy:0.930\nIteration: 4059, learning rate: 0.00775, Loss: 0.2320, Accuracy:0.898\nIteration: 4060, learning rate: 0.00775, Loss: 0.3348, Accuracy:0.844\nIteration: 4061, learning rate: 0.00774, Loss: 0.1951, Accuracy:0.925\nEpoch: 131, Loss: 0.2682, Accuracy:0.891, Val Loss: 0.3511, Val Accuracy: 0.846\nIteration: 4062, learning rate: 0.00774, Loss: 0.2607, Accuracy:0.891\nIteration: 4063, learning rate: 0.00774, Loss: 0.3229, Accuracy:0.883\nIteration: 4064, learning rate: 0.00774, Loss: 0.2346, Accuracy:0.898\nIteration: 4065, learning rate: 0.00774, Loss: 0.4408, Accuracy:0.797\nIteration: 4066, learning rate: 0.00774, Loss: 0.3511, Accuracy:0.867\nIteration: 4067, learning rate: 0.00774, Loss: 0.1785, Accuracy:0.945\nIteration: 4068, learning rate: 0.00774, Loss: 0.2634, Accuracy:0.867\nIteration: 4069, learning rate: 0.00774, Loss: 0.2137, Accuracy:0.922\nIteration: 4070, learning rate: 0.00774, Loss: 0.1912, Accuracy:0.930\nIteration: 4071, learning rate: 0.00774, Loss: 0.3168, Accuracy:0.852\nIteration: 4072, learning rate: 0.00774, Loss: 0.2966, Accuracy:0.852\nIteration: 4073, learning rate: 0.00774, Loss: 0.2139, Accuracy:0.914\nIteration: 4074, learning rate: 0.00774, Loss: 0.2225, Accuracy:0.914\nIteration: 4075, learning rate: 0.00774, Loss: 0.2493, Accuracy:0.891\nIteration: 4076, learning rate: 0.00774, Loss: 0.2739, Accuracy:0.891\nIteration: 4077, learning rate: 0.00774, Loss: 0.2278, Accuracy:0.938\nIteration: 4078, learning rate: 0.00774, Loss: 0.2526, Accuracy:0.898\nIteration: 4079, learning rate: 0.00774, Loss: 0.2352, Accuracy:0.891\nIteration: 4080, learning rate: 0.00774, Loss: 0.2684, Accuracy:0.914\nIteration: 4081, learning rate: 0.00774, Loss: 0.3933, Accuracy:0.820\nIteration: 4082, learning rate: 0.00774, Loss: 0.2509, Accuracy:0.883\nIteration: 4083, learning rate: 0.00774, Loss: 0.2696, Accuracy:0.883\nIteration: 4084, learning rate: 0.00774, Loss: 0.2468, Accuracy:0.906\nIteration: 4085, learning rate: 0.00773, Loss: 0.2872, Accuracy:0.867\nIteration: 4086, learning rate: 0.00773, Loss: 0.2352, Accuracy:0.898\nIteration: 4087, learning rate: 0.00773, Loss: 0.2918, Accuracy:0.891\nIteration: 4088, learning rate: 0.00773, Loss: 0.2523, Accuracy:0.852\nIteration: 4089, learning rate: 0.00773, Loss: 0.2750, Accuracy:0.891\nIteration: 4090, learning rate: 0.00773, Loss: 0.3320, Accuracy:0.875\nIteration: 4091, learning rate: 0.00773, Loss: 0.2706, Accuracy:0.914\nIteration: 4092, learning rate: 0.00773, Loss: 0.3138, Accuracy:0.882\nEpoch: 132, Loss: 0.2720, Accuracy:0.888, Val Loss: 0.3613, Val Accuracy: 0.853\nIteration: 4093, learning rate: 0.00773, Loss: 0.3438, Accuracy:0.859\nIteration: 4094, learning rate: 0.00773, Loss: 0.1874, Accuracy:0.945\nIteration: 4095, learning rate: 0.00773, Loss: 0.2536, Accuracy:0.875\nIteration: 4096, learning rate: 0.00773, Loss: 0.3700, Accuracy:0.805\nIteration: 4097, learning rate: 0.00773, Loss: 0.2594, Accuracy:0.898\nIteration: 4098, learning rate: 0.00773, Loss: 0.2992, Accuracy:0.859\nIteration: 4099, learning rate: 0.00773, Loss: 0.3702, Accuracy:0.852\nIteration: 4100, learning rate: 0.00773, Loss: 0.3042, Accuracy:0.883\nIteration: 4101, learning rate: 0.00773, Loss: 0.3072, Accuracy:0.867\nIteration: 4102, learning rate: 0.00773, Loss: 0.2561, Accuracy:0.891\nIteration: 4103, learning rate: 0.00773, Loss: 0.2194, Accuracy:0.922\nIteration: 4104, learning rate: 0.00773, Loss: 0.2369, Accuracy:0.906\nIteration: 4105, learning rate: 0.00773, Loss: 0.3179, Accuracy:0.883\nIteration: 4106, learning rate: 0.00773, Loss: 0.4131, Accuracy:0.844\nIteration: 4107, learning rate: 0.00773, Loss: 0.2306, Accuracy:0.898\nIteration: 4108, learning rate: 0.00773, Loss: 0.3404, Accuracy:0.867\nIteration: 4109, learning rate: 0.00773, Loss: 0.3365, Accuracy:0.844\nIteration: 4110, learning rate: 0.00772, Loss: 0.2793, Accuracy:0.891\nIteration: 4111, learning rate: 0.00772, Loss: 0.2754, Accuracy:0.883\nIteration: 4112, learning rate: 0.00772, Loss: 0.3619, Accuracy:0.836\nIteration: 4113, learning rate: 0.00772, Loss: 0.2141, Accuracy:0.938\nIteration: 4114, learning rate: 0.00772, Loss: 0.3561, Accuracy:0.859\nIteration: 4115, learning rate: 0.00772, Loss: 0.2971, Accuracy:0.852\nIteration: 4116, learning rate: 0.00772, Loss: 0.3345, Accuracy:0.867\nIteration: 4117, learning rate: 0.00772, Loss: 0.2348, Accuracy:0.891\nIteration: 4118, learning rate: 0.00772, Loss: 0.2867, Accuracy:0.883\nIteration: 4119, learning rate: 0.00772, Loss: 0.2660, Accuracy:0.891\nIteration: 4120, learning rate: 0.00772, Loss: 0.3678, Accuracy:0.836\nIteration: 4121, learning rate: 0.00772, Loss: 0.2174, Accuracy:0.898\nIteration: 4122, learning rate: 0.00772, Loss: 0.3989, Accuracy:0.797\nIteration: 4123, learning rate: 0.00772, Loss: 0.2738, Accuracy:0.860\nEpoch: 133, Loss: 0.2971, Accuracy:0.874, Val Loss: 0.4093, Val Accuracy: 0.822\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4124, learning rate: 0.00772, Loss: 0.4233, Accuracy:0.812\nIteration: 4125, learning rate: 0.00772, Loss: 0.3716, Accuracy:0.828\nIteration: 4126, learning rate: 0.00772, Loss: 0.2122, Accuracy:0.914\nIteration: 4127, learning rate: 0.00772, Loss: 0.3091, Accuracy:0.875\nIteration: 4128, learning rate: 0.00772, Loss: 0.2780, Accuracy:0.875\nIteration: 4129, learning rate: 0.00772, Loss: 0.2595, Accuracy:0.883\nIteration: 4130, learning rate: 0.00772, Loss: 0.2926, Accuracy:0.875\nIteration: 4131, learning rate: 0.00772, Loss: 0.2843, Accuracy:0.859\nIteration: 4132, learning rate: 0.00772, Loss: 0.2740, Accuracy:0.875\nIteration: 4133, learning rate: 0.00772, Loss: 0.3002, Accuracy:0.883\nIteration: 4134, learning rate: 0.00771, Loss: 0.2876, Accuracy:0.875\nIteration: 4135, learning rate: 0.00771, Loss: 0.3068, Accuracy:0.875\nIteration: 4136, learning rate: 0.00771, Loss: 0.2843, Accuracy:0.891\nIteration: 4137, learning rate: 0.00771, Loss: 0.3418, Accuracy:0.836\nIteration: 4138, learning rate: 0.00771, Loss: 0.2614, Accuracy:0.906\nIteration: 4139, learning rate: 0.00771, Loss: 0.3130, Accuracy:0.891\nIteration: 4140, learning rate: 0.00771, Loss: 0.2722, Accuracy:0.883\nIteration: 4141, learning rate: 0.00771, Loss: 0.2582, Accuracy:0.898\nIteration: 4142, learning rate: 0.00771, Loss: 0.2794, Accuracy:0.906\nIteration: 4143, learning rate: 0.00771, Loss: 0.2510, Accuracy:0.898\nIteration: 4144, learning rate: 0.00771, Loss: 0.3590, Accuracy:0.844\nIteration: 4145, learning rate: 0.00771, Loss: 0.3280, Accuracy:0.797\nIteration: 4146, learning rate: 0.00771, Loss: 0.2773, Accuracy:0.891\nIteration: 4147, learning rate: 0.00771, Loss: 0.2908, Accuracy:0.883\nIteration: 4148, learning rate: 0.00771, Loss: 0.2134, Accuracy:0.938\nIteration: 4149, learning rate: 0.00771, Loss: 0.2569, Accuracy:0.883\nIteration: 4150, learning rate: 0.00771, Loss: 0.3365, Accuracy:0.859\nIteration: 4151, learning rate: 0.00771, Loss: 0.2841, Accuracy:0.867\nIteration: 4152, learning rate: 0.00771, Loss: 0.2658, Accuracy:0.906\nIteration: 4153, learning rate: 0.00771, Loss: 0.2821, Accuracy:0.859\nIteration: 4154, learning rate: 0.00771, Loss: 0.3417, Accuracy:0.849\nEpoch: 134, Loss: 0.2934, Accuracy:0.875, Val Loss: 0.3373, Val Accuracy: 0.839\nIteration: 4155, learning rate: 0.00771, Loss: 0.2559, Accuracy:0.883\nIteration: 4156, learning rate: 0.00771, Loss: 0.3134, Accuracy:0.867\nIteration: 4157, learning rate: 0.00771, Loss: 0.2578, Accuracy:0.891\nIteration: 4158, learning rate: 0.00770, Loss: 0.2866, Accuracy:0.898\nIteration: 4159, learning rate: 0.00770, Loss: 0.2375, Accuracy:0.922\nIteration: 4160, learning rate: 0.00770, Loss: 0.3591, Accuracy:0.836\nIteration: 4161, learning rate: 0.00770, Loss: 0.2531, Accuracy:0.883\nIteration: 4162, learning rate: 0.00770, Loss: 0.2508, Accuracy:0.906\nIteration: 4163, learning rate: 0.00770, Loss: 0.2563, Accuracy:0.883\nIteration: 4164, learning rate: 0.00770, Loss: 0.3040, Accuracy:0.883\nIteration: 4165, learning rate: 0.00770, Loss: 0.3339, Accuracy:0.852\nIteration: 4166, learning rate: 0.00770, Loss: 0.2668, Accuracy:0.875\nIteration: 4167, learning rate: 0.00770, Loss: 0.3289, Accuracy:0.875\nIteration: 4168, learning rate: 0.00770, Loss: 0.3292, Accuracy:0.844\nIteration: 4169, learning rate: 0.00770, Loss: 0.2292, Accuracy:0.906\nIteration: 4170, learning rate: 0.00770, Loss: 0.2964, Accuracy:0.859\nIteration: 4171, learning rate: 0.00770, Loss: 0.2475, Accuracy:0.922\nIteration: 4172, learning rate: 0.00770, Loss: 0.2277, Accuracy:0.922\nIteration: 4173, learning rate: 0.00770, Loss: 0.1950, Accuracy:0.969\nIteration: 4174, learning rate: 0.00770, Loss: 0.3119, Accuracy:0.867\nIteration: 4175, learning rate: 0.00770, Loss: 0.3168, Accuracy:0.875\nIteration: 4176, learning rate: 0.00770, Loss: 0.2782, Accuracy:0.875\nIteration: 4177, learning rate: 0.00770, Loss: 0.2665, Accuracy:0.883\nIteration: 4178, learning rate: 0.00770, Loss: 0.2678, Accuracy:0.891\nIteration: 4179, learning rate: 0.00770, Loss: 0.3504, Accuracy:0.859\nIteration: 4180, learning rate: 0.00770, Loss: 0.2473, Accuracy:0.906\nIteration: 4181, learning rate: 0.00770, Loss: 0.3046, Accuracy:0.859\nIteration: 4182, learning rate: 0.00770, Loss: 0.2715, Accuracy:0.875\nIteration: 4183, learning rate: 0.00769, Loss: 0.2872, Accuracy:0.859\nIteration: 4184, learning rate: 0.00769, Loss: 0.2659, Accuracy:0.875\nIteration: 4185, learning rate: 0.00769, Loss: 0.3207, Accuracy:0.849\nEpoch: 135, Loss: 0.2812, Accuracy:0.882, Val Loss: 0.3574, Val Accuracy: 0.843\nIteration: 4186, learning rate: 0.00769, Loss: 0.2669, Accuracy:0.883\nIteration: 4187, learning rate: 0.00769, Loss: 0.3099, Accuracy:0.852\nIteration: 4188, learning rate: 0.00769, Loss: 0.2245, Accuracy:0.914\nIteration: 4189, learning rate: 0.00769, Loss: 0.2119, Accuracy:0.914\nIteration: 4190, learning rate: 0.00769, Loss: 0.3429, Accuracy:0.867\nIteration: 4191, learning rate: 0.00769, Loss: 0.3195, Accuracy:0.852\nIteration: 4192, learning rate: 0.00769, Loss: 0.2787, Accuracy:0.930\nIteration: 4193, learning rate: 0.00769, Loss: 0.4669, Accuracy:0.789\nIteration: 4194, learning rate: 0.00769, Loss: 0.3067, Accuracy:0.883\nIteration: 4195, learning rate: 0.00769, Loss: 0.3909, Accuracy:0.789\nIteration: 4196, learning rate: 0.00769, Loss: 0.2944, Accuracy:0.883\nIteration: 4197, learning rate: 0.00769, Loss: 0.1492, Accuracy:0.961\nIteration: 4198, learning rate: 0.00769, Loss: 0.2064, Accuracy:0.938\nIteration: 4199, learning rate: 0.00769, Loss: 0.2028, Accuracy:0.930\nIteration: 4200, learning rate: 0.00769, Loss: 0.2343, Accuracy:0.891\nIteration: 4201, learning rate: 0.00769, Loss: 0.2663, Accuracy:0.914\nIteration: 4202, learning rate: 0.00769, Loss: 0.2961, Accuracy:0.859\nIteration: 4203, learning rate: 0.00769, Loss: 0.3106, Accuracy:0.859\nIteration: 4204, learning rate: 0.00769, Loss: 0.2251, Accuracy:0.906\nIteration: 4205, learning rate: 0.00769, Loss: 0.2872, Accuracy:0.906\nIteration: 4206, learning rate: 0.00769, Loss: 0.3515, Accuracy:0.875\nIteration: 4207, learning rate: 0.00769, Loss: 0.1896, Accuracy:0.938\nIteration: 4208, learning rate: 0.00768, Loss: 0.2939, Accuracy:0.867\nIteration: 4209, learning rate: 0.00768, Loss: 0.3061, Accuracy:0.867\nIteration: 4210, learning rate: 0.00768, Loss: 0.2466, Accuracy:0.922\nIteration: 4211, learning rate: 0.00768, Loss: 0.2618, Accuracy:0.898\nIteration: 4212, learning rate: 0.00768, Loss: 0.2391, Accuracy:0.906\nIteration: 4213, learning rate: 0.00768, Loss: 0.2757, Accuracy:0.875\nIteration: 4214, learning rate: 0.00768, Loss: 0.2742, Accuracy:0.867\nIteration: 4215, learning rate: 0.00768, Loss: 0.2369, Accuracy:0.906\nIteration: 4216, learning rate: 0.00768, Loss: 0.3221, Accuracy:0.871\nEpoch: 136, Loss: 0.2771, Accuracy:0.887, Val Loss: 0.3330, Val Accuracy: 0.848\nIteration: 4217, learning rate: 0.00768, Loss: 0.2607, Accuracy:0.883\nIteration: 4218, learning rate: 0.00768, Loss: 0.2614, Accuracy:0.906\nIteration: 4219, learning rate: 0.00768, Loss: 0.3415, Accuracy:0.859\nIteration: 4220, learning rate: 0.00768, Loss: 0.3102, Accuracy:0.875\nIteration: 4221, learning rate: 0.00768, Loss: 0.2360, Accuracy:0.914\nIteration: 4222, learning rate: 0.00768, Loss: 0.2842, Accuracy:0.883\nIteration: 4223, learning rate: 0.00768, Loss: 0.3307, Accuracy:0.836\nIteration: 4224, learning rate: 0.00768, Loss: 0.3509, Accuracy:0.836\nIteration: 4225, learning rate: 0.00768, Loss: 0.2893, Accuracy:0.891\nIteration: 4226, learning rate: 0.00768, Loss: 0.2667, Accuracy:0.875\nIteration: 4227, learning rate: 0.00768, Loss: 0.3143, Accuracy:0.883\nIteration: 4228, learning rate: 0.00768, Loss: 0.3357, Accuracy:0.836\nIteration: 4229, learning rate: 0.00768, Loss: 0.3394, Accuracy:0.867\nIteration: 4230, learning rate: 0.00768, Loss: 0.3376, Accuracy:0.844\nIteration: 4231, learning rate: 0.00768, Loss: 0.2644, Accuracy:0.867\nIteration: 4232, learning rate: 0.00767, Loss: 0.2450, Accuracy:0.891\nIteration: 4233, learning rate: 0.00767, Loss: 0.2659, Accuracy:0.906\nIteration: 4234, learning rate: 0.00767, Loss: 0.2432, Accuracy:0.914\nIteration: 4235, learning rate: 0.00767, Loss: 0.2505, Accuracy:0.883\nIteration: 4236, learning rate: 0.00767, Loss: 0.3549, Accuracy:0.883\nIteration: 4237, learning rate: 0.00767, Loss: 0.1974, Accuracy:0.938\nIteration: 4238, learning rate: 0.00767, Loss: 0.2500, Accuracy:0.914\nIteration: 4239, learning rate: 0.00767, Loss: 0.2914, Accuracy:0.875\nIteration: 4240, learning rate: 0.00767, Loss: 0.2184, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4241, learning rate: 0.00767, Loss: 0.2421, Accuracy:0.883\nIteration: 4242, learning rate: 0.00767, Loss: 0.2382, Accuracy:0.930\nIteration: 4243, learning rate: 0.00767, Loss: 0.3166, Accuracy:0.852\nIteration: 4244, learning rate: 0.00767, Loss: 0.3090, Accuracy:0.859\nIteration: 4245, learning rate: 0.00767, Loss: 0.3046, Accuracy:0.859\nIteration: 4246, learning rate: 0.00767, Loss: 0.2697, Accuracy:0.859\nIteration: 4247, learning rate: 0.00767, Loss: 0.2088, Accuracy:0.914\nEpoch: 137, Loss: 0.2816, Accuracy:0.882, Val Loss: 0.3012, Val Accuracy: 0.862\nIteration: 4248, learning rate: 0.00767, Loss: 0.3579, Accuracy:0.867\nIteration: 4249, learning rate: 0.00767, Loss: 0.2646, Accuracy:0.898\nIteration: 4250, learning rate: 0.00767, Loss: 0.2686, Accuracy:0.922\nIteration: 4251, learning rate: 0.00767, Loss: 0.2536, Accuracy:0.883\nIteration: 4252, learning rate: 0.00767, Loss: 0.2983, Accuracy:0.891\nIteration: 4253, learning rate: 0.00767, Loss: 0.2628, Accuracy:0.898\nIteration: 4254, learning rate: 0.00767, Loss: 0.2216, Accuracy:0.930\nIteration: 4255, learning rate: 0.00767, Loss: 0.3418, Accuracy:0.867\nIteration: 4256, learning rate: 0.00767, Loss: 0.2726, Accuracy:0.859\nIteration: 4257, learning rate: 0.00766, Loss: 0.2525, Accuracy:0.906\nIteration: 4258, learning rate: 0.00766, Loss: 0.2799, Accuracy:0.852\nIteration: 4259, learning rate: 0.00766, Loss: 0.2777, Accuracy:0.891\nIteration: 4260, learning rate: 0.00766, Loss: 0.2969, Accuracy:0.867\nIteration: 4261, learning rate: 0.00766, Loss: 0.3224, Accuracy:0.844\nIteration: 4262, learning rate: 0.00766, Loss: 0.2564, Accuracy:0.891\nIteration: 4263, learning rate: 0.00766, Loss: 0.1886, Accuracy:0.945\nIteration: 4264, learning rate: 0.00766, Loss: 0.2557, Accuracy:0.875\nIteration: 4265, learning rate: 0.00766, Loss: 0.3015, Accuracy:0.867\nIteration: 4266, learning rate: 0.00766, Loss: 0.3061, Accuracy:0.875\nIteration: 4267, learning rate: 0.00766, Loss: 0.2706, Accuracy:0.891\nIteration: 4268, learning rate: 0.00766, Loss: 0.2846, Accuracy:0.883\nIteration: 4269, learning rate: 0.00766, Loss: 0.2925, Accuracy:0.867\nIteration: 4270, learning rate: 0.00766, Loss: 0.2381, Accuracy:0.891\nIteration: 4271, learning rate: 0.00766, Loss: 0.2562, Accuracy:0.883\nIteration: 4272, learning rate: 0.00766, Loss: 0.3063, Accuracy:0.859\nIteration: 4273, learning rate: 0.00766, Loss: 0.2950, Accuracy:0.859\nIteration: 4274, learning rate: 0.00766, Loss: 0.2903, Accuracy:0.867\nIteration: 4275, learning rate: 0.00766, Loss: 0.2360, Accuracy:0.898\nIteration: 4276, learning rate: 0.00766, Loss: 0.2727, Accuracy:0.906\nIteration: 4277, learning rate: 0.00766, Loss: 0.3160, Accuracy:0.852\nIteration: 4278, learning rate: 0.00766, Loss: 0.2792, Accuracy:0.860\nEpoch: 138, Loss: 0.2780, Accuracy:0.882, Val Loss: 0.3459, Val Accuracy: 0.842\nIteration: 4279, learning rate: 0.00766, Loss: 0.2685, Accuracy:0.922\nIteration: 4280, learning rate: 0.00766, Loss: 0.2282, Accuracy:0.914\nIteration: 4281, learning rate: 0.00766, Loss: 0.3846, Accuracy:0.852\nIteration: 4282, learning rate: 0.00765, Loss: 0.2385, Accuracy:0.922\nIteration: 4283, learning rate: 0.00765, Loss: 0.2143, Accuracy:0.906\nIteration: 4284, learning rate: 0.00765, Loss: 0.2140, Accuracy:0.914\nIteration: 4285, learning rate: 0.00765, Loss: 0.1791, Accuracy:0.922\nIteration: 4286, learning rate: 0.00765, Loss: 0.2420, Accuracy:0.898\nIteration: 4287, learning rate: 0.00765, Loss: 0.2187, Accuracy:0.914\nIteration: 4288, learning rate: 0.00765, Loss: 0.3637, Accuracy:0.859\nIteration: 4289, learning rate: 0.00765, Loss: 0.2445, Accuracy:0.938\nIteration: 4290, learning rate: 0.00765, Loss: 0.3229, Accuracy:0.867\nIteration: 4291, learning rate: 0.00765, Loss: 0.2949, Accuracy:0.891\nIteration: 4292, learning rate: 0.00765, Loss: 0.1876, Accuracy:0.922\nIteration: 4293, learning rate: 0.00765, Loss: 0.2478, Accuracy:0.883\nIteration: 4294, learning rate: 0.00765, Loss: 0.3049, Accuracy:0.859\nIteration: 4295, learning rate: 0.00765, Loss: 0.2662, Accuracy:0.883\nIteration: 4296, learning rate: 0.00765, Loss: 0.2220, Accuracy:0.898\nIteration: 4297, learning rate: 0.00765, Loss: 0.2349, Accuracy:0.891\nIteration: 4298, learning rate: 0.00765, Loss: 0.2938, Accuracy:0.891\nIteration: 4299, learning rate: 0.00765, Loss: 0.3509, Accuracy:0.844\nIteration: 4300, learning rate: 0.00765, Loss: 0.2488, Accuracy:0.883\nIteration: 4301, learning rate: 0.00765, Loss: 0.3069, Accuracy:0.914\nIteration: 4302, learning rate: 0.00765, Loss: 0.2028, Accuracy:0.906\nIteration: 4303, learning rate: 0.00765, Loss: 0.3088, Accuracy:0.836\nIteration: 4304, learning rate: 0.00765, Loss: 0.1641, Accuracy:0.938\nIteration: 4305, learning rate: 0.00765, Loss: 0.2818, Accuracy:0.867\nIteration: 4306, learning rate: 0.00765, Loss: 0.2745, Accuracy:0.898\nIteration: 4307, learning rate: 0.00764, Loss: 0.2136, Accuracy:0.938\nIteration: 4308, learning rate: 0.00764, Loss: 0.2870, Accuracy:0.859\nIteration: 4309, learning rate: 0.00764, Loss: 0.2786, Accuracy:0.828\nEpoch: 139, Loss: 0.2609, Accuracy:0.892, Val Loss: 0.3837, Val Accuracy: 0.819\nIteration: 4310, learning rate: 0.00764, Loss: 0.2542, Accuracy:0.891\nIteration: 4311, learning rate: 0.00764, Loss: 0.2786, Accuracy:0.891\nIteration: 4312, learning rate: 0.00764, Loss: 0.2909, Accuracy:0.875\nIteration: 4313, learning rate: 0.00764, Loss: 0.3159, Accuracy:0.875\nIteration: 4314, learning rate: 0.00764, Loss: 0.2448, Accuracy:0.898\nIteration: 4315, learning rate: 0.00764, Loss: 0.2136, Accuracy:0.906\nIteration: 4316, learning rate: 0.00764, Loss: 0.2167, Accuracy:0.922\nIteration: 4317, learning rate: 0.00764, Loss: 0.2601, Accuracy:0.875\nIteration: 4318, learning rate: 0.00764, Loss: 0.2509, Accuracy:0.875\nIteration: 4319, learning rate: 0.00764, Loss: 0.2767, Accuracy:0.898\nIteration: 4320, learning rate: 0.00764, Loss: 0.2660, Accuracy:0.875\nIteration: 4321, learning rate: 0.00764, Loss: 0.3393, Accuracy:0.875\nIteration: 4322, learning rate: 0.00764, Loss: 0.3435, Accuracy:0.859\nIteration: 4323, learning rate: 0.00764, Loss: 0.2870, Accuracy:0.891\nIteration: 4324, learning rate: 0.00764, Loss: 0.2646, Accuracy:0.906\nIteration: 4325, learning rate: 0.00764, Loss: 0.2640, Accuracy:0.906\nIteration: 4326, learning rate: 0.00764, Loss: 0.3132, Accuracy:0.867\nIteration: 4327, learning rate: 0.00764, Loss: 0.3065, Accuracy:0.867\nIteration: 4328, learning rate: 0.00764, Loss: 0.2771, Accuracy:0.867\nIteration: 4329, learning rate: 0.00764, Loss: 0.1932, Accuracy:0.930\nIteration: 4330, learning rate: 0.00764, Loss: 0.2335, Accuracy:0.906\nIteration: 4331, learning rate: 0.00764, Loss: 0.3309, Accuracy:0.875\nIteration: 4332, learning rate: 0.00763, Loss: 0.2644, Accuracy:0.891\nIteration: 4333, learning rate: 0.00763, Loss: 0.1835, Accuracy:0.922\nIteration: 4334, learning rate: 0.00763, Loss: 0.2808, Accuracy:0.875\nIteration: 4335, learning rate: 0.00763, Loss: 0.2992, Accuracy:0.867\nIteration: 4336, learning rate: 0.00763, Loss: 0.2199, Accuracy:0.922\nIteration: 4337, learning rate: 0.00763, Loss: 0.3091, Accuracy:0.875\nIteration: 4338, learning rate: 0.00763, Loss: 0.2606, Accuracy:0.898\nIteration: 4339, learning rate: 0.00763, Loss: 0.2322, Accuracy:0.914\nIteration: 4340, learning rate: 0.00763, Loss: 0.3501, Accuracy:0.860\nEpoch: 140, Loss: 0.2717, Accuracy:0.889, Val Loss: 0.3137, Val Accuracy: 0.850\nIteration: 4341, learning rate: 0.00763, Loss: 0.3053, Accuracy:0.852\nIteration: 4342, learning rate: 0.00763, Loss: 0.3067, Accuracy:0.883\nIteration: 4343, learning rate: 0.00763, Loss: 0.2147, Accuracy:0.898\nIteration: 4344, learning rate: 0.00763, Loss: 0.3414, Accuracy:0.875\nIteration: 4345, learning rate: 0.00763, Loss: 0.2721, Accuracy:0.867\nIteration: 4346, learning rate: 0.00763, Loss: 0.2652, Accuracy:0.898\nIteration: 4347, learning rate: 0.00763, Loss: 0.2985, Accuracy:0.844\nIteration: 4348, learning rate: 0.00763, Loss: 0.2562, Accuracy:0.891\nIteration: 4349, learning rate: 0.00763, Loss: 0.2382, Accuracy:0.883\nIteration: 4350, learning rate: 0.00763, Loss: 0.2786, Accuracy:0.875\nIteration: 4351, learning rate: 0.00763, Loss: 0.2656, Accuracy:0.867\nIteration: 4352, learning rate: 0.00763, Loss: 0.3826, Accuracy:0.805\nIteration: 4353, learning rate: 0.00763, Loss: 0.2603, Accuracy:0.906\nIteration: 4354, learning rate: 0.00763, Loss: 0.3041, Accuracy:0.859\nIteration: 4355, learning rate: 0.00763, Loss: 0.2661, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4356, learning rate: 0.00763, Loss: 0.2745, Accuracy:0.859\nIteration: 4357, learning rate: 0.00762, Loss: 0.2053, Accuracy:0.906\nIteration: 4358, learning rate: 0.00762, Loss: 0.2713, Accuracy:0.891\nIteration: 4359, learning rate: 0.00762, Loss: 0.2562, Accuracy:0.906\nIteration: 4360, learning rate: 0.00762, Loss: 0.2817, Accuracy:0.852\nIteration: 4361, learning rate: 0.00762, Loss: 0.2481, Accuracy:0.914\nIteration: 4362, learning rate: 0.00762, Loss: 0.1823, Accuracy:0.938\nIteration: 4363, learning rate: 0.00762, Loss: 0.2822, Accuracy:0.859\nIteration: 4364, learning rate: 0.00762, Loss: 0.3068, Accuracy:0.859\nIteration: 4365, learning rate: 0.00762, Loss: 0.3303, Accuracy:0.867\nIteration: 4366, learning rate: 0.00762, Loss: 0.3409, Accuracy:0.844\nIteration: 4367, learning rate: 0.00762, Loss: 0.2810, Accuracy:0.883\nIteration: 4368, learning rate: 0.00762, Loss: 0.3229, Accuracy:0.844\nIteration: 4369, learning rate: 0.00762, Loss: 0.2198, Accuracy:0.914\nIteration: 4370, learning rate: 0.00762, Loss: 0.2857, Accuracy:0.906\nIteration: 4371, learning rate: 0.00762, Loss: 0.2272, Accuracy:0.914\nEpoch: 141, Loss: 0.2765, Accuracy:0.880, Val Loss: 0.3165, Val Accuracy: 0.872\nIteration: 4372, learning rate: 0.00762, Loss: 0.2640, Accuracy:0.891\nIteration: 4373, learning rate: 0.00762, Loss: 0.2405, Accuracy:0.922\nIteration: 4374, learning rate: 0.00762, Loss: 0.2496, Accuracy:0.898\nIteration: 4375, learning rate: 0.00762, Loss: 0.2351, Accuracy:0.891\nIteration: 4376, learning rate: 0.00762, Loss: 0.3172, Accuracy:0.867\nIteration: 4377, learning rate: 0.00762, Loss: 0.3104, Accuracy:0.875\nIteration: 4378, learning rate: 0.00762, Loss: 0.2190, Accuracy:0.891\nIteration: 4379, learning rate: 0.00762, Loss: 0.3273, Accuracy:0.836\nIteration: 4380, learning rate: 0.00762, Loss: 0.2082, Accuracy:0.922\nIteration: 4381, learning rate: 0.00762, Loss: 0.2359, Accuracy:0.883\nIteration: 4382, learning rate: 0.00761, Loss: 0.1982, Accuracy:0.930\nIteration: 4383, learning rate: 0.00761, Loss: 0.2376, Accuracy:0.914\nIteration: 4384, learning rate: 0.00761, Loss: 0.2405, Accuracy:0.914\nIteration: 4385, learning rate: 0.00761, Loss: 0.2407, Accuracy:0.914\nIteration: 4386, learning rate: 0.00761, Loss: 0.2451, Accuracy:0.891\nIteration: 4387, learning rate: 0.00761, Loss: 0.2401, Accuracy:0.898\nIteration: 4388, learning rate: 0.00761, Loss: 0.2614, Accuracy:0.922\nIteration: 4389, learning rate: 0.00761, Loss: 0.2109, Accuracy:0.930\nIteration: 4390, learning rate: 0.00761, Loss: 0.2904, Accuracy:0.875\nIteration: 4391, learning rate: 0.00761, Loss: 0.2281, Accuracy:0.914\nIteration: 4392, learning rate: 0.00761, Loss: 0.3360, Accuracy:0.867\nIteration: 4393, learning rate: 0.00761, Loss: 0.1992, Accuracy:0.922\nIteration: 4394, learning rate: 0.00761, Loss: 0.2442, Accuracy:0.891\nIteration: 4395, learning rate: 0.00761, Loss: 0.2787, Accuracy:0.906\nIteration: 4396, learning rate: 0.00761, Loss: 0.2574, Accuracy:0.891\nIteration: 4397, learning rate: 0.00761, Loss: 0.2696, Accuracy:0.883\nIteration: 4398, learning rate: 0.00761, Loss: 0.2552, Accuracy:0.875\nIteration: 4399, learning rate: 0.00761, Loss: 0.3229, Accuracy:0.875\nIteration: 4400, learning rate: 0.00761, Loss: 0.2770, Accuracy:0.883\nIteration: 4401, learning rate: 0.00761, Loss: 0.2984, Accuracy:0.875\nIteration: 4402, learning rate: 0.00761, Loss: 0.2386, Accuracy:0.882\nEpoch: 142, Loss: 0.2573, Accuracy:0.894, Val Loss: 0.3142, Val Accuracy: 0.854\nIteration: 4403, learning rate: 0.00761, Loss: 0.3785, Accuracy:0.836\nIteration: 4404, learning rate: 0.00761, Loss: 0.2065, Accuracy:0.922\nIteration: 4405, learning rate: 0.00761, Loss: 0.2120, Accuracy:0.938\nIteration: 4406, learning rate: 0.00761, Loss: 0.2426, Accuracy:0.906\nIteration: 4407, learning rate: 0.00760, Loss: 0.2775, Accuracy:0.891\nIteration: 4408, learning rate: 0.00760, Loss: 0.3102, Accuracy:0.875\nIteration: 4409, learning rate: 0.00760, Loss: 0.2899, Accuracy:0.891\nIteration: 4410, learning rate: 0.00760, Loss: 0.2157, Accuracy:0.898\nIteration: 4411, learning rate: 0.00760, Loss: 0.2378, Accuracy:0.891\nIteration: 4412, learning rate: 0.00760, Loss: 0.2046, Accuracy:0.914\nIteration: 4413, learning rate: 0.00760, Loss: 0.2639, Accuracy:0.875\nIteration: 4414, learning rate: 0.00760, Loss: 0.2929, Accuracy:0.883\nIteration: 4415, learning rate: 0.00760, Loss: 0.2636, Accuracy:0.875\nIteration: 4416, learning rate: 0.00760, Loss: 0.2801, Accuracy:0.898\nIteration: 4417, learning rate: 0.00760, Loss: 0.2212, Accuracy:0.898\nIteration: 4418, learning rate: 0.00760, Loss: 0.3040, Accuracy:0.891\nIteration: 4419, learning rate: 0.00760, Loss: 0.2901, Accuracy:0.852\nIteration: 4420, learning rate: 0.00760, Loss: 0.3351, Accuracy:0.844\nIteration: 4421, learning rate: 0.00760, Loss: 0.2553, Accuracy:0.898\nIteration: 4422, learning rate: 0.00760, Loss: 0.2429, Accuracy:0.891\nIteration: 4423, learning rate: 0.00760, Loss: 0.3332, Accuracy:0.836\nIteration: 4424, learning rate: 0.00760, Loss: 0.3341, Accuracy:0.844\nIteration: 4425, learning rate: 0.00760, Loss: 0.2927, Accuracy:0.875\nIteration: 4426, learning rate: 0.00760, Loss: 0.3195, Accuracy:0.867\nIteration: 4427, learning rate: 0.00760, Loss: 0.2412, Accuracy:0.898\nIteration: 4428, learning rate: 0.00760, Loss: 0.2492, Accuracy:0.898\nIteration: 4429, learning rate: 0.00760, Loss: 0.2486, Accuracy:0.906\nIteration: 4430, learning rate: 0.00760, Loss: 0.2669, Accuracy:0.867\nIteration: 4431, learning rate: 0.00760, Loss: 0.1789, Accuracy:0.953\nIteration: 4432, learning rate: 0.00759, Loss: 0.2651, Accuracy:0.891\nIteration: 4433, learning rate: 0.00759, Loss: 0.3241, Accuracy:0.882\nEpoch: 143, Loss: 0.2703, Accuracy:0.887, Val Loss: 0.3706, Val Accuracy: 0.858\nIteration: 4434, learning rate: 0.00759, Loss: 0.2835, Accuracy:0.906\nIteration: 4435, learning rate: 0.00759, Loss: 0.2917, Accuracy:0.875\nIteration: 4436, learning rate: 0.00759, Loss: 0.2358, Accuracy:0.938\nIteration: 4437, learning rate: 0.00759, Loss: 0.3216, Accuracy:0.852\nIteration: 4438, learning rate: 0.00759, Loss: 0.2271, Accuracy:0.922\nIteration: 4439, learning rate: 0.00759, Loss: 0.2703, Accuracy:0.898\nIteration: 4440, learning rate: 0.00759, Loss: 0.2626, Accuracy:0.875\nIteration: 4441, learning rate: 0.00759, Loss: 0.2646, Accuracy:0.883\nIteration: 4442, learning rate: 0.00759, Loss: 0.1998, Accuracy:0.930\nIteration: 4443, learning rate: 0.00759, Loss: 0.2762, Accuracy:0.891\nIteration: 4444, learning rate: 0.00759, Loss: 0.2390, Accuracy:0.898\nIteration: 4445, learning rate: 0.00759, Loss: 0.2238, Accuracy:0.938\nIteration: 4446, learning rate: 0.00759, Loss: 0.2765, Accuracy:0.914\nIteration: 4447, learning rate: 0.00759, Loss: 0.2058, Accuracy:0.930\nIteration: 4448, learning rate: 0.00759, Loss: 0.2183, Accuracy:0.914\nIteration: 4449, learning rate: 0.00759, Loss: 0.2705, Accuracy:0.883\nIteration: 4450, learning rate: 0.00759, Loss: 0.2799, Accuracy:0.875\nIteration: 4451, learning rate: 0.00759, Loss: 0.2406, Accuracy:0.914\nIteration: 4452, learning rate: 0.00759, Loss: 0.2391, Accuracy:0.898\nIteration: 4453, learning rate: 0.00759, Loss: 0.2552, Accuracy:0.883\nIteration: 4454, learning rate: 0.00759, Loss: 0.2350, Accuracy:0.898\nIteration: 4455, learning rate: 0.00759, Loss: 0.4320, Accuracy:0.852\nIteration: 4456, learning rate: 0.00759, Loss: 0.2463, Accuracy:0.906\nIteration: 4457, learning rate: 0.00759, Loss: 0.2698, Accuracy:0.875\nIteration: 4458, learning rate: 0.00758, Loss: 0.3286, Accuracy:0.852\nIteration: 4459, learning rate: 0.00758, Loss: 0.2206, Accuracy:0.922\nIteration: 4460, learning rate: 0.00758, Loss: 0.2303, Accuracy:0.891\nIteration: 4461, learning rate: 0.00758, Loss: 0.2416, Accuracy:0.883\nIteration: 4462, learning rate: 0.00758, Loss: 0.2451, Accuracy:0.898\nIteration: 4463, learning rate: 0.00758, Loss: 0.3110, Accuracy:0.891\nIteration: 4464, learning rate: 0.00758, Loss: 0.2296, Accuracy:0.871\nEpoch: 144, Loss: 0.2604, Accuracy:0.895, Val Loss: 0.3117, Val Accuracy: 0.858\nIteration: 4465, learning rate: 0.00758, Loss: 0.3452, Accuracy:0.852\nIteration: 4466, learning rate: 0.00758, Loss: 0.2763, Accuracy:0.891\nIteration: 4467, learning rate: 0.00758, Loss: 0.2907, Accuracy:0.883\nIteration: 4468, learning rate: 0.00758, Loss: 0.3526, Accuracy:0.852\nIteration: 4469, learning rate: 0.00758, Loss: 0.2141, Accuracy:0.930\nIteration: 4470, learning rate: 0.00758, Loss: 0.2357, Accuracy:0.922\nIteration: 4471, learning rate: 0.00758, Loss: 0.2449, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4472, learning rate: 0.00758, Loss: 0.2118, Accuracy:0.922\nIteration: 4473, learning rate: 0.00758, Loss: 0.3435, Accuracy:0.859\nIteration: 4474, learning rate: 0.00758, Loss: 0.2725, Accuracy:0.867\nIteration: 4475, learning rate: 0.00758, Loss: 0.2679, Accuracy:0.867\nIteration: 4476, learning rate: 0.00758, Loss: 0.3009, Accuracy:0.898\nIteration: 4477, learning rate: 0.00758, Loss: 0.3204, Accuracy:0.883\nIteration: 4478, learning rate: 0.00758, Loss: 0.3104, Accuracy:0.859\nIteration: 4479, learning rate: 0.00758, Loss: 0.2873, Accuracy:0.867\nIteration: 4480, learning rate: 0.00758, Loss: 0.3504, Accuracy:0.820\nIteration: 4481, learning rate: 0.00758, Loss: 0.2468, Accuracy:0.891\nIteration: 4482, learning rate: 0.00758, Loss: 0.1925, Accuracy:0.914\nIteration: 4483, learning rate: 0.00757, Loss: 0.2747, Accuracy:0.852\nIteration: 4484, learning rate: 0.00757, Loss: 0.2599, Accuracy:0.891\nIteration: 4485, learning rate: 0.00757, Loss: 0.3441, Accuracy:0.820\nIteration: 4486, learning rate: 0.00757, Loss: 0.3019, Accuracy:0.891\nIteration: 4487, learning rate: 0.00757, Loss: 0.2285, Accuracy:0.898\nIteration: 4488, learning rate: 0.00757, Loss: 0.3161, Accuracy:0.883\nIteration: 4489, learning rate: 0.00757, Loss: 0.2555, Accuracy:0.898\nIteration: 4490, learning rate: 0.00757, Loss: 0.3147, Accuracy:0.867\nIteration: 4491, learning rate: 0.00757, Loss: 0.2603, Accuracy:0.883\nIteration: 4492, learning rate: 0.00757, Loss: 0.3635, Accuracy:0.820\nIteration: 4493, learning rate: 0.00757, Loss: 0.2521, Accuracy:0.906\nIteration: 4494, learning rate: 0.00757, Loss: 0.3145, Accuracy:0.875\nIteration: 4495, learning rate: 0.00757, Loss: 0.2289, Accuracy:0.903\nEpoch: 145, Loss: 0.2832, Accuracy:0.879, Val Loss: 0.3466, Val Accuracy: 0.843\nIteration: 4496, learning rate: 0.00757, Loss: 0.2355, Accuracy:0.914\nIteration: 4497, learning rate: 0.00757, Loss: 0.2601, Accuracy:0.883\nIteration: 4498, learning rate: 0.00757, Loss: 0.2947, Accuracy:0.859\nIteration: 4499, learning rate: 0.00757, Loss: 0.2349, Accuracy:0.898\nIteration: 4500, learning rate: 0.00757, Loss: 0.2063, Accuracy:0.930\nIteration: 4501, learning rate: 0.00757, Loss: 0.3761, Accuracy:0.820\nIteration: 4502, learning rate: 0.00757, Loss: 0.2791, Accuracy:0.891\nIteration: 4503, learning rate: 0.00757, Loss: 0.2593, Accuracy:0.898\nIteration: 4504, learning rate: 0.00757, Loss: 0.2718, Accuracy:0.875\nIteration: 4505, learning rate: 0.00757, Loss: 0.3031, Accuracy:0.859\nIteration: 4506, learning rate: 0.00757, Loss: 0.2382, Accuracy:0.914\nIteration: 4507, learning rate: 0.00757, Loss: 0.2596, Accuracy:0.875\nIteration: 4508, learning rate: 0.00757, Loss: 0.2965, Accuracy:0.883\nIteration: 4509, learning rate: 0.00756, Loss: 0.1766, Accuracy:0.938\nIteration: 4510, learning rate: 0.00756, Loss: 0.3290, Accuracy:0.859\nIteration: 4511, learning rate: 0.00756, Loss: 0.3177, Accuracy:0.875\nIteration: 4512, learning rate: 0.00756, Loss: 0.2208, Accuracy:0.930\nIteration: 4513, learning rate: 0.00756, Loss: 0.3255, Accuracy:0.875\nIteration: 4514, learning rate: 0.00756, Loss: 0.3217, Accuracy:0.859\nIteration: 4515, learning rate: 0.00756, Loss: 0.2686, Accuracy:0.883\nIteration: 4516, learning rate: 0.00756, Loss: 0.3196, Accuracy:0.859\nIteration: 4517, learning rate: 0.00756, Loss: 0.3200, Accuracy:0.836\nIteration: 4518, learning rate: 0.00756, Loss: 0.2856, Accuracy:0.883\nIteration: 4519, learning rate: 0.00756, Loss: 0.2181, Accuracy:0.906\nIteration: 4520, learning rate: 0.00756, Loss: 0.3076, Accuracy:0.867\nIteration: 4521, learning rate: 0.00756, Loss: 0.2764, Accuracy:0.891\nIteration: 4522, learning rate: 0.00756, Loss: 0.2574, Accuracy:0.898\nIteration: 4523, learning rate: 0.00756, Loss: 0.2546, Accuracy:0.914\nIteration: 4524, learning rate: 0.00756, Loss: 0.2715, Accuracy:0.891\nIteration: 4525, learning rate: 0.00756, Loss: 0.2591, Accuracy:0.891\nIteration: 4526, learning rate: 0.00756, Loss: 0.3366, Accuracy:0.849\nEpoch: 146, Loss: 0.2768, Accuracy:0.884, Val Loss: 0.3015, Val Accuracy: 0.859\nIteration: 4527, learning rate: 0.00756, Loss: 0.2408, Accuracy:0.883\nIteration: 4528, learning rate: 0.00756, Loss: 0.2456, Accuracy:0.891\nIteration: 4529, learning rate: 0.00756, Loss: 0.2355, Accuracy:0.891\nIteration: 4530, learning rate: 0.00756, Loss: 0.2454, Accuracy:0.906\nIteration: 4531, learning rate: 0.00756, Loss: 0.3089, Accuracy:0.844\nIteration: 4532, learning rate: 0.00756, Loss: 0.2393, Accuracy:0.898\nIteration: 4533, learning rate: 0.00756, Loss: 0.2617, Accuracy:0.906\nIteration: 4534, learning rate: 0.00755, Loss: 0.2828, Accuracy:0.875\nIteration: 4535, learning rate: 0.00755, Loss: 0.2319, Accuracy:0.898\nIteration: 4536, learning rate: 0.00755, Loss: 0.1859, Accuracy:0.930\nIteration: 4537, learning rate: 0.00755, Loss: 0.2196, Accuracy:0.922\nIteration: 4538, learning rate: 0.00755, Loss: 0.2735, Accuracy:0.875\nIteration: 4539, learning rate: 0.00755, Loss: 0.2937, Accuracy:0.883\nIteration: 4540, learning rate: 0.00755, Loss: 0.2597, Accuracy:0.898\nIteration: 4541, learning rate: 0.00755, Loss: 0.2033, Accuracy:0.898\nIteration: 4542, learning rate: 0.00755, Loss: 0.1491, Accuracy:0.961\nIteration: 4543, learning rate: 0.00755, Loss: 0.3070, Accuracy:0.875\nIteration: 4544, learning rate: 0.00755, Loss: 0.2213, Accuracy:0.898\nIteration: 4545, learning rate: 0.00755, Loss: 0.2476, Accuracy:0.906\nIteration: 4546, learning rate: 0.00755, Loss: 0.2989, Accuracy:0.859\nIteration: 4547, learning rate: 0.00755, Loss: 0.2724, Accuracy:0.891\nIteration: 4548, learning rate: 0.00755, Loss: 0.2301, Accuracy:0.891\nIteration: 4549, learning rate: 0.00755, Loss: 0.2704, Accuracy:0.891\nIteration: 4550, learning rate: 0.00755, Loss: 0.2814, Accuracy:0.883\nIteration: 4551, learning rate: 0.00755, Loss: 0.3263, Accuracy:0.867\nIteration: 4552, learning rate: 0.00755, Loss: 0.3186, Accuracy:0.867\nIteration: 4553, learning rate: 0.00755, Loss: 0.2819, Accuracy:0.875\nIteration: 4554, learning rate: 0.00755, Loss: 0.2849, Accuracy:0.875\nIteration: 4555, learning rate: 0.00755, Loss: 0.1977, Accuracy:0.906\nIteration: 4556, learning rate: 0.00755, Loss: 0.2683, Accuracy:0.898\nIteration: 4557, learning rate: 0.00755, Loss: 0.1981, Accuracy:0.935\nEpoch: 147, Loss: 0.2542, Accuracy:0.893, Val Loss: 0.3290, Val Accuracy: 0.854\nIteration: 4558, learning rate: 0.00755, Loss: 0.2565, Accuracy:0.898\nIteration: 4559, learning rate: 0.00755, Loss: 0.2211, Accuracy:0.898\nIteration: 4560, learning rate: 0.00754, Loss: 0.2593, Accuracy:0.938\nIteration: 4561, learning rate: 0.00754, Loss: 0.3959, Accuracy:0.805\nIteration: 4562, learning rate: 0.00754, Loss: 0.2352, Accuracy:0.914\nIteration: 4563, learning rate: 0.00754, Loss: 0.3232, Accuracy:0.883\nIteration: 4564, learning rate: 0.00754, Loss: 0.2521, Accuracy:0.898\nIteration: 4565, learning rate: 0.00754, Loss: 0.2710, Accuracy:0.906\nIteration: 4566, learning rate: 0.00754, Loss: 0.3358, Accuracy:0.852\nIteration: 4567, learning rate: 0.00754, Loss: 0.2377, Accuracy:0.906\nIteration: 4568, learning rate: 0.00754, Loss: 0.3023, Accuracy:0.883\nIteration: 4569, learning rate: 0.00754, Loss: 0.2544, Accuracy:0.883\nIteration: 4570, learning rate: 0.00754, Loss: 0.3313, Accuracy:0.836\nIteration: 4571, learning rate: 0.00754, Loss: 0.2807, Accuracy:0.891\nIteration: 4572, learning rate: 0.00754, Loss: 0.2802, Accuracy:0.875\nIteration: 4573, learning rate: 0.00754, Loss: 0.2413, Accuracy:0.898\nIteration: 4574, learning rate: 0.00754, Loss: 0.2703, Accuracy:0.883\nIteration: 4575, learning rate: 0.00754, Loss: 0.3711, Accuracy:0.820\nIteration: 4576, learning rate: 0.00754, Loss: 0.3244, Accuracy:0.844\nIteration: 4577, learning rate: 0.00754, Loss: 0.2819, Accuracy:0.875\nIteration: 4578, learning rate: 0.00754, Loss: 0.1992, Accuracy:0.922\nIteration: 4579, learning rate: 0.00754, Loss: 0.2622, Accuracy:0.898\nIteration: 4580, learning rate: 0.00754, Loss: 0.2426, Accuracy:0.883\nIteration: 4581, learning rate: 0.00754, Loss: 0.2451, Accuracy:0.875\nIteration: 4582, learning rate: 0.00754, Loss: 0.2732, Accuracy:0.875\nIteration: 4583, learning rate: 0.00754, Loss: 0.2435, Accuracy:0.875\nIteration: 4584, learning rate: 0.00754, Loss: 0.2909, Accuracy:0.875\nIteration: 4585, learning rate: 0.00754, Loss: 0.2585, Accuracy:0.867\nIteration: 4586, learning rate: 0.00753, Loss: 0.2278, Accuracy:0.914\nIteration: 4587, learning rate: 0.00753, Loss: 0.3246, Accuracy:0.859\nIteration: 4588, learning rate: 0.00753, Loss: 0.2875, Accuracy:0.892\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 148, Loss: 0.2768, Accuracy:0.881, Val Loss: 0.3286, Val Accuracy: 0.848\nIteration: 4589, learning rate: 0.00753, Loss: 0.2583, Accuracy:0.883\nIteration: 4590, learning rate: 0.00753, Loss: 0.2811, Accuracy:0.859\nIteration: 4591, learning rate: 0.00753, Loss: 0.2733, Accuracy:0.891\nIteration: 4592, learning rate: 0.00753, Loss: 0.3242, Accuracy:0.867\nIteration: 4593, learning rate: 0.00753, Loss: 0.2411, Accuracy:0.898\nIteration: 4594, learning rate: 0.00753, Loss: 0.2805, Accuracy:0.883\nIteration: 4595, learning rate: 0.00753, Loss: 0.2645, Accuracy:0.891\nIteration: 4596, learning rate: 0.00753, Loss: 0.2486, Accuracy:0.906\nIteration: 4597, learning rate: 0.00753, Loss: 0.2443, Accuracy:0.891\nIteration: 4598, learning rate: 0.00753, Loss: 0.2686, Accuracy:0.875\nIteration: 4599, learning rate: 0.00753, Loss: 0.2304, Accuracy:0.914\nIteration: 4600, learning rate: 0.00753, Loss: 0.3150, Accuracy:0.852\nIteration: 4601, learning rate: 0.00753, Loss: 0.2646, Accuracy:0.875\nIteration: 4602, learning rate: 0.00753, Loss: 0.2236, Accuracy:0.906\nIteration: 4603, learning rate: 0.00753, Loss: 0.2594, Accuracy:0.867\nIteration: 4604, learning rate: 0.00753, Loss: 0.2949, Accuracy:0.875\nIteration: 4605, learning rate: 0.00753, Loss: 0.2843, Accuracy:0.875\nIteration: 4606, learning rate: 0.00753, Loss: 0.3237, Accuracy:0.852\nIteration: 4607, learning rate: 0.00753, Loss: 0.2707, Accuracy:0.852\nIteration: 4608, learning rate: 0.00753, Loss: 0.2898, Accuracy:0.867\nIteration: 4609, learning rate: 0.00753, Loss: 0.2166, Accuracy:0.883\nIteration: 4610, learning rate: 0.00753, Loss: 0.2483, Accuracy:0.906\nIteration: 4611, learning rate: 0.00753, Loss: 0.2951, Accuracy:0.836\nIteration: 4612, learning rate: 0.00752, Loss: 0.2250, Accuracy:0.930\nIteration: 4613, learning rate: 0.00752, Loss: 0.2852, Accuracy:0.883\nIteration: 4614, learning rate: 0.00752, Loss: 0.2474, Accuracy:0.867\nIteration: 4615, learning rate: 0.00752, Loss: 0.2681, Accuracy:0.875\nIteration: 4616, learning rate: 0.00752, Loss: 0.2028, Accuracy:0.914\nIteration: 4617, learning rate: 0.00752, Loss: 0.3180, Accuracy:0.859\nIteration: 4618, learning rate: 0.00752, Loss: 0.3665, Accuracy:0.828\nIteration: 4619, learning rate: 0.00752, Loss: 0.2571, Accuracy:0.882\nEpoch: 149, Loss: 0.2700, Accuracy:0.879, Val Loss: 0.3386, Val Accuracy: 0.853\nIteration: 4620, learning rate: 0.00752, Loss: 0.2021, Accuracy:0.945\nIteration: 4621, learning rate: 0.00752, Loss: 0.2528, Accuracy:0.891\nIteration: 4622, learning rate: 0.00752, Loss: 0.1905, Accuracy:0.914\nIteration: 4623, learning rate: 0.00752, Loss: 0.3082, Accuracy:0.875\nIteration: 4624, learning rate: 0.00752, Loss: 0.2631, Accuracy:0.891\nIteration: 4625, learning rate: 0.00752, Loss: 0.2562, Accuracy:0.906\nIteration: 4626, learning rate: 0.00752, Loss: 0.3006, Accuracy:0.852\nIteration: 4627, learning rate: 0.00752, Loss: 0.1564, Accuracy:0.945\nIteration: 4628, learning rate: 0.00752, Loss: 0.2745, Accuracy:0.898\nIteration: 4629, learning rate: 0.00752, Loss: 0.3140, Accuracy:0.883\nIteration: 4630, learning rate: 0.00752, Loss: 0.2922, Accuracy:0.844\nIteration: 4631, learning rate: 0.00752, Loss: 0.2372, Accuracy:0.914\nIteration: 4632, learning rate: 0.00752, Loss: 0.3897, Accuracy:0.844\nIteration: 4633, learning rate: 0.00752, Loss: 0.2878, Accuracy:0.891\nIteration: 4634, learning rate: 0.00752, Loss: 0.2651, Accuracy:0.883\nIteration: 4635, learning rate: 0.00752, Loss: 0.2371, Accuracy:0.867\nIteration: 4636, learning rate: 0.00752, Loss: 0.2639, Accuracy:0.883\nIteration: 4637, learning rate: 0.00752, Loss: 0.2727, Accuracy:0.883\nIteration: 4638, learning rate: 0.00751, Loss: 0.1917, Accuracy:0.930\nIteration: 4639, learning rate: 0.00751, Loss: 0.2541, Accuracy:0.906\nIteration: 4640, learning rate: 0.00751, Loss: 0.2833, Accuracy:0.852\nIteration: 4641, learning rate: 0.00751, Loss: 0.2309, Accuracy:0.914\nIteration: 4642, learning rate: 0.00751, Loss: 0.2777, Accuracy:0.852\nIteration: 4643, learning rate: 0.00751, Loss: 0.2731, Accuracy:0.883\nIteration: 4644, learning rate: 0.00751, Loss: 0.2432, Accuracy:0.883\nIteration: 4645, learning rate: 0.00751, Loss: 0.2238, Accuracy:0.922\nIteration: 4646, learning rate: 0.00751, Loss: 0.2668, Accuracy:0.906\nIteration: 4647, learning rate: 0.00751, Loss: 0.2705, Accuracy:0.859\nIteration: 4648, learning rate: 0.00751, Loss: 0.1887, Accuracy:0.914\nIteration: 4649, learning rate: 0.00751, Loss: 0.2876, Accuracy:0.875\nIteration: 4650, learning rate: 0.00751, Loss: 0.2654, Accuracy:0.849\nEpoch: 150, Loss: 0.2587, Accuracy:0.889, Val Loss: 0.3125, Val Accuracy: 0.856\nIteration: 4651, learning rate: 0.00751, Loss: 0.2673, Accuracy:0.891\nIteration: 4652, learning rate: 0.00751, Loss: 0.2881, Accuracy:0.867\nIteration: 4653, learning rate: 0.00751, Loss: 0.2837, Accuracy:0.891\nIteration: 4654, learning rate: 0.00751, Loss: 0.3884, Accuracy:0.805\nIteration: 4655, learning rate: 0.00751, Loss: 0.3141, Accuracy:0.859\nIteration: 4656, learning rate: 0.00751, Loss: 0.2494, Accuracy:0.906\nIteration: 4657, learning rate: 0.00751, Loss: 0.2797, Accuracy:0.883\nIteration: 4658, learning rate: 0.00751, Loss: 0.2960, Accuracy:0.875\nIteration: 4659, learning rate: 0.00751, Loss: 0.2254, Accuracy:0.906\nIteration: 4660, learning rate: 0.00751, Loss: 0.2562, Accuracy:0.906\nIteration: 4661, learning rate: 0.00751, Loss: 0.2656, Accuracy:0.891\nIteration: 4662, learning rate: 0.00751, Loss: 0.2801, Accuracy:0.906\nIteration: 4663, learning rate: 0.00751, Loss: 0.2638, Accuracy:0.906\nIteration: 4664, learning rate: 0.00750, Loss: 0.3134, Accuracy:0.844\nIteration: 4665, learning rate: 0.00750, Loss: 0.3271, Accuracy:0.844\nIteration: 4666, learning rate: 0.00750, Loss: 0.2195, Accuracy:0.906\nIteration: 4667, learning rate: 0.00750, Loss: 0.3075, Accuracy:0.883\nIteration: 4668, learning rate: 0.00750, Loss: 0.2054, Accuracy:0.891\nIteration: 4669, learning rate: 0.00750, Loss: 0.2249, Accuracy:0.898\nIteration: 4670, learning rate: 0.00750, Loss: 0.2704, Accuracy:0.883\nIteration: 4671, learning rate: 0.00750, Loss: 0.1787, Accuracy:0.914\nIteration: 4672, learning rate: 0.00750, Loss: 0.3039, Accuracy:0.875\nIteration: 4673, learning rate: 0.00750, Loss: 0.2517, Accuracy:0.906\nIteration: 4674, learning rate: 0.00750, Loss: 0.2363, Accuracy:0.875\nIteration: 4675, learning rate: 0.00750, Loss: 0.3219, Accuracy:0.883\nIteration: 4676, learning rate: 0.00750, Loss: 0.2805, Accuracy:0.891\nIteration: 4677, learning rate: 0.00750, Loss: 0.2210, Accuracy:0.914\nIteration: 4678, learning rate: 0.00750, Loss: 0.2139, Accuracy:0.906\nIteration: 4679, learning rate: 0.00750, Loss: 0.2659, Accuracy:0.906\nIteration: 4680, learning rate: 0.00750, Loss: 0.1914, Accuracy:0.945\nIteration: 4681, learning rate: 0.00750, Loss: 0.1779, Accuracy:0.914\nEpoch: 151, Loss: 0.2635, Accuracy:0.889, Val Loss: 0.3220, Val Accuracy: 0.853\nIteration: 4682, learning rate: 0.00750, Loss: 0.2570, Accuracy:0.891\nIteration: 4683, learning rate: 0.00750, Loss: 0.2795, Accuracy:0.852\nIteration: 4684, learning rate: 0.00750, Loss: 0.3407, Accuracy:0.852\nIteration: 4685, learning rate: 0.00750, Loss: 0.2908, Accuracy:0.875\nIteration: 4686, learning rate: 0.00750, Loss: 0.2929, Accuracy:0.867\nIteration: 4687, learning rate: 0.00750, Loss: 0.2173, Accuracy:0.930\nIteration: 4688, learning rate: 0.00750, Loss: 0.2971, Accuracy:0.867\nIteration: 4689, learning rate: 0.00750, Loss: 0.3076, Accuracy:0.867\nIteration: 4690, learning rate: 0.00749, Loss: 0.2367, Accuracy:0.922\nIteration: 4691, learning rate: 0.00749, Loss: 0.2927, Accuracy:0.898\nIteration: 4692, learning rate: 0.00749, Loss: 0.2141, Accuracy:0.891\nIteration: 4693, learning rate: 0.00749, Loss: 0.2011, Accuracy:0.914\nIteration: 4694, learning rate: 0.00749, Loss: 0.1874, Accuracy:0.906\nIteration: 4695, learning rate: 0.00749, Loss: 0.2669, Accuracy:0.852\nIteration: 4696, learning rate: 0.00749, Loss: 0.2190, Accuracy:0.914\nIteration: 4697, learning rate: 0.00749, Loss: 0.2326, Accuracy:0.898\nIteration: 4698, learning rate: 0.00749, Loss: 0.2899, Accuracy:0.859\nIteration: 4699, learning rate: 0.00749, Loss: 0.2291, Accuracy:0.883\nIteration: 4700, learning rate: 0.00749, Loss: 0.3522, Accuracy:0.867\nIteration: 4701, learning rate: 0.00749, Loss: 0.2847, Accuracy:0.875\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4702, learning rate: 0.00749, Loss: 0.2441, Accuracy:0.898\nIteration: 4703, learning rate: 0.00749, Loss: 0.2134, Accuracy:0.914\nIteration: 4704, learning rate: 0.00749, Loss: 0.2752, Accuracy:0.844\nIteration: 4705, learning rate: 0.00749, Loss: 0.2371, Accuracy:0.875\nIteration: 4706, learning rate: 0.00749, Loss: 0.1999, Accuracy:0.945\nIteration: 4707, learning rate: 0.00749, Loss: 0.1666, Accuracy:0.922\nIteration: 4708, learning rate: 0.00749, Loss: 0.2372, Accuracy:0.898\nIteration: 4709, learning rate: 0.00749, Loss: 0.2341, Accuracy:0.914\nIteration: 4710, learning rate: 0.00749, Loss: 0.2791, Accuracy:0.898\nIteration: 4711, learning rate: 0.00749, Loss: 0.2707, Accuracy:0.898\nIteration: 4712, learning rate: 0.00749, Loss: 0.2202, Accuracy:0.903\nEpoch: 152, Loss: 0.2538, Accuracy:0.890, Val Loss: 0.3378, Val Accuracy: 0.844\nIteration: 4713, learning rate: 0.00749, Loss: 0.1794, Accuracy:0.938\nIteration: 4714, learning rate: 0.00749, Loss: 0.3385, Accuracy:0.836\nIteration: 4715, learning rate: 0.00749, Loss: 0.2343, Accuracy:0.922\nIteration: 4716, learning rate: 0.00748, Loss: 0.1884, Accuracy:0.938\nIteration: 4717, learning rate: 0.00748, Loss: 0.2184, Accuracy:0.914\nIteration: 4718, learning rate: 0.00748, Loss: 0.1750, Accuracy:0.930\nIteration: 4719, learning rate: 0.00748, Loss: 0.3411, Accuracy:0.828\nIteration: 4720, learning rate: 0.00748, Loss: 0.2517, Accuracy:0.867\nIteration: 4721, learning rate: 0.00748, Loss: 0.2640, Accuracy:0.891\nIteration: 4722, learning rate: 0.00748, Loss: 0.2186, Accuracy:0.898\nIteration: 4723, learning rate: 0.00748, Loss: 0.2284, Accuracy:0.914\nIteration: 4724, learning rate: 0.00748, Loss: 0.3364, Accuracy:0.844\nIteration: 4725, learning rate: 0.00748, Loss: 0.2649, Accuracy:0.898\nIteration: 4726, learning rate: 0.00748, Loss: 0.2330, Accuracy:0.914\nIteration: 4727, learning rate: 0.00748, Loss: 0.2293, Accuracy:0.914\nIteration: 4728, learning rate: 0.00748, Loss: 0.2411, Accuracy:0.898\nIteration: 4729, learning rate: 0.00748, Loss: 0.2348, Accuracy:0.891\nIteration: 4730, learning rate: 0.00748, Loss: 0.2259, Accuracy:0.898\nIteration: 4731, learning rate: 0.00748, Loss: 0.1643, Accuracy:0.930\nIteration: 4732, learning rate: 0.00748, Loss: 0.2921, Accuracy:0.859\nIteration: 4733, learning rate: 0.00748, Loss: 0.2642, Accuracy:0.906\nIteration: 4734, learning rate: 0.00748, Loss: 0.2256, Accuracy:0.930\nIteration: 4735, learning rate: 0.00748, Loss: 0.2719, Accuracy:0.875\nIteration: 4736, learning rate: 0.00748, Loss: 0.2787, Accuracy:0.883\nIteration: 4737, learning rate: 0.00748, Loss: 0.2667, Accuracy:0.883\nIteration: 4738, learning rate: 0.00748, Loss: 0.2647, Accuracy:0.883\nIteration: 4739, learning rate: 0.00748, Loss: 0.2703, Accuracy:0.875\nIteration: 4740, learning rate: 0.00748, Loss: 0.3020, Accuracy:0.852\nIteration: 4741, learning rate: 0.00748, Loss: 0.2183, Accuracy:0.906\nIteration: 4742, learning rate: 0.00747, Loss: 0.2696, Accuracy:0.867\nIteration: 4743, learning rate: 0.00747, Loss: 0.2077, Accuracy:0.935\nEpoch: 153, Loss: 0.2484, Accuracy:0.894, Val Loss: 0.3234, Val Accuracy: 0.850\nIteration: 4744, learning rate: 0.00747, Loss: 0.2578, Accuracy:0.898\nIteration: 4745, learning rate: 0.00747, Loss: 0.2808, Accuracy:0.898\nIteration: 4746, learning rate: 0.00747, Loss: 0.2129, Accuracy:0.922\nIteration: 4747, learning rate: 0.00747, Loss: 0.2869, Accuracy:0.906\nIteration: 4748, learning rate: 0.00747, Loss: 0.1950, Accuracy:0.914\nIteration: 4749, learning rate: 0.00747, Loss: 0.2584, Accuracy:0.938\nIteration: 4750, learning rate: 0.00747, Loss: 0.2892, Accuracy:0.867\nIteration: 4751, learning rate: 0.00747, Loss: 0.2508, Accuracy:0.922\nIteration: 4752, learning rate: 0.00747, Loss: 0.3230, Accuracy:0.875\nIteration: 4753, learning rate: 0.00747, Loss: 0.2761, Accuracy:0.875\nIteration: 4754, learning rate: 0.00747, Loss: 0.2285, Accuracy:0.922\nIteration: 4755, learning rate: 0.00747, Loss: 0.3563, Accuracy:0.836\nIteration: 4756, learning rate: 0.00747, Loss: 0.2621, Accuracy:0.898\nIteration: 4757, learning rate: 0.00747, Loss: 0.2926, Accuracy:0.891\nIteration: 4758, learning rate: 0.00747, Loss: 0.3019, Accuracy:0.875\nIteration: 4759, learning rate: 0.00747, Loss: 0.2923, Accuracy:0.898\nIteration: 4760, learning rate: 0.00747, Loss: 0.2594, Accuracy:0.891\nIteration: 4761, learning rate: 0.00747, Loss: 0.2652, Accuracy:0.883\nIteration: 4762, learning rate: 0.00747, Loss: 0.2513, Accuracy:0.875\nIteration: 4763, learning rate: 0.00747, Loss: 0.2159, Accuracy:0.914\nIteration: 4764, learning rate: 0.00747, Loss: 0.2346, Accuracy:0.906\nIteration: 4765, learning rate: 0.00747, Loss: 0.3331, Accuracy:0.859\nIteration: 4766, learning rate: 0.00747, Loss: 0.2057, Accuracy:0.914\nIteration: 4767, learning rate: 0.00747, Loss: 0.2931, Accuracy:0.875\nIteration: 4768, learning rate: 0.00747, Loss: 0.1964, Accuracy:0.922\nIteration: 4769, learning rate: 0.00746, Loss: 0.2711, Accuracy:0.898\nIteration: 4770, learning rate: 0.00746, Loss: 0.2229, Accuracy:0.898\nIteration: 4771, learning rate: 0.00746, Loss: 0.2243, Accuracy:0.914\nIteration: 4772, learning rate: 0.00746, Loss: 0.2866, Accuracy:0.898\nIteration: 4773, learning rate: 0.00746, Loss: 0.2495, Accuracy:0.898\nIteration: 4774, learning rate: 0.00746, Loss: 0.2991, Accuracy:0.871\nEpoch: 154, Loss: 0.2636, Accuracy:0.895, Val Loss: 0.2980, Val Accuracy: 0.883\nIteration: 4775, learning rate: 0.00746, Loss: 0.2144, Accuracy:0.906\nIteration: 4776, learning rate: 0.00746, Loss: 0.2484, Accuracy:0.914\nIteration: 4777, learning rate: 0.00746, Loss: 0.2516, Accuracy:0.898\nIteration: 4778, learning rate: 0.00746, Loss: 0.2348, Accuracy:0.914\nIteration: 4779, learning rate: 0.00746, Loss: 0.3324, Accuracy:0.883\nIteration: 4780, learning rate: 0.00746, Loss: 0.3030, Accuracy:0.859\nIteration: 4781, learning rate: 0.00746, Loss: 0.2155, Accuracy:0.914\nIteration: 4782, learning rate: 0.00746, Loss: 0.2605, Accuracy:0.906\nIteration: 4783, learning rate: 0.00746, Loss: 0.2481, Accuracy:0.898\nIteration: 4784, learning rate: 0.00746, Loss: 0.2252, Accuracy:0.922\nIteration: 4785, learning rate: 0.00746, Loss: 0.3001, Accuracy:0.883\nIteration: 4786, learning rate: 0.00746, Loss: 0.3073, Accuracy:0.844\nIteration: 4787, learning rate: 0.00746, Loss: 0.2876, Accuracy:0.852\nIteration: 4788, learning rate: 0.00746, Loss: 0.2228, Accuracy:0.922\nIteration: 4789, learning rate: 0.00746, Loss: 0.2311, Accuracy:0.914\nIteration: 4790, learning rate: 0.00746, Loss: 0.2536, Accuracy:0.875\nIteration: 4791, learning rate: 0.00746, Loss: 0.2003, Accuracy:0.914\nIteration: 4792, learning rate: 0.00746, Loss: 0.2509, Accuracy:0.891\nIteration: 4793, learning rate: 0.00746, Loss: 0.3214, Accuracy:0.859\nIteration: 4794, learning rate: 0.00746, Loss: 0.2632, Accuracy:0.867\nIteration: 4795, learning rate: 0.00745, Loss: 0.2855, Accuracy:0.891\nIteration: 4796, learning rate: 0.00745, Loss: 0.2891, Accuracy:0.859\nIteration: 4797, learning rate: 0.00745, Loss: 0.2182, Accuracy:0.914\nIteration: 4798, learning rate: 0.00745, Loss: 0.3058, Accuracy:0.891\nIteration: 4799, learning rate: 0.00745, Loss: 0.2258, Accuracy:0.914\nIteration: 4800, learning rate: 0.00745, Loss: 0.2538, Accuracy:0.898\nIteration: 4801, learning rate: 0.00745, Loss: 0.2946, Accuracy:0.844\nIteration: 4802, learning rate: 0.00745, Loss: 0.3382, Accuracy:0.891\nIteration: 4803, learning rate: 0.00745, Loss: 0.2888, Accuracy:0.898\nIteration: 4804, learning rate: 0.00745, Loss: 0.2616, Accuracy:0.867\nIteration: 4805, learning rate: 0.00745, Loss: 0.3231, Accuracy:0.828\nEpoch: 155, Loss: 0.2663, Accuracy:0.888, Val Loss: 0.3151, Val Accuracy: 0.856\nIteration: 4806, learning rate: 0.00745, Loss: 0.2553, Accuracy:0.906\nIteration: 4807, learning rate: 0.00745, Loss: 0.2165, Accuracy:0.906\nIteration: 4808, learning rate: 0.00745, Loss: 0.2494, Accuracy:0.906\nIteration: 4809, learning rate: 0.00745, Loss: 0.2719, Accuracy:0.883\nIteration: 4810, learning rate: 0.00745, Loss: 0.2263, Accuracy:0.906\nIteration: 4811, learning rate: 0.00745, Loss: 0.2088, Accuracy:0.922\nIteration: 4812, learning rate: 0.00745, Loss: 0.3034, Accuracy:0.883\nIteration: 4813, learning rate: 0.00745, Loss: 0.2159, Accuracy:0.898\nIteration: 4814, learning rate: 0.00745, Loss: 0.3512, Accuracy:0.836\nIteration: 4815, learning rate: 0.00745, Loss: 0.2257, Accuracy:0.922\nIteration: 4816, learning rate: 0.00745, Loss: 0.2150, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4817, learning rate: 0.00745, Loss: 0.2448, Accuracy:0.883\nIteration: 4818, learning rate: 0.00745, Loss: 0.2509, Accuracy:0.898\nIteration: 4819, learning rate: 0.00745, Loss: 0.2431, Accuracy:0.906\nIteration: 4820, learning rate: 0.00745, Loss: 0.3386, Accuracy:0.883\nIteration: 4821, learning rate: 0.00744, Loss: 0.1921, Accuracy:0.930\nIteration: 4822, learning rate: 0.00744, Loss: 0.2454, Accuracy:0.906\nIteration: 4823, learning rate: 0.00744, Loss: 0.3080, Accuracy:0.867\nIteration: 4824, learning rate: 0.00744, Loss: 0.2650, Accuracy:0.906\nIteration: 4825, learning rate: 0.00744, Loss: 0.2994, Accuracy:0.859\nIteration: 4826, learning rate: 0.00744, Loss: 0.3248, Accuracy:0.883\nIteration: 4827, learning rate: 0.00744, Loss: 0.2942, Accuracy:0.867\nIteration: 4828, learning rate: 0.00744, Loss: 0.2992, Accuracy:0.883\nIteration: 4829, learning rate: 0.00744, Loss: 0.2212, Accuracy:0.906\nIteration: 4830, learning rate: 0.00744, Loss: 0.3334, Accuracy:0.875\nIteration: 4831, learning rate: 0.00744, Loss: 0.3371, Accuracy:0.836\nIteration: 4832, learning rate: 0.00744, Loss: 0.2198, Accuracy:0.922\nIteration: 4833, learning rate: 0.00744, Loss: 0.1907, Accuracy:0.938\nIteration: 4834, learning rate: 0.00744, Loss: 0.2081, Accuracy:0.930\nIteration: 4835, learning rate: 0.00744, Loss: 0.3007, Accuracy:0.852\nIteration: 4836, learning rate: 0.00744, Loss: 0.2053, Accuracy:0.935\nEpoch: 156, Loss: 0.2600, Accuracy:0.895, Val Loss: 0.3169, Val Accuracy: 0.860\nIteration: 4837, learning rate: 0.00744, Loss: 0.2913, Accuracy:0.891\nIteration: 4838, learning rate: 0.00744, Loss: 0.2844, Accuracy:0.883\nIteration: 4839, learning rate: 0.00744, Loss: 0.2690, Accuracy:0.875\nIteration: 4840, learning rate: 0.00744, Loss: 0.2496, Accuracy:0.891\nIteration: 4841, learning rate: 0.00744, Loss: 0.2200, Accuracy:0.891\nIteration: 4842, learning rate: 0.00744, Loss: 0.3002, Accuracy:0.883\nIteration: 4843, learning rate: 0.00744, Loss: 0.2215, Accuracy:0.906\nIteration: 4844, learning rate: 0.00744, Loss: 0.2118, Accuracy:0.898\nIteration: 4845, learning rate: 0.00744, Loss: 0.2561, Accuracy:0.883\nIteration: 4846, learning rate: 0.00744, Loss: 0.3124, Accuracy:0.867\nIteration: 4847, learning rate: 0.00744, Loss: 0.1977, Accuracy:0.922\nIteration: 4848, learning rate: 0.00743, Loss: 0.2492, Accuracy:0.906\nIteration: 4849, learning rate: 0.00743, Loss: 0.2200, Accuracy:0.898\nIteration: 4850, learning rate: 0.00743, Loss: 0.1918, Accuracy:0.930\nIteration: 4851, learning rate: 0.00743, Loss: 0.2423, Accuracy:0.898\nIteration: 4852, learning rate: 0.00743, Loss: 0.3553, Accuracy:0.852\nIteration: 4853, learning rate: 0.00743, Loss: 0.2652, Accuracy:0.898\nIteration: 4854, learning rate: 0.00743, Loss: 0.3172, Accuracy:0.875\nIteration: 4855, learning rate: 0.00743, Loss: 0.2475, Accuracy:0.875\nIteration: 4856, learning rate: 0.00743, Loss: 0.3662, Accuracy:0.844\nIteration: 4857, learning rate: 0.00743, Loss: 0.2775, Accuracy:0.867\nIteration: 4858, learning rate: 0.00743, Loss: 0.2846, Accuracy:0.906\nIteration: 4859, learning rate: 0.00743, Loss: 0.2085, Accuracy:0.914\nIteration: 4860, learning rate: 0.00743, Loss: 0.4561, Accuracy:0.836\nIteration: 4861, learning rate: 0.00743, Loss: 0.1654, Accuracy:0.961\nIteration: 4862, learning rate: 0.00743, Loss: 0.1697, Accuracy:0.922\nIteration: 4863, learning rate: 0.00743, Loss: 0.2630, Accuracy:0.859\nIteration: 4864, learning rate: 0.00743, Loss: 0.2317, Accuracy:0.922\nIteration: 4865, learning rate: 0.00743, Loss: 0.1997, Accuracy:0.930\nIteration: 4866, learning rate: 0.00743, Loss: 0.1972, Accuracy:0.914\nIteration: 4867, learning rate: 0.00743, Loss: 0.3016, Accuracy:0.882\nEpoch: 157, Loss: 0.2588, Accuracy:0.893, Val Loss: 0.3096, Val Accuracy: 0.852\nIteration: 4868, learning rate: 0.00743, Loss: 0.1484, Accuracy:0.961\nIteration: 4869, learning rate: 0.00743, Loss: 0.3792, Accuracy:0.836\nIteration: 4870, learning rate: 0.00743, Loss: 0.2760, Accuracy:0.898\nIteration: 4871, learning rate: 0.00743, Loss: 0.3357, Accuracy:0.875\nIteration: 4872, learning rate: 0.00743, Loss: 0.2058, Accuracy:0.914\nIteration: 4873, learning rate: 0.00743, Loss: 0.2928, Accuracy:0.883\nIteration: 4874, learning rate: 0.00743, Loss: 0.2241, Accuracy:0.898\nIteration: 4875, learning rate: 0.00742, Loss: 0.3235, Accuracy:0.859\nIteration: 4876, learning rate: 0.00742, Loss: 0.2464, Accuracy:0.898\nIteration: 4877, learning rate: 0.00742, Loss: 0.3197, Accuracy:0.852\nIteration: 4878, learning rate: 0.00742, Loss: 0.1992, Accuracy:0.898\nIteration: 4879, learning rate: 0.00742, Loss: 0.2291, Accuracy:0.898\nIteration: 4880, learning rate: 0.00742, Loss: 0.3399, Accuracy:0.828\nIteration: 4881, learning rate: 0.00742, Loss: 0.1781, Accuracy:0.930\nIteration: 4882, learning rate: 0.00742, Loss: 0.2656, Accuracy:0.883\nIteration: 4883, learning rate: 0.00742, Loss: 0.2144, Accuracy:0.938\nIteration: 4884, learning rate: 0.00742, Loss: 0.3169, Accuracy:0.859\nIteration: 4885, learning rate: 0.00742, Loss: 0.2410, Accuracy:0.922\nIteration: 4886, learning rate: 0.00742, Loss: 0.2194, Accuracy:0.906\nIteration: 4887, learning rate: 0.00742, Loss: 0.3276, Accuracy:0.883\nIteration: 4888, learning rate: 0.00742, Loss: 0.2107, Accuracy:0.906\nIteration: 4889, learning rate: 0.00742, Loss: 0.2095, Accuracy:0.922\nIteration: 4890, learning rate: 0.00742, Loss: 0.2997, Accuracy:0.852\nIteration: 4891, learning rate: 0.00742, Loss: 0.3094, Accuracy:0.883\nIteration: 4892, learning rate: 0.00742, Loss: 0.1675, Accuracy:0.938\nIteration: 4893, learning rate: 0.00742, Loss: 0.2199, Accuracy:0.930\nIteration: 4894, learning rate: 0.00742, Loss: 0.2046, Accuracy:0.938\nIteration: 4895, learning rate: 0.00742, Loss: 0.1718, Accuracy:0.938\nIteration: 4896, learning rate: 0.00742, Loss: 0.2461, Accuracy:0.922\nIteration: 4897, learning rate: 0.00742, Loss: 0.3530, Accuracy:0.836\nIteration: 4898, learning rate: 0.00742, Loss: 0.2988, Accuracy:0.882\nEpoch: 158, Loss: 0.2572, Accuracy:0.896, Val Loss: 0.3298, Val Accuracy: 0.862\nIteration: 4899, learning rate: 0.00742, Loss: 0.3667, Accuracy:0.828\nIteration: 4900, learning rate: 0.00742, Loss: 0.1562, Accuracy:0.961\nIteration: 4901, learning rate: 0.00741, Loss: 0.2107, Accuracy:0.906\nIteration: 4902, learning rate: 0.00741, Loss: 0.2898, Accuracy:0.883\nIteration: 4903, learning rate: 0.00741, Loss: 0.2833, Accuracy:0.875\nIteration: 4904, learning rate: 0.00741, Loss: 0.3181, Accuracy:0.867\nIteration: 4905, learning rate: 0.00741, Loss: 0.2421, Accuracy:0.891\nIteration: 4906, learning rate: 0.00741, Loss: 0.2224, Accuracy:0.906\nIteration: 4907, learning rate: 0.00741, Loss: 0.2108, Accuracy:0.906\nIteration: 4908, learning rate: 0.00741, Loss: 0.2201, Accuracy:0.914\nIteration: 4909, learning rate: 0.00741, Loss: 0.2229, Accuracy:0.906\nIteration: 4910, learning rate: 0.00741, Loss: 0.2426, Accuracy:0.883\nIteration: 4911, learning rate: 0.00741, Loss: 0.2663, Accuracy:0.906\nIteration: 4912, learning rate: 0.00741, Loss: 0.2935, Accuracy:0.875\nIteration: 4913, learning rate: 0.00741, Loss: 0.2576, Accuracy:0.891\nIteration: 4914, learning rate: 0.00741, Loss: 0.2404, Accuracy:0.914\nIteration: 4915, learning rate: 0.00741, Loss: 0.2545, Accuracy:0.883\nIteration: 4916, learning rate: 0.00741, Loss: 0.3094, Accuracy:0.852\nIteration: 4917, learning rate: 0.00741, Loss: 0.1741, Accuracy:0.961\nIteration: 4918, learning rate: 0.00741, Loss: 0.2459, Accuracy:0.898\nIteration: 4919, learning rate: 0.00741, Loss: 0.2833, Accuracy:0.891\nIteration: 4920, learning rate: 0.00741, Loss: 0.2881, Accuracy:0.859\nIteration: 4921, learning rate: 0.00741, Loss: 0.2030, Accuracy:0.914\nIteration: 4922, learning rate: 0.00741, Loss: 0.2949, Accuracy:0.867\nIteration: 4923, learning rate: 0.00741, Loss: 0.2599, Accuracy:0.883\nIteration: 4924, learning rate: 0.00741, Loss: 0.1436, Accuracy:0.961\nIteration: 4925, learning rate: 0.00741, Loss: 0.2159, Accuracy:0.922\nIteration: 4926, learning rate: 0.00741, Loss: 0.2700, Accuracy:0.875\nIteration: 4927, learning rate: 0.00741, Loss: 0.2640, Accuracy:0.914\nIteration: 4928, learning rate: 0.00740, Loss: 0.2430, Accuracy:0.875\nIteration: 4929, learning rate: 0.00740, Loss: 0.2002, Accuracy:0.914\nEpoch: 159, Loss: 0.2482, Accuracy:0.896, Val Loss: 0.3414, Val Accuracy: 0.847\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 4930, learning rate: 0.00740, Loss: 0.2477, Accuracy:0.898\nIteration: 4931, learning rate: 0.00740, Loss: 0.2287, Accuracy:0.898\nIteration: 4932, learning rate: 0.00740, Loss: 0.2476, Accuracy:0.898\nIteration: 4933, learning rate: 0.00740, Loss: 0.2631, Accuracy:0.867\nIteration: 4934, learning rate: 0.00740, Loss: 0.2306, Accuracy:0.922\nIteration: 4935, learning rate: 0.00740, Loss: 0.2282, Accuracy:0.906\nIteration: 4936, learning rate: 0.00740, Loss: 0.1852, Accuracy:0.938\nIteration: 4937, learning rate: 0.00740, Loss: 0.3020, Accuracy:0.875\nIteration: 4938, learning rate: 0.00740, Loss: 0.2451, Accuracy:0.898\nIteration: 4939, learning rate: 0.00740, Loss: 0.2810, Accuracy:0.875\nIteration: 4940, learning rate: 0.00740, Loss: 0.2686, Accuracy:0.891\nIteration: 4941, learning rate: 0.00740, Loss: 0.3429, Accuracy:0.859\nIteration: 4942, learning rate: 0.00740, Loss: 0.2353, Accuracy:0.906\nIteration: 4943, learning rate: 0.00740, Loss: 0.2681, Accuracy:0.875\nIteration: 4944, learning rate: 0.00740, Loss: 0.2111, Accuracy:0.914\nIteration: 4945, learning rate: 0.00740, Loss: 0.2940, Accuracy:0.898\nIteration: 4946, learning rate: 0.00740, Loss: 0.1478, Accuracy:0.961\nIteration: 4947, learning rate: 0.00740, Loss: 0.2409, Accuracy:0.906\nIteration: 4948, learning rate: 0.00740, Loss: 0.2697, Accuracy:0.852\nIteration: 4949, learning rate: 0.00740, Loss: 0.2893, Accuracy:0.852\nIteration: 4950, learning rate: 0.00740, Loss: 0.2705, Accuracy:0.891\nIteration: 4951, learning rate: 0.00740, Loss: 0.2159, Accuracy:0.891\nIteration: 4952, learning rate: 0.00740, Loss: 0.2581, Accuracy:0.906\nIteration: 4953, learning rate: 0.00740, Loss: 0.1807, Accuracy:0.945\nIteration: 4954, learning rate: 0.00740, Loss: 0.3106, Accuracy:0.883\nIteration: 4955, learning rate: 0.00739, Loss: 0.2213, Accuracy:0.930\nIteration: 4956, learning rate: 0.00739, Loss: 0.2334, Accuracy:0.883\nIteration: 4957, learning rate: 0.00739, Loss: 0.3420, Accuracy:0.859\nIteration: 4958, learning rate: 0.00739, Loss: 0.3163, Accuracy:0.844\nIteration: 4959, learning rate: 0.00739, Loss: 0.2548, Accuracy:0.906\nIteration: 4960, learning rate: 0.00739, Loss: 0.1620, Accuracy:0.968\nEpoch: 160, Loss: 0.2514, Accuracy:0.897, Val Loss: 0.3108, Val Accuracy: 0.863\nIteration: 4961, learning rate: 0.00739, Loss: 0.2637, Accuracy:0.898\nIteration: 4962, learning rate: 0.00739, Loss: 0.2716, Accuracy:0.883\nIteration: 4963, learning rate: 0.00739, Loss: 0.3157, Accuracy:0.867\nIteration: 4964, learning rate: 0.00739, Loss: 0.3029, Accuracy:0.852\nIteration: 4965, learning rate: 0.00739, Loss: 0.3184, Accuracy:0.883\nIteration: 4966, learning rate: 0.00739, Loss: 0.2285, Accuracy:0.930\nIteration: 4967, learning rate: 0.00739, Loss: 0.2353, Accuracy:0.898\nIteration: 4968, learning rate: 0.00739, Loss: 0.2312, Accuracy:0.914\nIteration: 4969, learning rate: 0.00739, Loss: 0.2548, Accuracy:0.875\nIteration: 4970, learning rate: 0.00739, Loss: 0.2013, Accuracy:0.922\nIteration: 4971, learning rate: 0.00739, Loss: 0.2355, Accuracy:0.891\nIteration: 4972, learning rate: 0.00739, Loss: 0.1816, Accuracy:0.938\nIteration: 4973, learning rate: 0.00739, Loss: 0.2011, Accuracy:0.938\nIteration: 4974, learning rate: 0.00739, Loss: 0.2453, Accuracy:0.891\nIteration: 4975, learning rate: 0.00739, Loss: 0.3247, Accuracy:0.867\nIteration: 4976, learning rate: 0.00739, Loss: 0.2299, Accuracy:0.930\nIteration: 4977, learning rate: 0.00739, Loss: 0.2341, Accuracy:0.875\nIteration: 4978, learning rate: 0.00739, Loss: 0.2569, Accuracy:0.891\nIteration: 4979, learning rate: 0.00739, Loss: 0.2677, Accuracy:0.898\nIteration: 4980, learning rate: 0.00739, Loss: 0.3813, Accuracy:0.812\nIteration: 4981, learning rate: 0.00739, Loss: 0.2456, Accuracy:0.883\nIteration: 4982, learning rate: 0.00738, Loss: 0.3030, Accuracy:0.875\nIteration: 4983, learning rate: 0.00738, Loss: 0.2377, Accuracy:0.891\nIteration: 4984, learning rate: 0.00738, Loss: 0.2465, Accuracy:0.906\nIteration: 4985, learning rate: 0.00738, Loss: 0.2464, Accuracy:0.898\nIteration: 4986, learning rate: 0.00738, Loss: 0.2872, Accuracy:0.859\nIteration: 4987, learning rate: 0.00738, Loss: 0.2464, Accuracy:0.883\nIteration: 4988, learning rate: 0.00738, Loss: 0.2237, Accuracy:0.930\nIteration: 4989, learning rate: 0.00738, Loss: 0.2310, Accuracy:0.922\nIteration: 4990, learning rate: 0.00738, Loss: 0.3204, Accuracy:0.859\nIteration: 4991, learning rate: 0.00738, Loss: 0.2025, Accuracy:0.914\nEpoch: 161, Loss: 0.2572, Accuracy:0.893, Val Loss: 0.3704, Val Accuracy: 0.853\nIteration: 4992, learning rate: 0.00738, Loss: 0.2857, Accuracy:0.844\nIteration: 4993, learning rate: 0.00738, Loss: 0.2847, Accuracy:0.883\nIteration: 4994, learning rate: 0.00738, Loss: 0.2819, Accuracy:0.875\nIteration: 4995, learning rate: 0.00738, Loss: 0.2453, Accuracy:0.922\nIteration: 4996, learning rate: 0.00738, Loss: 0.2276, Accuracy:0.930\nIteration: 4997, learning rate: 0.00738, Loss: 0.2794, Accuracy:0.859\nIteration: 4998, learning rate: 0.00738, Loss: 0.2044, Accuracy:0.922\nIteration: 4999, learning rate: 0.00738, Loss: 0.4012, Accuracy:0.844\nIteration: 5000, learning rate: 0.00738, Loss: 0.1942, Accuracy:0.922\nIteration: 5001, learning rate: 0.00738, Loss: 0.2491, Accuracy:0.891\nIteration: 5002, learning rate: 0.00738, Loss: 0.3027, Accuracy:0.875\nIteration: 5003, learning rate: 0.00738, Loss: 0.2473, Accuracy:0.891\nIteration: 5004, learning rate: 0.00738, Loss: 0.2135, Accuracy:0.906\nIteration: 5005, learning rate: 0.00738, Loss: 0.2211, Accuracy:0.898\nIteration: 5006, learning rate: 0.00738, Loss: 0.2169, Accuracy:0.891\nIteration: 5007, learning rate: 0.00738, Loss: 0.2130, Accuracy:0.922\nIteration: 5008, learning rate: 0.00738, Loss: 0.2888, Accuracy:0.867\nIteration: 5009, learning rate: 0.00737, Loss: 0.1975, Accuracy:0.906\nIteration: 5010, learning rate: 0.00737, Loss: 0.2310, Accuracy:0.898\nIteration: 5011, learning rate: 0.00737, Loss: 0.3117, Accuracy:0.867\nIteration: 5012, learning rate: 0.00737, Loss: 0.3177, Accuracy:0.875\nIteration: 5013, learning rate: 0.00737, Loss: 0.2033, Accuracy:0.914\nIteration: 5014, learning rate: 0.00737, Loss: 0.2558, Accuracy:0.930\nIteration: 5015, learning rate: 0.00737, Loss: 0.2680, Accuracy:0.898\nIteration: 5016, learning rate: 0.00737, Loss: 0.2024, Accuracy:0.938\nIteration: 5017, learning rate: 0.00737, Loss: 0.2274, Accuracy:0.922\nIteration: 5018, learning rate: 0.00737, Loss: 0.1966, Accuracy:0.922\nIteration: 5019, learning rate: 0.00737, Loss: 0.2223, Accuracy:0.930\nIteration: 5020, learning rate: 0.00737, Loss: 0.1779, Accuracy:0.945\nIteration: 5021, learning rate: 0.00737, Loss: 0.3095, Accuracy:0.859\nIteration: 5022, learning rate: 0.00737, Loss: 0.2181, Accuracy:0.914\nEpoch: 162, Loss: 0.2483, Accuracy:0.899, Val Loss: 0.3553, Val Accuracy: 0.835\nIteration: 5023, learning rate: 0.00737, Loss: 0.2568, Accuracy:0.875\nIteration: 5024, learning rate: 0.00737, Loss: 0.2882, Accuracy:0.859\nIteration: 5025, learning rate: 0.00737, Loss: 0.2941, Accuracy:0.867\nIteration: 5026, learning rate: 0.00737, Loss: 0.3351, Accuracy:0.859\nIteration: 5027, learning rate: 0.00737, Loss: 0.3510, Accuracy:0.859\nIteration: 5028, learning rate: 0.00737, Loss: 0.2933, Accuracy:0.891\nIteration: 5029, learning rate: 0.00737, Loss: 0.3217, Accuracy:0.844\nIteration: 5030, learning rate: 0.00737, Loss: 0.2976, Accuracy:0.883\nIteration: 5031, learning rate: 0.00737, Loss: 0.2587, Accuracy:0.891\nIteration: 5032, learning rate: 0.00737, Loss: 0.1847, Accuracy:0.938\nIteration: 5033, learning rate: 0.00737, Loss: 0.2700, Accuracy:0.875\nIteration: 5034, learning rate: 0.00737, Loss: 0.2569, Accuracy:0.898\nIteration: 5035, learning rate: 0.00737, Loss: 0.2719, Accuracy:0.867\nIteration: 5036, learning rate: 0.00736, Loss: 0.2353, Accuracy:0.898\nIteration: 5037, learning rate: 0.00736, Loss: 0.2399, Accuracy:0.906\nIteration: 5038, learning rate: 0.00736, Loss: 0.1952, Accuracy:0.922\nIteration: 5039, learning rate: 0.00736, Loss: 0.2097, Accuracy:0.906\nIteration: 5040, learning rate: 0.00736, Loss: 0.2823, Accuracy:0.906\nIteration: 5041, learning rate: 0.00736, Loss: 0.1783, Accuracy:0.961\nIteration: 5042, learning rate: 0.00736, Loss: 0.2682, Accuracy:0.891\nIteration: 5043, learning rate: 0.00736, Loss: 0.2606, Accuracy:0.891\nIteration: 5044, learning rate: 0.00736, Loss: 0.2670, Accuracy:0.883\nIteration: 5045, learning rate: 0.00736, Loss: 0.2448, Accuracy:0.883\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5046, learning rate: 0.00736, Loss: 0.2733, Accuracy:0.859\nIteration: 5047, learning rate: 0.00736, Loss: 0.2529, Accuracy:0.867\nIteration: 5048, learning rate: 0.00736, Loss: 0.2891, Accuracy:0.875\nIteration: 5049, learning rate: 0.00736, Loss: 0.2916, Accuracy:0.875\nIteration: 5050, learning rate: 0.00736, Loss: 0.1894, Accuracy:0.938\nIteration: 5051, learning rate: 0.00736, Loss: 0.2951, Accuracy:0.883\nIteration: 5052, learning rate: 0.00736, Loss: 0.2715, Accuracy:0.867\nIteration: 5053, learning rate: 0.00736, Loss: 0.1751, Accuracy:0.946\nEpoch: 163, Loss: 0.2613, Accuracy:0.889, Val Loss: 0.3093, Val Accuracy: 0.872\nIteration: 5054, learning rate: 0.00736, Loss: 0.2657, Accuracy:0.914\nIteration: 5055, learning rate: 0.00736, Loss: 0.2227, Accuracy:0.898\nIteration: 5056, learning rate: 0.00736, Loss: 0.2275, Accuracy:0.914\nIteration: 5057, learning rate: 0.00736, Loss: 0.1979, Accuracy:0.906\nIteration: 5058, learning rate: 0.00736, Loss: 0.3037, Accuracy:0.859\nIteration: 5059, learning rate: 0.00736, Loss: 0.3070, Accuracy:0.891\nIteration: 5060, learning rate: 0.00736, Loss: 0.2388, Accuracy:0.898\nIteration: 5061, learning rate: 0.00736, Loss: 0.3025, Accuracy:0.891\nIteration: 5062, learning rate: 0.00736, Loss: 0.2124, Accuracy:0.906\nIteration: 5063, learning rate: 0.00736, Loss: 0.2693, Accuracy:0.875\nIteration: 5064, learning rate: 0.00735, Loss: 0.2346, Accuracy:0.898\nIteration: 5065, learning rate: 0.00735, Loss: 0.1991, Accuracy:0.922\nIteration: 5066, learning rate: 0.00735, Loss: 0.2531, Accuracy:0.906\nIteration: 5067, learning rate: 0.00735, Loss: 0.2441, Accuracy:0.891\nIteration: 5068, learning rate: 0.00735, Loss: 0.2253, Accuracy:0.914\nIteration: 5069, learning rate: 0.00735, Loss: 0.2244, Accuracy:0.938\nIteration: 5070, learning rate: 0.00735, Loss: 0.3336, Accuracy:0.875\nIteration: 5071, learning rate: 0.00735, Loss: 0.3302, Accuracy:0.859\nIteration: 5072, learning rate: 0.00735, Loss: 0.2961, Accuracy:0.852\nIteration: 5073, learning rate: 0.00735, Loss: 0.2604, Accuracy:0.875\nIteration: 5074, learning rate: 0.00735, Loss: 0.2822, Accuracy:0.875\nIteration: 5075, learning rate: 0.00735, Loss: 0.2097, Accuracy:0.914\nIteration: 5076, learning rate: 0.00735, Loss: 0.2287, Accuracy:0.883\nIteration: 5077, learning rate: 0.00735, Loss: 0.2900, Accuracy:0.898\nIteration: 5078, learning rate: 0.00735, Loss: 0.2097, Accuracy:0.898\nIteration: 5079, learning rate: 0.00735, Loss: 0.2325, Accuracy:0.898\nIteration: 5080, learning rate: 0.00735, Loss: 0.2896, Accuracy:0.875\nIteration: 5081, learning rate: 0.00735, Loss: 0.3142, Accuracy:0.836\nIteration: 5082, learning rate: 0.00735, Loss: 0.3227, Accuracy:0.859\nIteration: 5083, learning rate: 0.00735, Loss: 0.2441, Accuracy:0.914\nIteration: 5084, learning rate: 0.00735, Loss: 0.2841, Accuracy:0.882\nEpoch: 164, Loss: 0.2599, Accuracy:0.891, Val Loss: 0.3231, Val Accuracy: 0.844\nIteration: 5085, learning rate: 0.00735, Loss: 0.2726, Accuracy:0.883\nIteration: 5086, learning rate: 0.00735, Loss: 0.2468, Accuracy:0.922\nIteration: 5087, learning rate: 0.00735, Loss: 0.2773, Accuracy:0.883\nIteration: 5088, learning rate: 0.00735, Loss: 0.2691, Accuracy:0.844\nIteration: 5089, learning rate: 0.00735, Loss: 0.2525, Accuracy:0.891\nIteration: 5090, learning rate: 0.00735, Loss: 0.2766, Accuracy:0.891\nIteration: 5091, learning rate: 0.00734, Loss: 0.3060, Accuracy:0.875\nIteration: 5092, learning rate: 0.00734, Loss: 0.2523, Accuracy:0.906\nIteration: 5093, learning rate: 0.00734, Loss: 0.3551, Accuracy:0.867\nIteration: 5094, learning rate: 0.00734, Loss: 0.2476, Accuracy:0.891\nIteration: 5095, learning rate: 0.00734, Loss: 0.2089, Accuracy:0.922\nIteration: 5096, learning rate: 0.00734, Loss: 0.2486, Accuracy:0.922\nIteration: 5097, learning rate: 0.00734, Loss: 0.2535, Accuracy:0.867\nIteration: 5098, learning rate: 0.00734, Loss: 0.3114, Accuracy:0.898\nIteration: 5099, learning rate: 0.00734, Loss: 0.2363, Accuracy:0.898\nIteration: 5100, learning rate: 0.00734, Loss: 0.2556, Accuracy:0.922\nIteration: 5101, learning rate: 0.00734, Loss: 0.3126, Accuracy:0.867\nIteration: 5102, learning rate: 0.00734, Loss: 0.2567, Accuracy:0.891\nIteration: 5103, learning rate: 0.00734, Loss: 0.3748, Accuracy:0.836\nIteration: 5104, learning rate: 0.00734, Loss: 0.1650, Accuracy:0.945\nIteration: 5105, learning rate: 0.00734, Loss: 0.2201, Accuracy:0.898\nIteration: 5106, learning rate: 0.00734, Loss: 0.2880, Accuracy:0.875\nIteration: 5107, learning rate: 0.00734, Loss: 0.2417, Accuracy:0.914\nIteration: 5108, learning rate: 0.00734, Loss: 0.2087, Accuracy:0.922\nIteration: 5109, learning rate: 0.00734, Loss: 0.3004, Accuracy:0.891\nIteration: 5110, learning rate: 0.00734, Loss: 0.2118, Accuracy:0.914\nIteration: 5111, learning rate: 0.00734, Loss: 0.3294, Accuracy:0.891\nIteration: 5112, learning rate: 0.00734, Loss: 0.2532, Accuracy:0.883\nIteration: 5113, learning rate: 0.00734, Loss: 0.3266, Accuracy:0.852\nIteration: 5114, learning rate: 0.00734, Loss: 0.3140, Accuracy:0.898\nIteration: 5115, learning rate: 0.00734, Loss: 0.2596, Accuracy:0.914\nEpoch: 165, Loss: 0.2688, Accuracy:0.893, Val Loss: 0.3230, Val Accuracy: 0.853\nIteration: 5116, learning rate: 0.00734, Loss: 0.2463, Accuracy:0.875\nIteration: 5117, learning rate: 0.00734, Loss: 0.2900, Accuracy:0.867\nIteration: 5118, learning rate: 0.00734, Loss: 0.2101, Accuracy:0.898\nIteration: 5119, learning rate: 0.00733, Loss: 0.3006, Accuracy:0.867\nIteration: 5120, learning rate: 0.00733, Loss: 0.2311, Accuracy:0.914\nIteration: 5121, learning rate: 0.00733, Loss: 0.2439, Accuracy:0.883\nIteration: 5122, learning rate: 0.00733, Loss: 0.2531, Accuracy:0.914\nIteration: 5123, learning rate: 0.00733, Loss: 0.2533, Accuracy:0.867\nIteration: 5124, learning rate: 0.00733, Loss: 0.2072, Accuracy:0.906\nIteration: 5125, learning rate: 0.00733, Loss: 0.1933, Accuracy:0.953\nIteration: 5126, learning rate: 0.00733, Loss: 0.2703, Accuracy:0.883\nIteration: 5127, learning rate: 0.00733, Loss: 0.2586, Accuracy:0.867\nIteration: 5128, learning rate: 0.00733, Loss: 0.3059, Accuracy:0.859\nIteration: 5129, learning rate: 0.00733, Loss: 0.2156, Accuracy:0.922\nIteration: 5130, learning rate: 0.00733, Loss: 0.2473, Accuracy:0.922\nIteration: 5131, learning rate: 0.00733, Loss: 0.2589, Accuracy:0.891\nIteration: 5132, learning rate: 0.00733, Loss: 0.2578, Accuracy:0.891\nIteration: 5133, learning rate: 0.00733, Loss: 0.2348, Accuracy:0.891\nIteration: 5134, learning rate: 0.00733, Loss: 0.2216, Accuracy:0.898\nIteration: 5135, learning rate: 0.00733, Loss: 0.2713, Accuracy:0.906\nIteration: 5136, learning rate: 0.00733, Loss: 0.2098, Accuracy:0.898\nIteration: 5137, learning rate: 0.00733, Loss: 0.2066, Accuracy:0.914\nIteration: 5138, learning rate: 0.00733, Loss: 0.2079, Accuracy:0.930\nIteration: 5139, learning rate: 0.00733, Loss: 0.2448, Accuracy:0.898\nIteration: 5140, learning rate: 0.00733, Loss: 0.2250, Accuracy:0.930\nIteration: 5141, learning rate: 0.00733, Loss: 0.2882, Accuracy:0.867\nIteration: 5142, learning rate: 0.00733, Loss: 0.2267, Accuracy:0.914\nIteration: 5143, learning rate: 0.00733, Loss: 0.2945, Accuracy:0.883\nIteration: 5144, learning rate: 0.00733, Loss: 0.2543, Accuracy:0.883\nIteration: 5145, learning rate: 0.00733, Loss: 0.2622, Accuracy:0.883\nIteration: 5146, learning rate: 0.00732, Loss: 0.2520, Accuracy:0.871\nEpoch: 166, Loss: 0.2466, Accuracy:0.895, Val Loss: 0.2898, Val Accuracy: 0.860\nIteration: 5147, learning rate: 0.00732, Loss: 0.3022, Accuracy:0.891\nIteration: 5148, learning rate: 0.00732, Loss: 0.2616, Accuracy:0.852\nIteration: 5149, learning rate: 0.00732, Loss: 0.2645, Accuracy:0.867\nIteration: 5150, learning rate: 0.00732, Loss: 0.2086, Accuracy:0.906\nIteration: 5151, learning rate: 0.00732, Loss: 0.3117, Accuracy:0.867\nIteration: 5152, learning rate: 0.00732, Loss: 0.3389, Accuracy:0.875\nIteration: 5153, learning rate: 0.00732, Loss: 0.2368, Accuracy:0.891\nIteration: 5154, learning rate: 0.00732, Loss: 0.2235, Accuracy:0.914\nIteration: 5155, learning rate: 0.00732, Loss: 0.1930, Accuracy:0.922\nIteration: 5156, learning rate: 0.00732, Loss: 0.1685, Accuracy:0.961\nIteration: 5157, learning rate: 0.00732, Loss: 0.2396, Accuracy:0.883\nIteration: 5158, learning rate: 0.00732, Loss: 0.2299, Accuracy:0.914\nIteration: 5159, learning rate: 0.00732, Loss: 0.2373, Accuracy:0.891\nIteration: 5160, learning rate: 0.00732, Loss: 0.2022, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5161, learning rate: 0.00732, Loss: 0.2935, Accuracy:0.859\nIteration: 5162, learning rate: 0.00732, Loss: 0.1600, Accuracy:0.953\nIteration: 5163, learning rate: 0.00732, Loss: 0.2098, Accuracy:0.938\nIteration: 5164, learning rate: 0.00732, Loss: 0.2240, Accuracy:0.898\nIteration: 5165, learning rate: 0.00732, Loss: 0.3063, Accuracy:0.852\nIteration: 5166, learning rate: 0.00732, Loss: 0.3048, Accuracy:0.883\nIteration: 5167, learning rate: 0.00732, Loss: 0.2959, Accuracy:0.875\nIteration: 5168, learning rate: 0.00732, Loss: 0.2565, Accuracy:0.883\nIteration: 5169, learning rate: 0.00732, Loss: 0.2250, Accuracy:0.906\nIteration: 5170, learning rate: 0.00732, Loss: 0.3111, Accuracy:0.844\nIteration: 5171, learning rate: 0.00732, Loss: 0.2555, Accuracy:0.898\nIteration: 5172, learning rate: 0.00732, Loss: 0.1759, Accuracy:0.938\nIteration: 5173, learning rate: 0.00732, Loss: 0.2053, Accuracy:0.898\nIteration: 5174, learning rate: 0.00731, Loss: 0.3210, Accuracy:0.867\nIteration: 5175, learning rate: 0.00731, Loss: 0.2347, Accuracy:0.938\nIteration: 5176, learning rate: 0.00731, Loss: 0.3081, Accuracy:0.852\nIteration: 5177, learning rate: 0.00731, Loss: 0.2187, Accuracy:0.914\nEpoch: 167, Loss: 0.2492, Accuracy:0.896, Val Loss: 0.3342, Val Accuracy: 0.859\nIteration: 5178, learning rate: 0.00731, Loss: 0.3301, Accuracy:0.844\nIteration: 5179, learning rate: 0.00731, Loss: 0.3351, Accuracy:0.867\nIteration: 5180, learning rate: 0.00731, Loss: 0.2112, Accuracy:0.922\nIteration: 5181, learning rate: 0.00731, Loss: 0.2341, Accuracy:0.914\nIteration: 5182, learning rate: 0.00731, Loss: 0.2621, Accuracy:0.867\nIteration: 5183, learning rate: 0.00731, Loss: 0.2143, Accuracy:0.930\nIteration: 5184, learning rate: 0.00731, Loss: 0.2006, Accuracy:0.906\nIteration: 5185, learning rate: 0.00731, Loss: 0.2790, Accuracy:0.891\nIteration: 5186, learning rate: 0.00731, Loss: 0.2050, Accuracy:0.930\nIteration: 5187, learning rate: 0.00731, Loss: 0.2530, Accuracy:0.914\nIteration: 5188, learning rate: 0.00731, Loss: 0.3059, Accuracy:0.859\nIteration: 5189, learning rate: 0.00731, Loss: 0.2546, Accuracy:0.891\nIteration: 5190, learning rate: 0.00731, Loss: 0.3148, Accuracy:0.859\nIteration: 5191, learning rate: 0.00731, Loss: 0.2996, Accuracy:0.883\nIteration: 5192, learning rate: 0.00731, Loss: 0.2728, Accuracy:0.875\nIteration: 5193, learning rate: 0.00731, Loss: 0.1893, Accuracy:0.930\nIteration: 5194, learning rate: 0.00731, Loss: 0.3296, Accuracy:0.883\nIteration: 5195, learning rate: 0.00731, Loss: 0.2384, Accuracy:0.883\nIteration: 5196, learning rate: 0.00731, Loss: 0.2349, Accuracy:0.883\nIteration: 5197, learning rate: 0.00731, Loss: 0.2283, Accuracy:0.922\nIteration: 5198, learning rate: 0.00731, Loss: 0.2726, Accuracy:0.891\nIteration: 5199, learning rate: 0.00731, Loss: 0.3255, Accuracy:0.883\nIteration: 5200, learning rate: 0.00731, Loss: 0.2464, Accuracy:0.883\nIteration: 5201, learning rate: 0.00730, Loss: 0.3217, Accuracy:0.852\nIteration: 5202, learning rate: 0.00730, Loss: 0.3137, Accuracy:0.875\nIteration: 5203, learning rate: 0.00730, Loss: 0.2700, Accuracy:0.891\nIteration: 5204, learning rate: 0.00730, Loss: 0.1570, Accuracy:0.938\nIteration: 5205, learning rate: 0.00730, Loss: 0.3009, Accuracy:0.883\nIteration: 5206, learning rate: 0.00730, Loss: 0.1854, Accuracy:0.922\nIteration: 5207, learning rate: 0.00730, Loss: 0.2138, Accuracy:0.883\nIteration: 5208, learning rate: 0.00730, Loss: 0.2074, Accuracy:0.914\nEpoch: 168, Loss: 0.2583, Accuracy:0.892, Val Loss: 0.3566, Val Accuracy: 0.817\nIteration: 5209, learning rate: 0.00730, Loss: 0.2183, Accuracy:0.906\nIteration: 5210, learning rate: 0.00730, Loss: 0.2651, Accuracy:0.875\nIteration: 5211, learning rate: 0.00730, Loss: 0.2999, Accuracy:0.891\nIteration: 5212, learning rate: 0.00730, Loss: 0.2958, Accuracy:0.875\nIteration: 5213, learning rate: 0.00730, Loss: 0.3897, Accuracy:0.844\nIteration: 5214, learning rate: 0.00730, Loss: 0.2036, Accuracy:0.930\nIteration: 5215, learning rate: 0.00730, Loss: 0.2802, Accuracy:0.852\nIteration: 5216, learning rate: 0.00730, Loss: 0.2237, Accuracy:0.914\nIteration: 5217, learning rate: 0.00730, Loss: 0.2124, Accuracy:0.891\nIteration: 5218, learning rate: 0.00730, Loss: 0.2440, Accuracy:0.891\nIteration: 5219, learning rate: 0.00730, Loss: 0.1726, Accuracy:0.930\nIteration: 5220, learning rate: 0.00730, Loss: 0.2540, Accuracy:0.891\nIteration: 5221, learning rate: 0.00730, Loss: 0.2649, Accuracy:0.867\nIteration: 5222, learning rate: 0.00730, Loss: 0.2128, Accuracy:0.891\nIteration: 5223, learning rate: 0.00730, Loss: 0.2342, Accuracy:0.906\nIteration: 5224, learning rate: 0.00730, Loss: 0.2824, Accuracy:0.891\nIteration: 5225, learning rate: 0.00730, Loss: 0.2541, Accuracy:0.891\nIteration: 5226, learning rate: 0.00730, Loss: 0.2264, Accuracy:0.906\nIteration: 5227, learning rate: 0.00730, Loss: 0.3089, Accuracy:0.867\nIteration: 5228, learning rate: 0.00730, Loss: 0.1914, Accuracy:0.914\nIteration: 5229, learning rate: 0.00729, Loss: 0.2226, Accuracy:0.914\nIteration: 5230, learning rate: 0.00729, Loss: 0.2564, Accuracy:0.867\nIteration: 5231, learning rate: 0.00729, Loss: 0.3083, Accuracy:0.898\nIteration: 5232, learning rate: 0.00729, Loss: 0.2455, Accuracy:0.891\nIteration: 5233, learning rate: 0.00729, Loss: 0.3215, Accuracy:0.867\nIteration: 5234, learning rate: 0.00729, Loss: 0.2096, Accuracy:0.922\nIteration: 5235, learning rate: 0.00729, Loss: 0.2208, Accuracy:0.922\nIteration: 5236, learning rate: 0.00729, Loss: 0.3161, Accuracy:0.852\nIteration: 5237, learning rate: 0.00729, Loss: 0.2423, Accuracy:0.891\nIteration: 5238, learning rate: 0.00729, Loss: 0.2749, Accuracy:0.891\nIteration: 5239, learning rate: 0.00729, Loss: 0.2820, Accuracy:0.892\nEpoch: 169, Loss: 0.2559, Accuracy:0.891, Val Loss: 0.3148, Val Accuracy: 0.880\nIteration: 5240, learning rate: 0.00729, Loss: 0.2244, Accuracy:0.906\nIteration: 5241, learning rate: 0.00729, Loss: 0.1811, Accuracy:0.906\nIteration: 5242, learning rate: 0.00729, Loss: 0.3093, Accuracy:0.859\nIteration: 5243, learning rate: 0.00729, Loss: 0.2082, Accuracy:0.898\nIteration: 5244, learning rate: 0.00729, Loss: 0.2585, Accuracy:0.891\nIteration: 5245, learning rate: 0.00729, Loss: 0.2583, Accuracy:0.875\nIteration: 5246, learning rate: 0.00729, Loss: 0.3343, Accuracy:0.852\nIteration: 5247, learning rate: 0.00729, Loss: 0.3486, Accuracy:0.875\nIteration: 5248, learning rate: 0.00729, Loss: 0.2430, Accuracy:0.883\nIteration: 5249, learning rate: 0.00729, Loss: 0.2154, Accuracy:0.922\nIteration: 5250, learning rate: 0.00729, Loss: 0.2187, Accuracy:0.914\nIteration: 5251, learning rate: 0.00729, Loss: 0.4281, Accuracy:0.773\nIteration: 5252, learning rate: 0.00729, Loss: 0.2052, Accuracy:0.914\nIteration: 5253, learning rate: 0.00729, Loss: 0.2667, Accuracy:0.906\nIteration: 5254, learning rate: 0.00729, Loss: 0.2496, Accuracy:0.891\nIteration: 5255, learning rate: 0.00729, Loss: 0.2884, Accuracy:0.867\nIteration: 5256, learning rate: 0.00729, Loss: 0.3004, Accuracy:0.852\nIteration: 5257, learning rate: 0.00728, Loss: 0.2206, Accuracy:0.914\nIteration: 5258, learning rate: 0.00728, Loss: 0.3349, Accuracy:0.867\nIteration: 5259, learning rate: 0.00728, Loss: 0.2522, Accuracy:0.883\nIteration: 5260, learning rate: 0.00728, Loss: 0.2578, Accuracy:0.883\nIteration: 5261, learning rate: 0.00728, Loss: 0.2668, Accuracy:0.906\nIteration: 5262, learning rate: 0.00728, Loss: 0.2010, Accuracy:0.906\nIteration: 5263, learning rate: 0.00728, Loss: 0.3088, Accuracy:0.891\nIteration: 5264, learning rate: 0.00728, Loss: 0.2272, Accuracy:0.914\nIteration: 5265, learning rate: 0.00728, Loss: 0.2940, Accuracy:0.867\nIteration: 5266, learning rate: 0.00728, Loss: 0.2968, Accuracy:0.914\nIteration: 5267, learning rate: 0.00728, Loss: 0.2017, Accuracy:0.914\nIteration: 5268, learning rate: 0.00728, Loss: 0.3082, Accuracy:0.906\nIteration: 5269, learning rate: 0.00728, Loss: 0.1969, Accuracy:0.930\nIteration: 5270, learning rate: 0.00728, Loss: 0.2433, Accuracy:0.903\nEpoch: 170, Loss: 0.2629, Accuracy:0.890, Val Loss: 0.2946, Val Accuracy: 0.871\nIteration: 5271, learning rate: 0.00728, Loss: 0.2259, Accuracy:0.906\nIteration: 5272, learning rate: 0.00728, Loss: 0.2080, Accuracy:0.922\nIteration: 5273, learning rate: 0.00728, Loss: 0.2291, Accuracy:0.898\nIteration: 5274, learning rate: 0.00728, Loss: 0.3669, Accuracy:0.844\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5275, learning rate: 0.00728, Loss: 0.2070, Accuracy:0.938\nIteration: 5276, learning rate: 0.00728, Loss: 0.2403, Accuracy:0.898\nIteration: 5277, learning rate: 0.00728, Loss: 0.3434, Accuracy:0.844\nIteration: 5278, learning rate: 0.00728, Loss: 0.2071, Accuracy:0.914\nIteration: 5279, learning rate: 0.00728, Loss: 0.2565, Accuracy:0.891\nIteration: 5280, learning rate: 0.00728, Loss: 0.2156, Accuracy:0.898\nIteration: 5281, learning rate: 0.00728, Loss: 0.2345, Accuracy:0.883\nIteration: 5282, learning rate: 0.00728, Loss: 0.2643, Accuracy:0.883\nIteration: 5283, learning rate: 0.00728, Loss: 0.2486, Accuracy:0.883\nIteration: 5284, learning rate: 0.00728, Loss: 0.2998, Accuracy:0.867\nIteration: 5285, learning rate: 0.00727, Loss: 0.2536, Accuracy:0.930\nIteration: 5286, learning rate: 0.00727, Loss: 0.2385, Accuracy:0.875\nIteration: 5287, learning rate: 0.00727, Loss: 0.2338, Accuracy:0.891\nIteration: 5288, learning rate: 0.00727, Loss: 0.1857, Accuracy:0.945\nIteration: 5289, learning rate: 0.00727, Loss: 0.2926, Accuracy:0.891\nIteration: 5290, learning rate: 0.00727, Loss: 0.2524, Accuracy:0.891\nIteration: 5291, learning rate: 0.00727, Loss: 0.2545, Accuracy:0.875\nIteration: 5292, learning rate: 0.00727, Loss: 0.2380, Accuracy:0.891\nIteration: 5293, learning rate: 0.00727, Loss: 0.2568, Accuracy:0.906\nIteration: 5294, learning rate: 0.00727, Loss: 0.2055, Accuracy:0.906\nIteration: 5295, learning rate: 0.00727, Loss: 0.3717, Accuracy:0.859\nIteration: 5296, learning rate: 0.00727, Loss: 0.2329, Accuracy:0.906\nIteration: 5297, learning rate: 0.00727, Loss: 0.2458, Accuracy:0.914\nIteration: 5298, learning rate: 0.00727, Loss: 0.2225, Accuracy:0.914\nIteration: 5299, learning rate: 0.00727, Loss: 0.2289, Accuracy:0.922\nIteration: 5300, learning rate: 0.00727, Loss: 0.3425, Accuracy:0.883\nIteration: 5301, learning rate: 0.00727, Loss: 0.1777, Accuracy:0.925\nEpoch: 171, Loss: 0.2510, Accuracy:0.897, Val Loss: 0.3029, Val Accuracy: 0.868\nIteration: 5302, learning rate: 0.00727, Loss: 0.2286, Accuracy:0.914\nIteration: 5303, learning rate: 0.00727, Loss: 0.2406, Accuracy:0.898\nIteration: 5304, learning rate: 0.00727, Loss: 0.2127, Accuracy:0.914\nIteration: 5305, learning rate: 0.00727, Loss: 0.1862, Accuracy:0.922\nIteration: 5306, learning rate: 0.00727, Loss: 0.1892, Accuracy:0.914\nIteration: 5307, learning rate: 0.00727, Loss: 0.2924, Accuracy:0.859\nIteration: 5308, learning rate: 0.00727, Loss: 0.1655, Accuracy:0.953\nIteration: 5309, learning rate: 0.00727, Loss: 0.3222, Accuracy:0.898\nIteration: 5310, learning rate: 0.00727, Loss: 0.2398, Accuracy:0.914\nIteration: 5311, learning rate: 0.00727, Loss: 0.2831, Accuracy:0.867\nIteration: 5312, learning rate: 0.00727, Loss: 0.3527, Accuracy:0.836\nIteration: 5313, learning rate: 0.00726, Loss: 0.2595, Accuracy:0.891\nIteration: 5314, learning rate: 0.00726, Loss: 0.2091, Accuracy:0.906\nIteration: 5315, learning rate: 0.00726, Loss: 0.1517, Accuracy:0.961\nIteration: 5316, learning rate: 0.00726, Loss: 0.3195, Accuracy:0.859\nIteration: 5317, learning rate: 0.00726, Loss: 0.1978, Accuracy:0.914\nIteration: 5318, learning rate: 0.00726, Loss: 0.1790, Accuracy:0.945\nIteration: 5319, learning rate: 0.00726, Loss: 0.2574, Accuracy:0.883\nIteration: 5320, learning rate: 0.00726, Loss: 0.2445, Accuracy:0.922\nIteration: 5321, learning rate: 0.00726, Loss: 0.2425, Accuracy:0.906\nIteration: 5322, learning rate: 0.00726, Loss: 0.2379, Accuracy:0.867\nIteration: 5323, learning rate: 0.00726, Loss: 0.1924, Accuracy:0.938\nIteration: 5324, learning rate: 0.00726, Loss: 0.3239, Accuracy:0.852\nIteration: 5325, learning rate: 0.00726, Loss: 0.2490, Accuracy:0.883\nIteration: 5326, learning rate: 0.00726, Loss: 0.2602, Accuracy:0.875\nIteration: 5327, learning rate: 0.00726, Loss: 0.3083, Accuracy:0.852\nIteration: 5328, learning rate: 0.00726, Loss: 0.2806, Accuracy:0.867\nIteration: 5329, learning rate: 0.00726, Loss: 0.3286, Accuracy:0.875\nIteration: 5330, learning rate: 0.00726, Loss: 0.2172, Accuracy:0.906\nIteration: 5331, learning rate: 0.00726, Loss: 0.2939, Accuracy:0.867\nIteration: 5332, learning rate: 0.00726, Loss: 0.2000, Accuracy:0.925\nEpoch: 172, Loss: 0.2473, Accuracy:0.896, Val Loss: 0.2843, Val Accuracy: 0.878\nIteration: 5333, learning rate: 0.00726, Loss: 0.2368, Accuracy:0.883\nIteration: 5334, learning rate: 0.00726, Loss: 0.2060, Accuracy:0.930\nIteration: 5335, learning rate: 0.00726, Loss: 0.2221, Accuracy:0.906\nIteration: 5336, learning rate: 0.00726, Loss: 0.1861, Accuracy:0.945\nIteration: 5337, learning rate: 0.00726, Loss: 0.3285, Accuracy:0.867\nIteration: 5338, learning rate: 0.00726, Loss: 0.2889, Accuracy:0.891\nIteration: 5339, learning rate: 0.00726, Loss: 0.2668, Accuracy:0.859\nIteration: 5340, learning rate: 0.00726, Loss: 0.2548, Accuracy:0.883\nIteration: 5341, learning rate: 0.00725, Loss: 0.2935, Accuracy:0.891\nIteration: 5342, learning rate: 0.00725, Loss: 0.1985, Accuracy:0.898\nIteration: 5343, learning rate: 0.00725, Loss: 0.3314, Accuracy:0.867\nIteration: 5344, learning rate: 0.00725, Loss: 0.1946, Accuracy:0.922\nIteration: 5345, learning rate: 0.00725, Loss: 0.2064, Accuracy:0.922\nIteration: 5346, learning rate: 0.00725, Loss: 0.2012, Accuracy:0.922\nIteration: 5347, learning rate: 0.00725, Loss: 0.3274, Accuracy:0.844\nIteration: 5348, learning rate: 0.00725, Loss: 0.2084, Accuracy:0.914\nIteration: 5349, learning rate: 0.00725, Loss: 0.2505, Accuracy:0.891\nIteration: 5350, learning rate: 0.00725, Loss: 0.2460, Accuracy:0.906\nIteration: 5351, learning rate: 0.00725, Loss: 0.1808, Accuracy:0.922\nIteration: 5352, learning rate: 0.00725, Loss: 0.2738, Accuracy:0.844\nIteration: 5353, learning rate: 0.00725, Loss: 0.1803, Accuracy:0.938\nIteration: 5354, learning rate: 0.00725, Loss: 0.2896, Accuracy:0.844\nIteration: 5355, learning rate: 0.00725, Loss: 0.2596, Accuracy:0.922\nIteration: 5356, learning rate: 0.00725, Loss: 0.3457, Accuracy:0.836\nIteration: 5357, learning rate: 0.00725, Loss: 0.2080, Accuracy:0.938\nIteration: 5358, learning rate: 0.00725, Loss: 0.1498, Accuracy:0.953\nIteration: 5359, learning rate: 0.00725, Loss: 0.2646, Accuracy:0.914\nIteration: 5360, learning rate: 0.00725, Loss: 0.2717, Accuracy:0.883\nIteration: 5361, learning rate: 0.00725, Loss: 0.2578, Accuracy:0.906\nIteration: 5362, learning rate: 0.00725, Loss: 0.2321, Accuracy:0.906\nIteration: 5363, learning rate: 0.00725, Loss: 0.3309, Accuracy:0.849\nEpoch: 173, Loss: 0.2481, Accuracy:0.897, Val Loss: 0.3249, Val Accuracy: 0.853\nIteration: 5364, learning rate: 0.00725, Loss: 0.2201, Accuracy:0.906\nIteration: 5365, learning rate: 0.00725, Loss: 0.1698, Accuracy:0.930\nIteration: 5366, learning rate: 0.00725, Loss: 0.2245, Accuracy:0.938\nIteration: 5367, learning rate: 0.00725, Loss: 0.2050, Accuracy:0.914\nIteration: 5368, learning rate: 0.00725, Loss: 0.3373, Accuracy:0.859\nIteration: 5369, learning rate: 0.00724, Loss: 0.1989, Accuracy:0.914\nIteration: 5370, learning rate: 0.00724, Loss: 0.2702, Accuracy:0.859\nIteration: 5371, learning rate: 0.00724, Loss: 0.2081, Accuracy:0.906\nIteration: 5372, learning rate: 0.00724, Loss: 0.2708, Accuracy:0.906\nIteration: 5373, learning rate: 0.00724, Loss: 0.2407, Accuracy:0.906\nIteration: 5374, learning rate: 0.00724, Loss: 0.2314, Accuracy:0.891\nIteration: 5375, learning rate: 0.00724, Loss: 0.1957, Accuracy:0.922\nIteration: 5376, learning rate: 0.00724, Loss: 0.2096, Accuracy:0.922\nIteration: 5377, learning rate: 0.00724, Loss: 0.2160, Accuracy:0.922\nIteration: 5378, learning rate: 0.00724, Loss: 0.2439, Accuracy:0.914\nIteration: 5379, learning rate: 0.00724, Loss: 0.2724, Accuracy:0.883\nIteration: 5380, learning rate: 0.00724, Loss: 0.2464, Accuracy:0.867\nIteration: 5381, learning rate: 0.00724, Loss: 0.1836, Accuracy:0.938\nIteration: 5382, learning rate: 0.00724, Loss: 0.1616, Accuracy:0.969\nIteration: 5383, learning rate: 0.00724, Loss: 0.2797, Accuracy:0.898\nIteration: 5384, learning rate: 0.00724, Loss: 0.1714, Accuracy:0.961\nIteration: 5385, learning rate: 0.00724, Loss: 0.3229, Accuracy:0.891\nIteration: 5386, learning rate: 0.00724, Loss: 0.2245, Accuracy:0.930\nIteration: 5387, learning rate: 0.00724, Loss: 0.1733, Accuracy:0.922\nIteration: 5388, learning rate: 0.00724, Loss: 0.3084, Accuracy:0.820\nIteration: 5389, learning rate: 0.00724, Loss: 0.1933, Accuracy:0.945\nIteration: 5390, learning rate: 0.00724, Loss: 0.2553, Accuracy:0.891\nIteration: 5391, learning rate: 0.00724, Loss: 0.2073, Accuracy:0.922\nIteration: 5392, learning rate: 0.00724, Loss: 0.2510, Accuracy:0.883\nIteration: 5393, learning rate: 0.00724, Loss: 0.1843, Accuracy:0.938\nIteration: 5394, learning rate: 0.00724, Loss: 0.2353, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 174, Loss: 0.2294, Accuracy:0.909, Val Loss: 0.2965, Val Accuracy: 0.872\nIteration: 5395, learning rate: 0.00724, Loss: 0.2140, Accuracy:0.914\nIteration: 5396, learning rate: 0.00724, Loss: 0.2259, Accuracy:0.930\nIteration: 5397, learning rate: 0.00724, Loss: 0.2065, Accuracy:0.922\nIteration: 5398, learning rate: 0.00723, Loss: 0.2193, Accuracy:0.922\nIteration: 5399, learning rate: 0.00723, Loss: 0.2734, Accuracy:0.875\nIteration: 5400, learning rate: 0.00723, Loss: 0.2016, Accuracy:0.922\nIteration: 5401, learning rate: 0.00723, Loss: 0.2355, Accuracy:0.906\nIteration: 5402, learning rate: 0.00723, Loss: 0.2539, Accuracy:0.883\nIteration: 5403, learning rate: 0.00723, Loss: 0.2320, Accuracy:0.906\nIteration: 5404, learning rate: 0.00723, Loss: 0.1967, Accuracy:0.922\nIteration: 5405, learning rate: 0.00723, Loss: 0.2035, Accuracy:0.914\nIteration: 5406, learning rate: 0.00723, Loss: 0.1991, Accuracy:0.922\nIteration: 5407, learning rate: 0.00723, Loss: 0.2498, Accuracy:0.906\nIteration: 5408, learning rate: 0.00723, Loss: 0.2399, Accuracy:0.898\nIteration: 5409, learning rate: 0.00723, Loss: 0.2786, Accuracy:0.867\nIteration: 5410, learning rate: 0.00723, Loss: 0.2563, Accuracy:0.898\nIteration: 5411, learning rate: 0.00723, Loss: 0.3098, Accuracy:0.867\nIteration: 5412, learning rate: 0.00723, Loss: 0.2582, Accuracy:0.867\nIteration: 5413, learning rate: 0.00723, Loss: 0.3154, Accuracy:0.883\nIteration: 5414, learning rate: 0.00723, Loss: 0.2287, Accuracy:0.906\nIteration: 5415, learning rate: 0.00723, Loss: 0.2684, Accuracy:0.898\nIteration: 5416, learning rate: 0.00723, Loss: 0.2761, Accuracy:0.883\nIteration: 5417, learning rate: 0.00723, Loss: 0.2626, Accuracy:0.898\nIteration: 5418, learning rate: 0.00723, Loss: 0.2297, Accuracy:0.898\nIteration: 5419, learning rate: 0.00723, Loss: 0.2873, Accuracy:0.883\nIteration: 5420, learning rate: 0.00723, Loss: 0.2813, Accuracy:0.898\nIteration: 5421, learning rate: 0.00723, Loss: 0.3321, Accuracy:0.836\nIteration: 5422, learning rate: 0.00723, Loss: 0.2407, Accuracy:0.883\nIteration: 5423, learning rate: 0.00723, Loss: 0.2173, Accuracy:0.930\nIteration: 5424, learning rate: 0.00723, Loss: 0.3039, Accuracy:0.852\nIteration: 5425, learning rate: 0.00723, Loss: 0.2361, Accuracy:0.882\nEpoch: 175, Loss: 0.2495, Accuracy:0.896, Val Loss: 0.3344, Val Accuracy: 0.853\nIteration: 5426, learning rate: 0.00722, Loss: 0.2569, Accuracy:0.898\nIteration: 5427, learning rate: 0.00722, Loss: 0.2096, Accuracy:0.914\nIteration: 5428, learning rate: 0.00722, Loss: 0.2833, Accuracy:0.875\nIteration: 5429, learning rate: 0.00722, Loss: 0.1866, Accuracy:0.938\nIteration: 5430, learning rate: 0.00722, Loss: 0.1636, Accuracy:0.922\nIteration: 5431, learning rate: 0.00722, Loss: 0.2113, Accuracy:0.906\nIteration: 5432, learning rate: 0.00722, Loss: 0.2102, Accuracy:0.906\nIteration: 5433, learning rate: 0.00722, Loss: 0.2132, Accuracy:0.922\nIteration: 5434, learning rate: 0.00722, Loss: 0.2919, Accuracy:0.898\nIteration: 5435, learning rate: 0.00722, Loss: 0.2211, Accuracy:0.906\nIteration: 5436, learning rate: 0.00722, Loss: 0.1985, Accuracy:0.961\nIteration: 5437, learning rate: 0.00722, Loss: 0.2301, Accuracy:0.938\nIteration: 5438, learning rate: 0.00722, Loss: 0.2134, Accuracy:0.891\nIteration: 5439, learning rate: 0.00722, Loss: 0.2233, Accuracy:0.898\nIteration: 5440, learning rate: 0.00722, Loss: 0.2798, Accuracy:0.898\nIteration: 5441, learning rate: 0.00722, Loss: 0.2733, Accuracy:0.891\nIteration: 5442, learning rate: 0.00722, Loss: 0.2559, Accuracy:0.906\nIteration: 5443, learning rate: 0.00722, Loss: 0.1567, Accuracy:0.930\nIteration: 5444, learning rate: 0.00722, Loss: 0.2333, Accuracy:0.906\nIteration: 5445, learning rate: 0.00722, Loss: 0.2573, Accuracy:0.898\nIteration: 5446, learning rate: 0.00722, Loss: 0.2496, Accuracy:0.922\nIteration: 5447, learning rate: 0.00722, Loss: 0.2719, Accuracy:0.883\nIteration: 5448, learning rate: 0.00722, Loss: 0.2156, Accuracy:0.930\nIteration: 5449, learning rate: 0.00722, Loss: 0.1971, Accuracy:0.938\nIteration: 5450, learning rate: 0.00722, Loss: 0.2458, Accuracy:0.914\nIteration: 5451, learning rate: 0.00722, Loss: 0.2765, Accuracy:0.883\nIteration: 5452, learning rate: 0.00722, Loss: 0.2655, Accuracy:0.891\nIteration: 5453, learning rate: 0.00722, Loss: 0.3044, Accuracy:0.883\nIteration: 5454, learning rate: 0.00722, Loss: 0.2930, Accuracy:0.891\nIteration: 5455, learning rate: 0.00721, Loss: 0.2101, Accuracy:0.922\nIteration: 5456, learning rate: 0.00721, Loss: 0.2225, Accuracy:0.935\nEpoch: 176, Loss: 0.2362, Accuracy:0.909, Val Loss: 0.3465, Val Accuracy: 0.844\nIteration: 5457, learning rate: 0.00721, Loss: 0.3506, Accuracy:0.859\nIteration: 5458, learning rate: 0.00721, Loss: 0.2432, Accuracy:0.891\nIteration: 5459, learning rate: 0.00721, Loss: 0.2123, Accuracy:0.922\nIteration: 5460, learning rate: 0.00721, Loss: 0.3401, Accuracy:0.844\nIteration: 5461, learning rate: 0.00721, Loss: 0.1589, Accuracy:0.945\nIteration: 5462, learning rate: 0.00721, Loss: 0.2991, Accuracy:0.836\nIteration: 5463, learning rate: 0.00721, Loss: 0.2836, Accuracy:0.891\nIteration: 5464, learning rate: 0.00721, Loss: 0.2036, Accuracy:0.914\nIteration: 5465, learning rate: 0.00721, Loss: 0.2901, Accuracy:0.859\nIteration: 5466, learning rate: 0.00721, Loss: 0.2215, Accuracy:0.930\nIteration: 5467, learning rate: 0.00721, Loss: 0.2920, Accuracy:0.867\nIteration: 5468, learning rate: 0.00721, Loss: 0.2308, Accuracy:0.891\nIteration: 5469, learning rate: 0.00721, Loss: 0.2099, Accuracy:0.914\nIteration: 5470, learning rate: 0.00721, Loss: 0.1903, Accuracy:0.945\nIteration: 5471, learning rate: 0.00721, Loss: 0.2635, Accuracy:0.906\nIteration: 5472, learning rate: 0.00721, Loss: 0.2257, Accuracy:0.898\nIteration: 5473, learning rate: 0.00721, Loss: 0.2650, Accuracy:0.867\nIteration: 5474, learning rate: 0.00721, Loss: 0.3197, Accuracy:0.836\nIteration: 5475, learning rate: 0.00721, Loss: 0.3298, Accuracy:0.875\nIteration: 5476, learning rate: 0.00721, Loss: 0.2734, Accuracy:0.891\nIteration: 5477, learning rate: 0.00721, Loss: 0.2341, Accuracy:0.922\nIteration: 5478, learning rate: 0.00721, Loss: 0.3340, Accuracy:0.852\nIteration: 5479, learning rate: 0.00721, Loss: 0.2418, Accuracy:0.898\nIteration: 5480, learning rate: 0.00721, Loss: 0.2568, Accuracy:0.914\nIteration: 5481, learning rate: 0.00721, Loss: 0.3019, Accuracy:0.898\nIteration: 5482, learning rate: 0.00721, Loss: 0.2372, Accuracy:0.914\nIteration: 5483, learning rate: 0.00720, Loss: 0.2218, Accuracy:0.930\nIteration: 5484, learning rate: 0.00720, Loss: 0.3368, Accuracy:0.859\nIteration: 5485, learning rate: 0.00720, Loss: 0.2711, Accuracy:0.891\nIteration: 5486, learning rate: 0.00720, Loss: 0.3100, Accuracy:0.875\nIteration: 5487, learning rate: 0.00720, Loss: 0.4098, Accuracy:0.871\nEpoch: 177, Loss: 0.2696, Accuracy:0.890, Val Loss: 0.2879, Val Accuracy: 0.883\nIteration: 5488, learning rate: 0.00720, Loss: 0.2310, Accuracy:0.906\nIteration: 5489, learning rate: 0.00720, Loss: 0.2392, Accuracy:0.922\nIteration: 5490, learning rate: 0.00720, Loss: 0.2203, Accuracy:0.906\nIteration: 5491, learning rate: 0.00720, Loss: 0.2216, Accuracy:0.914\nIteration: 5492, learning rate: 0.00720, Loss: 0.1667, Accuracy:0.938\nIteration: 5493, learning rate: 0.00720, Loss: 0.1508, Accuracy:0.953\nIteration: 5494, learning rate: 0.00720, Loss: 0.1833, Accuracy:0.930\nIteration: 5495, learning rate: 0.00720, Loss: 0.1534, Accuracy:0.953\nIteration: 5496, learning rate: 0.00720, Loss: 0.2171, Accuracy:0.914\nIteration: 5497, learning rate: 0.00720, Loss: 0.2566, Accuracy:0.875\nIteration: 5498, learning rate: 0.00720, Loss: 0.2341, Accuracy:0.914\nIteration: 5499, learning rate: 0.00720, Loss: 0.2420, Accuracy:0.891\nIteration: 5500, learning rate: 0.00720, Loss: 0.2919, Accuracy:0.875\nIteration: 5501, learning rate: 0.00720, Loss: 0.1651, Accuracy:0.953\nIteration: 5502, learning rate: 0.00720, Loss: 0.1670, Accuracy:0.922\nIteration: 5503, learning rate: 0.00720, Loss: 0.1503, Accuracy:0.945\nIteration: 5504, learning rate: 0.00720, Loss: 0.2532, Accuracy:0.883\nIteration: 5505, learning rate: 0.00720, Loss: 0.1547, Accuracy:0.930\nIteration: 5506, learning rate: 0.00720, Loss: 0.2664, Accuracy:0.867\nIteration: 5507, learning rate: 0.00720, Loss: 0.2966, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5508, learning rate: 0.00720, Loss: 0.2015, Accuracy:0.930\nIteration: 5509, learning rate: 0.00720, Loss: 0.1960, Accuracy:0.922\nIteration: 5510, learning rate: 0.00720, Loss: 0.2629, Accuracy:0.883\nIteration: 5511, learning rate: 0.00720, Loss: 0.2697, Accuracy:0.914\nIteration: 5512, learning rate: 0.00719, Loss: 0.2687, Accuracy:0.875\nIteration: 5513, learning rate: 0.00719, Loss: 0.2071, Accuracy:0.930\nIteration: 5514, learning rate: 0.00719, Loss: 0.1926, Accuracy:0.945\nIteration: 5515, learning rate: 0.00719, Loss: 0.1605, Accuracy:0.953\nIteration: 5516, learning rate: 0.00719, Loss: 0.2871, Accuracy:0.859\nIteration: 5517, learning rate: 0.00719, Loss: 0.2867, Accuracy:0.883\nIteration: 5518, learning rate: 0.00719, Loss: 0.2317, Accuracy:0.914\nEpoch: 178, Loss: 0.2202, Accuracy:0.913, Val Loss: 0.3145, Val Accuracy: 0.868\nIteration: 5519, learning rate: 0.00719, Loss: 0.2188, Accuracy:0.898\nIteration: 5520, learning rate: 0.00719, Loss: 0.1985, Accuracy:0.883\nIteration: 5521, learning rate: 0.00719, Loss: 0.4410, Accuracy:0.836\nIteration: 5522, learning rate: 0.00719, Loss: 0.2847, Accuracy:0.891\nIteration: 5523, learning rate: 0.00719, Loss: 0.1635, Accuracy:0.930\nIteration: 5524, learning rate: 0.00719, Loss: 0.2205, Accuracy:0.898\nIteration: 5525, learning rate: 0.00719, Loss: 0.1857, Accuracy:0.938\nIteration: 5526, learning rate: 0.00719, Loss: 0.1906, Accuracy:0.914\nIteration: 5527, learning rate: 0.00719, Loss: 0.1547, Accuracy:0.961\nIteration: 5528, learning rate: 0.00719, Loss: 0.1763, Accuracy:0.945\nIteration: 5529, learning rate: 0.00719, Loss: 0.2744, Accuracy:0.891\nIteration: 5530, learning rate: 0.00719, Loss: 0.2088, Accuracy:0.906\nIteration: 5531, learning rate: 0.00719, Loss: 0.2864, Accuracy:0.852\nIteration: 5532, learning rate: 0.00719, Loss: 0.2226, Accuracy:0.922\nIteration: 5533, learning rate: 0.00719, Loss: 0.2699, Accuracy:0.883\nIteration: 5534, learning rate: 0.00719, Loss: 0.2081, Accuracy:0.922\nIteration: 5535, learning rate: 0.00719, Loss: 0.2530, Accuracy:0.898\nIteration: 5536, learning rate: 0.00719, Loss: 0.3166, Accuracy:0.859\nIteration: 5537, learning rate: 0.00719, Loss: 0.2182, Accuracy:0.891\nIteration: 5538, learning rate: 0.00719, Loss: 0.2196, Accuracy:0.883\nIteration: 5539, learning rate: 0.00719, Loss: 0.2666, Accuracy:0.898\nIteration: 5540, learning rate: 0.00719, Loss: 0.2268, Accuracy:0.930\nIteration: 5541, learning rate: 0.00718, Loss: 0.2138, Accuracy:0.898\nIteration: 5542, learning rate: 0.00718, Loss: 0.3082, Accuracy:0.883\nIteration: 5543, learning rate: 0.00718, Loss: 0.2172, Accuracy:0.922\nIteration: 5544, learning rate: 0.00718, Loss: 0.2692, Accuracy:0.875\nIteration: 5545, learning rate: 0.00718, Loss: 0.1912, Accuracy:0.953\nIteration: 5546, learning rate: 0.00718, Loss: 0.2327, Accuracy:0.883\nIteration: 5547, learning rate: 0.00718, Loss: 0.1726, Accuracy:0.945\nIteration: 5548, learning rate: 0.00718, Loss: 0.2738, Accuracy:0.875\nIteration: 5549, learning rate: 0.00718, Loss: 0.3037, Accuracy:0.860\nEpoch: 179, Loss: 0.2383, Accuracy:0.901, Val Loss: 0.3054, Val Accuracy: 0.864\nIteration: 5550, learning rate: 0.00718, Loss: 0.2317, Accuracy:0.898\nIteration: 5551, learning rate: 0.00718, Loss: 0.2801, Accuracy:0.883\nIteration: 5552, learning rate: 0.00718, Loss: 0.2186, Accuracy:0.914\nIteration: 5553, learning rate: 0.00718, Loss: 0.3517, Accuracy:0.836\nIteration: 5554, learning rate: 0.00718, Loss: 0.2432, Accuracy:0.906\nIteration: 5555, learning rate: 0.00718, Loss: 0.2571, Accuracy:0.867\nIteration: 5556, learning rate: 0.00718, Loss: 0.2351, Accuracy:0.891\nIteration: 5557, learning rate: 0.00718, Loss: 0.2547, Accuracy:0.891\nIteration: 5558, learning rate: 0.00718, Loss: 0.2906, Accuracy:0.875\nIteration: 5559, learning rate: 0.00718, Loss: 0.2272, Accuracy:0.883\nIteration: 5560, learning rate: 0.00718, Loss: 0.1833, Accuracy:0.922\nIteration: 5561, learning rate: 0.00718, Loss: 0.1986, Accuracy:0.930\nIteration: 5562, learning rate: 0.00718, Loss: 0.4240, Accuracy:0.852\nIteration: 5563, learning rate: 0.00718, Loss: 0.2433, Accuracy:0.883\nIteration: 5564, learning rate: 0.00718, Loss: 0.2631, Accuracy:0.906\nIteration: 5565, learning rate: 0.00718, Loss: 0.1912, Accuracy:0.922\nIteration: 5566, learning rate: 0.00718, Loss: 0.2144, Accuracy:0.914\nIteration: 5567, learning rate: 0.00718, Loss: 0.2774, Accuracy:0.891\nIteration: 5568, learning rate: 0.00718, Loss: 0.2476, Accuracy:0.914\nIteration: 5569, learning rate: 0.00718, Loss: 0.2211, Accuracy:0.938\nIteration: 5570, learning rate: 0.00717, Loss: 0.3100, Accuracy:0.836\nIteration: 5571, learning rate: 0.00717, Loss: 0.2156, Accuracy:0.914\nIteration: 5572, learning rate: 0.00717, Loss: 0.2253, Accuracy:0.906\nIteration: 5573, learning rate: 0.00717, Loss: 0.2073, Accuracy:0.914\nIteration: 5574, learning rate: 0.00717, Loss: 0.2264, Accuracy:0.883\nIteration: 5575, learning rate: 0.00717, Loss: 0.2733, Accuracy:0.906\nIteration: 5576, learning rate: 0.00717, Loss: 0.2622, Accuracy:0.898\nIteration: 5577, learning rate: 0.00717, Loss: 0.1735, Accuracy:0.945\nIteration: 5578, learning rate: 0.00717, Loss: 0.1585, Accuracy:0.953\nIteration: 5579, learning rate: 0.00717, Loss: 0.2827, Accuracy:0.906\nIteration: 5580, learning rate: 0.00717, Loss: 0.1655, Accuracy:0.946\nEpoch: 180, Loss: 0.2437, Accuracy:0.901, Val Loss: 0.3222, Val Accuracy: 0.856\nIteration: 5581, learning rate: 0.00717, Loss: 0.1294, Accuracy:0.969\nIteration: 5582, learning rate: 0.00717, Loss: 0.2158, Accuracy:0.930\nIteration: 5583, learning rate: 0.00717, Loss: 0.2524, Accuracy:0.898\nIteration: 5584, learning rate: 0.00717, Loss: 0.1789, Accuracy:0.938\nIteration: 5585, learning rate: 0.00717, Loss: 0.1815, Accuracy:0.938\nIteration: 5586, learning rate: 0.00717, Loss: 0.3016, Accuracy:0.836\nIteration: 5587, learning rate: 0.00717, Loss: 0.3062, Accuracy:0.844\nIteration: 5588, learning rate: 0.00717, Loss: 0.1867, Accuracy:0.906\nIteration: 5589, learning rate: 0.00717, Loss: 0.2661, Accuracy:0.875\nIteration: 5590, learning rate: 0.00717, Loss: 0.2339, Accuracy:0.906\nIteration: 5591, learning rate: 0.00717, Loss: 0.2362, Accuracy:0.883\nIteration: 5592, learning rate: 0.00717, Loss: 0.2473, Accuracy:0.922\nIteration: 5593, learning rate: 0.00717, Loss: 0.2413, Accuracy:0.883\nIteration: 5594, learning rate: 0.00717, Loss: 0.2368, Accuracy:0.891\nIteration: 5595, learning rate: 0.00717, Loss: 0.1990, Accuracy:0.914\nIteration: 5596, learning rate: 0.00717, Loss: 0.3169, Accuracy:0.867\nIteration: 5597, learning rate: 0.00717, Loss: 0.2476, Accuracy:0.883\nIteration: 5598, learning rate: 0.00717, Loss: 0.3118, Accuracy:0.828\nIteration: 5599, learning rate: 0.00716, Loss: 0.2390, Accuracy:0.875\nIteration: 5600, learning rate: 0.00716, Loss: 0.2825, Accuracy:0.883\nIteration: 5601, learning rate: 0.00716, Loss: 0.3545, Accuracy:0.867\nIteration: 5602, learning rate: 0.00716, Loss: 0.1383, Accuracy:0.953\nIteration: 5603, learning rate: 0.00716, Loss: 0.2013, Accuracy:0.914\nIteration: 5604, learning rate: 0.00716, Loss: 0.2728, Accuracy:0.898\nIteration: 5605, learning rate: 0.00716, Loss: 0.1762, Accuracy:0.938\nIteration: 5606, learning rate: 0.00716, Loss: 0.1757, Accuracy:0.953\nIteration: 5607, learning rate: 0.00716, Loss: 0.1875, Accuracy:0.930\nIteration: 5608, learning rate: 0.00716, Loss: 0.2127, Accuracy:0.922\nIteration: 5609, learning rate: 0.00716, Loss: 0.2633, Accuracy:0.875\nIteration: 5610, learning rate: 0.00716, Loss: 0.2300, Accuracy:0.906\nIteration: 5611, learning rate: 0.00716, Loss: 0.1470, Accuracy:0.935\nEpoch: 181, Loss: 0.2313, Accuracy:0.902, Val Loss: 0.3315, Val Accuracy: 0.852\nIteration: 5612, learning rate: 0.00716, Loss: 0.2101, Accuracy:0.930\nIteration: 5613, learning rate: 0.00716, Loss: 0.1741, Accuracy:0.945\nIteration: 5614, learning rate: 0.00716, Loss: 0.2181, Accuracy:0.906\nIteration: 5615, learning rate: 0.00716, Loss: 0.1835, Accuracy:0.922\nIteration: 5616, learning rate: 0.00716, Loss: 0.2272, Accuracy:0.922\nIteration: 5617, learning rate: 0.00716, Loss: 0.3218, Accuracy:0.859\nIteration: 5618, learning rate: 0.00716, Loss: 0.1687, Accuracy:0.938\nIteration: 5619, learning rate: 0.00716, Loss: 0.3142, Accuracy:0.867\nIteration: 5620, learning rate: 0.00716, Loss: 0.1319, Accuracy:0.945\nIteration: 5621, learning rate: 0.00716, Loss: 0.2327, Accuracy:0.914\nIteration: 5622, learning rate: 0.00716, Loss: 0.2717, Accuracy:0.883\nIteration: 5623, learning rate: 0.00716, Loss: 0.3054, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5624, learning rate: 0.00716, Loss: 0.1544, Accuracy:0.922\nIteration: 5625, learning rate: 0.00716, Loss: 0.2756, Accuracy:0.875\nIteration: 5626, learning rate: 0.00716, Loss: 0.1887, Accuracy:0.922\nIteration: 5627, learning rate: 0.00716, Loss: 0.3093, Accuracy:0.852\nIteration: 5628, learning rate: 0.00715, Loss: 0.2589, Accuracy:0.875\nIteration: 5629, learning rate: 0.00715, Loss: 0.2645, Accuracy:0.914\nIteration: 5630, learning rate: 0.00715, Loss: 0.2601, Accuracy:0.898\nIteration: 5631, learning rate: 0.00715, Loss: 0.3410, Accuracy:0.852\nIteration: 5632, learning rate: 0.00715, Loss: 0.2930, Accuracy:0.898\nIteration: 5633, learning rate: 0.00715, Loss: 0.2441, Accuracy:0.906\nIteration: 5634, learning rate: 0.00715, Loss: 0.2271, Accuracy:0.914\nIteration: 5635, learning rate: 0.00715, Loss: 0.2450, Accuracy:0.891\nIteration: 5636, learning rate: 0.00715, Loss: 0.2060, Accuracy:0.930\nIteration: 5637, learning rate: 0.00715, Loss: 0.2544, Accuracy:0.914\nIteration: 5638, learning rate: 0.00715, Loss: 0.2536, Accuracy:0.914\nIteration: 5639, learning rate: 0.00715, Loss: 0.2385, Accuracy:0.906\nIteration: 5640, learning rate: 0.00715, Loss: 0.2254, Accuracy:0.891\nIteration: 5641, learning rate: 0.00715, Loss: 0.1987, Accuracy:0.914\nIteration: 5642, learning rate: 0.00715, Loss: 0.2612, Accuracy:0.849\nEpoch: 182, Loss: 0.2406, Accuracy:0.902, Val Loss: 0.3100, Val Accuracy: 0.868\nIteration: 5643, learning rate: 0.00715, Loss: 0.2952, Accuracy:0.875\nIteration: 5644, learning rate: 0.00715, Loss: 0.2528, Accuracy:0.898\nIteration: 5645, learning rate: 0.00715, Loss: 0.1711, Accuracy:0.938\nIteration: 5646, learning rate: 0.00715, Loss: 0.1770, Accuracy:0.914\nIteration: 5647, learning rate: 0.00715, Loss: 0.2126, Accuracy:0.914\nIteration: 5648, learning rate: 0.00715, Loss: 0.1768, Accuracy:0.930\nIteration: 5649, learning rate: 0.00715, Loss: 0.2024, Accuracy:0.922\nIteration: 5650, learning rate: 0.00715, Loss: 0.2394, Accuracy:0.891\nIteration: 5651, learning rate: 0.00715, Loss: 0.2099, Accuracy:0.930\nIteration: 5652, learning rate: 0.00715, Loss: 0.1697, Accuracy:0.930\nIteration: 5653, learning rate: 0.00715, Loss: 0.2053, Accuracy:0.938\nIteration: 5654, learning rate: 0.00715, Loss: 0.1985, Accuracy:0.914\nIteration: 5655, learning rate: 0.00715, Loss: 0.2377, Accuracy:0.914\nIteration: 5656, learning rate: 0.00715, Loss: 0.2360, Accuracy:0.906\nIteration: 5657, learning rate: 0.00714, Loss: 0.2927, Accuracy:0.875\nIteration: 5658, learning rate: 0.00714, Loss: 0.2379, Accuracy:0.898\nIteration: 5659, learning rate: 0.00714, Loss: 0.2766, Accuracy:0.883\nIteration: 5660, learning rate: 0.00714, Loss: 0.2641, Accuracy:0.883\nIteration: 5661, learning rate: 0.00714, Loss: 0.3218, Accuracy:0.852\nIteration: 5662, learning rate: 0.00714, Loss: 0.3171, Accuracy:0.859\nIteration: 5663, learning rate: 0.00714, Loss: 0.2269, Accuracy:0.914\nIteration: 5664, learning rate: 0.00714, Loss: 0.3076, Accuracy:0.875\nIteration: 5665, learning rate: 0.00714, Loss: 0.3319, Accuracy:0.852\nIteration: 5666, learning rate: 0.00714, Loss: 0.2192, Accuracy:0.891\nIteration: 5667, learning rate: 0.00714, Loss: 0.2533, Accuracy:0.891\nIteration: 5668, learning rate: 0.00714, Loss: 0.2791, Accuracy:0.906\nIteration: 5669, learning rate: 0.00714, Loss: 0.2110, Accuracy:0.898\nIteration: 5670, learning rate: 0.00714, Loss: 0.1925, Accuracy:0.953\nIteration: 5671, learning rate: 0.00714, Loss: 0.2230, Accuracy:0.914\nIteration: 5672, learning rate: 0.00714, Loss: 0.1746, Accuracy:0.922\nIteration: 5673, learning rate: 0.00714, Loss: 0.3070, Accuracy:0.871\nEpoch: 183, Loss: 0.2394, Accuracy:0.902, Val Loss: 0.3055, Val Accuracy: 0.859\nIteration: 5674, learning rate: 0.00714, Loss: 0.2355, Accuracy:0.875\nIteration: 5675, learning rate: 0.00714, Loss: 0.2009, Accuracy:0.914\nIteration: 5676, learning rate: 0.00714, Loss: 0.1840, Accuracy:0.922\nIteration: 5677, learning rate: 0.00714, Loss: 0.2998, Accuracy:0.844\nIteration: 5678, learning rate: 0.00714, Loss: 0.2916, Accuracy:0.883\nIteration: 5679, learning rate: 0.00714, Loss: 0.2950, Accuracy:0.852\nIteration: 5680, learning rate: 0.00714, Loss: 0.3027, Accuracy:0.875\nIteration: 5681, learning rate: 0.00714, Loss: 0.2148, Accuracy:0.891\nIteration: 5682, learning rate: 0.00714, Loss: 0.2043, Accuracy:0.922\nIteration: 5683, learning rate: 0.00714, Loss: 0.2719, Accuracy:0.883\nIteration: 5684, learning rate: 0.00714, Loss: 0.2387, Accuracy:0.875\nIteration: 5685, learning rate: 0.00714, Loss: 0.2956, Accuracy:0.891\nIteration: 5686, learning rate: 0.00713, Loss: 0.2555, Accuracy:0.891\nIteration: 5687, learning rate: 0.00713, Loss: 0.2022, Accuracy:0.930\nIteration: 5688, learning rate: 0.00713, Loss: 0.1351, Accuracy:0.969\nIteration: 5689, learning rate: 0.00713, Loss: 0.2259, Accuracy:0.922\nIteration: 5690, learning rate: 0.00713, Loss: 0.2553, Accuracy:0.891\nIteration: 5691, learning rate: 0.00713, Loss: 0.1936, Accuracy:0.930\nIteration: 5692, learning rate: 0.00713, Loss: 0.2421, Accuracy:0.922\nIteration: 5693, learning rate: 0.00713, Loss: 0.1969, Accuracy:0.906\nIteration: 5694, learning rate: 0.00713, Loss: 0.2225, Accuracy:0.906\nIteration: 5695, learning rate: 0.00713, Loss: 0.2851, Accuracy:0.875\nIteration: 5696, learning rate: 0.00713, Loss: 0.3086, Accuracy:0.836\nIteration: 5697, learning rate: 0.00713, Loss: 0.2314, Accuracy:0.898\nIteration: 5698, learning rate: 0.00713, Loss: 0.3093, Accuracy:0.859\nIteration: 5699, learning rate: 0.00713, Loss: 0.2215, Accuracy:0.930\nIteration: 5700, learning rate: 0.00713, Loss: 0.1843, Accuracy:0.930\nIteration: 5701, learning rate: 0.00713, Loss: 0.2737, Accuracy:0.867\nIteration: 5702, learning rate: 0.00713, Loss: 0.1494, Accuracy:0.945\nIteration: 5703, learning rate: 0.00713, Loss: 0.2011, Accuracy:0.922\nIteration: 5704, learning rate: 0.00713, Loss: 0.1642, Accuracy:0.946\nEpoch: 184, Loss: 0.2352, Accuracy:0.900, Val Loss: 0.3238, Val Accuracy: 0.852\nIteration: 5705, learning rate: 0.00713, Loss: 0.2796, Accuracy:0.883\nIteration: 5706, learning rate: 0.00713, Loss: 0.2037, Accuracy:0.906\nIteration: 5707, learning rate: 0.00713, Loss: 0.1758, Accuracy:0.922\nIteration: 5708, learning rate: 0.00713, Loss: 0.2612, Accuracy:0.883\nIteration: 5709, learning rate: 0.00713, Loss: 0.2851, Accuracy:0.891\nIteration: 5710, learning rate: 0.00713, Loss: 0.1845, Accuracy:0.930\nIteration: 5711, learning rate: 0.00713, Loss: 0.1824, Accuracy:0.938\nIteration: 5712, learning rate: 0.00713, Loss: 0.3248, Accuracy:0.867\nIteration: 5713, learning rate: 0.00713, Loss: 0.3340, Accuracy:0.867\nIteration: 5714, learning rate: 0.00713, Loss: 0.2541, Accuracy:0.898\nIteration: 5715, learning rate: 0.00713, Loss: 0.2100, Accuracy:0.883\nIteration: 5716, learning rate: 0.00712, Loss: 0.1973, Accuracy:0.930\nIteration: 5717, learning rate: 0.00712, Loss: 0.1709, Accuracy:0.930\nIteration: 5718, learning rate: 0.00712, Loss: 0.2461, Accuracy:0.898\nIteration: 5719, learning rate: 0.00712, Loss: 0.1885, Accuracy:0.922\nIteration: 5720, learning rate: 0.00712, Loss: 0.2854, Accuracy:0.883\nIteration: 5721, learning rate: 0.00712, Loss: 0.1576, Accuracy:0.953\nIteration: 5722, learning rate: 0.00712, Loss: 0.2259, Accuracy:0.898\nIteration: 5723, learning rate: 0.00712, Loss: 0.2009, Accuracy:0.938\nIteration: 5724, learning rate: 0.00712, Loss: 0.2628, Accuracy:0.922\nIteration: 5725, learning rate: 0.00712, Loss: 0.2441, Accuracy:0.906\nIteration: 5726, learning rate: 0.00712, Loss: 0.3115, Accuracy:0.859\nIteration: 5727, learning rate: 0.00712, Loss: 0.1931, Accuracy:0.930\nIteration: 5728, learning rate: 0.00712, Loss: 0.2176, Accuracy:0.906\nIteration: 5729, learning rate: 0.00712, Loss: 0.2966, Accuracy:0.867\nIteration: 5730, learning rate: 0.00712, Loss: 0.2086, Accuracy:0.922\nIteration: 5731, learning rate: 0.00712, Loss: 0.1720, Accuracy:0.938\nIteration: 5732, learning rate: 0.00712, Loss: 0.1556, Accuracy:0.945\nIteration: 5733, learning rate: 0.00712, Loss: 0.2280, Accuracy:0.906\nIteration: 5734, learning rate: 0.00712, Loss: 0.2604, Accuracy:0.875\nIteration: 5735, learning rate: 0.00712, Loss: 0.2961, Accuracy:0.871\nEpoch: 185, Loss: 0.2327, Accuracy:0.905, Val Loss: 0.3303, Val Accuracy: 0.863\nIteration: 5736, learning rate: 0.00712, Loss: 0.2324, Accuracy:0.930\nIteration: 5737, learning rate: 0.00712, Loss: 0.2513, Accuracy:0.891\nIteration: 5738, learning rate: 0.00712, Loss: 0.1955, Accuracy:0.914\nIteration: 5739, learning rate: 0.00712, Loss: 0.2129, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5740, learning rate: 0.00712, Loss: 0.2043, Accuracy:0.922\nIteration: 5741, learning rate: 0.00712, Loss: 0.2694, Accuracy:0.914\nIteration: 5742, learning rate: 0.00712, Loss: 0.2174, Accuracy:0.891\nIteration: 5743, learning rate: 0.00712, Loss: 0.3393, Accuracy:0.852\nIteration: 5744, learning rate: 0.00712, Loss: 0.2313, Accuracy:0.914\nIteration: 5745, learning rate: 0.00711, Loss: 0.2131, Accuracy:0.906\nIteration: 5746, learning rate: 0.00711, Loss: 0.2890, Accuracy:0.891\nIteration: 5747, learning rate: 0.00711, Loss: 0.2210, Accuracy:0.898\nIteration: 5748, learning rate: 0.00711, Loss: 0.2011, Accuracy:0.898\nIteration: 5749, learning rate: 0.00711, Loss: 0.2037, Accuracy:0.922\nIteration: 5750, learning rate: 0.00711, Loss: 0.2735, Accuracy:0.891\nIteration: 5751, learning rate: 0.00711, Loss: 0.2542, Accuracy:0.891\nIteration: 5752, learning rate: 0.00711, Loss: 0.1701, Accuracy:0.930\nIteration: 5753, learning rate: 0.00711, Loss: 0.2001, Accuracy:0.922\nIteration: 5754, learning rate: 0.00711, Loss: 0.2297, Accuracy:0.898\nIteration: 5755, learning rate: 0.00711, Loss: 0.2483, Accuracy:0.883\nIteration: 5756, learning rate: 0.00711, Loss: 0.3466, Accuracy:0.836\nIteration: 5757, learning rate: 0.00711, Loss: 0.2498, Accuracy:0.906\nIteration: 5758, learning rate: 0.00711, Loss: 0.1816, Accuracy:0.938\nIteration: 5759, learning rate: 0.00711, Loss: 0.1997, Accuracy:0.914\nIteration: 5760, learning rate: 0.00711, Loss: 0.2635, Accuracy:0.891\nIteration: 5761, learning rate: 0.00711, Loss: 0.1950, Accuracy:0.945\nIteration: 5762, learning rate: 0.00711, Loss: 0.2423, Accuracy:0.883\nIteration: 5763, learning rate: 0.00711, Loss: 0.3133, Accuracy:0.875\nIteration: 5764, learning rate: 0.00711, Loss: 0.2342, Accuracy:0.898\nIteration: 5765, learning rate: 0.00711, Loss: 0.2808, Accuracy:0.898\nIteration: 5766, learning rate: 0.00711, Loss: 0.3093, Accuracy:0.871\nEpoch: 186, Loss: 0.2411, Accuracy:0.900, Val Loss: 0.3101, Val Accuracy: 0.869\nIteration: 5767, learning rate: 0.00711, Loss: 0.2419, Accuracy:0.906\nIteration: 5768, learning rate: 0.00711, Loss: 0.2144, Accuracy:0.922\nIteration: 5769, learning rate: 0.00711, Loss: 0.2136, Accuracy:0.938\nIteration: 5770, learning rate: 0.00711, Loss: 0.2486, Accuracy:0.898\nIteration: 5771, learning rate: 0.00711, Loss: 0.2467, Accuracy:0.867\nIteration: 5772, learning rate: 0.00711, Loss: 0.2367, Accuracy:0.898\nIteration: 5773, learning rate: 0.00711, Loss: 0.1985, Accuracy:0.906\nIteration: 5774, learning rate: 0.00711, Loss: 0.2404, Accuracy:0.922\nIteration: 5775, learning rate: 0.00710, Loss: 0.2121, Accuracy:0.898\nIteration: 5776, learning rate: 0.00710, Loss: 0.2795, Accuracy:0.875\nIteration: 5777, learning rate: 0.00710, Loss: 0.2483, Accuracy:0.898\nIteration: 5778, learning rate: 0.00710, Loss: 0.2284, Accuracy:0.922\nIteration: 5779, learning rate: 0.00710, Loss: 0.2619, Accuracy:0.906\nIteration: 5780, learning rate: 0.00710, Loss: 0.2652, Accuracy:0.898\nIteration: 5781, learning rate: 0.00710, Loss: 0.2386, Accuracy:0.883\nIteration: 5782, learning rate: 0.00710, Loss: 0.2468, Accuracy:0.914\nIteration: 5783, learning rate: 0.00710, Loss: 0.2945, Accuracy:0.867\nIteration: 5784, learning rate: 0.00710, Loss: 0.1394, Accuracy:0.969\nIteration: 5785, learning rate: 0.00710, Loss: 0.1724, Accuracy:0.953\nIteration: 5786, learning rate: 0.00710, Loss: 0.2182, Accuracy:0.906\nIteration: 5787, learning rate: 0.00710, Loss: 0.2355, Accuracy:0.914\nIteration: 5788, learning rate: 0.00710, Loss: 0.1695, Accuracy:0.945\nIteration: 5789, learning rate: 0.00710, Loss: 0.2249, Accuracy:0.914\nIteration: 5790, learning rate: 0.00710, Loss: 0.2150, Accuracy:0.914\nIteration: 5791, learning rate: 0.00710, Loss: 0.1788, Accuracy:0.945\nIteration: 5792, learning rate: 0.00710, Loss: 0.2504, Accuracy:0.906\nIteration: 5793, learning rate: 0.00710, Loss: 0.1476, Accuracy:0.938\nIteration: 5794, learning rate: 0.00710, Loss: 0.2817, Accuracy:0.844\nIteration: 5795, learning rate: 0.00710, Loss: 0.2235, Accuracy:0.914\nIteration: 5796, learning rate: 0.00710, Loss: 0.2534, Accuracy:0.883\nIteration: 5797, learning rate: 0.00710, Loss: 0.3314, Accuracy:0.871\nEpoch: 187, Loss: 0.2309, Accuracy:0.908, Val Loss: 0.3225, Val Accuracy: 0.849\nIteration: 5798, learning rate: 0.00710, Loss: 0.2487, Accuracy:0.898\nIteration: 5799, learning rate: 0.00710, Loss: 0.2376, Accuracy:0.906\nIteration: 5800, learning rate: 0.00710, Loss: 0.2042, Accuracy:0.891\nIteration: 5801, learning rate: 0.00710, Loss: 0.2107, Accuracy:0.867\nIteration: 5802, learning rate: 0.00710, Loss: 0.2122, Accuracy:0.922\nIteration: 5803, learning rate: 0.00710, Loss: 0.2820, Accuracy:0.852\nIteration: 5804, learning rate: 0.00709, Loss: 0.2088, Accuracy:0.930\nIteration: 5805, learning rate: 0.00709, Loss: 0.2230, Accuracy:0.898\nIteration: 5806, learning rate: 0.00709, Loss: 0.2247, Accuracy:0.914\nIteration: 5807, learning rate: 0.00709, Loss: 0.2220, Accuracy:0.914\nIteration: 5808, learning rate: 0.00709, Loss: 0.2156, Accuracy:0.922\nIteration: 5809, learning rate: 0.00709, Loss: 0.2814, Accuracy:0.867\nIteration: 5810, learning rate: 0.00709, Loss: 0.2665, Accuracy:0.898\nIteration: 5811, learning rate: 0.00709, Loss: 0.2225, Accuracy:0.922\nIteration: 5812, learning rate: 0.00709, Loss: 0.2643, Accuracy:0.883\nIteration: 5813, learning rate: 0.00709, Loss: 0.2778, Accuracy:0.875\nIteration: 5814, learning rate: 0.00709, Loss: 0.1834, Accuracy:0.922\nIteration: 5815, learning rate: 0.00709, Loss: 0.2457, Accuracy:0.914\nIteration: 5816, learning rate: 0.00709, Loss: 0.3320, Accuracy:0.852\nIteration: 5817, learning rate: 0.00709, Loss: 0.1384, Accuracy:0.953\nIteration: 5818, learning rate: 0.00709, Loss: 0.2905, Accuracy:0.867\nIteration: 5819, learning rate: 0.00709, Loss: 0.2355, Accuracy:0.898\nIteration: 5820, learning rate: 0.00709, Loss: 0.2470, Accuracy:0.891\nIteration: 5821, learning rate: 0.00709, Loss: 0.2053, Accuracy:0.922\nIteration: 5822, learning rate: 0.00709, Loss: 0.2239, Accuracy:0.914\nIteration: 5823, learning rate: 0.00709, Loss: 0.2879, Accuracy:0.883\nIteration: 5824, learning rate: 0.00709, Loss: 0.1811, Accuracy:0.914\nIteration: 5825, learning rate: 0.00709, Loss: 0.3094, Accuracy:0.867\nIteration: 5826, learning rate: 0.00709, Loss: 0.2531, Accuracy:0.898\nIteration: 5827, learning rate: 0.00709, Loss: 0.2536, Accuracy:0.891\nIteration: 5828, learning rate: 0.00709, Loss: 0.2023, Accuracy:0.914\nEpoch: 188, Loss: 0.2384, Accuracy:0.899, Val Loss: 0.2900, Val Accuracy: 0.872\nIteration: 5829, learning rate: 0.00709, Loss: 0.2963, Accuracy:0.883\nIteration: 5830, learning rate: 0.00709, Loss: 0.2562, Accuracy:0.891\nIteration: 5831, learning rate: 0.00709, Loss: 0.1981, Accuracy:0.930\nIteration: 5832, learning rate: 0.00709, Loss: 0.3240, Accuracy:0.859\nIteration: 5833, learning rate: 0.00709, Loss: 0.2089, Accuracy:0.906\nIteration: 5834, learning rate: 0.00708, Loss: 0.2673, Accuracy:0.891\nIteration: 5835, learning rate: 0.00708, Loss: 0.2263, Accuracy:0.906\nIteration: 5836, learning rate: 0.00708, Loss: 0.1741, Accuracy:0.930\nIteration: 5837, learning rate: 0.00708, Loss: 0.2238, Accuracy:0.906\nIteration: 5838, learning rate: 0.00708, Loss: 0.2483, Accuracy:0.922\nIteration: 5839, learning rate: 0.00708, Loss: 0.2039, Accuracy:0.914\nIteration: 5840, learning rate: 0.00708, Loss: 0.3775, Accuracy:0.844\nIteration: 5841, learning rate: 0.00708, Loss: 0.1799, Accuracy:0.914\nIteration: 5842, learning rate: 0.00708, Loss: 0.2870, Accuracy:0.867\nIteration: 5843, learning rate: 0.00708, Loss: 0.2937, Accuracy:0.844\nIteration: 5844, learning rate: 0.00708, Loss: 0.2355, Accuracy:0.898\nIteration: 5845, learning rate: 0.00708, Loss: 0.2290, Accuracy:0.906\nIteration: 5846, learning rate: 0.00708, Loss: 0.2305, Accuracy:0.875\nIteration: 5847, learning rate: 0.00708, Loss: 0.2062, Accuracy:0.898\nIteration: 5848, learning rate: 0.00708, Loss: 0.2442, Accuracy:0.891\nIteration: 5849, learning rate: 0.00708, Loss: 0.2467, Accuracy:0.898\nIteration: 5850, learning rate: 0.00708, Loss: 0.2011, Accuracy:0.922\nIteration: 5851, learning rate: 0.00708, Loss: 0.2458, Accuracy:0.883\nIteration: 5852, learning rate: 0.00708, Loss: 0.2353, Accuracy:0.906\nIteration: 5853, learning rate: 0.00708, Loss: 0.2112, Accuracy:0.930\nIteration: 5854, learning rate: 0.00708, Loss: 0.1555, Accuracy:0.930\nIteration: 5855, learning rate: 0.00708, Loss: 0.2421, Accuracy:0.922\nIteration: 5856, learning rate: 0.00708, Loss: 0.1899, Accuracy:0.930\nIteration: 5857, learning rate: 0.00708, Loss: 0.2074, Accuracy:0.922\nIteration: 5858, learning rate: 0.00708, Loss: 0.2509, Accuracy:0.898\nIteration: 5859, learning rate: 0.00708, Loss: 0.1691, Accuracy:0.935\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 189, Loss: 0.2344, Accuracy:0.902, Val Loss: 0.2777, Val Accuracy: 0.872\nIteration: 5860, learning rate: 0.00708, Loss: 0.2133, Accuracy:0.914\nIteration: 5861, learning rate: 0.00708, Loss: 0.1891, Accuracy:0.906\nIteration: 5862, learning rate: 0.00708, Loss: 0.2690, Accuracy:0.875\nIteration: 5863, learning rate: 0.00708, Loss: 0.2623, Accuracy:0.867\nIteration: 5864, learning rate: 0.00707, Loss: 0.2620, Accuracy:0.906\nIteration: 5865, learning rate: 0.00707, Loss: 0.3142, Accuracy:0.875\nIteration: 5866, learning rate: 0.00707, Loss: 0.2453, Accuracy:0.898\nIteration: 5867, learning rate: 0.00707, Loss: 0.2236, Accuracy:0.938\nIteration: 5868, learning rate: 0.00707, Loss: 0.2466, Accuracy:0.898\nIteration: 5869, learning rate: 0.00707, Loss: 0.2410, Accuracy:0.898\nIteration: 5870, learning rate: 0.00707, Loss: 0.2502, Accuracy:0.898\nIteration: 5871, learning rate: 0.00707, Loss: 0.2438, Accuracy:0.906\nIteration: 5872, learning rate: 0.00707, Loss: 0.2585, Accuracy:0.875\nIteration: 5873, learning rate: 0.00707, Loss: 0.2054, Accuracy:0.906\nIteration: 5874, learning rate: 0.00707, Loss: 0.1792, Accuracy:0.922\nIteration: 5875, learning rate: 0.00707, Loss: 0.2374, Accuracy:0.891\nIteration: 5876, learning rate: 0.00707, Loss: 0.2520, Accuracy:0.906\nIteration: 5877, learning rate: 0.00707, Loss: 0.1867, Accuracy:0.922\nIteration: 5878, learning rate: 0.00707, Loss: 0.2205, Accuracy:0.922\nIteration: 5879, learning rate: 0.00707, Loss: 0.1580, Accuracy:0.945\nIteration: 5880, learning rate: 0.00707, Loss: 0.2259, Accuracy:0.891\nIteration: 5881, learning rate: 0.00707, Loss: 0.2244, Accuracy:0.883\nIteration: 5882, learning rate: 0.00707, Loss: 0.2219, Accuracy:0.891\nIteration: 5883, learning rate: 0.00707, Loss: 0.2460, Accuracy:0.898\nIteration: 5884, learning rate: 0.00707, Loss: 0.2538, Accuracy:0.891\nIteration: 5885, learning rate: 0.00707, Loss: 0.1712, Accuracy:0.945\nIteration: 5886, learning rate: 0.00707, Loss: 0.1866, Accuracy:0.930\nIteration: 5887, learning rate: 0.00707, Loss: 0.1854, Accuracy:0.938\nIteration: 5888, learning rate: 0.00707, Loss: 0.1912, Accuracy:0.922\nIteration: 5889, learning rate: 0.00707, Loss: 0.1516, Accuracy:0.945\nIteration: 5890, learning rate: 0.00707, Loss: 0.2005, Accuracy:0.946\nEpoch: 190, Loss: 0.2231, Accuracy:0.908, Val Loss: 0.3008, Val Accuracy: 0.873\nIteration: 5891, learning rate: 0.00707, Loss: 0.2112, Accuracy:0.906\nIteration: 5892, learning rate: 0.00707, Loss: 0.1777, Accuracy:0.938\nIteration: 5893, learning rate: 0.00707, Loss: 0.2411, Accuracy:0.891\nIteration: 5894, learning rate: 0.00706, Loss: 0.2722, Accuracy:0.883\nIteration: 5895, learning rate: 0.00706, Loss: 0.2927, Accuracy:0.859\nIteration: 5896, learning rate: 0.00706, Loss: 0.1830, Accuracy:0.922\nIteration: 5897, learning rate: 0.00706, Loss: 0.1802, Accuracy:0.930\nIteration: 5898, learning rate: 0.00706, Loss: 0.2090, Accuracy:0.922\nIteration: 5899, learning rate: 0.00706, Loss: 0.2167, Accuracy:0.922\nIteration: 5900, learning rate: 0.00706, Loss: 0.1748, Accuracy:0.930\nIteration: 5901, learning rate: 0.00706, Loss: 0.1753, Accuracy:0.945\nIteration: 5902, learning rate: 0.00706, Loss: 0.2178, Accuracy:0.898\nIteration: 5903, learning rate: 0.00706, Loss: 0.1742, Accuracy:0.914\nIteration: 5904, learning rate: 0.00706, Loss: 0.2171, Accuracy:0.922\nIteration: 5905, learning rate: 0.00706, Loss: 0.1997, Accuracy:0.906\nIteration: 5906, learning rate: 0.00706, Loss: 0.2382, Accuracy:0.883\nIteration: 5907, learning rate: 0.00706, Loss: 0.3116, Accuracy:0.891\nIteration: 5908, learning rate: 0.00706, Loss: 0.2062, Accuracy:0.914\nIteration: 5909, learning rate: 0.00706, Loss: 0.2428, Accuracy:0.914\nIteration: 5910, learning rate: 0.00706, Loss: 0.2871, Accuracy:0.875\nIteration: 5911, learning rate: 0.00706, Loss: 0.2618, Accuracy:0.891\nIteration: 5912, learning rate: 0.00706, Loss: 0.2640, Accuracy:0.891\nIteration: 5913, learning rate: 0.00706, Loss: 0.1762, Accuracy:0.938\nIteration: 5914, learning rate: 0.00706, Loss: 0.2118, Accuracy:0.914\nIteration: 5915, learning rate: 0.00706, Loss: 0.1845, Accuracy:0.898\nIteration: 5916, learning rate: 0.00706, Loss: 0.2004, Accuracy:0.898\nIteration: 5917, learning rate: 0.00706, Loss: 0.2158, Accuracy:0.898\nIteration: 5918, learning rate: 0.00706, Loss: 0.1946, Accuracy:0.930\nIteration: 5919, learning rate: 0.00706, Loss: 0.1739, Accuracy:0.953\nIteration: 5920, learning rate: 0.00706, Loss: 0.2397, Accuracy:0.938\nIteration: 5921, learning rate: 0.00706, Loss: 0.1484, Accuracy:0.946\nEpoch: 191, Loss: 0.2161, Accuracy:0.912, Val Loss: 0.2805, Val Accuracy: 0.872\nIteration: 5922, learning rate: 0.00706, Loss: 0.1982, Accuracy:0.906\nIteration: 5923, learning rate: 0.00706, Loss: 0.3043, Accuracy:0.852\nIteration: 5924, learning rate: 0.00705, Loss: 0.1986, Accuracy:0.930\nIteration: 5925, learning rate: 0.00705, Loss: 0.2178, Accuracy:0.914\nIteration: 5926, learning rate: 0.00705, Loss: 0.2177, Accuracy:0.906\nIteration: 5927, learning rate: 0.00705, Loss: 0.2748, Accuracy:0.875\nIteration: 5928, learning rate: 0.00705, Loss: 0.2065, Accuracy:0.898\nIteration: 5929, learning rate: 0.00705, Loss: 0.2696, Accuracy:0.867\nIteration: 5930, learning rate: 0.00705, Loss: 0.1626, Accuracy:0.930\nIteration: 5931, learning rate: 0.00705, Loss: 0.3033, Accuracy:0.859\nIteration: 5932, learning rate: 0.00705, Loss: 0.2408, Accuracy:0.898\nIteration: 5933, learning rate: 0.00705, Loss: 0.2975, Accuracy:0.875\nIteration: 5934, learning rate: 0.00705, Loss: 0.2077, Accuracy:0.906\nIteration: 5935, learning rate: 0.00705, Loss: 0.2608, Accuracy:0.867\nIteration: 5936, learning rate: 0.00705, Loss: 0.2234, Accuracy:0.891\nIteration: 5937, learning rate: 0.00705, Loss: 0.2345, Accuracy:0.922\nIteration: 5938, learning rate: 0.00705, Loss: 0.1507, Accuracy:0.945\nIteration: 5939, learning rate: 0.00705, Loss: 0.2761, Accuracy:0.883\nIteration: 5940, learning rate: 0.00705, Loss: 0.1652, Accuracy:0.938\nIteration: 5941, learning rate: 0.00705, Loss: 0.1869, Accuracy:0.938\nIteration: 5942, learning rate: 0.00705, Loss: 0.2041, Accuracy:0.930\nIteration: 5943, learning rate: 0.00705, Loss: 0.1659, Accuracy:0.922\nIteration: 5944, learning rate: 0.00705, Loss: 0.2580, Accuracy:0.875\nIteration: 5945, learning rate: 0.00705, Loss: 0.2525, Accuracy:0.906\nIteration: 5946, learning rate: 0.00705, Loss: 0.2684, Accuracy:0.891\nIteration: 5947, learning rate: 0.00705, Loss: 0.2300, Accuracy:0.883\nIteration: 5948, learning rate: 0.00705, Loss: 0.2502, Accuracy:0.914\nIteration: 5949, learning rate: 0.00705, Loss: 0.2260, Accuracy:0.922\nIteration: 5950, learning rate: 0.00705, Loss: 0.2646, Accuracy:0.875\nIteration: 5951, learning rate: 0.00705, Loss: 0.2379, Accuracy:0.922\nIteration: 5952, learning rate: 0.00705, Loss: 0.2633, Accuracy:0.849\nEpoch: 192, Loss: 0.2328, Accuracy:0.900, Val Loss: 0.3220, Val Accuracy: 0.864\nIteration: 5953, learning rate: 0.00705, Loss: 0.1773, Accuracy:0.906\nIteration: 5954, learning rate: 0.00704, Loss: 0.2244, Accuracy:0.906\nIteration: 5955, learning rate: 0.00704, Loss: 0.2519, Accuracy:0.883\nIteration: 5956, learning rate: 0.00704, Loss: 0.2126, Accuracy:0.898\nIteration: 5957, learning rate: 0.00704, Loss: 0.2535, Accuracy:0.898\nIteration: 5958, learning rate: 0.00704, Loss: 0.2167, Accuracy:0.930\nIteration: 5959, learning rate: 0.00704, Loss: 0.2431, Accuracy:0.898\nIteration: 5960, learning rate: 0.00704, Loss: 0.1590, Accuracy:0.922\nIteration: 5961, learning rate: 0.00704, Loss: 0.2616, Accuracy:0.875\nIteration: 5962, learning rate: 0.00704, Loss: 0.2474, Accuracy:0.891\nIteration: 5963, learning rate: 0.00704, Loss: 0.3296, Accuracy:0.852\nIteration: 5964, learning rate: 0.00704, Loss: 0.2629, Accuracy:0.891\nIteration: 5965, learning rate: 0.00704, Loss: 0.3167, Accuracy:0.875\nIteration: 5966, learning rate: 0.00704, Loss: 0.2134, Accuracy:0.922\nIteration: 5967, learning rate: 0.00704, Loss: 0.2148, Accuracy:0.914\nIteration: 5968, learning rate: 0.00704, Loss: 0.1706, Accuracy:0.930\nIteration: 5969, learning rate: 0.00704, Loss: 0.2087, Accuracy:0.914\nIteration: 5970, learning rate: 0.00704, Loss: 0.2471, Accuracy:0.906\nIteration: 5971, learning rate: 0.00704, Loss: 0.1666, Accuracy:0.945\nIteration: 5972, learning rate: 0.00704, Loss: 0.1493, Accuracy:0.930\nIteration: 5973, learning rate: 0.00704, Loss: 0.2067, Accuracy:0.898\nIteration: 5974, learning rate: 0.00704, Loss: 0.2075, Accuracy:0.914\nIteration: 5975, learning rate: 0.00704, Loss: 0.2457, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 5976, learning rate: 0.00704, Loss: 0.1935, Accuracy:0.922\nIteration: 5977, learning rate: 0.00704, Loss: 0.1946, Accuracy:0.922\nIteration: 5978, learning rate: 0.00704, Loss: 0.2412, Accuracy:0.898\nIteration: 5979, learning rate: 0.00704, Loss: 0.1630, Accuracy:0.938\nIteration: 5980, learning rate: 0.00704, Loss: 0.2448, Accuracy:0.906\nIteration: 5981, learning rate: 0.00704, Loss: 0.2794, Accuracy:0.891\nIteration: 5982, learning rate: 0.00704, Loss: 0.2100, Accuracy:0.914\nIteration: 5983, learning rate: 0.00704, Loss: 0.2643, Accuracy:0.871\nEpoch: 193, Loss: 0.2251, Accuracy:0.905, Val Loss: 0.2680, Val Accuracy: 0.883\nval_loss_decreased from 0.2685 to 0.2680, saving_checkpoint for epoch 193\nIteration: 5984, learning rate: 0.00703, Loss: 0.2672, Accuracy:0.898\nIteration: 5985, learning rate: 0.00703, Loss: 0.1824, Accuracy:0.930\nIteration: 5986, learning rate: 0.00703, Loss: 0.2152, Accuracy:0.898\nIteration: 5987, learning rate: 0.00703, Loss: 0.3167, Accuracy:0.836\nIteration: 5988, learning rate: 0.00703, Loss: 0.1672, Accuracy:0.922\nIteration: 5989, learning rate: 0.00703, Loss: 0.1847, Accuracy:0.938\nIteration: 5990, learning rate: 0.00703, Loss: 0.2458, Accuracy:0.922\nIteration: 5991, learning rate: 0.00703, Loss: 0.1815, Accuracy:0.930\nIteration: 5992, learning rate: 0.00703, Loss: 0.2228, Accuracy:0.922\nIteration: 5993, learning rate: 0.00703, Loss: 0.2291, Accuracy:0.898\nIteration: 5994, learning rate: 0.00703, Loss: 0.2251, Accuracy:0.930\nIteration: 5995, learning rate: 0.00703, Loss: 0.2312, Accuracy:0.898\nIteration: 5996, learning rate: 0.00703, Loss: 0.1690, Accuracy:0.930\nIteration: 5997, learning rate: 0.00703, Loss: 0.1629, Accuracy:0.953\nIteration: 5998, learning rate: 0.00703, Loss: 0.1899, Accuracy:0.914\nIteration: 5999, learning rate: 0.00703, Loss: 0.2139, Accuracy:0.914\nIteration: 6000, learning rate: 0.00703, Loss: 0.2570, Accuracy:0.875\nIteration: 6001, learning rate: 0.00703, Loss: 0.1985, Accuracy:0.938\nIteration: 6002, learning rate: 0.00703, Loss: 0.2313, Accuracy:0.930\nIteration: 6003, learning rate: 0.00703, Loss: 0.2387, Accuracy:0.906\nIteration: 6004, learning rate: 0.00703, Loss: 0.2110, Accuracy:0.922\nIteration: 6005, learning rate: 0.00703, Loss: 0.1720, Accuracy:0.930\nIteration: 6006, learning rate: 0.00703, Loss: 0.1942, Accuracy:0.938\nIteration: 6007, learning rate: 0.00703, Loss: 0.2393, Accuracy:0.906\nIteration: 6008, learning rate: 0.00703, Loss: 0.1732, Accuracy:0.938\nIteration: 6009, learning rate: 0.00703, Loss: 0.3293, Accuracy:0.844\nIteration: 6010, learning rate: 0.00703, Loss: 0.1664, Accuracy:0.953\nIteration: 6011, learning rate: 0.00703, Loss: 0.2164, Accuracy:0.914\nIteration: 6012, learning rate: 0.00703, Loss: 0.1905, Accuracy:0.953\nIteration: 6013, learning rate: 0.00703, Loss: 0.1725, Accuracy:0.938\nIteration: 6014, learning rate: 0.00702, Loss: 0.2637, Accuracy:0.882\nEpoch: 194, Loss: 0.2148, Accuracy:0.916, Val Loss: 0.3893, Val Accuracy: 0.821\nIteration: 6015, learning rate: 0.00702, Loss: 0.2975, Accuracy:0.867\nIteration: 6016, learning rate: 0.00702, Loss: 0.1826, Accuracy:0.930\nIteration: 6017, learning rate: 0.00702, Loss: 0.2860, Accuracy:0.867\nIteration: 6018, learning rate: 0.00702, Loss: 0.2374, Accuracy:0.898\nIteration: 6019, learning rate: 0.00702, Loss: 0.1719, Accuracy:0.953\nIteration: 6020, learning rate: 0.00702, Loss: 0.2036, Accuracy:0.922\nIteration: 6021, learning rate: 0.00702, Loss: 0.2044, Accuracy:0.922\nIteration: 6022, learning rate: 0.00702, Loss: 0.2529, Accuracy:0.898\nIteration: 6023, learning rate: 0.00702, Loss: 0.2041, Accuracy:0.922\nIteration: 6024, learning rate: 0.00702, Loss: 0.2570, Accuracy:0.891\nIteration: 6025, learning rate: 0.00702, Loss: 0.2397, Accuracy:0.914\nIteration: 6026, learning rate: 0.00702, Loss: 0.3347, Accuracy:0.828\nIteration: 6027, learning rate: 0.00702, Loss: 0.1799, Accuracy:0.938\nIteration: 6028, learning rate: 0.00702, Loss: 0.2136, Accuracy:0.930\nIteration: 6029, learning rate: 0.00702, Loss: 0.2092, Accuracy:0.906\nIteration: 6030, learning rate: 0.00702, Loss: 0.2593, Accuracy:0.883\nIteration: 6031, learning rate: 0.00702, Loss: 0.1750, Accuracy:0.938\nIteration: 6032, learning rate: 0.00702, Loss: 0.2115, Accuracy:0.922\nIteration: 6033, learning rate: 0.00702, Loss: 0.2507, Accuracy:0.891\nIteration: 6034, learning rate: 0.00702, Loss: 0.2072, Accuracy:0.906\nIteration: 6035, learning rate: 0.00702, Loss: 0.3200, Accuracy:0.867\nIteration: 6036, learning rate: 0.00702, Loss: 0.2667, Accuracy:0.883\nIteration: 6037, learning rate: 0.00702, Loss: 0.2051, Accuracy:0.898\nIteration: 6038, learning rate: 0.00702, Loss: 0.2490, Accuracy:0.906\nIteration: 6039, learning rate: 0.00702, Loss: 0.3229, Accuracy:0.898\nIteration: 6040, learning rate: 0.00702, Loss: 0.2312, Accuracy:0.914\nIteration: 6041, learning rate: 0.00702, Loss: 0.2138, Accuracy:0.922\nIteration: 6042, learning rate: 0.00702, Loss: 0.2732, Accuracy:0.891\nIteration: 6043, learning rate: 0.00702, Loss: 0.2586, Accuracy:0.883\nIteration: 6044, learning rate: 0.00702, Loss: 0.1761, Accuracy:0.945\nIteration: 6045, learning rate: 0.00701, Loss: 0.4015, Accuracy:0.849\nEpoch: 195, Loss: 0.2418, Accuracy:0.903, Val Loss: 0.2904, Val Accuracy: 0.873\nIteration: 6046, learning rate: 0.00701, Loss: 0.1542, Accuracy:0.922\nIteration: 6047, learning rate: 0.00701, Loss: 0.2275, Accuracy:0.938\nIteration: 6048, learning rate: 0.00701, Loss: 0.2491, Accuracy:0.906\nIteration: 6049, learning rate: 0.00701, Loss: 0.1718, Accuracy:0.938\nIteration: 6050, learning rate: 0.00701, Loss: 0.1535, Accuracy:0.938\nIteration: 6051, learning rate: 0.00701, Loss: 0.2747, Accuracy:0.906\nIteration: 6052, learning rate: 0.00701, Loss: 0.3078, Accuracy:0.859\nIteration: 6053, learning rate: 0.00701, Loss: 0.2623, Accuracy:0.883\nIteration: 6054, learning rate: 0.00701, Loss: 0.2345, Accuracy:0.883\nIteration: 6055, learning rate: 0.00701, Loss: 0.2155, Accuracy:0.906\nIteration: 6056, learning rate: 0.00701, Loss: 0.2070, Accuracy:0.922\nIteration: 6057, learning rate: 0.00701, Loss: 0.2103, Accuracy:0.883\nIteration: 6058, learning rate: 0.00701, Loss: 0.2120, Accuracy:0.914\nIteration: 6059, learning rate: 0.00701, Loss: 0.2249, Accuracy:0.914\nIteration: 6060, learning rate: 0.00701, Loss: 0.2356, Accuracy:0.906\nIteration: 6061, learning rate: 0.00701, Loss: 0.2159, Accuracy:0.914\nIteration: 6062, learning rate: 0.00701, Loss: 0.2490, Accuracy:0.875\nIteration: 6063, learning rate: 0.00701, Loss: 0.2389, Accuracy:0.914\nIteration: 6064, learning rate: 0.00701, Loss: 0.2350, Accuracy:0.906\nIteration: 6065, learning rate: 0.00701, Loss: 0.2475, Accuracy:0.883\nIteration: 6066, learning rate: 0.00701, Loss: 0.1899, Accuracy:0.922\nIteration: 6067, learning rate: 0.00701, Loss: 0.2489, Accuracy:0.930\nIteration: 6068, learning rate: 0.00701, Loss: 0.2516, Accuracy:0.914\nIteration: 6069, learning rate: 0.00701, Loss: 0.2212, Accuracy:0.898\nIteration: 6070, learning rate: 0.00701, Loss: 0.2475, Accuracy:0.891\nIteration: 6071, learning rate: 0.00701, Loss: 0.1650, Accuracy:0.930\nIteration: 6072, learning rate: 0.00701, Loss: 0.2139, Accuracy:0.922\nIteration: 6073, learning rate: 0.00701, Loss: 0.2148, Accuracy:0.914\nIteration: 6074, learning rate: 0.00701, Loss: 0.2971, Accuracy:0.891\nIteration: 6075, learning rate: 0.00700, Loss: 0.2255, Accuracy:0.914\nIteration: 6076, learning rate: 0.00700, Loss: 0.1734, Accuracy:0.957\nEpoch: 196, Loss: 0.2250, Accuracy:0.909, Val Loss: 0.3785, Val Accuracy: 0.837\nIteration: 6077, learning rate: 0.00700, Loss: 0.1969, Accuracy:0.906\nIteration: 6078, learning rate: 0.00700, Loss: 0.2533, Accuracy:0.906\nIteration: 6079, learning rate: 0.00700, Loss: 0.1872, Accuracy:0.922\nIteration: 6080, learning rate: 0.00700, Loss: 0.2317, Accuracy:0.914\nIteration: 6081, learning rate: 0.00700, Loss: 0.2139, Accuracy:0.922\nIteration: 6082, learning rate: 0.00700, Loss: 0.1981, Accuracy:0.922\nIteration: 6083, learning rate: 0.00700, Loss: 0.2661, Accuracy:0.930\nIteration: 6084, learning rate: 0.00700, Loss: 0.2833, Accuracy:0.883\nIteration: 6085, learning rate: 0.00700, Loss: 0.2781, Accuracy:0.891\nIteration: 6086, learning rate: 0.00700, Loss: 0.2728, Accuracy:0.859\nIteration: 6087, learning rate: 0.00700, Loss: 0.2128, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6088, learning rate: 0.00700, Loss: 0.2473, Accuracy:0.867\nIteration: 6089, learning rate: 0.00700, Loss: 0.2823, Accuracy:0.875\nIteration: 6090, learning rate: 0.00700, Loss: 0.2471, Accuracy:0.906\nIteration: 6091, learning rate: 0.00700, Loss: 0.2412, Accuracy:0.867\nIteration: 6092, learning rate: 0.00700, Loss: 0.2629, Accuracy:0.859\nIteration: 6093, learning rate: 0.00700, Loss: 0.2367, Accuracy:0.930\nIteration: 6094, learning rate: 0.00700, Loss: 0.2816, Accuracy:0.898\nIteration: 6095, learning rate: 0.00700, Loss: 0.1826, Accuracy:0.945\nIteration: 6096, learning rate: 0.00700, Loss: 0.2443, Accuracy:0.891\nIteration: 6097, learning rate: 0.00700, Loss: 0.1814, Accuracy:0.945\nIteration: 6098, learning rate: 0.00700, Loss: 0.2190, Accuracy:0.883\nIteration: 6099, learning rate: 0.00700, Loss: 0.2928, Accuracy:0.859\nIteration: 6100, learning rate: 0.00700, Loss: 0.3040, Accuracy:0.859\nIteration: 6101, learning rate: 0.00700, Loss: 0.2411, Accuracy:0.898\nIteration: 6102, learning rate: 0.00700, Loss: 0.2775, Accuracy:0.859\nIteration: 6103, learning rate: 0.00700, Loss: 0.2581, Accuracy:0.852\nIteration: 6104, learning rate: 0.00700, Loss: 0.1809, Accuracy:0.930\nIteration: 6105, learning rate: 0.00700, Loss: 0.2814, Accuracy:0.891\nIteration: 6106, learning rate: 0.00699, Loss: 0.2581, Accuracy:0.883\nIteration: 6107, learning rate: 0.00699, Loss: 0.2413, Accuracy:0.903\nEpoch: 197, Loss: 0.2437, Accuracy:0.896, Val Loss: 0.3044, Val Accuracy: 0.858\nIteration: 6108, learning rate: 0.00699, Loss: 0.2583, Accuracy:0.867\nIteration: 6109, learning rate: 0.00699, Loss: 0.2754, Accuracy:0.844\nIteration: 6110, learning rate: 0.00699, Loss: 0.2820, Accuracy:0.898\nIteration: 6111, learning rate: 0.00699, Loss: 0.2348, Accuracy:0.906\nIteration: 6112, learning rate: 0.00699, Loss: 0.2562, Accuracy:0.883\nIteration: 6113, learning rate: 0.00699, Loss: 0.2562, Accuracy:0.906\nIteration: 6114, learning rate: 0.00699, Loss: 0.3119, Accuracy:0.875\nIteration: 6115, learning rate: 0.00699, Loss: 0.2684, Accuracy:0.875\nIteration: 6116, learning rate: 0.00699, Loss: 0.2831, Accuracy:0.906\nIteration: 6117, learning rate: 0.00699, Loss: 0.2386, Accuracy:0.914\nIteration: 6118, learning rate: 0.00699, Loss: 0.2858, Accuracy:0.898\nIteration: 6119, learning rate: 0.00699, Loss: 0.1592, Accuracy:0.938\nIteration: 6120, learning rate: 0.00699, Loss: 0.2001, Accuracy:0.914\nIteration: 6121, learning rate: 0.00699, Loss: 0.2314, Accuracy:0.883\nIteration: 6122, learning rate: 0.00699, Loss: 0.2090, Accuracy:0.922\nIteration: 6123, learning rate: 0.00699, Loss: 0.2250, Accuracy:0.930\nIteration: 6124, learning rate: 0.00699, Loss: 0.2648, Accuracy:0.867\nIteration: 6125, learning rate: 0.00699, Loss: 0.1426, Accuracy:0.969\nIteration: 6126, learning rate: 0.00699, Loss: 0.2529, Accuracy:0.891\nIteration: 6127, learning rate: 0.00699, Loss: 0.1791, Accuracy:0.922\nIteration: 6128, learning rate: 0.00699, Loss: 0.2271, Accuracy:0.891\nIteration: 6129, learning rate: 0.00699, Loss: 0.2100, Accuracy:0.922\nIteration: 6130, learning rate: 0.00699, Loss: 0.1601, Accuracy:0.922\nIteration: 6131, learning rate: 0.00699, Loss: 0.2467, Accuracy:0.891\nIteration: 6132, learning rate: 0.00699, Loss: 0.1946, Accuracy:0.938\nIteration: 6133, learning rate: 0.00699, Loss: 0.1628, Accuracy:0.953\nIteration: 6134, learning rate: 0.00699, Loss: 0.2418, Accuracy:0.898\nIteration: 6135, learning rate: 0.00699, Loss: 0.1677, Accuracy:0.930\nIteration: 6136, learning rate: 0.00699, Loss: 0.2514, Accuracy:0.883\nIteration: 6137, learning rate: 0.00698, Loss: 0.1844, Accuracy:0.930\nIteration: 6138, learning rate: 0.00698, Loss: 0.2461, Accuracy:0.892\nEpoch: 198, Loss: 0.2293, Accuracy:0.905, Val Loss: 0.3169, Val Accuracy: 0.870\nIteration: 6139, learning rate: 0.00698, Loss: 0.2444, Accuracy:0.922\nIteration: 6140, learning rate: 0.00698, Loss: 0.2234, Accuracy:0.906\nIteration: 6141, learning rate: 0.00698, Loss: 0.1956, Accuracy:0.922\nIteration: 6142, learning rate: 0.00698, Loss: 0.2251, Accuracy:0.898\nIteration: 6143, learning rate: 0.00698, Loss: 0.2127, Accuracy:0.867\nIteration: 6144, learning rate: 0.00698, Loss: 0.2384, Accuracy:0.883\nIteration: 6145, learning rate: 0.00698, Loss: 0.2043, Accuracy:0.945\nIteration: 6146, learning rate: 0.00698, Loss: 0.2465, Accuracy:0.875\nIteration: 6147, learning rate: 0.00698, Loss: 0.2729, Accuracy:0.906\nIteration: 6148, learning rate: 0.00698, Loss: 0.2709, Accuracy:0.883\nIteration: 6149, learning rate: 0.00698, Loss: 0.2164, Accuracy:0.914\nIteration: 6150, learning rate: 0.00698, Loss: 0.2103, Accuracy:0.938\nIteration: 6151, learning rate: 0.00698, Loss: 0.2311, Accuracy:0.914\nIteration: 6152, learning rate: 0.00698, Loss: 0.2764, Accuracy:0.891\nIteration: 6153, learning rate: 0.00698, Loss: 0.2039, Accuracy:0.906\nIteration: 6154, learning rate: 0.00698, Loss: 0.1642, Accuracy:0.945\nIteration: 6155, learning rate: 0.00698, Loss: 0.1832, Accuracy:0.930\nIteration: 6156, learning rate: 0.00698, Loss: 0.1391, Accuracy:0.953\nIteration: 6157, learning rate: 0.00698, Loss: 0.1841, Accuracy:0.930\nIteration: 6158, learning rate: 0.00698, Loss: 0.2203, Accuracy:0.898\nIteration: 6159, learning rate: 0.00698, Loss: 0.1883, Accuracy:0.914\nIteration: 6160, learning rate: 0.00698, Loss: 0.1528, Accuracy:0.945\nIteration: 6161, learning rate: 0.00698, Loss: 0.1400, Accuracy:0.961\nIteration: 6162, learning rate: 0.00698, Loss: 0.2371, Accuracy:0.891\nIteration: 6163, learning rate: 0.00698, Loss: 0.2627, Accuracy:0.906\nIteration: 6164, learning rate: 0.00698, Loss: 0.2877, Accuracy:0.875\nIteration: 6165, learning rate: 0.00698, Loss: 0.1863, Accuracy:0.922\nIteration: 6166, learning rate: 0.00698, Loss: 0.1729, Accuracy:0.930\nIteration: 6167, learning rate: 0.00698, Loss: 0.1596, Accuracy:0.938\nIteration: 6168, learning rate: 0.00697, Loss: 0.2077, Accuracy:0.914\nIteration: 6169, learning rate: 0.00697, Loss: 0.2124, Accuracy:0.882\nEpoch: 199, Loss: 0.2120, Accuracy:0.913, Val Loss: 0.3583, Val Accuracy: 0.853\nIteration: 6170, learning rate: 0.00697, Loss: 0.3666, Accuracy:0.852\nIteration: 6171, learning rate: 0.00697, Loss: 0.1993, Accuracy:0.945\nIteration: 6172, learning rate: 0.00697, Loss: 0.2314, Accuracy:0.914\nIteration: 6173, learning rate: 0.00697, Loss: 0.2103, Accuracy:0.938\nIteration: 6174, learning rate: 0.00697, Loss: 0.2536, Accuracy:0.891\nIteration: 6175, learning rate: 0.00697, Loss: 0.1601, Accuracy:0.945\nIteration: 6176, learning rate: 0.00697, Loss: 0.2614, Accuracy:0.898\nIteration: 6177, learning rate: 0.00697, Loss: 0.2135, Accuracy:0.891\nIteration: 6178, learning rate: 0.00697, Loss: 0.1925, Accuracy:0.914\nIteration: 6179, learning rate: 0.00697, Loss: 0.2309, Accuracy:0.883\nIteration: 6180, learning rate: 0.00697, Loss: 0.2047, Accuracy:0.922\nIteration: 6181, learning rate: 0.00697, Loss: 0.2140, Accuracy:0.891\nIteration: 6182, learning rate: 0.00697, Loss: 0.1795, Accuracy:0.938\nIteration: 6183, learning rate: 0.00697, Loss: 0.2020, Accuracy:0.930\nIteration: 6184, learning rate: 0.00697, Loss: 0.1956, Accuracy:0.906\nIteration: 6185, learning rate: 0.00697, Loss: 0.2608, Accuracy:0.898\nIteration: 6186, learning rate: 0.00697, Loss: 0.2157, Accuracy:0.930\nIteration: 6187, learning rate: 0.00697, Loss: 0.2541, Accuracy:0.922\nIteration: 6188, learning rate: 0.00697, Loss: 0.2288, Accuracy:0.914\nIteration: 6189, learning rate: 0.00697, Loss: 0.2254, Accuracy:0.906\nIteration: 6190, learning rate: 0.00697, Loss: 0.2228, Accuracy:0.906\nIteration: 6191, learning rate: 0.00697, Loss: 0.2102, Accuracy:0.914\nIteration: 6192, learning rate: 0.00697, Loss: 0.1778, Accuracy:0.930\nIteration: 6193, learning rate: 0.00697, Loss: 0.1586, Accuracy:0.953\nIteration: 6194, learning rate: 0.00697, Loss: 0.1755, Accuracy:0.938\nIteration: 6195, learning rate: 0.00697, Loss: 0.2025, Accuracy:0.930\nIteration: 6196, learning rate: 0.00697, Loss: 0.1592, Accuracy:0.953\nIteration: 6197, learning rate: 0.00697, Loss: 0.2548, Accuracy:0.883\nIteration: 6198, learning rate: 0.00697, Loss: 0.2044, Accuracy:0.930\nIteration: 6199, learning rate: 0.00696, Loss: 0.2706, Accuracy:0.891\nIteration: 6200, learning rate: 0.00696, Loss: 0.3056, Accuracy:0.882\nEpoch: 200, Loss: 0.2207, Accuracy:0.914, Val Loss: 0.3052, Val Accuracy: 0.873\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6201, learning rate: 0.00696, Loss: 0.2284, Accuracy:0.906\nIteration: 6202, learning rate: 0.00696, Loss: 0.2527, Accuracy:0.891\nIteration: 6203, learning rate: 0.00696, Loss: 0.2382, Accuracy:0.898\nIteration: 6204, learning rate: 0.00696, Loss: 0.1851, Accuracy:0.914\nIteration: 6205, learning rate: 0.00696, Loss: 0.3204, Accuracy:0.883\nIteration: 6206, learning rate: 0.00696, Loss: 0.2404, Accuracy:0.891\nIteration: 6207, learning rate: 0.00696, Loss: 0.1702, Accuracy:0.938\nIteration: 6208, learning rate: 0.00696, Loss: 0.1944, Accuracy:0.930\nIteration: 6209, learning rate: 0.00696, Loss: 0.2522, Accuracy:0.891\nIteration: 6210, learning rate: 0.00696, Loss: 0.1894, Accuracy:0.938\nIteration: 6211, learning rate: 0.00696, Loss: 0.1625, Accuracy:0.945\nIteration: 6212, learning rate: 0.00696, Loss: 0.2086, Accuracy:0.898\nIteration: 6213, learning rate: 0.00696, Loss: 0.2088, Accuracy:0.891\nIteration: 6214, learning rate: 0.00696, Loss: 0.2384, Accuracy:0.906\nIteration: 6215, learning rate: 0.00696, Loss: 0.2358, Accuracy:0.906\nIteration: 6216, learning rate: 0.00696, Loss: 0.2512, Accuracy:0.883\nIteration: 6217, learning rate: 0.00696, Loss: 0.2616, Accuracy:0.891\nIteration: 6218, learning rate: 0.00696, Loss: 0.2568, Accuracy:0.883\nIteration: 6219, learning rate: 0.00696, Loss: 0.2046, Accuracy:0.914\nIteration: 6220, learning rate: 0.00696, Loss: 0.2051, Accuracy:0.914\nIteration: 6221, learning rate: 0.00696, Loss: 0.2524, Accuracy:0.938\nIteration: 6222, learning rate: 0.00696, Loss: 0.2608, Accuracy:0.891\nIteration: 6223, learning rate: 0.00696, Loss: 0.1737, Accuracy:0.930\nIteration: 6224, learning rate: 0.00696, Loss: 0.2336, Accuracy:0.898\nIteration: 6225, learning rate: 0.00696, Loss: 0.1555, Accuracy:0.945\nIteration: 6226, learning rate: 0.00696, Loss: 0.2470, Accuracy:0.883\nIteration: 6227, learning rate: 0.00696, Loss: 0.1974, Accuracy:0.906\nIteration: 6228, learning rate: 0.00696, Loss: 0.1724, Accuracy:0.930\nIteration: 6229, learning rate: 0.00696, Loss: 0.2020, Accuracy:0.914\nIteration: 6230, learning rate: 0.00695, Loss: 0.2664, Accuracy:0.891\nIteration: 6231, learning rate: 0.00695, Loss: 0.1674, Accuracy:0.935\nEpoch: 201, Loss: 0.2204, Accuracy:0.909, Val Loss: 0.3234, Val Accuracy: 0.864\nIteration: 6232, learning rate: 0.00695, Loss: 0.2266, Accuracy:0.906\nIteration: 6233, learning rate: 0.00695, Loss: 0.2742, Accuracy:0.898\nIteration: 6234, learning rate: 0.00695, Loss: 0.1812, Accuracy:0.938\nIteration: 6235, learning rate: 0.00695, Loss: 0.2250, Accuracy:0.891\nIteration: 6236, learning rate: 0.00695, Loss: 0.1726, Accuracy:0.945\nIteration: 6237, learning rate: 0.00695, Loss: 0.2125, Accuracy:0.938\nIteration: 6238, learning rate: 0.00695, Loss: 0.1748, Accuracy:0.938\nIteration: 6239, learning rate: 0.00695, Loss: 0.2172, Accuracy:0.906\nIteration: 6240, learning rate: 0.00695, Loss: 0.2287, Accuracy:0.859\nIteration: 6241, learning rate: 0.00695, Loss: 0.1891, Accuracy:0.930\nIteration: 6242, learning rate: 0.00695, Loss: 0.1536, Accuracy:0.969\nIteration: 6243, learning rate: 0.00695, Loss: 0.1612, Accuracy:0.922\nIteration: 6244, learning rate: 0.00695, Loss: 0.1951, Accuracy:0.914\nIteration: 6245, learning rate: 0.00695, Loss: 0.2205, Accuracy:0.914\nIteration: 6246, learning rate: 0.00695, Loss: 0.2829, Accuracy:0.891\nIteration: 6247, learning rate: 0.00695, Loss: 0.2062, Accuracy:0.945\nIteration: 6248, learning rate: 0.00695, Loss: 0.2560, Accuracy:0.883\nIteration: 6249, learning rate: 0.00695, Loss: 0.2578, Accuracy:0.906\nIteration: 6250, learning rate: 0.00695, Loss: 0.2048, Accuracy:0.906\nIteration: 6251, learning rate: 0.00695, Loss: 0.3190, Accuracy:0.867\nIteration: 6252, learning rate: 0.00695, Loss: 0.2329, Accuracy:0.906\nIteration: 6253, learning rate: 0.00695, Loss: 0.1842, Accuracy:0.914\nIteration: 6254, learning rate: 0.00695, Loss: 0.3200, Accuracy:0.883\nIteration: 6255, learning rate: 0.00695, Loss: 0.2507, Accuracy:0.898\nIteration: 6256, learning rate: 0.00695, Loss: 0.2106, Accuracy:0.906\nIteration: 6257, learning rate: 0.00695, Loss: 0.2422, Accuracy:0.883\nIteration: 6258, learning rate: 0.00695, Loss: 0.1909, Accuracy:0.906\nIteration: 6259, learning rate: 0.00695, Loss: 0.1961, Accuracy:0.945\nIteration: 6260, learning rate: 0.00695, Loss: 0.1955, Accuracy:0.906\nIteration: 6261, learning rate: 0.00694, Loss: 0.2089, Accuracy:0.906\nIteration: 6262, learning rate: 0.00694, Loss: 0.1767, Accuracy:0.914\nEpoch: 202, Loss: 0.2183, Accuracy:0.911, Val Loss: 0.3211, Val Accuracy: 0.866\nIteration: 6263, learning rate: 0.00694, Loss: 0.2358, Accuracy:0.922\nIteration: 6264, learning rate: 0.00694, Loss: 0.1683, Accuracy:0.922\nIteration: 6265, learning rate: 0.00694, Loss: 0.1753, Accuracy:0.945\nIteration: 6266, learning rate: 0.00694, Loss: 0.2712, Accuracy:0.883\nIteration: 6267, learning rate: 0.00694, Loss: 0.1863, Accuracy:0.938\nIteration: 6268, learning rate: 0.00694, Loss: 0.1800, Accuracy:0.938\nIteration: 6269, learning rate: 0.00694, Loss: 0.1850, Accuracy:0.914\nIteration: 6270, learning rate: 0.00694, Loss: 0.2191, Accuracy:0.906\nIteration: 6271, learning rate: 0.00694, Loss: 0.1781, Accuracy:0.938\nIteration: 6272, learning rate: 0.00694, Loss: 0.1481, Accuracy:0.953\nIteration: 6273, learning rate: 0.00694, Loss: 0.2547, Accuracy:0.883\nIteration: 6274, learning rate: 0.00694, Loss: 0.2316, Accuracy:0.883\nIteration: 6275, learning rate: 0.00694, Loss: 0.2589, Accuracy:0.891\nIteration: 6276, learning rate: 0.00694, Loss: 0.2383, Accuracy:0.922\nIteration: 6277, learning rate: 0.00694, Loss: 0.2286, Accuracy:0.930\nIteration: 6278, learning rate: 0.00694, Loss: 0.2449, Accuracy:0.898\nIteration: 6279, learning rate: 0.00694, Loss: 0.1848, Accuracy:0.914\nIteration: 6280, learning rate: 0.00694, Loss: 0.1893, Accuracy:0.906\nIteration: 6281, learning rate: 0.00694, Loss: 0.1887, Accuracy:0.914\nIteration: 6282, learning rate: 0.00694, Loss: 0.2193, Accuracy:0.930\nIteration: 6283, learning rate: 0.00694, Loss: 0.1890, Accuracy:0.922\nIteration: 6284, learning rate: 0.00694, Loss: 0.1906, Accuracy:0.930\nIteration: 6285, learning rate: 0.00694, Loss: 0.2399, Accuracy:0.906\nIteration: 6286, learning rate: 0.00694, Loss: 0.2714, Accuracy:0.891\nIteration: 6287, learning rate: 0.00694, Loss: 0.2276, Accuracy:0.914\nIteration: 6288, learning rate: 0.00694, Loss: 0.1919, Accuracy:0.891\nIteration: 6289, learning rate: 0.00694, Loss: 0.2149, Accuracy:0.906\nIteration: 6290, learning rate: 0.00694, Loss: 0.2562, Accuracy:0.906\nIteration: 6291, learning rate: 0.00694, Loss: 0.2869, Accuracy:0.867\nIteration: 6292, learning rate: 0.00693, Loss: 0.2489, Accuracy:0.914\nIteration: 6293, learning rate: 0.00693, Loss: 0.2366, Accuracy:0.871\nEpoch: 203, Loss: 0.2174, Accuracy:0.911, Val Loss: 0.3610, Val Accuracy: 0.840\nIteration: 6294, learning rate: 0.00693, Loss: 0.1836, Accuracy:0.938\nIteration: 6295, learning rate: 0.00693, Loss: 0.1940, Accuracy:0.938\nIteration: 6296, learning rate: 0.00693, Loss: 0.2147, Accuracy:0.914\nIteration: 6297, learning rate: 0.00693, Loss: 0.2197, Accuracy:0.930\nIteration: 6298, learning rate: 0.00693, Loss: 0.2626, Accuracy:0.898\nIteration: 6299, learning rate: 0.00693, Loss: 0.2472, Accuracy:0.914\nIteration: 6300, learning rate: 0.00693, Loss: 0.2285, Accuracy:0.883\nIteration: 6301, learning rate: 0.00693, Loss: 0.2652, Accuracy:0.891\nIteration: 6302, learning rate: 0.00693, Loss: 0.2469, Accuracy:0.875\nIteration: 6303, learning rate: 0.00693, Loss: 0.2641, Accuracy:0.891\nIteration: 6304, learning rate: 0.00693, Loss: 0.2575, Accuracy:0.883\nIteration: 6305, learning rate: 0.00693, Loss: 0.1441, Accuracy:0.961\nIteration: 6306, learning rate: 0.00693, Loss: 0.1771, Accuracy:0.930\nIteration: 6307, learning rate: 0.00693, Loss: 0.2839, Accuracy:0.859\nIteration: 6308, learning rate: 0.00693, Loss: 0.2372, Accuracy:0.891\nIteration: 6309, learning rate: 0.00693, Loss: 0.2345, Accuracy:0.930\nIteration: 6310, learning rate: 0.00693, Loss: 0.2333, Accuracy:0.891\nIteration: 6311, learning rate: 0.00693, Loss: 0.2971, Accuracy:0.891\nIteration: 6312, learning rate: 0.00693, Loss: 0.2566, Accuracy:0.875\nIteration: 6313, learning rate: 0.00693, Loss: 0.2324, Accuracy:0.922\nIteration: 6314, learning rate: 0.00693, Loss: 0.1919, Accuracy:0.945\nIteration: 6315, learning rate: 0.00693, Loss: 0.2029, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6316, learning rate: 0.00693, Loss: 0.2688, Accuracy:0.875\nIteration: 6317, learning rate: 0.00693, Loss: 0.2093, Accuracy:0.938\nIteration: 6318, learning rate: 0.00693, Loss: 0.2144, Accuracy:0.898\nIteration: 6319, learning rate: 0.00693, Loss: 0.1231, Accuracy:0.961\nIteration: 6320, learning rate: 0.00693, Loss: 0.1911, Accuracy:0.922\nIteration: 6321, learning rate: 0.00693, Loss: 0.2086, Accuracy:0.906\nIteration: 6322, learning rate: 0.00693, Loss: 0.2640, Accuracy:0.914\nIteration: 6323, learning rate: 0.00693, Loss: 0.2870, Accuracy:0.883\nIteration: 6324, learning rate: 0.00692, Loss: 0.1919, Accuracy:0.914\nEpoch: 204, Loss: 0.2269, Accuracy:0.909, Val Loss: 0.3505, Val Accuracy: 0.858\nIteration: 6325, learning rate: 0.00692, Loss: 0.1974, Accuracy:0.945\nIteration: 6326, learning rate: 0.00692, Loss: 0.2663, Accuracy:0.891\nIteration: 6327, learning rate: 0.00692, Loss: 0.2691, Accuracy:0.914\nIteration: 6328, learning rate: 0.00692, Loss: 0.2230, Accuracy:0.891\nIteration: 6329, learning rate: 0.00692, Loss: 0.1849, Accuracy:0.938\nIteration: 6330, learning rate: 0.00692, Loss: 0.1831, Accuracy:0.938\nIteration: 6331, learning rate: 0.00692, Loss: 0.2830, Accuracy:0.883\nIteration: 6332, learning rate: 0.00692, Loss: 0.1656, Accuracy:0.945\nIteration: 6333, learning rate: 0.00692, Loss: 0.2589, Accuracy:0.891\nIteration: 6334, learning rate: 0.00692, Loss: 0.1629, Accuracy:0.922\nIteration: 6335, learning rate: 0.00692, Loss: 0.2392, Accuracy:0.906\nIteration: 6336, learning rate: 0.00692, Loss: 0.2187, Accuracy:0.930\nIteration: 6337, learning rate: 0.00692, Loss: 0.2562, Accuracy:0.906\nIteration: 6338, learning rate: 0.00692, Loss: 0.2693, Accuracy:0.906\nIteration: 6339, learning rate: 0.00692, Loss: 0.2309, Accuracy:0.914\nIteration: 6340, learning rate: 0.00692, Loss: 0.1967, Accuracy:0.922\nIteration: 6341, learning rate: 0.00692, Loss: 0.1928, Accuracy:0.906\nIteration: 6342, learning rate: 0.00692, Loss: 0.2442, Accuracy:0.898\nIteration: 6343, learning rate: 0.00692, Loss: 0.1858, Accuracy:0.914\nIteration: 6344, learning rate: 0.00692, Loss: 0.1303, Accuracy:0.945\nIteration: 6345, learning rate: 0.00692, Loss: 0.1760, Accuracy:0.938\nIteration: 6346, learning rate: 0.00692, Loss: 0.3283, Accuracy:0.875\nIteration: 6347, learning rate: 0.00692, Loss: 0.2457, Accuracy:0.891\nIteration: 6348, learning rate: 0.00692, Loss: 0.3461, Accuracy:0.852\nIteration: 6349, learning rate: 0.00692, Loss: 0.2854, Accuracy:0.891\nIteration: 6350, learning rate: 0.00692, Loss: 0.2175, Accuracy:0.898\nIteration: 6351, learning rate: 0.00692, Loss: 0.2058, Accuracy:0.914\nIteration: 6352, learning rate: 0.00692, Loss: 0.1626, Accuracy:0.945\nIteration: 6353, learning rate: 0.00692, Loss: 0.2817, Accuracy:0.852\nIteration: 6354, learning rate: 0.00692, Loss: 0.1356, Accuracy:0.961\nIteration: 6355, learning rate: 0.00691, Loss: 0.2312, Accuracy:0.892\nEpoch: 205, Loss: 0.2250, Accuracy:0.910, Val Loss: 0.2990, Val Accuracy: 0.876\nIteration: 6356, learning rate: 0.00691, Loss: 0.2560, Accuracy:0.883\nIteration: 6357, learning rate: 0.00691, Loss: 0.2118, Accuracy:0.891\nIteration: 6358, learning rate: 0.00691, Loss: 0.1443, Accuracy:0.961\nIteration: 6359, learning rate: 0.00691, Loss: 0.2348, Accuracy:0.898\nIteration: 6360, learning rate: 0.00691, Loss: 0.2698, Accuracy:0.883\nIteration: 6361, learning rate: 0.00691, Loss: 0.1900, Accuracy:0.930\nIteration: 6362, learning rate: 0.00691, Loss: 0.1472, Accuracy:0.953\nIteration: 6363, learning rate: 0.00691, Loss: 0.1907, Accuracy:0.938\nIteration: 6364, learning rate: 0.00691, Loss: 0.2274, Accuracy:0.914\nIteration: 6365, learning rate: 0.00691, Loss: 0.1666, Accuracy:0.938\nIteration: 6366, learning rate: 0.00691, Loss: 0.1955, Accuracy:0.938\nIteration: 6367, learning rate: 0.00691, Loss: 0.1731, Accuracy:0.930\nIteration: 6368, learning rate: 0.00691, Loss: 0.1699, Accuracy:0.953\nIteration: 6369, learning rate: 0.00691, Loss: 0.2194, Accuracy:0.914\nIteration: 6370, learning rate: 0.00691, Loss: 0.1917, Accuracy:0.922\nIteration: 6371, learning rate: 0.00691, Loss: 0.2102, Accuracy:0.914\nIteration: 6372, learning rate: 0.00691, Loss: 0.2352, Accuracy:0.914\nIteration: 6373, learning rate: 0.00691, Loss: 0.2566, Accuracy:0.906\nIteration: 6374, learning rate: 0.00691, Loss: 0.2653, Accuracy:0.883\nIteration: 6375, learning rate: 0.00691, Loss: 0.2919, Accuracy:0.867\nIteration: 6376, learning rate: 0.00691, Loss: 0.2057, Accuracy:0.922\nIteration: 6377, learning rate: 0.00691, Loss: 0.3122, Accuracy:0.906\nIteration: 6378, learning rate: 0.00691, Loss: 0.2462, Accuracy:0.883\nIteration: 6379, learning rate: 0.00691, Loss: 0.1939, Accuracy:0.945\nIteration: 6380, learning rate: 0.00691, Loss: 0.2045, Accuracy:0.914\nIteration: 6381, learning rate: 0.00691, Loss: 0.2568, Accuracy:0.875\nIteration: 6382, learning rate: 0.00691, Loss: 0.2213, Accuracy:0.891\nIteration: 6383, learning rate: 0.00691, Loss: 0.2463, Accuracy:0.891\nIteration: 6384, learning rate: 0.00691, Loss: 0.1949, Accuracy:0.930\nIteration: 6385, learning rate: 0.00691, Loss: 0.2479, Accuracy:0.891\nIteration: 6386, learning rate: 0.00691, Loss: 0.1776, Accuracy:0.935\nEpoch: 206, Loss: 0.2179, Accuracy:0.913, Val Loss: 0.3362, Val Accuracy: 0.830\nIteration: 6387, learning rate: 0.00690, Loss: 0.2128, Accuracy:0.922\nIteration: 6388, learning rate: 0.00690, Loss: 0.2554, Accuracy:0.906\nIteration: 6389, learning rate: 0.00690, Loss: 0.3133, Accuracy:0.883\nIteration: 6390, learning rate: 0.00690, Loss: 0.2220, Accuracy:0.906\nIteration: 6391, learning rate: 0.00690, Loss: 0.1776, Accuracy:0.938\nIteration: 6392, learning rate: 0.00690, Loss: 0.2442, Accuracy:0.898\nIteration: 6393, learning rate: 0.00690, Loss: 0.1822, Accuracy:0.938\nIteration: 6394, learning rate: 0.00690, Loss: 0.2875, Accuracy:0.875\nIteration: 6395, learning rate: 0.00690, Loss: 0.2546, Accuracy:0.906\nIteration: 6396, learning rate: 0.00690, Loss: 0.1337, Accuracy:0.961\nIteration: 6397, learning rate: 0.00690, Loss: 0.2298, Accuracy:0.906\nIteration: 6398, learning rate: 0.00690, Loss: 0.2069, Accuracy:0.930\nIteration: 6399, learning rate: 0.00690, Loss: 0.2642, Accuracy:0.875\nIteration: 6400, learning rate: 0.00690, Loss: 0.1859, Accuracy:0.914\nIteration: 6401, learning rate: 0.00690, Loss: 0.1903, Accuracy:0.930\nIteration: 6402, learning rate: 0.00690, Loss: 0.1922, Accuracy:0.938\nIteration: 6403, learning rate: 0.00690, Loss: 0.2800, Accuracy:0.867\nIteration: 6404, learning rate: 0.00690, Loss: 0.1520, Accuracy:0.945\nIteration: 6405, learning rate: 0.00690, Loss: 0.1792, Accuracy:0.930\nIteration: 6406, learning rate: 0.00690, Loss: 0.1776, Accuracy:0.930\nIteration: 6407, learning rate: 0.00690, Loss: 0.1535, Accuracy:0.953\nIteration: 6408, learning rate: 0.00690, Loss: 0.1765, Accuracy:0.930\nIteration: 6409, learning rate: 0.00690, Loss: 0.2471, Accuracy:0.906\nIteration: 6410, learning rate: 0.00690, Loss: 0.2176, Accuracy:0.938\nIteration: 6411, learning rate: 0.00690, Loss: 0.3209, Accuracy:0.875\nIteration: 6412, learning rate: 0.00690, Loss: 0.3160, Accuracy:0.828\nIteration: 6413, learning rate: 0.00690, Loss: 0.2041, Accuracy:0.906\nIteration: 6414, learning rate: 0.00690, Loss: 0.2726, Accuracy:0.898\nIteration: 6415, learning rate: 0.00690, Loss: 0.2758, Accuracy:0.883\nIteration: 6416, learning rate: 0.00690, Loss: 0.1538, Accuracy:0.922\nIteration: 6417, learning rate: 0.00690, Loss: 0.2144, Accuracy:0.903\nEpoch: 207, Loss: 0.2224, Accuracy:0.911, Val Loss: 0.2954, Val Accuracy: 0.875\nIteration: 6418, learning rate: 0.00689, Loss: 0.1479, Accuracy:0.945\nIteration: 6419, learning rate: 0.00689, Loss: 0.2640, Accuracy:0.906\nIteration: 6420, learning rate: 0.00689, Loss: 0.2079, Accuracy:0.930\nIteration: 6421, learning rate: 0.00689, Loss: 0.1383, Accuracy:0.930\nIteration: 6422, learning rate: 0.00689, Loss: 0.1831, Accuracy:0.914\nIteration: 6423, learning rate: 0.00689, Loss: 0.3802, Accuracy:0.875\nIteration: 6424, learning rate: 0.00689, Loss: 0.2257, Accuracy:0.922\nIteration: 6425, learning rate: 0.00689, Loss: 0.2938, Accuracy:0.867\nIteration: 6426, learning rate: 0.00689, Loss: 0.1600, Accuracy:0.938\nIteration: 6427, learning rate: 0.00689, Loss: 0.2167, Accuracy:0.898\nIteration: 6428, learning rate: 0.00689, Loss: 0.2193, Accuracy:0.938\nIteration: 6429, learning rate: 0.00689, Loss: 0.1989, Accuracy:0.906\nIteration: 6430, learning rate: 0.00689, Loss: 0.2486, Accuracy:0.898\nIteration: 6431, learning rate: 0.00689, Loss: 0.2052, Accuracy:0.930\nIteration: 6432, learning rate: 0.00689, Loss: 0.1956, Accuracy:0.914\nIteration: 6433, learning rate: 0.00689, Loss: 0.3022, Accuracy:0.867\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6434, learning rate: 0.00689, Loss: 0.2723, Accuracy:0.906\nIteration: 6435, learning rate: 0.00689, Loss: 0.2203, Accuracy:0.914\nIteration: 6436, learning rate: 0.00689, Loss: 0.2333, Accuracy:0.891\nIteration: 6437, learning rate: 0.00689, Loss: 0.1295, Accuracy:0.961\nIteration: 6438, learning rate: 0.00689, Loss: 0.1855, Accuracy:0.914\nIteration: 6439, learning rate: 0.00689, Loss: 0.1759, Accuracy:0.953\nIteration: 6440, learning rate: 0.00689, Loss: 0.1715, Accuracy:0.930\nIteration: 6441, learning rate: 0.00689, Loss: 0.3002, Accuracy:0.867\nIteration: 6442, learning rate: 0.00689, Loss: 0.2924, Accuracy:0.891\nIteration: 6443, learning rate: 0.00689, Loss: 0.2295, Accuracy:0.883\nIteration: 6444, learning rate: 0.00689, Loss: 0.2125, Accuracy:0.922\nIteration: 6445, learning rate: 0.00689, Loss: 0.1697, Accuracy:0.938\nIteration: 6446, learning rate: 0.00689, Loss: 0.1770, Accuracy:0.930\nIteration: 6447, learning rate: 0.00689, Loss: 0.2224, Accuracy:0.875\nIteration: 6448, learning rate: 0.00689, Loss: 0.2383, Accuracy:0.903\nEpoch: 208, Loss: 0.2199, Accuracy:0.911, Val Loss: 0.3111, Val Accuracy: 0.869\nIteration: 6449, learning rate: 0.00689, Loss: 0.2342, Accuracy:0.914\nIteration: 6450, learning rate: 0.00688, Loss: 0.2433, Accuracy:0.906\nIteration: 6451, learning rate: 0.00688, Loss: 0.2060, Accuracy:0.930\nIteration: 6452, learning rate: 0.00688, Loss: 0.1378, Accuracy:0.969\nIteration: 6453, learning rate: 0.00688, Loss: 0.2972, Accuracy:0.875\nIteration: 6454, learning rate: 0.00688, Loss: 0.2186, Accuracy:0.922\nIteration: 6455, learning rate: 0.00688, Loss: 0.2039, Accuracy:0.898\nIteration: 6456, learning rate: 0.00688, Loss: 0.1708, Accuracy:0.953\nIteration: 6457, learning rate: 0.00688, Loss: 0.2210, Accuracy:0.891\nIteration: 6458, learning rate: 0.00688, Loss: 0.1715, Accuracy:0.953\nIteration: 6459, learning rate: 0.00688, Loss: 0.1573, Accuracy:0.945\nIteration: 6460, learning rate: 0.00688, Loss: 0.3457, Accuracy:0.867\nIteration: 6461, learning rate: 0.00688, Loss: 0.2014, Accuracy:0.906\nIteration: 6462, learning rate: 0.00688, Loss: 0.2211, Accuracy:0.906\nIteration: 6463, learning rate: 0.00688, Loss: 0.2630, Accuracy:0.891\nIteration: 6464, learning rate: 0.00688, Loss: 0.1884, Accuracy:0.906\nIteration: 6465, learning rate: 0.00688, Loss: 0.1523, Accuracy:0.961\nIteration: 6466, learning rate: 0.00688, Loss: 0.1339, Accuracy:0.945\nIteration: 6467, learning rate: 0.00688, Loss: 0.2590, Accuracy:0.891\nIteration: 6468, learning rate: 0.00688, Loss: 0.1806, Accuracy:0.930\nIteration: 6469, learning rate: 0.00688, Loss: 0.1563, Accuracy:0.938\nIteration: 6470, learning rate: 0.00688, Loss: 0.2579, Accuracy:0.898\nIteration: 6471, learning rate: 0.00688, Loss: 0.2238, Accuracy:0.906\nIteration: 6472, learning rate: 0.00688, Loss: 0.3034, Accuracy:0.875\nIteration: 6473, learning rate: 0.00688, Loss: 0.2593, Accuracy:0.891\nIteration: 6474, learning rate: 0.00688, Loss: 0.2197, Accuracy:0.883\nIteration: 6475, learning rate: 0.00688, Loss: 0.1343, Accuracy:0.961\nIteration: 6476, learning rate: 0.00688, Loss: 0.2867, Accuracy:0.875\nIteration: 6477, learning rate: 0.00688, Loss: 0.2235, Accuracy:0.922\nIteration: 6478, learning rate: 0.00688, Loss: 0.2478, Accuracy:0.898\nIteration: 6479, learning rate: 0.00688, Loss: 0.1769, Accuracy:0.935\nEpoch: 209, Loss: 0.2160, Accuracy:0.914, Val Loss: 0.3003, Val Accuracy: 0.878\nIteration: 6480, learning rate: 0.00688, Loss: 0.2705, Accuracy:0.883\nIteration: 6481, learning rate: 0.00688, Loss: 0.2868, Accuracy:0.898\nIteration: 6482, learning rate: 0.00687, Loss: 0.2051, Accuracy:0.938\nIteration: 6483, learning rate: 0.00687, Loss: 0.3626, Accuracy:0.836\nIteration: 6484, learning rate: 0.00687, Loss: 0.1763, Accuracy:0.914\nIteration: 6485, learning rate: 0.00687, Loss: 0.2889, Accuracy:0.867\nIteration: 6486, learning rate: 0.00687, Loss: 0.1865, Accuracy:0.922\nIteration: 6487, learning rate: 0.00687, Loss: 0.1853, Accuracy:0.930\nIteration: 6488, learning rate: 0.00687, Loss: 0.2350, Accuracy:0.898\nIteration: 6489, learning rate: 0.00687, Loss: 0.1872, Accuracy:0.938\nIteration: 6490, learning rate: 0.00687, Loss: 0.3037, Accuracy:0.883\nIteration: 6491, learning rate: 0.00687, Loss: 0.1604, Accuracy:0.945\nIteration: 6492, learning rate: 0.00687, Loss: 0.2263, Accuracy:0.930\nIteration: 6493, learning rate: 0.00687, Loss: 0.1760, Accuracy:0.938\nIteration: 6494, learning rate: 0.00687, Loss: 0.2750, Accuracy:0.875\nIteration: 6495, learning rate: 0.00687, Loss: 0.2190, Accuracy:0.898\nIteration: 6496, learning rate: 0.00687, Loss: 0.2536, Accuracy:0.875\nIteration: 6497, learning rate: 0.00687, Loss: 0.1933, Accuracy:0.922\nIteration: 6498, learning rate: 0.00687, Loss: 0.1779, Accuracy:0.945\nIteration: 6499, learning rate: 0.00687, Loss: 0.1879, Accuracy:0.945\nIteration: 6500, learning rate: 0.00687, Loss: 0.2393, Accuracy:0.883\nIteration: 6501, learning rate: 0.00687, Loss: 0.2335, Accuracy:0.891\nIteration: 6502, learning rate: 0.00687, Loss: 0.1854, Accuracy:0.922\nIteration: 6503, learning rate: 0.00687, Loss: 0.1653, Accuracy:0.945\nIteration: 6504, learning rate: 0.00687, Loss: 0.3165, Accuracy:0.852\nIteration: 6505, learning rate: 0.00687, Loss: 0.2504, Accuracy:0.914\nIteration: 6506, learning rate: 0.00687, Loss: 0.2765, Accuracy:0.883\nIteration: 6507, learning rate: 0.00687, Loss: 0.2126, Accuracy:0.914\nIteration: 6508, learning rate: 0.00687, Loss: 0.2738, Accuracy:0.898\nIteration: 6509, learning rate: 0.00687, Loss: 0.2588, Accuracy:0.898\nIteration: 6510, learning rate: 0.00687, Loss: 0.2640, Accuracy:0.892\nEpoch: 210, Loss: 0.2333, Accuracy:0.906, Val Loss: 0.3811, Val Accuracy: 0.830\nIteration: 6511, learning rate: 0.00687, Loss: 0.2617, Accuracy:0.898\nIteration: 6512, learning rate: 0.00687, Loss: 0.1778, Accuracy:0.938\nIteration: 6513, learning rate: 0.00687, Loss: 0.1523, Accuracy:0.953\nIteration: 6514, learning rate: 0.00686, Loss: 0.1631, Accuracy:0.938\nIteration: 6515, learning rate: 0.00686, Loss: 0.2381, Accuracy:0.891\nIteration: 6516, learning rate: 0.00686, Loss: 0.2276, Accuracy:0.891\nIteration: 6517, learning rate: 0.00686, Loss: 0.2204, Accuracy:0.898\nIteration: 6518, learning rate: 0.00686, Loss: 0.2802, Accuracy:0.898\nIteration: 6519, learning rate: 0.00686, Loss: 0.2747, Accuracy:0.898\nIteration: 6520, learning rate: 0.00686, Loss: 0.1816, Accuracy:0.930\nIteration: 6521, learning rate: 0.00686, Loss: 0.1875, Accuracy:0.930\nIteration: 6522, learning rate: 0.00686, Loss: 0.2490, Accuracy:0.914\nIteration: 6523, learning rate: 0.00686, Loss: 0.2210, Accuracy:0.922\nIteration: 6524, learning rate: 0.00686, Loss: 0.1629, Accuracy:0.945\nIteration: 6525, learning rate: 0.00686, Loss: 0.1958, Accuracy:0.938\nIteration: 6526, learning rate: 0.00686, Loss: 0.1854, Accuracy:0.953\nIteration: 6527, learning rate: 0.00686, Loss: 0.2181, Accuracy:0.914\nIteration: 6528, learning rate: 0.00686, Loss: 0.2209, Accuracy:0.898\nIteration: 6529, learning rate: 0.00686, Loss: 0.1485, Accuracy:0.953\nIteration: 6530, learning rate: 0.00686, Loss: 0.3015, Accuracy:0.859\nIteration: 6531, learning rate: 0.00686, Loss: 0.2668, Accuracy:0.883\nIteration: 6532, learning rate: 0.00686, Loss: 0.2117, Accuracy:0.906\nIteration: 6533, learning rate: 0.00686, Loss: 0.2427, Accuracy:0.914\nIteration: 6534, learning rate: 0.00686, Loss: 0.1384, Accuracy:0.984\nIteration: 6535, learning rate: 0.00686, Loss: 0.1998, Accuracy:0.898\nIteration: 6536, learning rate: 0.00686, Loss: 0.1992, Accuracy:0.930\nIteration: 6537, learning rate: 0.00686, Loss: 0.3225, Accuracy:0.875\nIteration: 6538, learning rate: 0.00686, Loss: 0.1462, Accuracy:0.953\nIteration: 6539, learning rate: 0.00686, Loss: 0.1902, Accuracy:0.945\nIteration: 6540, learning rate: 0.00686, Loss: 0.2448, Accuracy:0.883\nIteration: 6541, learning rate: 0.00686, Loss: 0.1359, Accuracy:0.957\nEpoch: 211, Loss: 0.2118, Accuracy:0.919, Val Loss: 0.2886, Val Accuracy: 0.885\nIteration: 6542, learning rate: 0.00686, Loss: 0.2031, Accuracy:0.922\nIteration: 6543, learning rate: 0.00686, Loss: 0.2449, Accuracy:0.914\nIteration: 6544, learning rate: 0.00686, Loss: 0.2412, Accuracy:0.906\nIteration: 6545, learning rate: 0.00686, Loss: 0.2296, Accuracy:0.898\nIteration: 6546, learning rate: 0.00685, Loss: 0.1731, Accuracy:0.930\nIteration: 6547, learning rate: 0.00685, Loss: 0.2983, Accuracy:0.867\nIteration: 6548, learning rate: 0.00685, Loss: 0.2030, Accuracy:0.922\nIteration: 6549, learning rate: 0.00685, Loss: 0.1863, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6550, learning rate: 0.00685, Loss: 0.1750, Accuracy:0.938\nIteration: 6551, learning rate: 0.00685, Loss: 0.2131, Accuracy:0.898\nIteration: 6552, learning rate: 0.00685, Loss: 0.1933, Accuracy:0.930\nIteration: 6553, learning rate: 0.00685, Loss: 0.2737, Accuracy:0.914\nIteration: 6554, learning rate: 0.00685, Loss: 0.1535, Accuracy:0.938\nIteration: 6555, learning rate: 0.00685, Loss: 0.2842, Accuracy:0.906\nIteration: 6556, learning rate: 0.00685, Loss: 0.1951, Accuracy:0.930\nIteration: 6557, learning rate: 0.00685, Loss: 0.2126, Accuracy:0.938\nIteration: 6558, learning rate: 0.00685, Loss: 0.1665, Accuracy:0.930\nIteration: 6559, learning rate: 0.00685, Loss: 0.1966, Accuracy:0.953\nIteration: 6560, learning rate: 0.00685, Loss: 0.2497, Accuracy:0.891\nIteration: 6561, learning rate: 0.00685, Loss: 0.1996, Accuracy:0.914\nIteration: 6562, learning rate: 0.00685, Loss: 0.2077, Accuracy:0.922\nIteration: 6563, learning rate: 0.00685, Loss: 0.2411, Accuracy:0.898\nIteration: 6564, learning rate: 0.00685, Loss: 0.2759, Accuracy:0.875\nIteration: 6565, learning rate: 0.00685, Loss: 0.1678, Accuracy:0.945\nIteration: 6566, learning rate: 0.00685, Loss: 0.2314, Accuracy:0.891\nIteration: 6567, learning rate: 0.00685, Loss: 0.1460, Accuracy:0.953\nIteration: 6568, learning rate: 0.00685, Loss: 0.2985, Accuracy:0.891\nIteration: 6569, learning rate: 0.00685, Loss: 0.1887, Accuracy:0.945\nIteration: 6570, learning rate: 0.00685, Loss: 0.2919, Accuracy:0.883\nIteration: 6571, learning rate: 0.00685, Loss: 0.1506, Accuracy:0.938\nIteration: 6572, learning rate: 0.00685, Loss: 0.2122, Accuracy:0.882\nEpoch: 212, Loss: 0.2163, Accuracy:0.916, Val Loss: 0.3057, Val Accuracy: 0.864\nIteration: 6573, learning rate: 0.00685, Loss: 0.1800, Accuracy:0.938\nIteration: 6574, learning rate: 0.00685, Loss: 0.1711, Accuracy:0.953\nIteration: 6575, learning rate: 0.00685, Loss: 0.2597, Accuracy:0.875\nIteration: 6576, learning rate: 0.00685, Loss: 0.2485, Accuracy:0.883\nIteration: 6577, learning rate: 0.00685, Loss: 0.2692, Accuracy:0.922\nIteration: 6578, learning rate: 0.00684, Loss: 0.2242, Accuracy:0.906\nIteration: 6579, learning rate: 0.00684, Loss: 0.1726, Accuracy:0.906\nIteration: 6580, learning rate: 0.00684, Loss: 0.1813, Accuracy:0.938\nIteration: 6581, learning rate: 0.00684, Loss: 0.1953, Accuracy:0.922\nIteration: 6582, learning rate: 0.00684, Loss: 0.2728, Accuracy:0.859\nIteration: 6583, learning rate: 0.00684, Loss: 0.2255, Accuracy:0.906\nIteration: 6584, learning rate: 0.00684, Loss: 0.2547, Accuracy:0.883\nIteration: 6585, learning rate: 0.00684, Loss: 0.2196, Accuracy:0.930\nIteration: 6586, learning rate: 0.00684, Loss: 0.2549, Accuracy:0.898\nIteration: 6587, learning rate: 0.00684, Loss: 0.2397, Accuracy:0.906\nIteration: 6588, learning rate: 0.00684, Loss: 0.2894, Accuracy:0.898\nIteration: 6589, learning rate: 0.00684, Loss: 0.1847, Accuracy:0.922\nIteration: 6590, learning rate: 0.00684, Loss: 0.2117, Accuracy:0.922\nIteration: 6591, learning rate: 0.00684, Loss: 0.2461, Accuracy:0.914\nIteration: 6592, learning rate: 0.00684, Loss: 0.1870, Accuracy:0.930\nIteration: 6593, learning rate: 0.00684, Loss: 0.1791, Accuracy:0.930\nIteration: 6594, learning rate: 0.00684, Loss: 0.2710, Accuracy:0.875\nIteration: 6595, learning rate: 0.00684, Loss: 0.2314, Accuracy:0.898\nIteration: 6596, learning rate: 0.00684, Loss: 0.2085, Accuracy:0.914\nIteration: 6597, learning rate: 0.00684, Loss: 0.1764, Accuracy:0.953\nIteration: 6598, learning rate: 0.00684, Loss: 0.1775, Accuracy:0.945\nIteration: 6599, learning rate: 0.00684, Loss: 0.2370, Accuracy:0.898\nIteration: 6600, learning rate: 0.00684, Loss: 0.2934, Accuracy:0.852\nIteration: 6601, learning rate: 0.00684, Loss: 0.2215, Accuracy:0.922\nIteration: 6602, learning rate: 0.00684, Loss: 0.2423, Accuracy:0.898\nIteration: 6603, learning rate: 0.00684, Loss: 0.3049, Accuracy:0.871\nEpoch: 213, Loss: 0.2268, Accuracy:0.909, Val Loss: 0.2879, Val Accuracy: 0.878\nIteration: 6604, learning rate: 0.00684, Loss: 0.1955, Accuracy:0.922\nIteration: 6605, learning rate: 0.00684, Loss: 0.2359, Accuracy:0.906\nIteration: 6606, learning rate: 0.00684, Loss: 0.1760, Accuracy:0.953\nIteration: 6607, learning rate: 0.00684, Loss: 0.1495, Accuracy:0.961\nIteration: 6608, learning rate: 0.00684, Loss: 0.2979, Accuracy:0.867\nIteration: 6609, learning rate: 0.00684, Loss: 0.1685, Accuracy:0.945\nIteration: 6610, learning rate: 0.00684, Loss: 0.2751, Accuracy:0.867\nIteration: 6611, learning rate: 0.00683, Loss: 0.1929, Accuracy:0.930\nIteration: 6612, learning rate: 0.00683, Loss: 0.2266, Accuracy:0.914\nIteration: 6613, learning rate: 0.00683, Loss: 0.2032, Accuracy:0.906\nIteration: 6614, learning rate: 0.00683, Loss: 0.2379, Accuracy:0.875\nIteration: 6615, learning rate: 0.00683, Loss: 0.2160, Accuracy:0.922\nIteration: 6616, learning rate: 0.00683, Loss: 0.2525, Accuracy:0.898\nIteration: 6617, learning rate: 0.00683, Loss: 0.1924, Accuracy:0.922\nIteration: 6618, learning rate: 0.00683, Loss: 0.1655, Accuracy:0.922\nIteration: 6619, learning rate: 0.00683, Loss: 0.2557, Accuracy:0.914\nIteration: 6620, learning rate: 0.00683, Loss: 0.3230, Accuracy:0.859\nIteration: 6621, learning rate: 0.00683, Loss: 0.1829, Accuracy:0.930\nIteration: 6622, learning rate: 0.00683, Loss: 0.2346, Accuracy:0.914\nIteration: 6623, learning rate: 0.00683, Loss: 0.2157, Accuracy:0.914\nIteration: 6624, learning rate: 0.00683, Loss: 0.2526, Accuracy:0.898\nIteration: 6625, learning rate: 0.00683, Loss: 0.2509, Accuracy:0.875\nIteration: 6626, learning rate: 0.00683, Loss: 0.2175, Accuracy:0.898\nIteration: 6627, learning rate: 0.00683, Loss: 0.2038, Accuracy:0.930\nIteration: 6628, learning rate: 0.00683, Loss: 0.2313, Accuracy:0.914\nIteration: 6629, learning rate: 0.00683, Loss: 0.2629, Accuracy:0.898\nIteration: 6630, learning rate: 0.00683, Loss: 0.1749, Accuracy:0.922\nIteration: 6631, learning rate: 0.00683, Loss: 0.1523, Accuracy:0.938\nIteration: 6632, learning rate: 0.00683, Loss: 0.1742, Accuracy:0.938\nIteration: 6633, learning rate: 0.00683, Loss: 0.1626, Accuracy:0.945\nIteration: 6634, learning rate: 0.00683, Loss: 0.2046, Accuracy:0.925\nEpoch: 214, Loss: 0.2156, Accuracy:0.914, Val Loss: 0.2753, Val Accuracy: 0.867\nIteration: 6635, learning rate: 0.00683, Loss: 0.2030, Accuracy:0.930\nIteration: 6636, learning rate: 0.00683, Loss: 0.2673, Accuracy:0.875\nIteration: 6637, learning rate: 0.00683, Loss: 0.1811, Accuracy:0.945\nIteration: 6638, learning rate: 0.00683, Loss: 0.1593, Accuracy:0.945\nIteration: 6639, learning rate: 0.00683, Loss: 0.2536, Accuracy:0.898\nIteration: 6640, learning rate: 0.00683, Loss: 0.2148, Accuracy:0.898\nIteration: 6641, learning rate: 0.00683, Loss: 0.2390, Accuracy:0.891\nIteration: 6642, learning rate: 0.00683, Loss: 0.1669, Accuracy:0.922\nIteration: 6643, learning rate: 0.00682, Loss: 0.2577, Accuracy:0.859\nIteration: 6644, learning rate: 0.00682, Loss: 0.1554, Accuracy:0.938\nIteration: 6645, learning rate: 0.00682, Loss: 0.1825, Accuracy:0.938\nIteration: 6646, learning rate: 0.00682, Loss: 0.2951, Accuracy:0.867\nIteration: 6647, learning rate: 0.00682, Loss: 0.1661, Accuracy:0.930\nIteration: 6648, learning rate: 0.00682, Loss: 0.1911, Accuracy:0.938\nIteration: 6649, learning rate: 0.00682, Loss: 0.1499, Accuracy:0.938\nIteration: 6650, learning rate: 0.00682, Loss: 0.2167, Accuracy:0.938\nIteration: 6651, learning rate: 0.00682, Loss: 0.3111, Accuracy:0.883\nIteration: 6652, learning rate: 0.00682, Loss: 0.2609, Accuracy:0.875\nIteration: 6653, learning rate: 0.00682, Loss: 0.2525, Accuracy:0.883\nIteration: 6654, learning rate: 0.00682, Loss: 0.2165, Accuracy:0.914\nIteration: 6655, learning rate: 0.00682, Loss: 0.2009, Accuracy:0.930\nIteration: 6656, learning rate: 0.00682, Loss: 0.1878, Accuracy:0.945\nIteration: 6657, learning rate: 0.00682, Loss: 0.2973, Accuracy:0.891\nIteration: 6658, learning rate: 0.00682, Loss: 0.2323, Accuracy:0.906\nIteration: 6659, learning rate: 0.00682, Loss: 0.2449, Accuracy:0.914\nIteration: 6660, learning rate: 0.00682, Loss: 0.2231, Accuracy:0.898\nIteration: 6661, learning rate: 0.00682, Loss: 0.2160, Accuracy:0.930\nIteration: 6662, learning rate: 0.00682, Loss: 0.2275, Accuracy:0.891\nIteration: 6663, learning rate: 0.00682, Loss: 0.1502, Accuracy:0.953\nIteration: 6664, learning rate: 0.00682, Loss: 0.2834, Accuracy:0.883\nIteration: 6665, learning rate: 0.00682, Loss: 0.2624, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 215, Loss: 0.2215, Accuracy:0.912, Val Loss: 0.2757, Val Accuracy: 0.888\nIteration: 6666, learning rate: 0.00682, Loss: 0.2445, Accuracy:0.945\nIteration: 6667, learning rate: 0.00682, Loss: 0.1564, Accuracy:0.922\nIteration: 6668, learning rate: 0.00682, Loss: 0.2759, Accuracy:0.898\nIteration: 6669, learning rate: 0.00682, Loss: 0.0989, Accuracy:0.977\nIteration: 6670, learning rate: 0.00682, Loss: 0.1891, Accuracy:0.930\nIteration: 6671, learning rate: 0.00682, Loss: 0.2024, Accuracy:0.930\nIteration: 6672, learning rate: 0.00682, Loss: 0.2782, Accuracy:0.883\nIteration: 6673, learning rate: 0.00682, Loss: 0.2137, Accuracy:0.891\nIteration: 6674, learning rate: 0.00682, Loss: 0.2064, Accuracy:0.922\nIteration: 6675, learning rate: 0.00682, Loss: 0.2336, Accuracy:0.883\nIteration: 6676, learning rate: 0.00681, Loss: 0.1712, Accuracy:0.930\nIteration: 6677, learning rate: 0.00681, Loss: 0.2816, Accuracy:0.883\nIteration: 6678, learning rate: 0.00681, Loss: 0.1964, Accuracy:0.922\nIteration: 6679, learning rate: 0.00681, Loss: 0.1988, Accuracy:0.914\nIteration: 6680, learning rate: 0.00681, Loss: 0.1355, Accuracy:0.953\nIteration: 6681, learning rate: 0.00681, Loss: 0.1933, Accuracy:0.914\nIteration: 6682, learning rate: 0.00681, Loss: 0.1616, Accuracy:0.961\nIteration: 6683, learning rate: 0.00681, Loss: 0.1888, Accuracy:0.930\nIteration: 6684, learning rate: 0.00681, Loss: 0.3579, Accuracy:0.859\nIteration: 6685, learning rate: 0.00681, Loss: 0.2064, Accuracy:0.922\nIteration: 6686, learning rate: 0.00681, Loss: 0.2357, Accuracy:0.914\nIteration: 6687, learning rate: 0.00681, Loss: 0.3712, Accuracy:0.844\nIteration: 6688, learning rate: 0.00681, Loss: 0.2169, Accuracy:0.906\nIteration: 6689, learning rate: 0.00681, Loss: 0.1749, Accuracy:0.938\nIteration: 6690, learning rate: 0.00681, Loss: 0.2318, Accuracy:0.914\nIteration: 6691, learning rate: 0.00681, Loss: 0.2746, Accuracy:0.883\nIteration: 6692, learning rate: 0.00681, Loss: 0.3019, Accuracy:0.883\nIteration: 6693, learning rate: 0.00681, Loss: 0.2100, Accuracy:0.898\nIteration: 6694, learning rate: 0.00681, Loss: 0.1810, Accuracy:0.922\nIteration: 6695, learning rate: 0.00681, Loss: 0.1747, Accuracy:0.961\nIteration: 6696, learning rate: 0.00681, Loss: 0.2131, Accuracy:0.946\nEpoch: 216, Loss: 0.2186, Accuracy:0.915, Val Loss: 0.3153, Val Accuracy: 0.869\nIteration: 6697, learning rate: 0.00681, Loss: 0.1874, Accuracy:0.906\nIteration: 6698, learning rate: 0.00681, Loss: 0.2260, Accuracy:0.914\nIteration: 6699, learning rate: 0.00681, Loss: 0.1755, Accuracy:0.953\nIteration: 6700, learning rate: 0.00681, Loss: 0.1419, Accuracy:0.961\nIteration: 6701, learning rate: 0.00681, Loss: 0.3104, Accuracy:0.844\nIteration: 6702, learning rate: 0.00681, Loss: 0.2683, Accuracy:0.914\nIteration: 6703, learning rate: 0.00681, Loss: 0.2623, Accuracy:0.891\nIteration: 6704, learning rate: 0.00681, Loss: 0.2436, Accuracy:0.914\nIteration: 6705, learning rate: 0.00681, Loss: 0.1971, Accuracy:0.930\nIteration: 6706, learning rate: 0.00681, Loss: 0.1286, Accuracy:0.961\nIteration: 6707, learning rate: 0.00681, Loss: 0.1790, Accuracy:0.922\nIteration: 6708, learning rate: 0.00680, Loss: 0.2439, Accuracy:0.898\nIteration: 6709, learning rate: 0.00680, Loss: 0.2432, Accuracy:0.898\nIteration: 6710, learning rate: 0.00680, Loss: 0.2671, Accuracy:0.859\nIteration: 6711, learning rate: 0.00680, Loss: 0.2071, Accuracy:0.930\nIteration: 6712, learning rate: 0.00680, Loss: 0.2546, Accuracy:0.891\nIteration: 6713, learning rate: 0.00680, Loss: 0.1495, Accuracy:0.961\nIteration: 6714, learning rate: 0.00680, Loss: 0.2230, Accuracy:0.914\nIteration: 6715, learning rate: 0.00680, Loss: 0.2304, Accuracy:0.891\nIteration: 6716, learning rate: 0.00680, Loss: 0.2437, Accuracy:0.906\nIteration: 6717, learning rate: 0.00680, Loss: 0.1976, Accuracy:0.922\nIteration: 6718, learning rate: 0.00680, Loss: 0.2973, Accuracy:0.906\nIteration: 6719, learning rate: 0.00680, Loss: 0.2233, Accuracy:0.922\nIteration: 6720, learning rate: 0.00680, Loss: 0.2491, Accuracy:0.914\nIteration: 6721, learning rate: 0.00680, Loss: 0.2993, Accuracy:0.883\nIteration: 6722, learning rate: 0.00680, Loss: 0.2212, Accuracy:0.922\nIteration: 6723, learning rate: 0.00680, Loss: 0.1918, Accuracy:0.922\nIteration: 6724, learning rate: 0.00680, Loss: 0.1884, Accuracy:0.922\nIteration: 6725, learning rate: 0.00680, Loss: 0.1606, Accuracy:0.930\nIteration: 6726, learning rate: 0.00680, Loss: 0.2052, Accuracy:0.922\nIteration: 6727, learning rate: 0.00680, Loss: 0.2701, Accuracy:0.914\nEpoch: 217, Loss: 0.2221, Accuracy:0.914, Val Loss: 0.3107, Val Accuracy: 0.858\nIteration: 6728, learning rate: 0.00680, Loss: 0.1680, Accuracy:0.961\nIteration: 6729, learning rate: 0.00680, Loss: 0.2440, Accuracy:0.906\nIteration: 6730, learning rate: 0.00680, Loss: 0.2000, Accuracy:0.922\nIteration: 6731, learning rate: 0.00680, Loss: 0.1580, Accuracy:0.953\nIteration: 6732, learning rate: 0.00680, Loss: 0.2044, Accuracy:0.930\nIteration: 6733, learning rate: 0.00680, Loss: 0.1297, Accuracy:0.953\nIteration: 6734, learning rate: 0.00680, Loss: 0.2019, Accuracy:0.906\nIteration: 6735, learning rate: 0.00680, Loss: 0.2273, Accuracy:0.898\nIteration: 6736, learning rate: 0.00680, Loss: 0.2011, Accuracy:0.914\nIteration: 6737, learning rate: 0.00680, Loss: 0.1795, Accuracy:0.953\nIteration: 6738, learning rate: 0.00680, Loss: 0.1736, Accuracy:0.906\nIteration: 6739, learning rate: 0.00680, Loss: 0.2787, Accuracy:0.883\nIteration: 6740, learning rate: 0.00680, Loss: 0.2072, Accuracy:0.922\nIteration: 6741, learning rate: 0.00679, Loss: 0.2355, Accuracy:0.875\nIteration: 6742, learning rate: 0.00679, Loss: 0.2297, Accuracy:0.938\nIteration: 6743, learning rate: 0.00679, Loss: 0.3008, Accuracy:0.891\nIteration: 6744, learning rate: 0.00679, Loss: 0.1690, Accuracy:0.922\nIteration: 6745, learning rate: 0.00679, Loss: 0.2105, Accuracy:0.914\nIteration: 6746, learning rate: 0.00679, Loss: 0.2335, Accuracy:0.891\nIteration: 6747, learning rate: 0.00679, Loss: 0.2741, Accuracy:0.906\nIteration: 6748, learning rate: 0.00679, Loss: 0.2876, Accuracy:0.875\nIteration: 6749, learning rate: 0.00679, Loss: 0.1509, Accuracy:0.953\nIteration: 6750, learning rate: 0.00679, Loss: 0.2315, Accuracy:0.906\nIteration: 6751, learning rate: 0.00679, Loss: 0.2319, Accuracy:0.906\nIteration: 6752, learning rate: 0.00679, Loss: 0.1745, Accuracy:0.930\nIteration: 6753, learning rate: 0.00679, Loss: 0.2181, Accuracy:0.930\nIteration: 6754, learning rate: 0.00679, Loss: 0.2278, Accuracy:0.914\nIteration: 6755, learning rate: 0.00679, Loss: 0.2640, Accuracy:0.891\nIteration: 6756, learning rate: 0.00679, Loss: 0.1589, Accuracy:0.930\nIteration: 6757, learning rate: 0.00679, Loss: 0.2130, Accuracy:0.898\nIteration: 6758, learning rate: 0.00679, Loss: 0.3280, Accuracy:0.849\nEpoch: 218, Loss: 0.2165, Accuracy:0.914, Val Loss: 0.2842, Val Accuracy: 0.874\nIteration: 6759, learning rate: 0.00679, Loss: 0.2250, Accuracy:0.891\nIteration: 6760, learning rate: 0.00679, Loss: 0.1703, Accuracy:0.922\nIteration: 6761, learning rate: 0.00679, Loss: 0.1754, Accuracy:0.930\nIteration: 6762, learning rate: 0.00679, Loss: 0.1939, Accuracy:0.898\nIteration: 6763, learning rate: 0.00679, Loss: 0.2534, Accuracy:0.891\nIteration: 6764, learning rate: 0.00679, Loss: 0.2625, Accuracy:0.898\nIteration: 6765, learning rate: 0.00679, Loss: 0.2432, Accuracy:0.898\nIteration: 6766, learning rate: 0.00679, Loss: 0.2187, Accuracy:0.906\nIteration: 6767, learning rate: 0.00679, Loss: 0.1672, Accuracy:0.945\nIteration: 6768, learning rate: 0.00679, Loss: 0.1690, Accuracy:0.922\nIteration: 6769, learning rate: 0.00679, Loss: 0.2151, Accuracy:0.906\nIteration: 6770, learning rate: 0.00679, Loss: 0.1649, Accuracy:0.961\nIteration: 6771, learning rate: 0.00679, Loss: 0.2909, Accuracy:0.867\nIteration: 6772, learning rate: 0.00679, Loss: 0.1428, Accuracy:0.953\nIteration: 6773, learning rate: 0.00679, Loss: 0.2142, Accuracy:0.898\nIteration: 6774, learning rate: 0.00678, Loss: 0.1950, Accuracy:0.922\nIteration: 6775, learning rate: 0.00678, Loss: 0.2688, Accuracy:0.883\nIteration: 6776, learning rate: 0.00678, Loss: 0.2793, Accuracy:0.867\nIteration: 6777, learning rate: 0.00678, Loss: 0.2534, Accuracy:0.883\nIteration: 6778, learning rate: 0.00678, Loss: 0.1320, Accuracy:0.969\nIteration: 6779, learning rate: 0.00678, Loss: 0.2101, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6780, learning rate: 0.00678, Loss: 0.2127, Accuracy:0.898\nIteration: 6781, learning rate: 0.00678, Loss: 0.2359, Accuracy:0.883\nIteration: 6782, learning rate: 0.00678, Loss: 0.2736, Accuracy:0.898\nIteration: 6783, learning rate: 0.00678, Loss: 0.1944, Accuracy:0.922\nIteration: 6784, learning rate: 0.00678, Loss: 0.1666, Accuracy:0.914\nIteration: 6785, learning rate: 0.00678, Loss: 0.2841, Accuracy:0.883\nIteration: 6786, learning rate: 0.00678, Loss: 0.2392, Accuracy:0.914\nIteration: 6787, learning rate: 0.00678, Loss: 0.2178, Accuracy:0.922\nIteration: 6788, learning rate: 0.00678, Loss: 0.2442, Accuracy:0.883\nIteration: 6789, learning rate: 0.00678, Loss: 0.2666, Accuracy:0.860\nEpoch: 219, Loss: 0.2187, Accuracy:0.906, Val Loss: 0.3142, Val Accuracy: 0.856\nIteration: 6790, learning rate: 0.00678, Loss: 0.1687, Accuracy:0.906\nIteration: 6791, learning rate: 0.00678, Loss: 0.2282, Accuracy:0.898\nIteration: 6792, learning rate: 0.00678, Loss: 0.2213, Accuracy:0.898\nIteration: 6793, learning rate: 0.00678, Loss: 0.2449, Accuracy:0.906\nIteration: 6794, learning rate: 0.00678, Loss: 0.2250, Accuracy:0.906\nIteration: 6795, learning rate: 0.00678, Loss: 0.2052, Accuracy:0.938\nIteration: 6796, learning rate: 0.00678, Loss: 0.1755, Accuracy:0.930\nIteration: 6797, learning rate: 0.00678, Loss: 0.2071, Accuracy:0.930\nIteration: 6798, learning rate: 0.00678, Loss: 0.1832, Accuracy:0.922\nIteration: 6799, learning rate: 0.00678, Loss: 0.2291, Accuracy:0.898\nIteration: 6800, learning rate: 0.00678, Loss: 0.1762, Accuracy:0.914\nIteration: 6801, learning rate: 0.00678, Loss: 0.2383, Accuracy:0.883\nIteration: 6802, learning rate: 0.00678, Loss: 0.2854, Accuracy:0.867\nIteration: 6803, learning rate: 0.00678, Loss: 0.2067, Accuracy:0.906\nIteration: 6804, learning rate: 0.00678, Loss: 0.2555, Accuracy:0.891\nIteration: 6805, learning rate: 0.00678, Loss: 0.2772, Accuracy:0.875\nIteration: 6806, learning rate: 0.00678, Loss: 0.2686, Accuracy:0.875\nIteration: 6807, learning rate: 0.00677, Loss: 0.2374, Accuracy:0.898\nIteration: 6808, learning rate: 0.00677, Loss: 0.1702, Accuracy:0.953\nIteration: 6809, learning rate: 0.00677, Loss: 0.1995, Accuracy:0.898\nIteration: 6810, learning rate: 0.00677, Loss: 0.2075, Accuracy:0.914\nIteration: 6811, learning rate: 0.00677, Loss: 0.2288, Accuracy:0.906\nIteration: 6812, learning rate: 0.00677, Loss: 0.2570, Accuracy:0.898\nIteration: 6813, learning rate: 0.00677, Loss: 0.2701, Accuracy:0.891\nIteration: 6814, learning rate: 0.00677, Loss: 0.1791, Accuracy:0.945\nIteration: 6815, learning rate: 0.00677, Loss: 0.1883, Accuracy:0.930\nIteration: 6816, learning rate: 0.00677, Loss: 0.1845, Accuracy:0.922\nIteration: 6817, learning rate: 0.00677, Loss: 0.2337, Accuracy:0.922\nIteration: 6818, learning rate: 0.00677, Loss: 0.1728, Accuracy:0.938\nIteration: 6819, learning rate: 0.00677, Loss: 0.2656, Accuracy:0.883\nIteration: 6820, learning rate: 0.00677, Loss: 0.2029, Accuracy:0.882\nEpoch: 220, Loss: 0.2191, Accuracy:0.907, Val Loss: 0.2545, Val Accuracy: 0.892\nval_loss_decreased from 0.2680 to 0.2545, saving_checkpoint for epoch 220\nIteration: 6821, learning rate: 0.00677, Loss: 0.3318, Accuracy:0.852\nIteration: 6822, learning rate: 0.00677, Loss: 0.2245, Accuracy:0.898\nIteration: 6823, learning rate: 0.00677, Loss: 0.2244, Accuracy:0.922\nIteration: 6824, learning rate: 0.00677, Loss: 0.2273, Accuracy:0.891\nIteration: 6825, learning rate: 0.00677, Loss: 0.2365, Accuracy:0.898\nIteration: 6826, learning rate: 0.00677, Loss: 0.2908, Accuracy:0.883\nIteration: 6827, learning rate: 0.00677, Loss: 0.1963, Accuracy:0.930\nIteration: 6828, learning rate: 0.00677, Loss: 0.3006, Accuracy:0.898\nIteration: 6829, learning rate: 0.00677, Loss: 0.2297, Accuracy:0.930\nIteration: 6830, learning rate: 0.00677, Loss: 0.2166, Accuracy:0.891\nIteration: 6831, learning rate: 0.00677, Loss: 0.3084, Accuracy:0.852\nIteration: 6832, learning rate: 0.00677, Loss: 0.2016, Accuracy:0.930\nIteration: 6833, learning rate: 0.00677, Loss: 0.3141, Accuracy:0.859\nIteration: 6834, learning rate: 0.00677, Loss: 0.1486, Accuracy:0.945\nIteration: 6835, learning rate: 0.00677, Loss: 0.1972, Accuracy:0.914\nIteration: 6836, learning rate: 0.00677, Loss: 0.2975, Accuracy:0.883\nIteration: 6837, learning rate: 0.00677, Loss: 0.2370, Accuracy:0.891\nIteration: 6838, learning rate: 0.00677, Loss: 0.2443, Accuracy:0.859\nIteration: 6839, learning rate: 0.00677, Loss: 0.1553, Accuracy:0.945\nIteration: 6840, learning rate: 0.00676, Loss: 0.2397, Accuracy:0.891\nIteration: 6841, learning rate: 0.00676, Loss: 0.2222, Accuracy:0.891\nIteration: 6842, learning rate: 0.00676, Loss: 0.1978, Accuracy:0.945\nIteration: 6843, learning rate: 0.00676, Loss: 0.2331, Accuracy:0.914\nIteration: 6844, learning rate: 0.00676, Loss: 0.2482, Accuracy:0.898\nIteration: 6845, learning rate: 0.00676, Loss: 0.1559, Accuracy:0.938\nIteration: 6846, learning rate: 0.00676, Loss: 0.2273, Accuracy:0.914\nIteration: 6847, learning rate: 0.00676, Loss: 0.1991, Accuracy:0.945\nIteration: 6848, learning rate: 0.00676, Loss: 0.1998, Accuracy:0.898\nIteration: 6849, learning rate: 0.00676, Loss: 0.2041, Accuracy:0.938\nIteration: 6850, learning rate: 0.00676, Loss: 0.2110, Accuracy:0.945\nIteration: 6851, learning rate: 0.00676, Loss: 0.2016, Accuracy:0.925\nEpoch: 221, Loss: 0.2298, Accuracy:0.907, Val Loss: 0.2842, Val Accuracy: 0.882\nIteration: 6852, learning rate: 0.00676, Loss: 0.1627, Accuracy:0.938\nIteration: 6853, learning rate: 0.00676, Loss: 0.2737, Accuracy:0.898\nIteration: 6854, learning rate: 0.00676, Loss: 0.2587, Accuracy:0.883\nIteration: 6855, learning rate: 0.00676, Loss: 0.2225, Accuracy:0.891\nIteration: 6856, learning rate: 0.00676, Loss: 0.1865, Accuracy:0.906\nIteration: 6857, learning rate: 0.00676, Loss: 0.2301, Accuracy:0.906\nIteration: 6858, learning rate: 0.00676, Loss: 0.3171, Accuracy:0.891\nIteration: 6859, learning rate: 0.00676, Loss: 0.2034, Accuracy:0.922\nIteration: 6860, learning rate: 0.00676, Loss: 0.2873, Accuracy:0.891\nIteration: 6861, learning rate: 0.00676, Loss: 0.1844, Accuracy:0.906\nIteration: 6862, learning rate: 0.00676, Loss: 0.1429, Accuracy:0.961\nIteration: 6863, learning rate: 0.00676, Loss: 0.2176, Accuracy:0.914\nIteration: 6864, learning rate: 0.00676, Loss: 0.2426, Accuracy:0.914\nIteration: 6865, learning rate: 0.00676, Loss: 0.2138, Accuracy:0.914\nIteration: 6866, learning rate: 0.00676, Loss: 0.2201, Accuracy:0.898\nIteration: 6867, learning rate: 0.00676, Loss: 0.2931, Accuracy:0.875\nIteration: 6868, learning rate: 0.00676, Loss: 0.2569, Accuracy:0.898\nIteration: 6869, learning rate: 0.00676, Loss: 0.2572, Accuracy:0.883\nIteration: 6870, learning rate: 0.00676, Loss: 0.2035, Accuracy:0.938\nIteration: 6871, learning rate: 0.00676, Loss: 0.2131, Accuracy:0.891\nIteration: 6872, learning rate: 0.00676, Loss: 0.2262, Accuracy:0.867\nIteration: 6873, learning rate: 0.00675, Loss: 0.1983, Accuracy:0.945\nIteration: 6874, learning rate: 0.00675, Loss: 0.1585, Accuracy:0.953\nIteration: 6875, learning rate: 0.00675, Loss: 0.1890, Accuracy:0.891\nIteration: 6876, learning rate: 0.00675, Loss: 0.1187, Accuracy:0.953\nIteration: 6877, learning rate: 0.00675, Loss: 0.2848, Accuracy:0.898\nIteration: 6878, learning rate: 0.00675, Loss: 0.2338, Accuracy:0.914\nIteration: 6879, learning rate: 0.00675, Loss: 0.2238, Accuracy:0.883\nIteration: 6880, learning rate: 0.00675, Loss: 0.1952, Accuracy:0.938\nIteration: 6881, learning rate: 0.00675, Loss: 0.1681, Accuracy:0.930\nIteration: 6882, learning rate: 0.00675, Loss: 0.2436, Accuracy:0.914\nEpoch: 222, Loss: 0.2202, Accuracy:0.910, Val Loss: 0.2947, Val Accuracy: 0.867\nIteration: 6883, learning rate: 0.00675, Loss: 0.1632, Accuracy:0.938\nIteration: 6884, learning rate: 0.00675, Loss: 0.2698, Accuracy:0.891\nIteration: 6885, learning rate: 0.00675, Loss: 0.1973, Accuracy:0.930\nIteration: 6886, learning rate: 0.00675, Loss: 0.2742, Accuracy:0.891\nIteration: 6887, learning rate: 0.00675, Loss: 0.1984, Accuracy:0.930\nIteration: 6888, learning rate: 0.00675, Loss: 0.2378, Accuracy:0.906\nIteration: 6889, learning rate: 0.00675, Loss: 0.2863, Accuracy:0.898\nIteration: 6890, learning rate: 0.00675, Loss: 0.2489, Accuracy:0.867\nIteration: 6891, learning rate: 0.00675, Loss: 0.2620, Accuracy:0.898\nIteration: 6892, learning rate: 0.00675, Loss: 0.2269, Accuracy:0.891\nIteration: 6893, learning rate: 0.00675, Loss: 0.3068, Accuracy:0.844\nIteration: 6894, learning rate: 0.00675, Loss: 0.2043, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 6895, learning rate: 0.00675, Loss: 0.2781, Accuracy:0.867\nIteration: 6896, learning rate: 0.00675, Loss: 0.1914, Accuracy:0.914\nIteration: 6897, learning rate: 0.00675, Loss: 0.2995, Accuracy:0.875\nIteration: 6898, learning rate: 0.00675, Loss: 0.1593, Accuracy:0.945\nIteration: 6899, learning rate: 0.00675, Loss: 0.1997, Accuracy:0.906\nIteration: 6900, learning rate: 0.00675, Loss: 0.2293, Accuracy:0.906\nIteration: 6901, learning rate: 0.00675, Loss: 0.2199, Accuracy:0.891\nIteration: 6902, learning rate: 0.00675, Loss: 0.2237, Accuracy:0.898\nIteration: 6903, learning rate: 0.00675, Loss: 0.2846, Accuracy:0.891\nIteration: 6904, learning rate: 0.00675, Loss: 0.2080, Accuracy:0.906\nIteration: 6905, learning rate: 0.00675, Loss: 0.1477, Accuracy:0.938\nIteration: 6906, learning rate: 0.00675, Loss: 0.1351, Accuracy:0.945\nIteration: 6907, learning rate: 0.00674, Loss: 0.1885, Accuracy:0.906\nIteration: 6908, learning rate: 0.00674, Loss: 0.2752, Accuracy:0.883\nIteration: 6909, learning rate: 0.00674, Loss: 0.1838, Accuracy:0.891\nIteration: 6910, learning rate: 0.00674, Loss: 0.2749, Accuracy:0.906\nIteration: 6911, learning rate: 0.00674, Loss: 0.2744, Accuracy:0.859\nIteration: 6912, learning rate: 0.00674, Loss: 0.1885, Accuracy:0.898\nIteration: 6913, learning rate: 0.00674, Loss: 0.1972, Accuracy:0.935\nEpoch: 223, Loss: 0.2269, Accuracy:0.902, Val Loss: 0.3129, Val Accuracy: 0.867\nIteration: 6914, learning rate: 0.00674, Loss: 0.2301, Accuracy:0.883\nIteration: 6915, learning rate: 0.00674, Loss: 0.2166, Accuracy:0.898\nIteration: 6916, learning rate: 0.00674, Loss: 0.2218, Accuracy:0.891\nIteration: 6917, learning rate: 0.00674, Loss: 0.1830, Accuracy:0.922\nIteration: 6918, learning rate: 0.00674, Loss: 0.1776, Accuracy:0.938\nIteration: 6919, learning rate: 0.00674, Loss: 0.1963, Accuracy:0.945\nIteration: 6920, learning rate: 0.00674, Loss: 0.2751, Accuracy:0.906\nIteration: 6921, learning rate: 0.00674, Loss: 0.1480, Accuracy:0.961\nIteration: 6922, learning rate: 0.00674, Loss: 0.2583, Accuracy:0.883\nIteration: 6923, learning rate: 0.00674, Loss: 0.1807, Accuracy:0.914\nIteration: 6924, learning rate: 0.00674, Loss: 0.3070, Accuracy:0.906\nIteration: 6925, learning rate: 0.00674, Loss: 0.2485, Accuracy:0.875\nIteration: 6926, learning rate: 0.00674, Loss: 0.2491, Accuracy:0.906\nIteration: 6927, learning rate: 0.00674, Loss: 0.2287, Accuracy:0.914\nIteration: 6928, learning rate: 0.00674, Loss: 0.2567, Accuracy:0.930\nIteration: 6929, learning rate: 0.00674, Loss: 0.3165, Accuracy:0.859\nIteration: 6930, learning rate: 0.00674, Loss: 0.2169, Accuracy:0.930\nIteration: 6931, learning rate: 0.00674, Loss: 0.2201, Accuracy:0.898\nIteration: 6932, learning rate: 0.00674, Loss: 0.1949, Accuracy:0.938\nIteration: 6933, learning rate: 0.00674, Loss: 0.1622, Accuracy:0.938\nIteration: 6934, learning rate: 0.00674, Loss: 0.1838, Accuracy:0.938\nIteration: 6935, learning rate: 0.00674, Loss: 0.2029, Accuracy:0.922\nIteration: 6936, learning rate: 0.00674, Loss: 0.2443, Accuracy:0.922\nIteration: 6937, learning rate: 0.00674, Loss: 0.1558, Accuracy:0.961\nIteration: 6938, learning rate: 0.00674, Loss: 0.1365, Accuracy:0.953\nIteration: 6939, learning rate: 0.00674, Loss: 0.2522, Accuracy:0.906\nIteration: 6940, learning rate: 0.00673, Loss: 0.1999, Accuracy:0.906\nIteration: 6941, learning rate: 0.00673, Loss: 0.1540, Accuracy:0.953\nIteration: 6942, learning rate: 0.00673, Loss: 0.2026, Accuracy:0.922\nIteration: 6943, learning rate: 0.00673, Loss: 0.1746, Accuracy:0.930\nIteration: 6944, learning rate: 0.00673, Loss: 0.4313, Accuracy:0.806\nEpoch: 224, Loss: 0.2202, Accuracy:0.915, Val Loss: 0.2858, Val Accuracy: 0.882\nIteration: 6945, learning rate: 0.00673, Loss: 0.2429, Accuracy:0.906\nIteration: 6946, learning rate: 0.00673, Loss: 0.2704, Accuracy:0.906\nIteration: 6947, learning rate: 0.00673, Loss: 0.1780, Accuracy:0.930\nIteration: 6948, learning rate: 0.00673, Loss: 0.1802, Accuracy:0.938\nIteration: 6949, learning rate: 0.00673, Loss: 0.1648, Accuracy:0.930\nIteration: 6950, learning rate: 0.00673, Loss: 0.2089, Accuracy:0.898\nIteration: 6951, learning rate: 0.00673, Loss: 0.1807, Accuracy:0.914\nIteration: 6952, learning rate: 0.00673, Loss: 0.1979, Accuracy:0.914\nIteration: 6953, learning rate: 0.00673, Loss: 0.3015, Accuracy:0.867\nIteration: 6954, learning rate: 0.00673, Loss: 0.1685, Accuracy:0.945\nIteration: 6955, learning rate: 0.00673, Loss: 0.2429, Accuracy:0.898\nIteration: 6956, learning rate: 0.00673, Loss: 0.2502, Accuracy:0.914\nIteration: 6957, learning rate: 0.00673, Loss: 0.1554, Accuracy:0.969\nIteration: 6958, learning rate: 0.00673, Loss: 0.2396, Accuracy:0.891\nIteration: 6959, learning rate: 0.00673, Loss: 0.2252, Accuracy:0.898\nIteration: 6960, learning rate: 0.00673, Loss: 0.3022, Accuracy:0.867\nIteration: 6961, learning rate: 0.00673, Loss: 0.2150, Accuracy:0.945\nIteration: 6962, learning rate: 0.00673, Loss: 0.2146, Accuracy:0.906\nIteration: 6963, learning rate: 0.00673, Loss: 0.1898, Accuracy:0.914\nIteration: 6964, learning rate: 0.00673, Loss: 0.2679, Accuracy:0.891\nIteration: 6965, learning rate: 0.00673, Loss: 0.2199, Accuracy:0.898\nIteration: 6966, learning rate: 0.00673, Loss: 0.2709, Accuracy:0.883\nIteration: 6967, learning rate: 0.00673, Loss: 0.2311, Accuracy:0.875\nIteration: 6968, learning rate: 0.00673, Loss: 0.2046, Accuracy:0.891\nIteration: 6969, learning rate: 0.00673, Loss: 0.2208, Accuracy:0.898\nIteration: 6970, learning rate: 0.00673, Loss: 0.1850, Accuracy:0.938\nIteration: 6971, learning rate: 0.00673, Loss: 0.2229, Accuracy:0.914\nIteration: 6972, learning rate: 0.00673, Loss: 0.2349, Accuracy:0.906\nIteration: 6973, learning rate: 0.00673, Loss: 0.1886, Accuracy:0.922\nIteration: 6974, learning rate: 0.00672, Loss: 0.2513, Accuracy:0.891\nIteration: 6975, learning rate: 0.00672, Loss: 0.2340, Accuracy:0.903\nEpoch: 225, Loss: 0.2213, Accuracy:0.908, Val Loss: 0.2782, Val Accuracy: 0.895\nIteration: 6976, learning rate: 0.00672, Loss: 0.3401, Accuracy:0.859\nIteration: 6977, learning rate: 0.00672, Loss: 0.1854, Accuracy:0.938\nIteration: 6978, learning rate: 0.00672, Loss: 0.1698, Accuracy:0.930\nIteration: 6979, learning rate: 0.00672, Loss: 0.2804, Accuracy:0.898\nIteration: 6980, learning rate: 0.00672, Loss: 0.2204, Accuracy:0.891\nIteration: 6981, learning rate: 0.00672, Loss: 0.1176, Accuracy:0.969\nIteration: 6982, learning rate: 0.00672, Loss: 0.2136, Accuracy:0.914\nIteration: 6983, learning rate: 0.00672, Loss: 0.1251, Accuracy:0.953\nIteration: 6984, learning rate: 0.00672, Loss: 0.2094, Accuracy:0.930\nIteration: 6985, learning rate: 0.00672, Loss: 0.1494, Accuracy:0.945\nIteration: 6986, learning rate: 0.00672, Loss: 0.2670, Accuracy:0.891\nIteration: 6987, learning rate: 0.00672, Loss: 0.2866, Accuracy:0.852\nIteration: 6988, learning rate: 0.00672, Loss: 0.2081, Accuracy:0.922\nIteration: 6989, learning rate: 0.00672, Loss: 0.2443, Accuracy:0.914\nIteration: 6990, learning rate: 0.00672, Loss: 0.2613, Accuracy:0.891\nIteration: 6991, learning rate: 0.00672, Loss: 0.2301, Accuracy:0.914\nIteration: 6992, learning rate: 0.00672, Loss: 0.2441, Accuracy:0.914\nIteration: 6993, learning rate: 0.00672, Loss: 0.1695, Accuracy:0.914\nIteration: 6994, learning rate: 0.00672, Loss: 0.2894, Accuracy:0.867\nIteration: 6995, learning rate: 0.00672, Loss: 0.1899, Accuracy:0.906\nIteration: 6996, learning rate: 0.00672, Loss: 0.1799, Accuracy:0.938\nIteration: 6997, learning rate: 0.00672, Loss: 0.2262, Accuracy:0.922\nIteration: 6998, learning rate: 0.00672, Loss: 0.1763, Accuracy:0.922\nIteration: 6999, learning rate: 0.00672, Loss: 0.1850, Accuracy:0.953\nIteration: 7000, learning rate: 0.00672, Loss: 0.2636, Accuracy:0.891\nIteration: 7001, learning rate: 0.00672, Loss: 0.1644, Accuracy:0.945\nIteration: 7002, learning rate: 0.00672, Loss: 0.2428, Accuracy:0.898\nIteration: 7003, learning rate: 0.00672, Loss: 0.1618, Accuracy:0.930\nIteration: 7004, learning rate: 0.00672, Loss: 0.1738, Accuracy:0.906\nIteration: 7005, learning rate: 0.00672, Loss: 0.1891, Accuracy:0.945\nIteration: 7006, learning rate: 0.00672, Loss: 0.2535, Accuracy:0.871\nEpoch: 226, Loss: 0.2135, Accuracy:0.914, Val Loss: 0.2935, Val Accuracy: 0.860\nIteration: 7007, learning rate: 0.00672, Loss: 0.2278, Accuracy:0.906\nIteration: 7008, learning rate: 0.00671, Loss: 0.1727, Accuracy:0.922\nIteration: 7009, learning rate: 0.00671, Loss: 0.1718, Accuracy:0.938\nIteration: 7010, learning rate: 0.00671, Loss: 0.2142, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7011, learning rate: 0.00671, Loss: 0.2350, Accuracy:0.883\nIteration: 7012, learning rate: 0.00671, Loss: 0.2197, Accuracy:0.930\nIteration: 7013, learning rate: 0.00671, Loss: 0.2337, Accuracy:0.883\nIteration: 7014, learning rate: 0.00671, Loss: 0.2282, Accuracy:0.898\nIteration: 7015, learning rate: 0.00671, Loss: 0.1963, Accuracy:0.930\nIteration: 7016, learning rate: 0.00671, Loss: 0.1771, Accuracy:0.922\nIteration: 7017, learning rate: 0.00671, Loss: 0.2131, Accuracy:0.891\nIteration: 7018, learning rate: 0.00671, Loss: 0.2014, Accuracy:0.922\nIteration: 7019, learning rate: 0.00671, Loss: 0.1688, Accuracy:0.930\nIteration: 7020, learning rate: 0.00671, Loss: 0.2348, Accuracy:0.914\nIteration: 7021, learning rate: 0.00671, Loss: 0.2222, Accuracy:0.914\nIteration: 7022, learning rate: 0.00671, Loss: 0.2322, Accuracy:0.875\nIteration: 7023, learning rate: 0.00671, Loss: 0.2414, Accuracy:0.922\nIteration: 7024, learning rate: 0.00671, Loss: 0.2663, Accuracy:0.883\nIteration: 7025, learning rate: 0.00671, Loss: 0.2088, Accuracy:0.906\nIteration: 7026, learning rate: 0.00671, Loss: 0.3156, Accuracy:0.891\nIteration: 7027, learning rate: 0.00671, Loss: 0.2514, Accuracy:0.891\nIteration: 7028, learning rate: 0.00671, Loss: 0.2250, Accuracy:0.906\nIteration: 7029, learning rate: 0.00671, Loss: 0.1712, Accuracy:0.922\nIteration: 7030, learning rate: 0.00671, Loss: 0.1553, Accuracy:0.945\nIteration: 7031, learning rate: 0.00671, Loss: 0.2583, Accuracy:0.883\nIteration: 7032, learning rate: 0.00671, Loss: 0.1907, Accuracy:0.906\nIteration: 7033, learning rate: 0.00671, Loss: 0.1732, Accuracy:0.953\nIteration: 7034, learning rate: 0.00671, Loss: 0.1822, Accuracy:0.945\nIteration: 7035, learning rate: 0.00671, Loss: 0.2437, Accuracy:0.883\nIteration: 7036, learning rate: 0.00671, Loss: 0.2198, Accuracy:0.922\nIteration: 7037, learning rate: 0.00671, Loss: 0.2152, Accuracy:0.925\nEpoch: 227, Loss: 0.2151, Accuracy:0.911, Val Loss: 0.2905, Val Accuracy: 0.879\nIteration: 7038, learning rate: 0.00671, Loss: 0.2173, Accuracy:0.898\nIteration: 7039, learning rate: 0.00671, Loss: 0.1958, Accuracy:0.922\nIteration: 7040, learning rate: 0.00671, Loss: 0.2396, Accuracy:0.906\nIteration: 7041, learning rate: 0.00670, Loss: 0.1811, Accuracy:0.930\nIteration: 7042, learning rate: 0.00670, Loss: 0.2079, Accuracy:0.906\nIteration: 7043, learning rate: 0.00670, Loss: 0.1262, Accuracy:0.953\nIteration: 7044, learning rate: 0.00670, Loss: 0.1981, Accuracy:0.922\nIteration: 7045, learning rate: 0.00670, Loss: 0.2680, Accuracy:0.875\nIteration: 7046, learning rate: 0.00670, Loss: 0.2712, Accuracy:0.906\nIteration: 7047, learning rate: 0.00670, Loss: 0.1653, Accuracy:0.930\nIteration: 7048, learning rate: 0.00670, Loss: 0.1645, Accuracy:0.945\nIteration: 7049, learning rate: 0.00670, Loss: 0.1734, Accuracy:0.953\nIteration: 7050, learning rate: 0.00670, Loss: 0.2062, Accuracy:0.953\nIteration: 7051, learning rate: 0.00670, Loss: 0.1597, Accuracy:0.938\nIteration: 7052, learning rate: 0.00670, Loss: 0.1751, Accuracy:0.930\nIteration: 7053, learning rate: 0.00670, Loss: 0.1880, Accuracy:0.938\nIteration: 7054, learning rate: 0.00670, Loss: 0.2582, Accuracy:0.883\nIteration: 7055, learning rate: 0.00670, Loss: 0.2193, Accuracy:0.930\nIteration: 7056, learning rate: 0.00670, Loss: 0.1558, Accuracy:0.930\nIteration: 7057, learning rate: 0.00670, Loss: 0.2427, Accuracy:0.906\nIteration: 7058, learning rate: 0.00670, Loss: 0.2930, Accuracy:0.883\nIteration: 7059, learning rate: 0.00670, Loss: 0.2111, Accuracy:0.906\nIteration: 7060, learning rate: 0.00670, Loss: 0.1734, Accuracy:0.938\nIteration: 7061, learning rate: 0.00670, Loss: 0.2728, Accuracy:0.898\nIteration: 7062, learning rate: 0.00670, Loss: 0.2129, Accuracy:0.914\nIteration: 7063, learning rate: 0.00670, Loss: 0.1576, Accuracy:0.938\nIteration: 7064, learning rate: 0.00670, Loss: 0.2336, Accuracy:0.914\nIteration: 7065, learning rate: 0.00670, Loss: 0.3461, Accuracy:0.891\nIteration: 7066, learning rate: 0.00670, Loss: 0.2173, Accuracy:0.906\nIteration: 7067, learning rate: 0.00670, Loss: 0.3101, Accuracy:0.891\nIteration: 7068, learning rate: 0.00670, Loss: 0.1529, Accuracy:0.946\nEpoch: 228, Loss: 0.2127, Accuracy:0.919, Val Loss: 0.2958, Val Accuracy: 0.882\nIteration: 7069, learning rate: 0.00670, Loss: 0.1683, Accuracy:0.938\nIteration: 7070, learning rate: 0.00670, Loss: 0.1818, Accuracy:0.930\nIteration: 7071, learning rate: 0.00670, Loss: 0.1869, Accuracy:0.938\nIteration: 7072, learning rate: 0.00670, Loss: 0.2642, Accuracy:0.875\nIteration: 7073, learning rate: 0.00670, Loss: 0.2156, Accuracy:0.906\nIteration: 7074, learning rate: 0.00670, Loss: 0.2571, Accuracy:0.859\nIteration: 7075, learning rate: 0.00669, Loss: 0.2123, Accuracy:0.945\nIteration: 7076, learning rate: 0.00669, Loss: 0.2778, Accuracy:0.875\nIteration: 7077, learning rate: 0.00669, Loss: 0.1710, Accuracy:0.938\nIteration: 7078, learning rate: 0.00669, Loss: 0.2173, Accuracy:0.922\nIteration: 7079, learning rate: 0.00669, Loss: 0.2224, Accuracy:0.930\nIteration: 7080, learning rate: 0.00669, Loss: 0.2498, Accuracy:0.883\nIteration: 7081, learning rate: 0.00669, Loss: 0.1868, Accuracy:0.922\nIteration: 7082, learning rate: 0.00669, Loss: 0.1954, Accuracy:0.930\nIteration: 7083, learning rate: 0.00669, Loss: 0.1962, Accuracy:0.914\nIteration: 7084, learning rate: 0.00669, Loss: 0.3020, Accuracy:0.883\nIteration: 7085, learning rate: 0.00669, Loss: 0.2022, Accuracy:0.922\nIteration: 7086, learning rate: 0.00669, Loss: 0.2119, Accuracy:0.930\nIteration: 7087, learning rate: 0.00669, Loss: 0.1476, Accuracy:0.930\nIteration: 7088, learning rate: 0.00669, Loss: 0.2362, Accuracy:0.906\nIteration: 7089, learning rate: 0.00669, Loss: 0.1105, Accuracy:0.977\nIteration: 7090, learning rate: 0.00669, Loss: 0.1545, Accuracy:0.953\nIteration: 7091, learning rate: 0.00669, Loss: 0.2162, Accuracy:0.914\nIteration: 7092, learning rate: 0.00669, Loss: 0.2399, Accuracy:0.906\nIteration: 7093, learning rate: 0.00669, Loss: 0.2188, Accuracy:0.906\nIteration: 7094, learning rate: 0.00669, Loss: 0.1147, Accuracy:0.961\nIteration: 7095, learning rate: 0.00669, Loss: 0.1804, Accuracy:0.953\nIteration: 7096, learning rate: 0.00669, Loss: 0.1858, Accuracy:0.945\nIteration: 7097, learning rate: 0.00669, Loss: 0.1484, Accuracy:0.930\nIteration: 7098, learning rate: 0.00669, Loss: 0.2334, Accuracy:0.891\nIteration: 7099, learning rate: 0.00669, Loss: 0.1984, Accuracy:0.925\nEpoch: 229, Loss: 0.2033, Accuracy:0.920, Val Loss: 0.3293, Val Accuracy: 0.878\nIteration: 7100, learning rate: 0.00669, Loss: 0.2716, Accuracy:0.898\nIteration: 7101, learning rate: 0.00669, Loss: 0.1208, Accuracy:0.961\nIteration: 7102, learning rate: 0.00669, Loss: 0.2293, Accuracy:0.906\nIteration: 7103, learning rate: 0.00669, Loss: 0.1648, Accuracy:0.938\nIteration: 7104, learning rate: 0.00669, Loss: 0.2908, Accuracy:0.875\nIteration: 7105, learning rate: 0.00669, Loss: 0.0891, Accuracy:0.977\nIteration: 7106, learning rate: 0.00669, Loss: 0.2188, Accuracy:0.914\nIteration: 7107, learning rate: 0.00669, Loss: 0.2639, Accuracy:0.883\nIteration: 7108, learning rate: 0.00669, Loss: 0.1856, Accuracy:0.914\nIteration: 7109, learning rate: 0.00668, Loss: 0.1597, Accuracy:0.922\nIteration: 7110, learning rate: 0.00668, Loss: 0.2029, Accuracy:0.891\nIteration: 7111, learning rate: 0.00668, Loss: 0.1323, Accuracy:0.953\nIteration: 7112, learning rate: 0.00668, Loss: 0.2086, Accuracy:0.930\nIteration: 7113, learning rate: 0.00668, Loss: 0.3083, Accuracy:0.883\nIteration: 7114, learning rate: 0.00668, Loss: 0.2014, Accuracy:0.891\nIteration: 7115, learning rate: 0.00668, Loss: 0.2007, Accuracy:0.914\nIteration: 7116, learning rate: 0.00668, Loss: 0.2176, Accuracy:0.922\nIteration: 7117, learning rate: 0.00668, Loss: 0.2051, Accuracy:0.922\nIteration: 7118, learning rate: 0.00668, Loss: 0.2972, Accuracy:0.852\nIteration: 7119, learning rate: 0.00668, Loss: 0.1865, Accuracy:0.922\nIteration: 7120, learning rate: 0.00668, Loss: 0.2223, Accuracy:0.898\nIteration: 7121, learning rate: 0.00668, Loss: 0.1687, Accuracy:0.938\nIteration: 7122, learning rate: 0.00668, Loss: 0.2553, Accuracy:0.914\nIteration: 7123, learning rate: 0.00668, Loss: 0.2050, Accuracy:0.914\nIteration: 7124, learning rate: 0.00668, Loss: 0.1682, Accuracy:0.930\nIteration: 7125, learning rate: 0.00668, Loss: 0.2114, Accuracy:0.914\nIteration: 7126, learning rate: 0.00668, Loss: 0.1487, Accuracy:0.945\nIteration: 7127, learning rate: 0.00668, Loss: 0.1766, Accuracy:0.945\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7128, learning rate: 0.00668, Loss: 0.2048, Accuracy:0.922\nIteration: 7129, learning rate: 0.00668, Loss: 0.3207, Accuracy:0.852\nIteration: 7130, learning rate: 0.00668, Loss: 0.3130, Accuracy:0.849\nEpoch: 230, Loss: 0.2113, Accuracy:0.912, Val Loss: 0.2615, Val Accuracy: 0.893\nIteration: 7131, learning rate: 0.00668, Loss: 0.2886, Accuracy:0.836\nIteration: 7132, learning rate: 0.00668, Loss: 0.2611, Accuracy:0.883\nIteration: 7133, learning rate: 0.00668, Loss: 0.2092, Accuracy:0.914\nIteration: 7134, learning rate: 0.00668, Loss: 0.1435, Accuracy:0.953\nIteration: 7135, learning rate: 0.00668, Loss: 0.2203, Accuracy:0.891\nIteration: 7136, learning rate: 0.00668, Loss: 0.1769, Accuracy:0.930\nIteration: 7137, learning rate: 0.00668, Loss: 0.2168, Accuracy:0.930\nIteration: 7138, learning rate: 0.00668, Loss: 0.2084, Accuracy:0.914\nIteration: 7139, learning rate: 0.00668, Loss: 0.1907, Accuracy:0.938\nIteration: 7140, learning rate: 0.00668, Loss: 0.2032, Accuracy:0.922\nIteration: 7141, learning rate: 0.00668, Loss: 0.2324, Accuracy:0.914\nIteration: 7142, learning rate: 0.00668, Loss: 0.1943, Accuracy:0.906\nIteration: 7143, learning rate: 0.00668, Loss: 0.1779, Accuracy:0.922\nIteration: 7144, learning rate: 0.00667, Loss: 0.1794, Accuracy:0.938\nIteration: 7145, learning rate: 0.00667, Loss: 0.2418, Accuracy:0.891\nIteration: 7146, learning rate: 0.00667, Loss: 0.2179, Accuracy:0.914\nIteration: 7147, learning rate: 0.00667, Loss: 0.1943, Accuracy:0.914\nIteration: 7148, learning rate: 0.00667, Loss: 0.2279, Accuracy:0.953\nIteration: 7149, learning rate: 0.00667, Loss: 0.2380, Accuracy:0.883\nIteration: 7150, learning rate: 0.00667, Loss: 0.1532, Accuracy:0.938\nIteration: 7151, learning rate: 0.00667, Loss: 0.1941, Accuracy:0.922\nIteration: 7152, learning rate: 0.00667, Loss: 0.2024, Accuracy:0.906\nIteration: 7153, learning rate: 0.00667, Loss: 0.2259, Accuracy:0.914\nIteration: 7154, learning rate: 0.00667, Loss: 0.2332, Accuracy:0.914\nIteration: 7155, learning rate: 0.00667, Loss: 0.1769, Accuracy:0.914\nIteration: 7156, learning rate: 0.00667, Loss: 0.3286, Accuracy:0.859\nIteration: 7157, learning rate: 0.00667, Loss: 0.1890, Accuracy:0.930\nIteration: 7158, learning rate: 0.00667, Loss: 0.2556, Accuracy:0.906\nIteration: 7159, learning rate: 0.00667, Loss: 0.2699, Accuracy:0.875\nIteration: 7160, learning rate: 0.00667, Loss: 0.2191, Accuracy:0.906\nIteration: 7161, learning rate: 0.00667, Loss: 0.1747, Accuracy:0.925\nEpoch: 231, Loss: 0.2144, Accuracy:0.911, Val Loss: 0.3137, Val Accuracy: 0.868\nIteration: 7162, learning rate: 0.00667, Loss: 0.1875, Accuracy:0.898\nIteration: 7163, learning rate: 0.00667, Loss: 0.2214, Accuracy:0.898\nIteration: 7164, learning rate: 0.00667, Loss: 0.2462, Accuracy:0.906\nIteration: 7165, learning rate: 0.00667, Loss: 0.2148, Accuracy:0.914\nIteration: 7166, learning rate: 0.00667, Loss: 0.1702, Accuracy:0.922\nIteration: 7167, learning rate: 0.00667, Loss: 0.1927, Accuracy:0.945\nIteration: 7168, learning rate: 0.00667, Loss: 0.1439, Accuracy:0.914\nIteration: 7169, learning rate: 0.00667, Loss: 0.2544, Accuracy:0.898\nIteration: 7170, learning rate: 0.00667, Loss: 0.2169, Accuracy:0.914\nIteration: 7171, learning rate: 0.00667, Loss: 0.1995, Accuracy:0.922\nIteration: 7172, learning rate: 0.00667, Loss: 0.2385, Accuracy:0.898\nIteration: 7173, learning rate: 0.00667, Loss: 0.2519, Accuracy:0.875\nIteration: 7174, learning rate: 0.00667, Loss: 0.1487, Accuracy:0.953\nIteration: 7175, learning rate: 0.00667, Loss: 0.1723, Accuracy:0.914\nIteration: 7176, learning rate: 0.00667, Loss: 0.2541, Accuracy:0.906\nIteration: 7177, learning rate: 0.00667, Loss: 0.2266, Accuracy:0.898\nIteration: 7178, learning rate: 0.00666, Loss: 0.1915, Accuracy:0.906\nIteration: 7179, learning rate: 0.00666, Loss: 0.2073, Accuracy:0.914\nIteration: 7180, learning rate: 0.00666, Loss: 0.2319, Accuracy:0.922\nIteration: 7181, learning rate: 0.00666, Loss: 0.2074, Accuracy:0.922\nIteration: 7182, learning rate: 0.00666, Loss: 0.2806, Accuracy:0.859\nIteration: 7183, learning rate: 0.00666, Loss: 0.2664, Accuracy:0.906\nIteration: 7184, learning rate: 0.00666, Loss: 0.2019, Accuracy:0.914\nIteration: 7185, learning rate: 0.00666, Loss: 0.1883, Accuracy:0.938\nIteration: 7186, learning rate: 0.00666, Loss: 0.1804, Accuracy:0.945\nIteration: 7187, learning rate: 0.00666, Loss: 0.1891, Accuracy:0.930\nIteration: 7188, learning rate: 0.00666, Loss: 0.1665, Accuracy:0.930\nIteration: 7189, learning rate: 0.00666, Loss: 0.3005, Accuracy:0.875\nIteration: 7190, learning rate: 0.00666, Loss: 0.2133, Accuracy:0.914\nIteration: 7191, learning rate: 0.00666, Loss: 0.2710, Accuracy:0.891\nIteration: 7192, learning rate: 0.00666, Loss: 0.2364, Accuracy:0.871\nEpoch: 232, Loss: 0.2152, Accuracy:0.910, Val Loss: 0.3055, Val Accuracy: 0.867\nIteration: 7193, learning rate: 0.00666, Loss: 0.1610, Accuracy:0.945\nIteration: 7194, learning rate: 0.00666, Loss: 0.2072, Accuracy:0.938\nIteration: 7195, learning rate: 0.00666, Loss: 0.1910, Accuracy:0.930\nIteration: 7196, learning rate: 0.00666, Loss: 0.1980, Accuracy:0.906\nIteration: 7197, learning rate: 0.00666, Loss: 0.2050, Accuracy:0.906\nIteration: 7198, learning rate: 0.00666, Loss: 0.1550, Accuracy:0.953\nIteration: 7199, learning rate: 0.00666, Loss: 0.1640, Accuracy:0.945\nIteration: 7200, learning rate: 0.00666, Loss: 0.1220, Accuracy:0.977\nIteration: 7201, learning rate: 0.00666, Loss: 0.2602, Accuracy:0.906\nIteration: 7202, learning rate: 0.00666, Loss: 0.2079, Accuracy:0.883\nIteration: 7203, learning rate: 0.00666, Loss: 0.2387, Accuracy:0.922\nIteration: 7204, learning rate: 0.00666, Loss: 0.2676, Accuracy:0.891\nIteration: 7205, learning rate: 0.00666, Loss: 0.1700, Accuracy:0.945\nIteration: 7206, learning rate: 0.00666, Loss: 0.2313, Accuracy:0.898\nIteration: 7207, learning rate: 0.00666, Loss: 0.1746, Accuracy:0.930\nIteration: 7208, learning rate: 0.00666, Loss: 0.2002, Accuracy:0.930\nIteration: 7209, learning rate: 0.00666, Loss: 0.1758, Accuracy:0.922\nIteration: 7210, learning rate: 0.00666, Loss: 0.2463, Accuracy:0.883\nIteration: 7211, learning rate: 0.00666, Loss: 0.1611, Accuracy:0.914\nIteration: 7212, learning rate: 0.00665, Loss: 0.2239, Accuracy:0.914\nIteration: 7213, learning rate: 0.00665, Loss: 0.1741, Accuracy:0.953\nIteration: 7214, learning rate: 0.00665, Loss: 0.2086, Accuracy:0.930\nIteration: 7215, learning rate: 0.00665, Loss: 0.1993, Accuracy:0.898\nIteration: 7216, learning rate: 0.00665, Loss: 0.2011, Accuracy:0.930\nIteration: 7217, learning rate: 0.00665, Loss: 0.1629, Accuracy:0.930\nIteration: 7218, learning rate: 0.00665, Loss: 0.2028, Accuracy:0.930\nIteration: 7219, learning rate: 0.00665, Loss: 0.1709, Accuracy:0.938\nIteration: 7220, learning rate: 0.00665, Loss: 0.1786, Accuracy:0.961\nIteration: 7221, learning rate: 0.00665, Loss: 0.1570, Accuracy:0.938\nIteration: 7222, learning rate: 0.00665, Loss: 0.2271, Accuracy:0.898\nIteration: 7223, learning rate: 0.00665, Loss: 0.2233, Accuracy:0.892\nEpoch: 233, Loss: 0.1957, Accuracy:0.924, Val Loss: 0.3045, Val Accuracy: 0.873\nIteration: 7224, learning rate: 0.00665, Loss: 0.2549, Accuracy:0.891\nIteration: 7225, learning rate: 0.00665, Loss: 0.1335, Accuracy:0.953\nIteration: 7226, learning rate: 0.00665, Loss: 0.2023, Accuracy:0.906\nIteration: 7227, learning rate: 0.00665, Loss: 0.2097, Accuracy:0.906\nIteration: 7228, learning rate: 0.00665, Loss: 0.2049, Accuracy:0.922\nIteration: 7229, learning rate: 0.00665, Loss: 0.1806, Accuracy:0.945\nIteration: 7230, learning rate: 0.00665, Loss: 0.2016, Accuracy:0.914\nIteration: 7231, learning rate: 0.00665, Loss: 0.2229, Accuracy:0.898\nIteration: 7232, learning rate: 0.00665, Loss: 0.2410, Accuracy:0.898\nIteration: 7233, learning rate: 0.00665, Loss: 0.2237, Accuracy:0.898\nIteration: 7234, learning rate: 0.00665, Loss: 0.1568, Accuracy:0.930\nIteration: 7235, learning rate: 0.00665, Loss: 0.3226, Accuracy:0.867\nIteration: 7236, learning rate: 0.00665, Loss: 0.1814, Accuracy:0.906\nIteration: 7237, learning rate: 0.00665, Loss: 0.2133, Accuracy:0.914\nIteration: 7238, learning rate: 0.00665, Loss: 0.1724, Accuracy:0.945\nIteration: 7239, learning rate: 0.00665, Loss: 0.2072, Accuracy:0.938\nIteration: 7240, learning rate: 0.00665, Loss: 0.1850, Accuracy:0.945\nIteration: 7241, learning rate: 0.00665, Loss: 0.1616, Accuracy:0.945\nIteration: 7242, learning rate: 0.00665, Loss: 0.2109, Accuracy:0.898\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7243, learning rate: 0.00665, Loss: 0.2496, Accuracy:0.898\nIteration: 7244, learning rate: 0.00665, Loss: 0.1956, Accuracy:0.922\nIteration: 7245, learning rate: 0.00665, Loss: 0.1944, Accuracy:0.914\nIteration: 7246, learning rate: 0.00665, Loss: 0.2129, Accuracy:0.906\nIteration: 7247, learning rate: 0.00664, Loss: 0.2051, Accuracy:0.914\nIteration: 7248, learning rate: 0.00664, Loss: 0.2132, Accuracy:0.906\nIteration: 7249, learning rate: 0.00664, Loss: 0.1107, Accuracy:0.969\nIteration: 7250, learning rate: 0.00664, Loss: 0.1767, Accuracy:0.930\nIteration: 7251, learning rate: 0.00664, Loss: 0.2101, Accuracy:0.930\nIteration: 7252, learning rate: 0.00664, Loss: 0.1666, Accuracy:0.938\nIteration: 7253, learning rate: 0.00664, Loss: 0.2148, Accuracy:0.914\nIteration: 7254, learning rate: 0.00664, Loss: 0.1813, Accuracy:0.925\nEpoch: 234, Loss: 0.2006, Accuracy:0.919, Val Loss: 0.3087, Val Accuracy: 0.870\nIteration: 7255, learning rate: 0.00664, Loss: 0.1277, Accuracy:0.945\nIteration: 7256, learning rate: 0.00664, Loss: 0.1821, Accuracy:0.930\nIteration: 7257, learning rate: 0.00664, Loss: 0.2386, Accuracy:0.922\nIteration: 7258, learning rate: 0.00664, Loss: 0.1979, Accuracy:0.922\nIteration: 7259, learning rate: 0.00664, Loss: 0.2258, Accuracy:0.898\nIteration: 7260, learning rate: 0.00664, Loss: 0.1306, Accuracy:0.969\nIteration: 7261, learning rate: 0.00664, Loss: 0.1869, Accuracy:0.938\nIteration: 7262, learning rate: 0.00664, Loss: 0.3019, Accuracy:0.867\nIteration: 7263, learning rate: 0.00664, Loss: 0.2412, Accuracy:0.898\nIteration: 7264, learning rate: 0.00664, Loss: 0.1688, Accuracy:0.922\nIteration: 7265, learning rate: 0.00664, Loss: 0.1755, Accuracy:0.922\nIteration: 7266, learning rate: 0.00664, Loss: 0.1598, Accuracy:0.945\nIteration: 7267, learning rate: 0.00664, Loss: 0.2571, Accuracy:0.898\nIteration: 7268, learning rate: 0.00664, Loss: 0.2016, Accuracy:0.914\nIteration: 7269, learning rate: 0.00664, Loss: 0.2641, Accuracy:0.898\nIteration: 7270, learning rate: 0.00664, Loss: 0.2181, Accuracy:0.922\nIteration: 7271, learning rate: 0.00664, Loss: 0.1830, Accuracy:0.938\nIteration: 7272, learning rate: 0.00664, Loss: 0.1606, Accuracy:0.938\nIteration: 7273, learning rate: 0.00664, Loss: 0.1969, Accuracy:0.922\nIteration: 7274, learning rate: 0.00664, Loss: 0.2337, Accuracy:0.898\nIteration: 7275, learning rate: 0.00664, Loss: 0.2821, Accuracy:0.883\nIteration: 7276, learning rate: 0.00664, Loss: 0.2006, Accuracy:0.914\nIteration: 7277, learning rate: 0.00664, Loss: 0.2733, Accuracy:0.875\nIteration: 7278, learning rate: 0.00664, Loss: 0.2041, Accuracy:0.914\nIteration: 7279, learning rate: 0.00664, Loss: 0.2281, Accuracy:0.914\nIteration: 7280, learning rate: 0.00664, Loss: 0.2062, Accuracy:0.922\nIteration: 7281, learning rate: 0.00664, Loss: 0.1046, Accuracy:0.984\nIteration: 7282, learning rate: 0.00663, Loss: 0.2279, Accuracy:0.914\nIteration: 7283, learning rate: 0.00663, Loss: 0.1972, Accuracy:0.938\nIteration: 7284, learning rate: 0.00663, Loss: 0.1742, Accuracy:0.945\nIteration: 7285, learning rate: 0.00663, Loss: 0.2510, Accuracy:0.892\nEpoch: 235, Loss: 0.2065, Accuracy:0.919, Val Loss: 0.2912, Val Accuracy: 0.872\nIteration: 7286, learning rate: 0.00663, Loss: 0.2136, Accuracy:0.922\nIteration: 7287, learning rate: 0.00663, Loss: 0.1912, Accuracy:0.922\nIteration: 7288, learning rate: 0.00663, Loss: 0.2472, Accuracy:0.875\nIteration: 7289, learning rate: 0.00663, Loss: 0.2190, Accuracy:0.922\nIteration: 7290, learning rate: 0.00663, Loss: 0.1466, Accuracy:0.953\nIteration: 7291, learning rate: 0.00663, Loss: 0.2846, Accuracy:0.875\nIteration: 7292, learning rate: 0.00663, Loss: 0.2436, Accuracy:0.906\nIteration: 7293, learning rate: 0.00663, Loss: 0.2617, Accuracy:0.875\nIteration: 7294, learning rate: 0.00663, Loss: 0.2053, Accuracy:0.914\nIteration: 7295, learning rate: 0.00663, Loss: 0.2050, Accuracy:0.945\nIteration: 7296, learning rate: 0.00663, Loss: 0.1798, Accuracy:0.938\nIteration: 7297, learning rate: 0.00663, Loss: 0.2511, Accuracy:0.883\nIteration: 7298, learning rate: 0.00663, Loss: 0.1593, Accuracy:0.938\nIteration: 7299, learning rate: 0.00663, Loss: 0.1749, Accuracy:0.922\nIteration: 7300, learning rate: 0.00663, Loss: 0.2996, Accuracy:0.891\nIteration: 7301, learning rate: 0.00663, Loss: 0.1572, Accuracy:0.953\nIteration: 7302, learning rate: 0.00663, Loss: 0.1428, Accuracy:0.945\nIteration: 7303, learning rate: 0.00663, Loss: 0.1978, Accuracy:0.938\nIteration: 7304, learning rate: 0.00663, Loss: 0.2313, Accuracy:0.906\nIteration: 7305, learning rate: 0.00663, Loss: 0.2202, Accuracy:0.906\nIteration: 7306, learning rate: 0.00663, Loss: 0.1279, Accuracy:0.969\nIteration: 7307, learning rate: 0.00663, Loss: 0.2263, Accuracy:0.922\nIteration: 7308, learning rate: 0.00663, Loss: 0.2029, Accuracy:0.938\nIteration: 7309, learning rate: 0.00663, Loss: 0.2203, Accuracy:0.930\nIteration: 7310, learning rate: 0.00663, Loss: 0.2335, Accuracy:0.906\nIteration: 7311, learning rate: 0.00663, Loss: 0.1989, Accuracy:0.930\nIteration: 7312, learning rate: 0.00663, Loss: 0.2817, Accuracy:0.875\nIteration: 7313, learning rate: 0.00663, Loss: 0.2399, Accuracy:0.875\nIteration: 7314, learning rate: 0.00663, Loss: 0.1723, Accuracy:0.945\nIteration: 7315, learning rate: 0.00663, Loss: 0.1556, Accuracy:0.945\nIteration: 7316, learning rate: 0.00662, Loss: 0.2306, Accuracy:0.903\nEpoch: 236, Loss: 0.2104, Accuracy:0.918, Val Loss: 0.2813, Val Accuracy: 0.877\nIteration: 7317, learning rate: 0.00662, Loss: 0.2276, Accuracy:0.891\nIteration: 7318, learning rate: 0.00662, Loss: 0.1993, Accuracy:0.938\nIteration: 7319, learning rate: 0.00662, Loss: 0.3091, Accuracy:0.859\nIteration: 7320, learning rate: 0.00662, Loss: 0.2250, Accuracy:0.922\nIteration: 7321, learning rate: 0.00662, Loss: 0.3630, Accuracy:0.844\nIteration: 7322, learning rate: 0.00662, Loss: 0.2020, Accuracy:0.898\nIteration: 7323, learning rate: 0.00662, Loss: 0.1931, Accuracy:0.914\nIteration: 7324, learning rate: 0.00662, Loss: 0.2192, Accuracy:0.930\nIteration: 7325, learning rate: 0.00662, Loss: 0.2076, Accuracy:0.930\nIteration: 7326, learning rate: 0.00662, Loss: 0.1787, Accuracy:0.938\nIteration: 7327, learning rate: 0.00662, Loss: 0.1539, Accuracy:0.945\nIteration: 7328, learning rate: 0.00662, Loss: 0.1557, Accuracy:0.930\nIteration: 7329, learning rate: 0.00662, Loss: 0.1820, Accuracy:0.930\nIteration: 7330, learning rate: 0.00662, Loss: 0.2748, Accuracy:0.867\nIteration: 7331, learning rate: 0.00662, Loss: 0.1733, Accuracy:0.961\nIteration: 7332, learning rate: 0.00662, Loss: 0.1996, Accuracy:0.906\nIteration: 7333, learning rate: 0.00662, Loss: 0.2199, Accuracy:0.891\nIteration: 7334, learning rate: 0.00662, Loss: 0.2496, Accuracy:0.891\nIteration: 7335, learning rate: 0.00662, Loss: 0.2116, Accuracy:0.891\nIteration: 7336, learning rate: 0.00662, Loss: 0.1806, Accuracy:0.914\nIteration: 7337, learning rate: 0.00662, Loss: 0.2569, Accuracy:0.883\nIteration: 7338, learning rate: 0.00662, Loss: 0.1731, Accuracy:0.938\nIteration: 7339, learning rate: 0.00662, Loss: 0.2264, Accuracy:0.898\nIteration: 7340, learning rate: 0.00662, Loss: 0.2426, Accuracy:0.875\nIteration: 7341, learning rate: 0.00662, Loss: 0.2172, Accuracy:0.875\nIteration: 7342, learning rate: 0.00662, Loss: 0.1694, Accuracy:0.938\nIteration: 7343, learning rate: 0.00662, Loss: 0.2035, Accuracy:0.922\nIteration: 7344, learning rate: 0.00662, Loss: 0.2297, Accuracy:0.906\nIteration: 7345, learning rate: 0.00662, Loss: 0.2434, Accuracy:0.906\nIteration: 7346, learning rate: 0.00662, Loss: 0.1783, Accuracy:0.914\nIteration: 7347, learning rate: 0.00662, Loss: 0.1978, Accuracy:0.946\nEpoch: 237, Loss: 0.2150, Accuracy:0.909, Val Loss: 0.4083, Val Accuracy: 0.834\nIteration: 7348, learning rate: 0.00662, Loss: 0.1912, Accuracy:0.938\nIteration: 7349, learning rate: 0.00662, Loss: 0.1660, Accuracy:0.938\nIteration: 7350, learning rate: 0.00662, Loss: 0.2269, Accuracy:0.906\nIteration: 7351, learning rate: 0.00661, Loss: 0.2069, Accuracy:0.930\nIteration: 7352, learning rate: 0.00661, Loss: 0.1926, Accuracy:0.930\nIteration: 7353, learning rate: 0.00661, Loss: 0.2252, Accuracy:0.914\nIteration: 7354, learning rate: 0.00661, Loss: 0.1668, Accuracy:0.938\nIteration: 7355, learning rate: 0.00661, Loss: 0.1761, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7356, learning rate: 0.00661, Loss: 0.2157, Accuracy:0.914\nIteration: 7357, learning rate: 0.00661, Loss: 0.2038, Accuracy:0.914\nIteration: 7358, learning rate: 0.00661, Loss: 0.2136, Accuracy:0.914\nIteration: 7359, learning rate: 0.00661, Loss: 0.1896, Accuracy:0.914\nIteration: 7360, learning rate: 0.00661, Loss: 0.1472, Accuracy:0.961\nIteration: 7361, learning rate: 0.00661, Loss: 0.1472, Accuracy:0.922\nIteration: 7362, learning rate: 0.00661, Loss: 0.2008, Accuracy:0.938\nIteration: 7363, learning rate: 0.00661, Loss: 0.1771, Accuracy:0.922\nIteration: 7364, learning rate: 0.00661, Loss: 0.1766, Accuracy:0.930\nIteration: 7365, learning rate: 0.00661, Loss: 0.1516, Accuracy:0.945\nIteration: 7366, learning rate: 0.00661, Loss: 0.2203, Accuracy:0.906\nIteration: 7367, learning rate: 0.00661, Loss: 0.1393, Accuracy:0.945\nIteration: 7368, learning rate: 0.00661, Loss: 0.2479, Accuracy:0.914\nIteration: 7369, learning rate: 0.00661, Loss: 0.2102, Accuracy:0.922\nIteration: 7370, learning rate: 0.00661, Loss: 0.2059, Accuracy:0.906\nIteration: 7371, learning rate: 0.00661, Loss: 0.1940, Accuracy:0.930\nIteration: 7372, learning rate: 0.00661, Loss: 0.1765, Accuracy:0.938\nIteration: 7373, learning rate: 0.00661, Loss: 0.2552, Accuracy:0.891\nIteration: 7374, learning rate: 0.00661, Loss: 0.1277, Accuracy:0.961\nIteration: 7375, learning rate: 0.00661, Loss: 0.2509, Accuracy:0.898\nIteration: 7376, learning rate: 0.00661, Loss: 0.2990, Accuracy:0.867\nIteration: 7377, learning rate: 0.00661, Loss: 0.2043, Accuracy:0.922\nIteration: 7378, learning rate: 0.00661, Loss: 0.1961, Accuracy:0.925\nEpoch: 238, Loss: 0.1968, Accuracy:0.924, Val Loss: 0.2746, Val Accuracy: 0.878\nIteration: 7379, learning rate: 0.00661, Loss: 0.1669, Accuracy:0.930\nIteration: 7380, learning rate: 0.00661, Loss: 0.2079, Accuracy:0.938\nIteration: 7381, learning rate: 0.00661, Loss: 0.1803, Accuracy:0.914\nIteration: 7382, learning rate: 0.00661, Loss: 0.1950, Accuracy:0.922\nIteration: 7383, learning rate: 0.00661, Loss: 0.2370, Accuracy:0.922\nIteration: 7384, learning rate: 0.00661, Loss: 0.2960, Accuracy:0.875\nIteration: 7385, learning rate: 0.00661, Loss: 0.2014, Accuracy:0.930\nIteration: 7386, learning rate: 0.00660, Loss: 0.2821, Accuracy:0.891\nIteration: 7387, learning rate: 0.00660, Loss: 0.2052, Accuracy:0.914\nIteration: 7388, learning rate: 0.00660, Loss: 0.1889, Accuracy:0.930\nIteration: 7389, learning rate: 0.00660, Loss: 0.2096, Accuracy:0.930\nIteration: 7390, learning rate: 0.00660, Loss: 0.1540, Accuracy:0.953\nIteration: 7391, learning rate: 0.00660, Loss: 0.2481, Accuracy:0.875\nIteration: 7392, learning rate: 0.00660, Loss: 0.1495, Accuracy:0.938\nIteration: 7393, learning rate: 0.00660, Loss: 0.2156, Accuracy:0.906\nIteration: 7394, learning rate: 0.00660, Loss: 0.2473, Accuracy:0.891\nIteration: 7395, learning rate: 0.00660, Loss: 0.1672, Accuracy:0.945\nIteration: 7396, learning rate: 0.00660, Loss: 0.2394, Accuracy:0.898\nIteration: 7397, learning rate: 0.00660, Loss: 0.1670, Accuracy:0.922\nIteration: 7398, learning rate: 0.00660, Loss: 0.1402, Accuracy:0.961\nIteration: 7399, learning rate: 0.00660, Loss: 0.2217, Accuracy:0.898\nIteration: 7400, learning rate: 0.00660, Loss: 0.2610, Accuracy:0.898\nIteration: 7401, learning rate: 0.00660, Loss: 0.1956, Accuracy:0.914\nIteration: 7402, learning rate: 0.00660, Loss: 0.1533, Accuracy:0.938\nIteration: 7403, learning rate: 0.00660, Loss: 0.1957, Accuracy:0.914\nIteration: 7404, learning rate: 0.00660, Loss: 0.1350, Accuracy:0.953\nIteration: 7405, learning rate: 0.00660, Loss: 0.1805, Accuracy:0.945\nIteration: 7406, learning rate: 0.00660, Loss: 0.1554, Accuracy:0.953\nIteration: 7407, learning rate: 0.00660, Loss: 0.1758, Accuracy:0.938\nIteration: 7408, learning rate: 0.00660, Loss: 0.2188, Accuracy:0.914\nIteration: 7409, learning rate: 0.00660, Loss: 0.1043, Accuracy:0.978\nEpoch: 239, Loss: 0.1966, Accuracy:0.923, Val Loss: 0.2632, Val Accuracy: 0.888\nIteration: 7410, learning rate: 0.00660, Loss: 0.2023, Accuracy:0.938\nIteration: 7411, learning rate: 0.00660, Loss: 0.1564, Accuracy:0.938\nIteration: 7412, learning rate: 0.00660, Loss: 0.2020, Accuracy:0.922\nIteration: 7413, learning rate: 0.00660, Loss: 0.2594, Accuracy:0.883\nIteration: 7414, learning rate: 0.00660, Loss: 0.2755, Accuracy:0.891\nIteration: 7415, learning rate: 0.00660, Loss: 0.2381, Accuracy:0.898\nIteration: 7416, learning rate: 0.00660, Loss: 0.2662, Accuracy:0.906\nIteration: 7417, learning rate: 0.00660, Loss: 0.2121, Accuracy:0.922\nIteration: 7418, learning rate: 0.00660, Loss: 0.2106, Accuracy:0.922\nIteration: 7419, learning rate: 0.00660, Loss: 0.2373, Accuracy:0.906\nIteration: 7420, learning rate: 0.00660, Loss: 0.2627, Accuracy:0.875\nIteration: 7421, learning rate: 0.00659, Loss: 0.2216, Accuracy:0.930\nIteration: 7422, learning rate: 0.00659, Loss: 0.1527, Accuracy:0.961\nIteration: 7423, learning rate: 0.00659, Loss: 0.1728, Accuracy:0.930\nIteration: 7424, learning rate: 0.00659, Loss: 0.2023, Accuracy:0.906\nIteration: 7425, learning rate: 0.00659, Loss: 0.1722, Accuracy:0.938\nIteration: 7426, learning rate: 0.00659, Loss: 0.1586, Accuracy:0.914\nIteration: 7427, learning rate: 0.00659, Loss: 0.2681, Accuracy:0.883\nIteration: 7428, learning rate: 0.00659, Loss: 0.1644, Accuracy:0.938\nIteration: 7429, learning rate: 0.00659, Loss: 0.1342, Accuracy:0.961\nIteration: 7430, learning rate: 0.00659, Loss: 0.2102, Accuracy:0.914\nIteration: 7431, learning rate: 0.00659, Loss: 0.2099, Accuracy:0.922\nIteration: 7432, learning rate: 0.00659, Loss: 0.2396, Accuracy:0.891\nIteration: 7433, learning rate: 0.00659, Loss: 0.2282, Accuracy:0.906\nIteration: 7434, learning rate: 0.00659, Loss: 0.2636, Accuracy:0.891\nIteration: 7435, learning rate: 0.00659, Loss: 0.1636, Accuracy:0.938\nIteration: 7436, learning rate: 0.00659, Loss: 0.2408, Accuracy:0.891\nIteration: 7437, learning rate: 0.00659, Loss: 0.1306, Accuracy:0.961\nIteration: 7438, learning rate: 0.00659, Loss: 0.1331, Accuracy:0.961\nIteration: 7439, learning rate: 0.00659, Loss: 0.2395, Accuracy:0.891\nIteration: 7440, learning rate: 0.00659, Loss: 0.1676, Accuracy:0.925\nEpoch: 240, Loss: 0.2063, Accuracy:0.918, Val Loss: 0.2859, Val Accuracy: 0.880\nIteration: 7441, learning rate: 0.00659, Loss: 0.1579, Accuracy:0.930\nIteration: 7442, learning rate: 0.00659, Loss: 0.2348, Accuracy:0.891\nIteration: 7443, learning rate: 0.00659, Loss: 0.1931, Accuracy:0.906\nIteration: 7444, learning rate: 0.00659, Loss: 0.1116, Accuracy:0.961\nIteration: 7445, learning rate: 0.00659, Loss: 0.2066, Accuracy:0.906\nIteration: 7446, learning rate: 0.00659, Loss: 0.2954, Accuracy:0.844\nIteration: 7447, learning rate: 0.00659, Loss: 0.2468, Accuracy:0.883\nIteration: 7448, learning rate: 0.00659, Loss: 0.2028, Accuracy:0.914\nIteration: 7449, learning rate: 0.00659, Loss: 0.3465, Accuracy:0.859\nIteration: 7450, learning rate: 0.00659, Loss: 0.1927, Accuracy:0.938\nIteration: 7451, learning rate: 0.00659, Loss: 0.0889, Accuracy:0.992\nIteration: 7452, learning rate: 0.00659, Loss: 0.2083, Accuracy:0.922\nIteration: 7453, learning rate: 0.00659, Loss: 0.2096, Accuracy:0.922\nIteration: 7454, learning rate: 0.00659, Loss: 0.2450, Accuracy:0.867\nIteration: 7455, learning rate: 0.00659, Loss: 0.2400, Accuracy:0.891\nIteration: 7456, learning rate: 0.00659, Loss: 0.2214, Accuracy:0.922\nIteration: 7457, learning rate: 0.00658, Loss: 0.2211, Accuracy:0.891\nIteration: 7458, learning rate: 0.00658, Loss: 0.1978, Accuracy:0.906\nIteration: 7459, learning rate: 0.00658, Loss: 0.2025, Accuracy:0.930\nIteration: 7460, learning rate: 0.00658, Loss: 0.1769, Accuracy:0.922\nIteration: 7461, learning rate: 0.00658, Loss: 0.1977, Accuracy:0.930\nIteration: 7462, learning rate: 0.00658, Loss: 0.1163, Accuracy:0.953\nIteration: 7463, learning rate: 0.00658, Loss: 0.2585, Accuracy:0.922\nIteration: 7464, learning rate: 0.00658, Loss: 0.2308, Accuracy:0.930\nIteration: 7465, learning rate: 0.00658, Loss: 0.2085, Accuracy:0.898\nIteration: 7466, learning rate: 0.00658, Loss: 0.2278, Accuracy:0.906\nIteration: 7467, learning rate: 0.00658, Loss: 0.2139, Accuracy:0.906\nIteration: 7468, learning rate: 0.00658, Loss: 0.1828, Accuracy:0.914\nIteration: 7469, learning rate: 0.00658, Loss: 0.1785, Accuracy:0.914\nIteration: 7470, learning rate: 0.00658, Loss: 0.2080, Accuracy:0.883\nIteration: 7471, learning rate: 0.00658, Loss: 0.2007, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 241, Loss: 0.2072, Accuracy:0.912, Val Loss: 0.3052, Val Accuracy: 0.877\nIteration: 7472, learning rate: 0.00658, Loss: 0.1904, Accuracy:0.914\nIteration: 7473, learning rate: 0.00658, Loss: 0.2294, Accuracy:0.922\nIteration: 7474, learning rate: 0.00658, Loss: 0.2119, Accuracy:0.914\nIteration: 7475, learning rate: 0.00658, Loss: 0.2075, Accuracy:0.922\nIteration: 7476, learning rate: 0.00658, Loss: 0.2028, Accuracy:0.906\nIteration: 7477, learning rate: 0.00658, Loss: 0.1111, Accuracy:0.953\nIteration: 7478, learning rate: 0.00658, Loss: 0.2798, Accuracy:0.891\nIteration: 7479, learning rate: 0.00658, Loss: 0.1811, Accuracy:0.914\nIteration: 7480, learning rate: 0.00658, Loss: 0.1430, Accuracy:0.953\nIteration: 7481, learning rate: 0.00658, Loss: 0.1948, Accuracy:0.914\nIteration: 7482, learning rate: 0.00658, Loss: 0.2077, Accuracy:0.906\nIteration: 7483, learning rate: 0.00658, Loss: 0.2151, Accuracy:0.922\nIteration: 7484, learning rate: 0.00658, Loss: 0.1640, Accuracy:0.914\nIteration: 7485, learning rate: 0.00658, Loss: 0.2137, Accuracy:0.938\nIteration: 7486, learning rate: 0.00658, Loss: 0.1572, Accuracy:0.938\nIteration: 7487, learning rate: 0.00658, Loss: 0.1604, Accuracy:0.953\nIteration: 7488, learning rate: 0.00658, Loss: 0.2364, Accuracy:0.922\nIteration: 7489, learning rate: 0.00658, Loss: 0.1785, Accuracy:0.938\nIteration: 7490, learning rate: 0.00658, Loss: 0.1735, Accuracy:0.938\nIteration: 7491, learning rate: 0.00658, Loss: 0.1870, Accuracy:0.938\nIteration: 7492, learning rate: 0.00657, Loss: 0.2526, Accuracy:0.891\nIteration: 7493, learning rate: 0.00657, Loss: 0.2289, Accuracy:0.922\nIteration: 7494, learning rate: 0.00657, Loss: 0.1520, Accuracy:0.938\nIteration: 7495, learning rate: 0.00657, Loss: 0.2541, Accuracy:0.891\nIteration: 7496, learning rate: 0.00657, Loss: 0.2156, Accuracy:0.906\nIteration: 7497, learning rate: 0.00657, Loss: 0.2462, Accuracy:0.883\nIteration: 7498, learning rate: 0.00657, Loss: 0.2062, Accuracy:0.898\nIteration: 7499, learning rate: 0.00657, Loss: 0.1753, Accuracy:0.930\nIteration: 7500, learning rate: 0.00657, Loss: 0.2064, Accuracy:0.891\nIteration: 7501, learning rate: 0.00657, Loss: 0.2142, Accuracy:0.891\nIteration: 7502, learning rate: 0.00657, Loss: 0.2773, Accuracy:0.860\nEpoch: 242, Loss: 0.2024, Accuracy:0.916, Val Loss: 0.3098, Val Accuracy: 0.864\nIteration: 7503, learning rate: 0.00657, Loss: 0.1549, Accuracy:0.930\nIteration: 7504, learning rate: 0.00657, Loss: 0.1555, Accuracy:0.945\nIteration: 7505, learning rate: 0.00657, Loss: 0.1997, Accuracy:0.922\nIteration: 7506, learning rate: 0.00657, Loss: 0.2040, Accuracy:0.906\nIteration: 7507, learning rate: 0.00657, Loss: 0.1430, Accuracy:0.945\nIteration: 7508, learning rate: 0.00657, Loss: 0.1314, Accuracy:0.961\nIteration: 7509, learning rate: 0.00657, Loss: 0.1998, Accuracy:0.922\nIteration: 7510, learning rate: 0.00657, Loss: 0.2168, Accuracy:0.906\nIteration: 7511, learning rate: 0.00657, Loss: 0.1854, Accuracy:0.961\nIteration: 7512, learning rate: 0.00657, Loss: 0.2698, Accuracy:0.875\nIteration: 7513, learning rate: 0.00657, Loss: 0.1443, Accuracy:0.969\nIteration: 7514, learning rate: 0.00657, Loss: 0.2707, Accuracy:0.883\nIteration: 7515, learning rate: 0.00657, Loss: 0.1942, Accuracy:0.914\nIteration: 7516, learning rate: 0.00657, Loss: 0.1680, Accuracy:0.930\nIteration: 7517, learning rate: 0.00657, Loss: 0.2525, Accuracy:0.914\nIteration: 7518, learning rate: 0.00657, Loss: 0.2342, Accuracy:0.930\nIteration: 7519, learning rate: 0.00657, Loss: 0.1924, Accuracy:0.906\nIteration: 7520, learning rate: 0.00657, Loss: 0.2088, Accuracy:0.922\nIteration: 7521, learning rate: 0.00657, Loss: 0.2326, Accuracy:0.906\nIteration: 7522, learning rate: 0.00657, Loss: 0.1840, Accuracy:0.930\nIteration: 7523, learning rate: 0.00657, Loss: 0.1122, Accuracy:0.969\nIteration: 7524, learning rate: 0.00657, Loss: 0.1790, Accuracy:0.938\nIteration: 7525, learning rate: 0.00657, Loss: 0.1620, Accuracy:0.953\nIteration: 7526, learning rate: 0.00657, Loss: 0.1849, Accuracy:0.930\nIteration: 7527, learning rate: 0.00657, Loss: 0.2168, Accuracy:0.906\nIteration: 7528, learning rate: 0.00656, Loss: 0.1744, Accuracy:0.938\nIteration: 7529, learning rate: 0.00656, Loss: 0.2042, Accuracy:0.930\nIteration: 7530, learning rate: 0.00656, Loss: 0.2183, Accuracy:0.906\nIteration: 7531, learning rate: 0.00656, Loss: 0.1412, Accuracy:0.953\nIteration: 7532, learning rate: 0.00656, Loss: 0.2628, Accuracy:0.922\nIteration: 7533, learning rate: 0.00656, Loss: 0.2126, Accuracy:0.935\nEpoch: 243, Loss: 0.1939, Accuracy:0.928, Val Loss: 0.3229, Val Accuracy: 0.860\nIteration: 7534, learning rate: 0.00656, Loss: 0.1903, Accuracy:0.922\nIteration: 7535, learning rate: 0.00656, Loss: 0.1466, Accuracy:0.938\nIteration: 7536, learning rate: 0.00656, Loss: 0.2611, Accuracy:0.898\nIteration: 7537, learning rate: 0.00656, Loss: 0.2141, Accuracy:0.914\nIteration: 7538, learning rate: 0.00656, Loss: 0.1833, Accuracy:0.953\nIteration: 7539, learning rate: 0.00656, Loss: 0.1870, Accuracy:0.922\nIteration: 7540, learning rate: 0.00656, Loss: 0.2025, Accuracy:0.922\nIteration: 7541, learning rate: 0.00656, Loss: 0.2248, Accuracy:0.891\nIteration: 7542, learning rate: 0.00656, Loss: 0.2222, Accuracy:0.914\nIteration: 7543, learning rate: 0.00656, Loss: 0.2010, Accuracy:0.914\nIteration: 7544, learning rate: 0.00656, Loss: 0.1634, Accuracy:0.945\nIteration: 7545, learning rate: 0.00656, Loss: 0.1726, Accuracy:0.945\nIteration: 7546, learning rate: 0.00656, Loss: 0.1484, Accuracy:0.938\nIteration: 7547, learning rate: 0.00656, Loss: 0.1335, Accuracy:0.953\nIteration: 7548, learning rate: 0.00656, Loss: 0.1512, Accuracy:0.953\nIteration: 7549, learning rate: 0.00656, Loss: 0.2774, Accuracy:0.891\nIteration: 7550, learning rate: 0.00656, Loss: 0.1410, Accuracy:0.945\nIteration: 7551, learning rate: 0.00656, Loss: 0.1387, Accuracy:0.953\nIteration: 7552, learning rate: 0.00656, Loss: 0.1547, Accuracy:0.945\nIteration: 7553, learning rate: 0.00656, Loss: 0.1325, Accuracy:0.953\nIteration: 7554, learning rate: 0.00656, Loss: 0.2976, Accuracy:0.891\nIteration: 7555, learning rate: 0.00656, Loss: 0.1360, Accuracy:0.945\nIteration: 7556, learning rate: 0.00656, Loss: 0.1647, Accuracy:0.930\nIteration: 7557, learning rate: 0.00656, Loss: 0.1890, Accuracy:0.914\nIteration: 7558, learning rate: 0.00656, Loss: 0.1596, Accuracy:0.930\nIteration: 7559, learning rate: 0.00656, Loss: 0.2061, Accuracy:0.914\nIteration: 7560, learning rate: 0.00656, Loss: 0.2019, Accuracy:0.914\nIteration: 7561, learning rate: 0.00656, Loss: 0.2020, Accuracy:0.930\nIteration: 7562, learning rate: 0.00656, Loss: 0.2341, Accuracy:0.898\nIteration: 7563, learning rate: 0.00655, Loss: 0.1566, Accuracy:0.938\nIteration: 7564, learning rate: 0.00655, Loss: 0.1471, Accuracy:0.935\nEpoch: 244, Loss: 0.1852, Accuracy:0.927, Val Loss: 0.3462, Val Accuracy: 0.860\nIteration: 7565, learning rate: 0.00655, Loss: 0.2575, Accuracy:0.906\nIteration: 7566, learning rate: 0.00655, Loss: 0.1812, Accuracy:0.914\nIteration: 7567, learning rate: 0.00655, Loss: 0.1983, Accuracy:0.898\nIteration: 7568, learning rate: 0.00655, Loss: 0.1738, Accuracy:0.930\nIteration: 7569, learning rate: 0.00655, Loss: 0.2587, Accuracy:0.898\nIteration: 7570, learning rate: 0.00655, Loss: 0.1645, Accuracy:0.938\nIteration: 7571, learning rate: 0.00655, Loss: 0.1660, Accuracy:0.922\nIteration: 7572, learning rate: 0.00655, Loss: 0.1965, Accuracy:0.938\nIteration: 7573, learning rate: 0.00655, Loss: 0.2030, Accuracy:0.914\nIteration: 7574, learning rate: 0.00655, Loss: 0.1639, Accuracy:0.922\nIteration: 7575, learning rate: 0.00655, Loss: 0.2173, Accuracy:0.914\nIteration: 7576, learning rate: 0.00655, Loss: 0.1542, Accuracy:0.938\nIteration: 7577, learning rate: 0.00655, Loss: 0.1423, Accuracy:0.938\nIteration: 7578, learning rate: 0.00655, Loss: 0.1611, Accuracy:0.953\nIteration: 7579, learning rate: 0.00655, Loss: 0.2270, Accuracy:0.883\nIteration: 7580, learning rate: 0.00655, Loss: 0.2199, Accuracy:0.906\nIteration: 7581, learning rate: 0.00655, Loss: 0.1441, Accuracy:0.930\nIteration: 7582, learning rate: 0.00655, Loss: 0.2603, Accuracy:0.859\nIteration: 7583, learning rate: 0.00655, Loss: 0.1533, Accuracy:0.945\nIteration: 7584, learning rate: 0.00655, Loss: 0.1942, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7585, learning rate: 0.00655, Loss: 0.2041, Accuracy:0.883\nIteration: 7586, learning rate: 0.00655, Loss: 0.2002, Accuracy:0.922\nIteration: 7587, learning rate: 0.00655, Loss: 0.1986, Accuracy:0.930\nIteration: 7588, learning rate: 0.00655, Loss: 0.3770, Accuracy:0.836\nIteration: 7589, learning rate: 0.00655, Loss: 0.1953, Accuracy:0.898\nIteration: 7590, learning rate: 0.00655, Loss: 0.2261, Accuracy:0.891\nIteration: 7591, learning rate: 0.00655, Loss: 0.2421, Accuracy:0.906\nIteration: 7592, learning rate: 0.00655, Loss: 0.1202, Accuracy:0.977\nIteration: 7593, learning rate: 0.00655, Loss: 0.1816, Accuracy:0.914\nIteration: 7594, learning rate: 0.00655, Loss: 0.2190, Accuracy:0.945\nIteration: 7595, learning rate: 0.00655, Loss: 0.2664, Accuracy:0.882\nEpoch: 245, Loss: 0.2022, Accuracy:0.916, Val Loss: 0.2879, Val Accuracy: 0.870\nIteration: 7596, learning rate: 0.00655, Loss: 0.2148, Accuracy:0.922\nIteration: 7597, learning rate: 0.00655, Loss: 0.1659, Accuracy:0.938\nIteration: 7598, learning rate: 0.00655, Loss: 0.1569, Accuracy:0.961\nIteration: 7599, learning rate: 0.00654, Loss: 0.1576, Accuracy:0.938\nIteration: 7600, learning rate: 0.00654, Loss: 0.1976, Accuracy:0.930\nIteration: 7601, learning rate: 0.00654, Loss: 0.1709, Accuracy:0.930\nIteration: 7602, learning rate: 0.00654, Loss: 0.1588, Accuracy:0.953\nIteration: 7603, learning rate: 0.00654, Loss: 0.2893, Accuracy:0.859\nIteration: 7604, learning rate: 0.00654, Loss: 0.2340, Accuracy:0.906\nIteration: 7605, learning rate: 0.00654, Loss: 0.1930, Accuracy:0.914\nIteration: 7606, learning rate: 0.00654, Loss: 0.2585, Accuracy:0.883\nIteration: 7607, learning rate: 0.00654, Loss: 0.1529, Accuracy:0.945\nIteration: 7608, learning rate: 0.00654, Loss: 0.2797, Accuracy:0.867\nIteration: 7609, learning rate: 0.00654, Loss: 0.1870, Accuracy:0.930\nIteration: 7610, learning rate: 0.00654, Loss: 0.1766, Accuracy:0.930\nIteration: 7611, learning rate: 0.00654, Loss: 0.2294, Accuracy:0.906\nIteration: 7612, learning rate: 0.00654, Loss: 0.2146, Accuracy:0.930\nIteration: 7613, learning rate: 0.00654, Loss: 0.1955, Accuracy:0.922\nIteration: 7614, learning rate: 0.00654, Loss: 0.2045, Accuracy:0.914\nIteration: 7615, learning rate: 0.00654, Loss: 0.3050, Accuracy:0.867\nIteration: 7616, learning rate: 0.00654, Loss: 0.2090, Accuracy:0.914\nIteration: 7617, learning rate: 0.00654, Loss: 0.2193, Accuracy:0.914\nIteration: 7618, learning rate: 0.00654, Loss: 0.2009, Accuracy:0.914\nIteration: 7619, learning rate: 0.00654, Loss: 0.1939, Accuracy:0.930\nIteration: 7620, learning rate: 0.00654, Loss: 0.2454, Accuracy:0.906\nIteration: 7621, learning rate: 0.00654, Loss: 0.3183, Accuracy:0.867\nIteration: 7622, learning rate: 0.00654, Loss: 0.2819, Accuracy:0.883\nIteration: 7623, learning rate: 0.00654, Loss: 0.1744, Accuracy:0.930\nIteration: 7624, learning rate: 0.00654, Loss: 0.2379, Accuracy:0.867\nIteration: 7625, learning rate: 0.00654, Loss: 0.1645, Accuracy:0.922\nIteration: 7626, learning rate: 0.00654, Loss: 0.1753, Accuracy:0.914\nEpoch: 246, Loss: 0.2117, Accuracy:0.913, Val Loss: 0.3248, Val Accuracy: 0.855\nIteration: 7627, learning rate: 0.00654, Loss: 0.1592, Accuracy:0.953\nIteration: 7628, learning rate: 0.00654, Loss: 0.2018, Accuracy:0.945\nIteration: 7629, learning rate: 0.00654, Loss: 0.2231, Accuracy:0.914\nIteration: 7630, learning rate: 0.00654, Loss: 0.1771, Accuracy:0.945\nIteration: 7631, learning rate: 0.00654, Loss: 0.2729, Accuracy:0.906\nIteration: 7632, learning rate: 0.00654, Loss: 0.2164, Accuracy:0.914\nIteration: 7633, learning rate: 0.00654, Loss: 0.2077, Accuracy:0.906\nIteration: 7634, learning rate: 0.00654, Loss: 0.2366, Accuracy:0.891\nIteration: 7635, learning rate: 0.00653, Loss: 0.2265, Accuracy:0.891\nIteration: 7636, learning rate: 0.00653, Loss: 0.1499, Accuracy:0.945\nIteration: 7637, learning rate: 0.00653, Loss: 0.1653, Accuracy:0.953\nIteration: 7638, learning rate: 0.00653, Loss: 0.1787, Accuracy:0.922\nIteration: 7639, learning rate: 0.00653, Loss: 0.2253, Accuracy:0.906\nIteration: 7640, learning rate: 0.00653, Loss: 0.1743, Accuracy:0.922\nIteration: 7641, learning rate: 0.00653, Loss: 0.1525, Accuracy:0.930\nIteration: 7642, learning rate: 0.00653, Loss: 0.2077, Accuracy:0.922\nIteration: 7643, learning rate: 0.00653, Loss: 0.1963, Accuracy:0.930\nIteration: 7644, learning rate: 0.00653, Loss: 0.2176, Accuracy:0.938\nIteration: 7645, learning rate: 0.00653, Loss: 0.1559, Accuracy:0.938\nIteration: 7646, learning rate: 0.00653, Loss: 0.3362, Accuracy:0.820\nIteration: 7647, learning rate: 0.00653, Loss: 0.1623, Accuracy:0.953\nIteration: 7648, learning rate: 0.00653, Loss: 0.2208, Accuracy:0.914\nIteration: 7649, learning rate: 0.00653, Loss: 0.1120, Accuracy:0.961\nIteration: 7650, learning rate: 0.00653, Loss: 0.2119, Accuracy:0.922\nIteration: 7651, learning rate: 0.00653, Loss: 0.1667, Accuracy:0.938\nIteration: 7652, learning rate: 0.00653, Loss: 0.2523, Accuracy:0.914\nIteration: 7653, learning rate: 0.00653, Loss: 0.1719, Accuracy:0.945\nIteration: 7654, learning rate: 0.00653, Loss: 0.1973, Accuracy:0.898\nIteration: 7655, learning rate: 0.00653, Loss: 0.2280, Accuracy:0.883\nIteration: 7656, learning rate: 0.00653, Loss: 0.2320, Accuracy:0.914\nIteration: 7657, learning rate: 0.00653, Loss: 0.2040, Accuracy:0.935\nEpoch: 247, Loss: 0.2013, Accuracy:0.922, Val Loss: 0.3302, Val Accuracy: 0.854\nIteration: 7658, learning rate: 0.00653, Loss: 0.2071, Accuracy:0.898\nIteration: 7659, learning rate: 0.00653, Loss: 0.1331, Accuracy:0.961\nIteration: 7660, learning rate: 0.00653, Loss: 0.1400, Accuracy:0.953\nIteration: 7661, learning rate: 0.00653, Loss: 0.1932, Accuracy:0.922\nIteration: 7662, learning rate: 0.00653, Loss: 0.1690, Accuracy:0.922\nIteration: 7663, learning rate: 0.00653, Loss: 0.1973, Accuracy:0.914\nIteration: 7664, learning rate: 0.00653, Loss: 0.2182, Accuracy:0.930\nIteration: 7665, learning rate: 0.00653, Loss: 0.2196, Accuracy:0.930\nIteration: 7666, learning rate: 0.00653, Loss: 0.1669, Accuracy:0.938\nIteration: 7667, learning rate: 0.00653, Loss: 0.1787, Accuracy:0.930\nIteration: 7668, learning rate: 0.00653, Loss: 0.1248, Accuracy:0.969\nIteration: 7669, learning rate: 0.00653, Loss: 0.1682, Accuracy:0.922\nIteration: 7670, learning rate: 0.00653, Loss: 0.2270, Accuracy:0.914\nIteration: 7671, learning rate: 0.00652, Loss: 0.2022, Accuracy:0.930\nIteration: 7672, learning rate: 0.00652, Loss: 0.2715, Accuracy:0.883\nIteration: 7673, learning rate: 0.00652, Loss: 0.2251, Accuracy:0.922\nIteration: 7674, learning rate: 0.00652, Loss: 0.2177, Accuracy:0.906\nIteration: 7675, learning rate: 0.00652, Loss: 0.2854, Accuracy:0.883\nIteration: 7676, learning rate: 0.00652, Loss: 0.1534, Accuracy:0.930\nIteration: 7677, learning rate: 0.00652, Loss: 0.1773, Accuracy:0.922\nIteration: 7678, learning rate: 0.00652, Loss: 0.1897, Accuracy:0.945\nIteration: 7679, learning rate: 0.00652, Loss: 0.2281, Accuracy:0.914\nIteration: 7680, learning rate: 0.00652, Loss: 0.2380, Accuracy:0.930\nIteration: 7681, learning rate: 0.00652, Loss: 0.1804, Accuracy:0.922\nIteration: 7682, learning rate: 0.00652, Loss: 0.2209, Accuracy:0.930\nIteration: 7683, learning rate: 0.00652, Loss: 0.1926, Accuracy:0.922\nIteration: 7684, learning rate: 0.00652, Loss: 0.2041, Accuracy:0.930\nIteration: 7685, learning rate: 0.00652, Loss: 0.2031, Accuracy:0.930\nIteration: 7686, learning rate: 0.00652, Loss: 0.2945, Accuracy:0.891\nIteration: 7687, learning rate: 0.00652, Loss: 0.2226, Accuracy:0.906\nIteration: 7688, learning rate: 0.00652, Loss: 0.1987, Accuracy:0.892\nEpoch: 248, Loss: 0.2016, Accuracy:0.922, Val Loss: 0.3771, Val Accuracy: 0.847\nIteration: 7689, learning rate: 0.00652, Loss: 0.1913, Accuracy:0.945\nIteration: 7690, learning rate: 0.00652, Loss: 0.2420, Accuracy:0.867\nIteration: 7691, learning rate: 0.00652, Loss: 0.1873, Accuracy:0.906\nIteration: 7692, learning rate: 0.00652, Loss: 0.1355, Accuracy:0.930\nIteration: 7693, learning rate: 0.00652, Loss: 0.1790, Accuracy:0.930\nIteration: 7694, learning rate: 0.00652, Loss: 0.2033, Accuracy:0.922\nIteration: 7695, learning rate: 0.00652, Loss: 0.1978, Accuracy:0.906\nIteration: 7696, learning rate: 0.00652, Loss: 0.2157, Accuracy:0.914\nIteration: 7697, learning rate: 0.00652, Loss: 0.2546, Accuracy:0.875\nIteration: 7698, learning rate: 0.00652, Loss: 0.2512, Accuracy:0.883\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7699, learning rate: 0.00652, Loss: 0.1453, Accuracy:0.938\nIteration: 7700, learning rate: 0.00652, Loss: 0.1631, Accuracy:0.930\nIteration: 7701, learning rate: 0.00652, Loss: 0.2176, Accuracy:0.898\nIteration: 7702, learning rate: 0.00652, Loss: 0.2375, Accuracy:0.891\nIteration: 7703, learning rate: 0.00652, Loss: 0.2504, Accuracy:0.914\nIteration: 7704, learning rate: 0.00652, Loss: 0.1149, Accuracy:0.969\nIteration: 7705, learning rate: 0.00652, Loss: 0.2711, Accuracy:0.891\nIteration: 7706, learning rate: 0.00652, Loss: 0.1848, Accuracy:0.922\nIteration: 7707, learning rate: 0.00651, Loss: 0.1288, Accuracy:0.961\nIteration: 7708, learning rate: 0.00651, Loss: 0.1445, Accuracy:0.961\nIteration: 7709, learning rate: 0.00651, Loss: 0.1554, Accuracy:0.938\nIteration: 7710, learning rate: 0.00651, Loss: 0.2415, Accuracy:0.930\nIteration: 7711, learning rate: 0.00651, Loss: 0.1912, Accuracy:0.914\nIteration: 7712, learning rate: 0.00651, Loss: 0.2413, Accuracy:0.883\nIteration: 7713, learning rate: 0.00651, Loss: 0.1951, Accuracy:0.914\nIteration: 7714, learning rate: 0.00651, Loss: 0.1478, Accuracy:0.969\nIteration: 7715, learning rate: 0.00651, Loss: 0.1806, Accuracy:0.883\nIteration: 7716, learning rate: 0.00651, Loss: 0.2573, Accuracy:0.938\nIteration: 7717, learning rate: 0.00651, Loss: 0.2013, Accuracy:0.883\nIteration: 7718, learning rate: 0.00651, Loss: 0.2664, Accuracy:0.852\nIteration: 7719, learning rate: 0.00651, Loss: 0.2410, Accuracy:0.903\nEpoch: 249, Loss: 0.2011, Accuracy:0.915, Val Loss: 0.3513, Val Accuracy: 0.842\nIteration: 7720, learning rate: 0.00651, Loss: 0.2085, Accuracy:0.906\nIteration: 7721, learning rate: 0.00651, Loss: 0.1745, Accuracy:0.930\nIteration: 7722, learning rate: 0.00651, Loss: 0.1505, Accuracy:0.938\nIteration: 7723, learning rate: 0.00651, Loss: 0.1677, Accuracy:0.938\nIteration: 7724, learning rate: 0.00651, Loss: 0.1614, Accuracy:0.930\nIteration: 7725, learning rate: 0.00651, Loss: 0.2222, Accuracy:0.867\nIteration: 7726, learning rate: 0.00651, Loss: 0.3521, Accuracy:0.852\nIteration: 7727, learning rate: 0.00651, Loss: 0.1608, Accuracy:0.969\nIteration: 7728, learning rate: 0.00651, Loss: 0.2285, Accuracy:0.898\nIteration: 7729, learning rate: 0.00651, Loss: 0.1500, Accuracy:0.930\nIteration: 7730, learning rate: 0.00651, Loss: 0.2268, Accuracy:0.891\nIteration: 7731, learning rate: 0.00651, Loss: 0.1781, Accuracy:0.930\nIteration: 7732, learning rate: 0.00651, Loss: 0.3071, Accuracy:0.875\nIteration: 7733, learning rate: 0.00651, Loss: 0.1757, Accuracy:0.945\nIteration: 7734, learning rate: 0.00651, Loss: 0.2212, Accuracy:0.922\nIteration: 7735, learning rate: 0.00651, Loss: 0.2745, Accuracy:0.875\nIteration: 7736, learning rate: 0.00651, Loss: 0.2028, Accuracy:0.938\nIteration: 7737, learning rate: 0.00651, Loss: 0.0901, Accuracy:0.969\nIteration: 7738, learning rate: 0.00651, Loss: 0.1718, Accuracy:0.953\nIteration: 7739, learning rate: 0.00651, Loss: 0.1913, Accuracy:0.922\nIteration: 7740, learning rate: 0.00651, Loss: 0.1823, Accuracy:0.914\nIteration: 7741, learning rate: 0.00651, Loss: 0.1691, Accuracy:0.938\nIteration: 7742, learning rate: 0.00651, Loss: 0.1785, Accuracy:0.914\nIteration: 7743, learning rate: 0.00651, Loss: 0.1810, Accuracy:0.938\nIteration: 7744, learning rate: 0.00650, Loss: 0.2709, Accuracy:0.883\nIteration: 7745, learning rate: 0.00650, Loss: 0.2084, Accuracy:0.922\nIteration: 7746, learning rate: 0.00650, Loss: 0.2059, Accuracy:0.906\nIteration: 7747, learning rate: 0.00650, Loss: 0.1897, Accuracy:0.938\nIteration: 7748, learning rate: 0.00650, Loss: 0.2109, Accuracy:0.906\nIteration: 7749, learning rate: 0.00650, Loss: 0.2550, Accuracy:0.898\nIteration: 7750, learning rate: 0.00650, Loss: 0.1511, Accuracy:0.925\nEpoch: 250, Loss: 0.2006, Accuracy:0.918, Val Loss: 0.3145, Val Accuracy: 0.868\nIteration: 7751, learning rate: 0.00650, Loss: 0.1047, Accuracy:0.984\nIteration: 7752, learning rate: 0.00650, Loss: 0.2013, Accuracy:0.906\nIteration: 7753, learning rate: 0.00650, Loss: 0.2433, Accuracy:0.906\nIteration: 7754, learning rate: 0.00650, Loss: 0.1896, Accuracy:0.914\nIteration: 7755, learning rate: 0.00650, Loss: 0.1829, Accuracy:0.922\nIteration: 7756, learning rate: 0.00650, Loss: 0.2158, Accuracy:0.922\nIteration: 7757, learning rate: 0.00650, Loss: 0.2301, Accuracy:0.922\nIteration: 7758, learning rate: 0.00650, Loss: 0.1870, Accuracy:0.914\nIteration: 7759, learning rate: 0.00650, Loss: 0.1355, Accuracy:0.953\nIteration: 7760, learning rate: 0.00650, Loss: 0.2122, Accuracy:0.930\nIteration: 7761, learning rate: 0.00650, Loss: 0.1721, Accuracy:0.938\nIteration: 7762, learning rate: 0.00650, Loss: 0.2169, Accuracy:0.930\nIteration: 7763, learning rate: 0.00650, Loss: 0.2121, Accuracy:0.930\nIteration: 7764, learning rate: 0.00650, Loss: 0.1889, Accuracy:0.922\nIteration: 7765, learning rate: 0.00650, Loss: 0.2517, Accuracy:0.883\nIteration: 7766, learning rate: 0.00650, Loss: 0.2168, Accuracy:0.906\nIteration: 7767, learning rate: 0.00650, Loss: 0.2872, Accuracy:0.859\nIteration: 7768, learning rate: 0.00650, Loss: 0.2220, Accuracy:0.914\nIteration: 7769, learning rate: 0.00650, Loss: 0.2254, Accuracy:0.898\nIteration: 7770, learning rate: 0.00650, Loss: 0.2027, Accuracy:0.930\nIteration: 7771, learning rate: 0.00650, Loss: 0.1864, Accuracy:0.930\nIteration: 7772, learning rate: 0.00650, Loss: 0.1730, Accuracy:0.938\nIteration: 7773, learning rate: 0.00650, Loss: 0.2156, Accuracy:0.914\nIteration: 7774, learning rate: 0.00650, Loss: 0.2081, Accuracy:0.914\nIteration: 7775, learning rate: 0.00650, Loss: 0.2275, Accuracy:0.891\nIteration: 7776, learning rate: 0.00650, Loss: 0.2233, Accuracy:0.922\nIteration: 7777, learning rate: 0.00650, Loss: 0.1981, Accuracy:0.922\nIteration: 7778, learning rate: 0.00650, Loss: 0.3595, Accuracy:0.859\nIteration: 7779, learning rate: 0.00650, Loss: 0.2638, Accuracy:0.906\nIteration: 7780, learning rate: 0.00649, Loss: 0.1751, Accuracy:0.914\nIteration: 7781, learning rate: 0.00649, Loss: 0.2322, Accuracy:0.914\nEpoch: 251, Loss: 0.2116, Accuracy:0.916, Val Loss: 0.3235, Val Accuracy: 0.857\nIteration: 7782, learning rate: 0.00649, Loss: 0.1874, Accuracy:0.922\nIteration: 7783, learning rate: 0.00649, Loss: 0.2665, Accuracy:0.891\nIteration: 7784, learning rate: 0.00649, Loss: 0.2335, Accuracy:0.898\nIteration: 7785, learning rate: 0.00649, Loss: 0.2514, Accuracy:0.891\nIteration: 7786, learning rate: 0.00649, Loss: 0.2160, Accuracy:0.914\nIteration: 7787, learning rate: 0.00649, Loss: 0.1504, Accuracy:0.930\nIteration: 7788, learning rate: 0.00649, Loss: 0.2387, Accuracy:0.914\nIteration: 7789, learning rate: 0.00649, Loss: 0.1483, Accuracy:0.922\nIteration: 7790, learning rate: 0.00649, Loss: 0.3482, Accuracy:0.844\nIteration: 7791, learning rate: 0.00649, Loss: 0.1434, Accuracy:0.938\nIteration: 7792, learning rate: 0.00649, Loss: 0.2126, Accuracy:0.906\nIteration: 7793, learning rate: 0.00649, Loss: 0.2006, Accuracy:0.914\nIteration: 7794, learning rate: 0.00649, Loss: 0.2525, Accuracy:0.891\nIteration: 7795, learning rate: 0.00649, Loss: 0.3132, Accuracy:0.852\nIteration: 7796, learning rate: 0.00649, Loss: 0.2143, Accuracy:0.930\nIteration: 7797, learning rate: 0.00649, Loss: 0.2015, Accuracy:0.906\nIteration: 7798, learning rate: 0.00649, Loss: 0.1627, Accuracy:0.930\nIteration: 7799, learning rate: 0.00649, Loss: 0.1880, Accuracy:0.938\nIteration: 7800, learning rate: 0.00649, Loss: 0.1580, Accuracy:0.953\nIteration: 7801, learning rate: 0.00649, Loss: 0.1989, Accuracy:0.914\nIteration: 7802, learning rate: 0.00649, Loss: 0.1799, Accuracy:0.922\nIteration: 7803, learning rate: 0.00649, Loss: 0.2831, Accuracy:0.883\nIteration: 7804, learning rate: 0.00649, Loss: 0.2276, Accuracy:0.906\nIteration: 7805, learning rate: 0.00649, Loss: 0.2369, Accuracy:0.875\nIteration: 7806, learning rate: 0.00649, Loss: 0.1486, Accuracy:0.938\nIteration: 7807, learning rate: 0.00649, Loss: 0.1672, Accuracy:0.922\nIteration: 7808, learning rate: 0.00649, Loss: 0.2360, Accuracy:0.906\nIteration: 7809, learning rate: 0.00649, Loss: 0.1324, Accuracy:0.945\nIteration: 7810, learning rate: 0.00649, Loss: 0.2429, Accuracy:0.898\nIteration: 7811, learning rate: 0.00649, Loss: 0.2096, Accuracy:0.914\nIteration: 7812, learning rate: 0.00649, Loss: 0.2874, Accuracy:0.882\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 252, Loss: 0.2141, Accuracy:0.909, Val Loss: 0.2841, Val Accuracy: 0.887\nIteration: 7813, learning rate: 0.00649, Loss: 0.2301, Accuracy:0.898\nIteration: 7814, learning rate: 0.00649, Loss: 0.1299, Accuracy:0.953\nIteration: 7815, learning rate: 0.00649, Loss: 0.2032, Accuracy:0.906\nIteration: 7816, learning rate: 0.00649, Loss: 0.2771, Accuracy:0.867\nIteration: 7817, learning rate: 0.00648, Loss: 0.1815, Accuracy:0.945\nIteration: 7818, learning rate: 0.00648, Loss: 0.1651, Accuracy:0.945\nIteration: 7819, learning rate: 0.00648, Loss: 0.1754, Accuracy:0.922\nIteration: 7820, learning rate: 0.00648, Loss: 0.1904, Accuracy:0.914\nIteration: 7821, learning rate: 0.00648, Loss: 0.1530, Accuracy:0.938\nIteration: 7822, learning rate: 0.00648, Loss: 0.2357, Accuracy:0.914\nIteration: 7823, learning rate: 0.00648, Loss: 0.2893, Accuracy:0.875\nIteration: 7824, learning rate: 0.00648, Loss: 0.2404, Accuracy:0.898\nIteration: 7825, learning rate: 0.00648, Loss: 0.1732, Accuracy:0.914\nIteration: 7826, learning rate: 0.00648, Loss: 0.2070, Accuracy:0.922\nIteration: 7827, learning rate: 0.00648, Loss: 0.1690, Accuracy:0.938\nIteration: 7828, learning rate: 0.00648, Loss: 0.2422, Accuracy:0.883\nIteration: 7829, learning rate: 0.00648, Loss: 0.1906, Accuracy:0.945\nIteration: 7830, learning rate: 0.00648, Loss: 0.1480, Accuracy:0.961\nIteration: 7831, learning rate: 0.00648, Loss: 0.2313, Accuracy:0.898\nIteration: 7832, learning rate: 0.00648, Loss: 0.1705, Accuracy:0.906\nIteration: 7833, learning rate: 0.00648, Loss: 0.2178, Accuracy:0.938\nIteration: 7834, learning rate: 0.00648, Loss: 0.1870, Accuracy:0.930\nIteration: 7835, learning rate: 0.00648, Loss: 0.1979, Accuracy:0.938\nIteration: 7836, learning rate: 0.00648, Loss: 0.2173, Accuracy:0.914\nIteration: 7837, learning rate: 0.00648, Loss: 0.2097, Accuracy:0.898\nIteration: 7838, learning rate: 0.00648, Loss: 0.2621, Accuracy:0.891\nIteration: 7839, learning rate: 0.00648, Loss: 0.1717, Accuracy:0.914\nIteration: 7840, learning rate: 0.00648, Loss: 0.2211, Accuracy:0.922\nIteration: 7841, learning rate: 0.00648, Loss: 0.2127, Accuracy:0.922\nIteration: 7842, learning rate: 0.00648, Loss: 0.2428, Accuracy:0.914\nIteration: 7843, learning rate: 0.00648, Loss: 0.2867, Accuracy:0.914\nEpoch: 253, Loss: 0.2074, Accuracy:0.917, Val Loss: 0.2857, Val Accuracy: 0.873\nIteration: 7844, learning rate: 0.00648, Loss: 0.2167, Accuracy:0.930\nIteration: 7845, learning rate: 0.00648, Loss: 0.1451, Accuracy:0.938\nIteration: 7846, learning rate: 0.00648, Loss: 0.2009, Accuracy:0.930\nIteration: 7847, learning rate: 0.00648, Loss: 0.2444, Accuracy:0.883\nIteration: 7848, learning rate: 0.00648, Loss: 0.2205, Accuracy:0.891\nIteration: 7849, learning rate: 0.00648, Loss: 0.1617, Accuracy:0.961\nIteration: 7850, learning rate: 0.00648, Loss: 0.2374, Accuracy:0.891\nIteration: 7851, learning rate: 0.00648, Loss: 0.2201, Accuracy:0.906\nIteration: 7852, learning rate: 0.00648, Loss: 0.1788, Accuracy:0.930\nIteration: 7853, learning rate: 0.00647, Loss: 0.1627, Accuracy:0.938\nIteration: 7854, learning rate: 0.00647, Loss: 0.2491, Accuracy:0.891\nIteration: 7855, learning rate: 0.00647, Loss: 0.2469, Accuracy:0.883\nIteration: 7856, learning rate: 0.00647, Loss: 0.2673, Accuracy:0.883\nIteration: 7857, learning rate: 0.00647, Loss: 0.2035, Accuracy:0.922\nIteration: 7858, learning rate: 0.00647, Loss: 0.1769, Accuracy:0.945\nIteration: 7859, learning rate: 0.00647, Loss: 0.1621, Accuracy:0.945\nIteration: 7860, learning rate: 0.00647, Loss: 0.2925, Accuracy:0.883\nIteration: 7861, learning rate: 0.00647, Loss: 0.2194, Accuracy:0.914\nIteration: 7862, learning rate: 0.00647, Loss: 0.1729, Accuracy:0.922\nIteration: 7863, learning rate: 0.00647, Loss: 0.1724, Accuracy:0.930\nIteration: 7864, learning rate: 0.00647, Loss: 0.1656, Accuracy:0.938\nIteration: 7865, learning rate: 0.00647, Loss: 0.1444, Accuracy:0.930\nIteration: 7866, learning rate: 0.00647, Loss: 0.1892, Accuracy:0.914\nIteration: 7867, learning rate: 0.00647, Loss: 0.1913, Accuracy:0.930\nIteration: 7868, learning rate: 0.00647, Loss: 0.2285, Accuracy:0.898\nIteration: 7869, learning rate: 0.00647, Loss: 0.3117, Accuracy:0.852\nIteration: 7870, learning rate: 0.00647, Loss: 0.1279, Accuracy:0.961\nIteration: 7871, learning rate: 0.00647, Loss: 0.1488, Accuracy:0.930\nIteration: 7872, learning rate: 0.00647, Loss: 0.2076, Accuracy:0.922\nIteration: 7873, learning rate: 0.00647, Loss: 0.1854, Accuracy:0.930\nIteration: 7874, learning rate: 0.00647, Loss: 0.2576, Accuracy:0.925\nEpoch: 254, Loss: 0.2035, Accuracy:0.917, Val Loss: 0.2913, Val Accuracy: 0.848\nIteration: 7875, learning rate: 0.00647, Loss: 0.1989, Accuracy:0.914\nIteration: 7876, learning rate: 0.00647, Loss: 0.1949, Accuracy:0.945\nIteration: 7877, learning rate: 0.00647, Loss: 0.1815, Accuracy:0.930\nIteration: 7878, learning rate: 0.00647, Loss: 0.2000, Accuracy:0.922\nIteration: 7879, learning rate: 0.00647, Loss: 0.1562, Accuracy:0.961\nIteration: 7880, learning rate: 0.00647, Loss: 0.1753, Accuracy:0.938\nIteration: 7881, learning rate: 0.00647, Loss: 0.2068, Accuracy:0.906\nIteration: 7882, learning rate: 0.00647, Loss: 0.2285, Accuracy:0.906\nIteration: 7883, learning rate: 0.00647, Loss: 0.2013, Accuracy:0.945\nIteration: 7884, learning rate: 0.00647, Loss: 0.2124, Accuracy:0.930\nIteration: 7885, learning rate: 0.00647, Loss: 0.1978, Accuracy:0.938\nIteration: 7886, learning rate: 0.00647, Loss: 0.1816, Accuracy:0.930\nIteration: 7887, learning rate: 0.00647, Loss: 0.1639, Accuracy:0.938\nIteration: 7888, learning rate: 0.00647, Loss: 0.1673, Accuracy:0.930\nIteration: 7889, learning rate: 0.00647, Loss: 0.2192, Accuracy:0.906\nIteration: 7890, learning rate: 0.00646, Loss: 0.1835, Accuracy:0.930\nIteration: 7891, learning rate: 0.00646, Loss: 0.2082, Accuracy:0.922\nIteration: 7892, learning rate: 0.00646, Loss: 0.2033, Accuracy:0.914\nIteration: 7893, learning rate: 0.00646, Loss: 0.1725, Accuracy:0.938\nIteration: 7894, learning rate: 0.00646, Loss: 0.2199, Accuracy:0.906\nIteration: 7895, learning rate: 0.00646, Loss: 0.2204, Accuracy:0.930\nIteration: 7896, learning rate: 0.00646, Loss: 0.1175, Accuracy:0.953\nIteration: 7897, learning rate: 0.00646, Loss: 0.1981, Accuracy:0.930\nIteration: 7898, learning rate: 0.00646, Loss: 0.2331, Accuracy:0.891\nIteration: 7899, learning rate: 0.00646, Loss: 0.1454, Accuracy:0.961\nIteration: 7900, learning rate: 0.00646, Loss: 0.1664, Accuracy:0.930\nIteration: 7901, learning rate: 0.00646, Loss: 0.3283, Accuracy:0.852\nIteration: 7902, learning rate: 0.00646, Loss: 0.2258, Accuracy:0.922\nIteration: 7903, learning rate: 0.00646, Loss: 0.2707, Accuracy:0.922\nIteration: 7904, learning rate: 0.00646, Loss: 0.1646, Accuracy:0.945\nIteration: 7905, learning rate: 0.00646, Loss: 0.2185, Accuracy:0.914\nEpoch: 255, Loss: 0.1988, Accuracy:0.926, Val Loss: 0.2847, Val Accuracy: 0.861\nIteration: 7906, learning rate: 0.00646, Loss: 0.1918, Accuracy:0.914\nIteration: 7907, learning rate: 0.00646, Loss: 0.2616, Accuracy:0.906\nIteration: 7908, learning rate: 0.00646, Loss: 0.1740, Accuracy:0.930\nIteration: 7909, learning rate: 0.00646, Loss: 0.2581, Accuracy:0.883\nIteration: 7910, learning rate: 0.00646, Loss: 0.2129, Accuracy:0.906\nIteration: 7911, learning rate: 0.00646, Loss: 0.1802, Accuracy:0.945\nIteration: 7912, learning rate: 0.00646, Loss: 0.2142, Accuracy:0.930\nIteration: 7913, learning rate: 0.00646, Loss: 0.1880, Accuracy:0.953\nIteration: 7914, learning rate: 0.00646, Loss: 0.2235, Accuracy:0.906\nIteration: 7915, learning rate: 0.00646, Loss: 0.2334, Accuracy:0.891\nIteration: 7916, learning rate: 0.00646, Loss: 0.1366, Accuracy:0.945\nIteration: 7917, learning rate: 0.00646, Loss: 0.1534, Accuracy:0.945\nIteration: 7918, learning rate: 0.00646, Loss: 0.2086, Accuracy:0.914\nIteration: 7919, learning rate: 0.00646, Loss: 0.2114, Accuracy:0.906\nIteration: 7920, learning rate: 0.00646, Loss: 0.1820, Accuracy:0.945\nIteration: 7921, learning rate: 0.00646, Loss: 0.2618, Accuracy:0.930\nIteration: 7922, learning rate: 0.00646, Loss: 0.1850, Accuracy:0.953\nIteration: 7923, learning rate: 0.00646, Loss: 0.1822, Accuracy:0.914\nIteration: 7924, learning rate: 0.00646, Loss: 0.1973, Accuracy:0.930\nIteration: 7925, learning rate: 0.00646, Loss: 0.1755, Accuracy:0.922\nIteration: 7926, learning rate: 0.00646, Loss: 0.2101, Accuracy:0.930\nIteration: 7927, learning rate: 0.00645, Loss: 0.1615, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 7928, learning rate: 0.00645, Loss: 0.1832, Accuracy:0.922\nIteration: 7929, learning rate: 0.00645, Loss: 0.1754, Accuracy:0.938\nIteration: 7930, learning rate: 0.00645, Loss: 0.1634, Accuracy:0.922\nIteration: 7931, learning rate: 0.00645, Loss: 0.1483, Accuracy:0.945\nIteration: 7932, learning rate: 0.00645, Loss: 0.1382, Accuracy:0.953\nIteration: 7933, learning rate: 0.00645, Loss: 0.1803, Accuracy:0.945\nIteration: 7934, learning rate: 0.00645, Loss: 0.2341, Accuracy:0.914\nIteration: 7935, learning rate: 0.00645, Loss: 0.1460, Accuracy:0.938\nIteration: 7936, learning rate: 0.00645, Loss: 0.1775, Accuracy:0.925\nEpoch: 256, Loss: 0.1919, Accuracy:0.927, Val Loss: 0.2754, Val Accuracy: 0.883\nIteration: 7937, learning rate: 0.00645, Loss: 0.1525, Accuracy:0.953\nIteration: 7938, learning rate: 0.00645, Loss: 0.2570, Accuracy:0.883\nIteration: 7939, learning rate: 0.00645, Loss: 0.2237, Accuracy:0.859\nIteration: 7940, learning rate: 0.00645, Loss: 0.1858, Accuracy:0.914\nIteration: 7941, learning rate: 0.00645, Loss: 0.2205, Accuracy:0.938\nIteration: 7942, learning rate: 0.00645, Loss: 0.2502, Accuracy:0.906\nIteration: 7943, learning rate: 0.00645, Loss: 0.2726, Accuracy:0.898\nIteration: 7944, learning rate: 0.00645, Loss: 0.1623, Accuracy:0.922\nIteration: 7945, learning rate: 0.00645, Loss: 0.2023, Accuracy:0.906\nIteration: 7946, learning rate: 0.00645, Loss: 0.2001, Accuracy:0.914\nIteration: 7947, learning rate: 0.00645, Loss: 0.2532, Accuracy:0.906\nIteration: 7948, learning rate: 0.00645, Loss: 0.1873, Accuracy:0.930\nIteration: 7949, learning rate: 0.00645, Loss: 0.1777, Accuracy:0.930\nIteration: 7950, learning rate: 0.00645, Loss: 0.2046, Accuracy:0.930\nIteration: 7951, learning rate: 0.00645, Loss: 0.2017, Accuracy:0.922\nIteration: 7952, learning rate: 0.00645, Loss: 0.1094, Accuracy:0.969\nIteration: 7953, learning rate: 0.00645, Loss: 0.1933, Accuracy:0.914\nIteration: 7954, learning rate: 0.00645, Loss: 0.2725, Accuracy:0.891\nIteration: 7955, learning rate: 0.00645, Loss: 0.2245, Accuracy:0.930\nIteration: 7956, learning rate: 0.00645, Loss: 0.2025, Accuracy:0.914\nIteration: 7957, learning rate: 0.00645, Loss: 0.2018, Accuracy:0.922\nIteration: 7958, learning rate: 0.00645, Loss: 0.2541, Accuracy:0.906\nIteration: 7959, learning rate: 0.00645, Loss: 0.1412, Accuracy:0.945\nIteration: 7960, learning rate: 0.00645, Loss: 0.2563, Accuracy:0.891\nIteration: 7961, learning rate: 0.00645, Loss: 0.2192, Accuracy:0.906\nIteration: 7962, learning rate: 0.00645, Loss: 0.2008, Accuracy:0.914\nIteration: 7963, learning rate: 0.00645, Loss: 0.1443, Accuracy:0.930\nIteration: 7964, learning rate: 0.00644, Loss: 0.2579, Accuracy:0.906\nIteration: 7965, learning rate: 0.00644, Loss: 0.1725, Accuracy:0.953\nIteration: 7966, learning rate: 0.00644, Loss: 0.2276, Accuracy:0.898\nIteration: 7967, learning rate: 0.00644, Loss: 0.1955, Accuracy:0.935\nEpoch: 257, Loss: 0.2073, Accuracy:0.917, Val Loss: 0.2621, Val Accuracy: 0.891\nIteration: 7968, learning rate: 0.00644, Loss: 0.1744, Accuracy:0.922\nIteration: 7969, learning rate: 0.00644, Loss: 0.2134, Accuracy:0.914\nIteration: 7970, learning rate: 0.00644, Loss: 0.1714, Accuracy:0.922\nIteration: 7971, learning rate: 0.00644, Loss: 0.2019, Accuracy:0.938\nIteration: 7972, learning rate: 0.00644, Loss: 0.1590, Accuracy:0.945\nIteration: 7973, learning rate: 0.00644, Loss: 0.2768, Accuracy:0.883\nIteration: 7974, learning rate: 0.00644, Loss: 0.2487, Accuracy:0.906\nIteration: 7975, learning rate: 0.00644, Loss: 0.1717, Accuracy:0.922\nIteration: 7976, learning rate: 0.00644, Loss: 0.2470, Accuracy:0.883\nIteration: 7977, learning rate: 0.00644, Loss: 0.2085, Accuracy:0.914\nIteration: 7978, learning rate: 0.00644, Loss: 0.1926, Accuracy:0.922\nIteration: 7979, learning rate: 0.00644, Loss: 0.1744, Accuracy:0.945\nIteration: 7980, learning rate: 0.00644, Loss: 0.1794, Accuracy:0.914\nIteration: 7981, learning rate: 0.00644, Loss: 0.1575, Accuracy:0.930\nIteration: 7982, learning rate: 0.00644, Loss: 0.2315, Accuracy:0.922\nIteration: 7983, learning rate: 0.00644, Loss: 0.1973, Accuracy:0.938\nIteration: 7984, learning rate: 0.00644, Loss: 0.1517, Accuracy:0.938\nIteration: 7985, learning rate: 0.00644, Loss: 0.2232, Accuracy:0.922\nIteration: 7986, learning rate: 0.00644, Loss: 0.1435, Accuracy:0.945\nIteration: 7987, learning rate: 0.00644, Loss: 0.1497, Accuracy:0.938\nIteration: 7988, learning rate: 0.00644, Loss: 0.1447, Accuracy:0.938\nIteration: 7989, learning rate: 0.00644, Loss: 0.2042, Accuracy:0.906\nIteration: 7990, learning rate: 0.00644, Loss: 0.1924, Accuracy:0.930\nIteration: 7991, learning rate: 0.00644, Loss: 0.1691, Accuracy:0.945\nIteration: 7992, learning rate: 0.00644, Loss: 0.2678, Accuracy:0.875\nIteration: 7993, learning rate: 0.00644, Loss: 0.3032, Accuracy:0.867\nIteration: 7994, learning rate: 0.00644, Loss: 0.1647, Accuracy:0.922\nIteration: 7995, learning rate: 0.00644, Loss: 0.2028, Accuracy:0.914\nIteration: 7996, learning rate: 0.00644, Loss: 0.1856, Accuracy:0.922\nIteration: 7997, learning rate: 0.00644, Loss: 0.2319, Accuracy:0.922\nIteration: 7998, learning rate: 0.00644, Loss: 0.1764, Accuracy:0.946\nEpoch: 258, Loss: 0.1973, Accuracy:0.921, Val Loss: 0.3005, Val Accuracy: 0.876\nIteration: 7999, learning rate: 0.00644, Loss: 0.1964, Accuracy:0.914\nIteration: 8000, learning rate: 0.00644, Loss: 0.1391, Accuracy:0.961\nIteration: 8001, learning rate: 0.00643, Loss: 0.2513, Accuracy:0.914\nIteration: 8002, learning rate: 0.00643, Loss: 0.1983, Accuracy:0.938\nIteration: 8003, learning rate: 0.00643, Loss: 0.1736, Accuracy:0.930\nIteration: 8004, learning rate: 0.00643, Loss: 0.1362, Accuracy:0.953\nIteration: 8005, learning rate: 0.00643, Loss: 0.1883, Accuracy:0.945\nIteration: 8006, learning rate: 0.00643, Loss: 0.2220, Accuracy:0.906\nIteration: 8007, learning rate: 0.00643, Loss: 0.1772, Accuracy:0.930\nIteration: 8008, learning rate: 0.00643, Loss: 0.2493, Accuracy:0.883\nIteration: 8009, learning rate: 0.00643, Loss: 0.1016, Accuracy:0.969\nIteration: 8010, learning rate: 0.00643, Loss: 0.1487, Accuracy:0.953\nIteration: 8011, learning rate: 0.00643, Loss: 0.1331, Accuracy:0.961\nIteration: 8012, learning rate: 0.00643, Loss: 0.1744, Accuracy:0.945\nIteration: 8013, learning rate: 0.00643, Loss: 0.1789, Accuracy:0.922\nIteration: 8014, learning rate: 0.00643, Loss: 0.2042, Accuracy:0.914\nIteration: 8015, learning rate: 0.00643, Loss: 0.1982, Accuracy:0.922\nIteration: 8016, learning rate: 0.00643, Loss: 0.2533, Accuracy:0.906\nIteration: 8017, learning rate: 0.00643, Loss: 0.2171, Accuracy:0.914\nIteration: 8018, learning rate: 0.00643, Loss: 0.1482, Accuracy:0.938\nIteration: 8019, learning rate: 0.00643, Loss: 0.1543, Accuracy:0.945\nIteration: 8020, learning rate: 0.00643, Loss: 0.2047, Accuracy:0.914\nIteration: 8021, learning rate: 0.00643, Loss: 0.1943, Accuracy:0.891\nIteration: 8022, learning rate: 0.00643, Loss: 0.2717, Accuracy:0.875\nIteration: 8023, learning rate: 0.00643, Loss: 0.1809, Accuracy:0.930\nIteration: 8024, learning rate: 0.00643, Loss: 0.1968, Accuracy:0.914\nIteration: 8025, learning rate: 0.00643, Loss: 0.1649, Accuracy:0.938\nIteration: 8026, learning rate: 0.00643, Loss: 0.1816, Accuracy:0.922\nIteration: 8027, learning rate: 0.00643, Loss: 0.1768, Accuracy:0.938\nIteration: 8028, learning rate: 0.00643, Loss: 0.1847, Accuracy:0.922\nIteration: 8029, learning rate: 0.00643, Loss: 0.2627, Accuracy:0.871\nEpoch: 259, Loss: 0.1891, Accuracy:0.925, Val Loss: 0.2698, Val Accuracy: 0.873\nIteration: 8030, learning rate: 0.00643, Loss: 0.1269, Accuracy:0.953\nIteration: 8031, learning rate: 0.00643, Loss: 0.2864, Accuracy:0.875\nIteration: 8032, learning rate: 0.00643, Loss: 0.1603, Accuracy:0.938\nIteration: 8033, learning rate: 0.00643, Loss: 0.2303, Accuracy:0.898\nIteration: 8034, learning rate: 0.00643, Loss: 0.2259, Accuracy:0.914\nIteration: 8035, learning rate: 0.00643, Loss: 0.1842, Accuracy:0.906\nIteration: 8036, learning rate: 0.00643, Loss: 0.1835, Accuracy:0.922\nIteration: 8037, learning rate: 0.00643, Loss: 0.1373, Accuracy:0.961\nIteration: 8038, learning rate: 0.00643, Loss: 0.2391, Accuracy:0.914\nIteration: 8039, learning rate: 0.00642, Loss: 0.2169, Accuracy:0.922\nIteration: 8040, learning rate: 0.00642, Loss: 0.2040, Accuracy:0.930\nIteration: 8041, learning rate: 0.00642, Loss: 0.1975, Accuracy:0.922\nIteration: 8042, learning rate: 0.00642, Loss: 0.2495, Accuracy:0.891\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8043, learning rate: 0.00642, Loss: 0.1194, Accuracy:0.969\nIteration: 8044, learning rate: 0.00642, Loss: 0.2559, Accuracy:0.875\nIteration: 8045, learning rate: 0.00642, Loss: 0.1387, Accuracy:0.938\nIteration: 8046, learning rate: 0.00642, Loss: 0.2234, Accuracy:0.930\nIteration: 8047, learning rate: 0.00642, Loss: 0.2620, Accuracy:0.867\nIteration: 8048, learning rate: 0.00642, Loss: 0.1635, Accuracy:0.914\nIteration: 8049, learning rate: 0.00642, Loss: 0.2010, Accuracy:0.906\nIteration: 8050, learning rate: 0.00642, Loss: 0.1791, Accuracy:0.930\nIteration: 8051, learning rate: 0.00642, Loss: 0.1488, Accuracy:0.953\nIteration: 8052, learning rate: 0.00642, Loss: 0.3223, Accuracy:0.883\nIteration: 8053, learning rate: 0.00642, Loss: 0.1423, Accuracy:0.953\nIteration: 8054, learning rate: 0.00642, Loss: 0.2369, Accuracy:0.898\nIteration: 8055, learning rate: 0.00642, Loss: 0.1660, Accuracy:0.953\nIteration: 8056, learning rate: 0.00642, Loss: 0.2341, Accuracy:0.914\nIteration: 8057, learning rate: 0.00642, Loss: 0.1797, Accuracy:0.922\nIteration: 8058, learning rate: 0.00642, Loss: 0.2344, Accuracy:0.891\nIteration: 8059, learning rate: 0.00642, Loss: 0.2728, Accuracy:0.898\nIteration: 8060, learning rate: 0.00642, Loss: 0.2246, Accuracy:0.892\nEpoch: 260, Loss: 0.2047, Accuracy:0.917, Val Loss: 0.2775, Val Accuracy: 0.884\nIteration: 8061, learning rate: 0.00642, Loss: 0.1743, Accuracy:0.930\nIteration: 8062, learning rate: 0.00642, Loss: 0.1543, Accuracy:0.930\nIteration: 8063, learning rate: 0.00642, Loss: 0.2843, Accuracy:0.891\nIteration: 8064, learning rate: 0.00642, Loss: 0.2578, Accuracy:0.867\nIteration: 8065, learning rate: 0.00642, Loss: 0.2081, Accuracy:0.891\nIteration: 8066, learning rate: 0.00642, Loss: 0.1936, Accuracy:0.938\nIteration: 8067, learning rate: 0.00642, Loss: 0.1515, Accuracy:0.953\nIteration: 8068, learning rate: 0.00642, Loss: 0.1230, Accuracy:0.961\nIteration: 8069, learning rate: 0.00642, Loss: 0.2481, Accuracy:0.867\nIteration: 8070, learning rate: 0.00642, Loss: 0.1686, Accuracy:0.930\nIteration: 8071, learning rate: 0.00642, Loss: 0.1238, Accuracy:0.969\nIteration: 8072, learning rate: 0.00642, Loss: 0.2794, Accuracy:0.867\nIteration: 8073, learning rate: 0.00642, Loss: 0.1621, Accuracy:0.938\nIteration: 8074, learning rate: 0.00642, Loss: 0.2163, Accuracy:0.930\nIteration: 8075, learning rate: 0.00642, Loss: 0.1964, Accuracy:0.938\nIteration: 8076, learning rate: 0.00641, Loss: 0.1704, Accuracy:0.953\nIteration: 8077, learning rate: 0.00641, Loss: 0.2062, Accuracy:0.930\nIteration: 8078, learning rate: 0.00641, Loss: 0.1477, Accuracy:0.953\nIteration: 8079, learning rate: 0.00641, Loss: 0.1741, Accuracy:0.953\nIteration: 8080, learning rate: 0.00641, Loss: 0.1713, Accuracy:0.922\nIteration: 8081, learning rate: 0.00641, Loss: 0.2570, Accuracy:0.914\nIteration: 8082, learning rate: 0.00641, Loss: 0.1949, Accuracy:0.930\nIteration: 8083, learning rate: 0.00641, Loss: 0.1096, Accuracy:0.953\nIteration: 8084, learning rate: 0.00641, Loss: 0.2021, Accuracy:0.898\nIteration: 8085, learning rate: 0.00641, Loss: 0.2318, Accuracy:0.906\nIteration: 8086, learning rate: 0.00641, Loss: 0.1792, Accuracy:0.922\nIteration: 8087, learning rate: 0.00641, Loss: 0.1869, Accuracy:0.938\nIteration: 8088, learning rate: 0.00641, Loss: 0.2346, Accuracy:0.883\nIteration: 8089, learning rate: 0.00641, Loss: 0.1443, Accuracy:0.930\nIteration: 8090, learning rate: 0.00641, Loss: 0.1855, Accuracy:0.945\nIteration: 8091, learning rate: 0.00641, Loss: 0.2107, Accuracy:0.892\nEpoch: 261, Loss: 0.1919, Accuracy:0.923, Val Loss: 0.3099, Val Accuracy: 0.872\nIteration: 8092, learning rate: 0.00641, Loss: 0.1892, Accuracy:0.914\nIteration: 8093, learning rate: 0.00641, Loss: 0.1897, Accuracy:0.906\nIteration: 8094, learning rate: 0.00641, Loss: 0.1810, Accuracy:0.930\nIteration: 8095, learning rate: 0.00641, Loss: 0.2233, Accuracy:0.906\nIteration: 8096, learning rate: 0.00641, Loss: 0.1491, Accuracy:0.945\nIteration: 8097, learning rate: 0.00641, Loss: 0.2331, Accuracy:0.922\nIteration: 8098, learning rate: 0.00641, Loss: 0.2376, Accuracy:0.922\nIteration: 8099, learning rate: 0.00641, Loss: 0.2412, Accuracy:0.883\nIteration: 8100, learning rate: 0.00641, Loss: 0.1935, Accuracy:0.930\nIteration: 8101, learning rate: 0.00641, Loss: 0.2495, Accuracy:0.898\nIteration: 8102, learning rate: 0.00641, Loss: 0.2597, Accuracy:0.898\nIteration: 8103, learning rate: 0.00641, Loss: 0.2144, Accuracy:0.922\nIteration: 8104, learning rate: 0.00641, Loss: 0.1788, Accuracy:0.922\nIteration: 8105, learning rate: 0.00641, Loss: 0.1331, Accuracy:0.969\nIteration: 8106, learning rate: 0.00641, Loss: 0.1483, Accuracy:0.953\nIteration: 8107, learning rate: 0.00641, Loss: 0.2441, Accuracy:0.914\nIteration: 8108, learning rate: 0.00641, Loss: 0.2127, Accuracy:0.930\nIteration: 8109, learning rate: 0.00641, Loss: 0.2080, Accuracy:0.930\nIteration: 8110, learning rate: 0.00641, Loss: 0.2653, Accuracy:0.891\nIteration: 8111, learning rate: 0.00641, Loss: 0.2092, Accuracy:0.914\nIteration: 8112, learning rate: 0.00641, Loss: 0.2129, Accuracy:0.914\nIteration: 8113, learning rate: 0.00641, Loss: 0.1582, Accuracy:0.930\nIteration: 8114, learning rate: 0.00640, Loss: 0.2775, Accuracy:0.898\nIteration: 8115, learning rate: 0.00640, Loss: 0.2561, Accuracy:0.898\nIteration: 8116, learning rate: 0.00640, Loss: 0.2284, Accuracy:0.906\nIteration: 8117, learning rate: 0.00640, Loss: 0.1670, Accuracy:0.906\nIteration: 8118, learning rate: 0.00640, Loss: 0.2080, Accuracy:0.930\nIteration: 8119, learning rate: 0.00640, Loss: 0.1946, Accuracy:0.930\nIteration: 8120, learning rate: 0.00640, Loss: 0.1935, Accuracy:0.906\nIteration: 8121, learning rate: 0.00640, Loss: 0.1533, Accuracy:0.945\nIteration: 8122, learning rate: 0.00640, Loss: 0.2080, Accuracy:0.903\nEpoch: 262, Loss: 0.2070, Accuracy:0.918, Val Loss: 0.3191, Val Accuracy: 0.879\nIteration: 8123, learning rate: 0.00640, Loss: 0.1803, Accuracy:0.945\nIteration: 8124, learning rate: 0.00640, Loss: 0.1954, Accuracy:0.906\nIteration: 8125, learning rate: 0.00640, Loss: 0.1861, Accuracy:0.922\nIteration: 8126, learning rate: 0.00640, Loss: 0.1925, Accuracy:0.906\nIteration: 8127, learning rate: 0.00640, Loss: 0.1836, Accuracy:0.914\nIteration: 8128, learning rate: 0.00640, Loss: 0.1977, Accuracy:0.914\nIteration: 8129, learning rate: 0.00640, Loss: 0.1301, Accuracy:0.953\nIteration: 8130, learning rate: 0.00640, Loss: 0.1383, Accuracy:0.953\nIteration: 8131, learning rate: 0.00640, Loss: 0.1860, Accuracy:0.914\nIteration: 8132, learning rate: 0.00640, Loss: 0.1826, Accuracy:0.938\nIteration: 8133, learning rate: 0.00640, Loss: 0.1814, Accuracy:0.914\nIteration: 8134, learning rate: 0.00640, Loss: 0.2213, Accuracy:0.922\nIteration: 8135, learning rate: 0.00640, Loss: 0.1736, Accuracy:0.930\nIteration: 8136, learning rate: 0.00640, Loss: 0.1874, Accuracy:0.922\nIteration: 8137, learning rate: 0.00640, Loss: 0.1696, Accuracy:0.930\nIteration: 8138, learning rate: 0.00640, Loss: 0.1184, Accuracy:0.953\nIteration: 8139, learning rate: 0.00640, Loss: 0.1650, Accuracy:0.930\nIteration: 8140, learning rate: 0.00640, Loss: 0.1954, Accuracy:0.938\nIteration: 8141, learning rate: 0.00640, Loss: 0.1360, Accuracy:0.945\nIteration: 8142, learning rate: 0.00640, Loss: 0.2682, Accuracy:0.891\nIteration: 8143, learning rate: 0.00640, Loss: 0.2103, Accuracy:0.922\nIteration: 8144, learning rate: 0.00640, Loss: 0.1931, Accuracy:0.914\nIteration: 8145, learning rate: 0.00640, Loss: 0.1898, Accuracy:0.906\nIteration: 8146, learning rate: 0.00640, Loss: 0.2530, Accuracy:0.883\nIteration: 8147, learning rate: 0.00640, Loss: 0.1580, Accuracy:0.945\nIteration: 8148, learning rate: 0.00640, Loss: 0.2409, Accuracy:0.891\nIteration: 8149, learning rate: 0.00640, Loss: 0.2115, Accuracy:0.906\nIteration: 8150, learning rate: 0.00640, Loss: 0.2678, Accuracy:0.906\nIteration: 8151, learning rate: 0.00640, Loss: 0.1851, Accuracy:0.914\nIteration: 8152, learning rate: 0.00639, Loss: 0.1433, Accuracy:0.930\nIteration: 8153, learning rate: 0.00639, Loss: 0.2541, Accuracy:0.903\nEpoch: 263, Loss: 0.1902, Accuracy:0.921, Val Loss: 0.2930, Val Accuracy: 0.882\nIteration: 8154, learning rate: 0.00639, Loss: 0.1667, Accuracy:0.922\nIteration: 8155, learning rate: 0.00639, Loss: 0.2459, Accuracy:0.898\nIteration: 8156, learning rate: 0.00639, Loss: 0.1656, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8157, learning rate: 0.00639, Loss: 0.1419, Accuracy:0.961\nIteration: 8158, learning rate: 0.00639, Loss: 0.1567, Accuracy:0.961\nIteration: 8159, learning rate: 0.00639, Loss: 0.1790, Accuracy:0.945\nIteration: 8160, learning rate: 0.00639, Loss: 0.1805, Accuracy:0.922\nIteration: 8161, learning rate: 0.00639, Loss: 0.2350, Accuracy:0.906\nIteration: 8162, learning rate: 0.00639, Loss: 0.1541, Accuracy:0.961\nIteration: 8163, learning rate: 0.00639, Loss: 0.2875, Accuracy:0.867\nIteration: 8164, learning rate: 0.00639, Loss: 0.1240, Accuracy:0.953\nIteration: 8165, learning rate: 0.00639, Loss: 0.1686, Accuracy:0.938\nIteration: 8166, learning rate: 0.00639, Loss: 0.1956, Accuracy:0.906\nIteration: 8167, learning rate: 0.00639, Loss: 0.2361, Accuracy:0.914\nIteration: 8168, learning rate: 0.00639, Loss: 0.1171, Accuracy:0.945\nIteration: 8169, learning rate: 0.00639, Loss: 0.1449, Accuracy:0.961\nIteration: 8170, learning rate: 0.00639, Loss: 0.2567, Accuracy:0.875\nIteration: 8171, learning rate: 0.00639, Loss: 0.1123, Accuracy:0.961\nIteration: 8172, learning rate: 0.00639, Loss: 0.1974, Accuracy:0.938\nIteration: 8173, learning rate: 0.00639, Loss: 0.2171, Accuracy:0.891\nIteration: 8174, learning rate: 0.00639, Loss: 0.1612, Accuracy:0.945\nIteration: 8175, learning rate: 0.00639, Loss: 0.1791, Accuracy:0.898\nIteration: 8176, learning rate: 0.00639, Loss: 0.1951, Accuracy:0.914\nIteration: 8177, learning rate: 0.00639, Loss: 0.1684, Accuracy:0.945\nIteration: 8178, learning rate: 0.00639, Loss: 0.1552, Accuracy:0.930\nIteration: 8179, learning rate: 0.00639, Loss: 0.1885, Accuracy:0.922\nIteration: 8180, learning rate: 0.00639, Loss: 0.2458, Accuracy:0.883\nIteration: 8181, learning rate: 0.00639, Loss: 0.1404, Accuracy:0.945\nIteration: 8182, learning rate: 0.00639, Loss: 0.1952, Accuracy:0.922\nIteration: 8183, learning rate: 0.00639, Loss: 0.2560, Accuracy:0.898\nIteration: 8184, learning rate: 0.00639, Loss: 0.1858, Accuracy:0.925\nEpoch: 264, Loss: 0.1856, Accuracy:0.925, Val Loss: 0.3373, Val Accuracy: 0.863\nIteration: 8185, learning rate: 0.00639, Loss: 0.2074, Accuracy:0.922\nIteration: 8186, learning rate: 0.00639, Loss: 0.1317, Accuracy:0.969\nIteration: 8187, learning rate: 0.00639, Loss: 0.1942, Accuracy:0.922\nIteration: 8188, learning rate: 0.00639, Loss: 0.1739, Accuracy:0.930\nIteration: 8189, learning rate: 0.00639, Loss: 0.1699, Accuracy:0.930\nIteration: 8190, learning rate: 0.00638, Loss: 0.1931, Accuracy:0.938\nIteration: 8191, learning rate: 0.00638, Loss: 0.1754, Accuracy:0.922\nIteration: 8192, learning rate: 0.00638, Loss: 0.2465, Accuracy:0.898\nIteration: 8193, learning rate: 0.00638, Loss: 0.1640, Accuracy:0.961\nIteration: 8194, learning rate: 0.00638, Loss: 0.2709, Accuracy:0.891\nIteration: 8195, learning rate: 0.00638, Loss: 0.1832, Accuracy:0.922\nIteration: 8196, learning rate: 0.00638, Loss: 0.2340, Accuracy:0.898\nIteration: 8197, learning rate: 0.00638, Loss: 0.1629, Accuracy:0.945\nIteration: 8198, learning rate: 0.00638, Loss: 0.2089, Accuracy:0.930\nIteration: 8199, learning rate: 0.00638, Loss: 0.2132, Accuracy:0.906\nIteration: 8200, learning rate: 0.00638, Loss: 0.2326, Accuracy:0.875\nIteration: 8201, learning rate: 0.00638, Loss: 0.1814, Accuracy:0.898\nIteration: 8202, learning rate: 0.00638, Loss: 0.0986, Accuracy:0.961\nIteration: 8203, learning rate: 0.00638, Loss: 0.2066, Accuracy:0.922\nIteration: 8204, learning rate: 0.00638, Loss: 0.1061, Accuracy:0.984\nIteration: 8205, learning rate: 0.00638, Loss: 0.1888, Accuracy:0.922\nIteration: 8206, learning rate: 0.00638, Loss: 0.1770, Accuracy:0.938\nIteration: 8207, learning rate: 0.00638, Loss: 0.1654, Accuracy:0.930\nIteration: 8208, learning rate: 0.00638, Loss: 0.2015, Accuracy:0.922\nIteration: 8209, learning rate: 0.00638, Loss: 0.2089, Accuracy:0.906\nIteration: 8210, learning rate: 0.00638, Loss: 0.1789, Accuracy:0.922\nIteration: 8211, learning rate: 0.00638, Loss: 0.2565, Accuracy:0.906\nIteration: 8212, learning rate: 0.00638, Loss: 0.2053, Accuracy:0.930\nIteration: 8213, learning rate: 0.00638, Loss: 0.1544, Accuracy:0.977\nIteration: 8214, learning rate: 0.00638, Loss: 0.1662, Accuracy:0.930\nIteration: 8215, learning rate: 0.00638, Loss: 0.2100, Accuracy:0.914\nEpoch: 265, Loss: 0.1893, Accuracy:0.926, Val Loss: 0.3058, Val Accuracy: 0.881\nIteration: 8216, learning rate: 0.00638, Loss: 0.1306, Accuracy:0.953\nIteration: 8217, learning rate: 0.00638, Loss: 0.2822, Accuracy:0.883\nIteration: 8218, learning rate: 0.00638, Loss: 0.2445, Accuracy:0.883\nIteration: 8219, learning rate: 0.00638, Loss: 0.2175, Accuracy:0.914\nIteration: 8220, learning rate: 0.00638, Loss: 0.1741, Accuracy:0.906\nIteration: 8221, learning rate: 0.00638, Loss: 0.3131, Accuracy:0.852\nIteration: 8222, learning rate: 0.00638, Loss: 0.1767, Accuracy:0.938\nIteration: 8223, learning rate: 0.00638, Loss: 0.1127, Accuracy:0.961\nIteration: 8224, learning rate: 0.00638, Loss: 0.1989, Accuracy:0.898\nIteration: 8225, learning rate: 0.00638, Loss: 0.2598, Accuracy:0.891\nIteration: 8226, learning rate: 0.00638, Loss: 0.2465, Accuracy:0.945\nIteration: 8227, learning rate: 0.00638, Loss: 0.1536, Accuracy:0.945\nIteration: 8228, learning rate: 0.00637, Loss: 0.2545, Accuracy:0.898\nIteration: 8229, learning rate: 0.00637, Loss: 0.1758, Accuracy:0.945\nIteration: 8230, learning rate: 0.00637, Loss: 0.1978, Accuracy:0.891\nIteration: 8231, learning rate: 0.00637, Loss: 0.1879, Accuracy:0.922\nIteration: 8232, learning rate: 0.00637, Loss: 0.2067, Accuracy:0.938\nIteration: 8233, learning rate: 0.00637, Loss: 0.1647, Accuracy:0.922\nIteration: 8234, learning rate: 0.00637, Loss: 0.1902, Accuracy:0.891\nIteration: 8235, learning rate: 0.00637, Loss: 0.1882, Accuracy:0.922\nIteration: 8236, learning rate: 0.00637, Loss: 0.1997, Accuracy:0.898\nIteration: 8237, learning rate: 0.00637, Loss: 0.2577, Accuracy:0.883\nIteration: 8238, learning rate: 0.00637, Loss: 0.0794, Accuracy:0.992\nIteration: 8239, learning rate: 0.00637, Loss: 0.1965, Accuracy:0.922\nIteration: 8240, learning rate: 0.00637, Loss: 0.2088, Accuracy:0.891\nIteration: 8241, learning rate: 0.00637, Loss: 0.2057, Accuracy:0.922\nIteration: 8242, learning rate: 0.00637, Loss: 0.2307, Accuracy:0.891\nIteration: 8243, learning rate: 0.00637, Loss: 0.1849, Accuracy:0.938\nIteration: 8244, learning rate: 0.00637, Loss: 0.2030, Accuracy:0.938\nIteration: 8245, learning rate: 0.00637, Loss: 0.1995, Accuracy:0.898\nIteration: 8246, learning rate: 0.00637, Loss: 0.1997, Accuracy:0.914\nEpoch: 266, Loss: 0.2013, Accuracy:0.916, Val Loss: 0.3393, Val Accuracy: 0.868\nIteration: 8247, learning rate: 0.00637, Loss: 0.1926, Accuracy:0.922\nIteration: 8248, learning rate: 0.00637, Loss: 0.1988, Accuracy:0.922\nIteration: 8249, learning rate: 0.00637, Loss: 0.1843, Accuracy:0.914\nIteration: 8250, learning rate: 0.00637, Loss: 0.2334, Accuracy:0.922\nIteration: 8251, learning rate: 0.00637, Loss: 0.2537, Accuracy:0.898\nIteration: 8252, learning rate: 0.00637, Loss: 0.1983, Accuracy:0.922\nIteration: 8253, learning rate: 0.00637, Loss: 0.1970, Accuracy:0.922\nIteration: 8254, learning rate: 0.00637, Loss: 0.1928, Accuracy:0.922\nIteration: 8255, learning rate: 0.00637, Loss: 0.2044, Accuracy:0.922\nIteration: 8256, learning rate: 0.00637, Loss: 0.1987, Accuracy:0.898\nIteration: 8257, learning rate: 0.00637, Loss: 0.1920, Accuracy:0.922\nIteration: 8258, learning rate: 0.00637, Loss: 0.2081, Accuracy:0.914\nIteration: 8259, learning rate: 0.00637, Loss: 0.1697, Accuracy:0.930\nIteration: 8260, learning rate: 0.00637, Loss: 0.2345, Accuracy:0.891\nIteration: 8261, learning rate: 0.00637, Loss: 0.1847, Accuracy:0.938\nIteration: 8262, learning rate: 0.00637, Loss: 0.1723, Accuracy:0.906\nIteration: 8263, learning rate: 0.00637, Loss: 0.1395, Accuracy:0.945\nIteration: 8264, learning rate: 0.00637, Loss: 0.1942, Accuracy:0.945\nIteration: 8265, learning rate: 0.00637, Loss: 0.1534, Accuracy:0.938\nIteration: 8266, learning rate: 0.00636, Loss: 0.2011, Accuracy:0.898\nIteration: 8267, learning rate: 0.00636, Loss: 0.2190, Accuracy:0.914\nIteration: 8268, learning rate: 0.00636, Loss: 0.2067, Accuracy:0.906\nIteration: 8269, learning rate: 0.00636, Loss: 0.1987, Accuracy:0.914\nIteration: 8270, learning rate: 0.00636, Loss: 0.2460, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8271, learning rate: 0.00636, Loss: 0.2368, Accuracy:0.906\nIteration: 8272, learning rate: 0.00636, Loss: 0.1517, Accuracy:0.953\nIteration: 8273, learning rate: 0.00636, Loss: 0.2320, Accuracy:0.906\nIteration: 8274, learning rate: 0.00636, Loss: 0.1811, Accuracy:0.938\nIteration: 8275, learning rate: 0.00636, Loss: 0.2039, Accuracy:0.930\nIteration: 8276, learning rate: 0.00636, Loss: 0.2180, Accuracy:0.930\nIteration: 8277, learning rate: 0.00636, Loss: 0.0961, Accuracy:0.978\nEpoch: 267, Loss: 0.1966, Accuracy:0.922, Val Loss: 0.3829, Val Accuracy: 0.847\nIteration: 8278, learning rate: 0.00636, Loss: 0.2948, Accuracy:0.906\nIteration: 8279, learning rate: 0.00636, Loss: 0.1743, Accuracy:0.906\nIteration: 8280, learning rate: 0.00636, Loss: 0.2018, Accuracy:0.914\nIteration: 8281, learning rate: 0.00636, Loss: 0.2096, Accuracy:0.875\nIteration: 8282, learning rate: 0.00636, Loss: 0.2408, Accuracy:0.906\nIteration: 8283, learning rate: 0.00636, Loss: 0.1099, Accuracy:0.977\nIteration: 8284, learning rate: 0.00636, Loss: 0.1954, Accuracy:0.930\nIteration: 8285, learning rate: 0.00636, Loss: 0.1676, Accuracy:0.945\nIteration: 8286, learning rate: 0.00636, Loss: 0.1838, Accuracy:0.938\nIteration: 8287, learning rate: 0.00636, Loss: 0.1364, Accuracy:0.953\nIteration: 8288, learning rate: 0.00636, Loss: 0.2163, Accuracy:0.914\nIteration: 8289, learning rate: 0.00636, Loss: 0.1482, Accuracy:0.938\nIteration: 8290, learning rate: 0.00636, Loss: 0.1620, Accuracy:0.945\nIteration: 8291, learning rate: 0.00636, Loss: 0.2803, Accuracy:0.898\nIteration: 8292, learning rate: 0.00636, Loss: 0.1730, Accuracy:0.945\nIteration: 8293, learning rate: 0.00636, Loss: 0.1444, Accuracy:0.953\nIteration: 8294, learning rate: 0.00636, Loss: 0.1771, Accuracy:0.945\nIteration: 8295, learning rate: 0.00636, Loss: 0.2006, Accuracy:0.938\nIteration: 8296, learning rate: 0.00636, Loss: 0.1990, Accuracy:0.938\nIteration: 8297, learning rate: 0.00636, Loss: 0.1657, Accuracy:0.938\nIteration: 8298, learning rate: 0.00636, Loss: 0.1743, Accuracy:0.938\nIteration: 8299, learning rate: 0.00636, Loss: 0.1748, Accuracy:0.930\nIteration: 8300, learning rate: 0.00636, Loss: 0.2160, Accuracy:0.906\nIteration: 8301, learning rate: 0.00636, Loss: 0.2092, Accuracy:0.930\nIteration: 8302, learning rate: 0.00636, Loss: 0.1867, Accuracy:0.945\nIteration: 8303, learning rate: 0.00636, Loss: 0.2572, Accuracy:0.891\nIteration: 8304, learning rate: 0.00635, Loss: 0.2482, Accuracy:0.906\nIteration: 8305, learning rate: 0.00635, Loss: 0.2518, Accuracy:0.906\nIteration: 8306, learning rate: 0.00635, Loss: 0.2231, Accuracy:0.922\nIteration: 8307, learning rate: 0.00635, Loss: 0.2173, Accuracy:0.898\nIteration: 8308, learning rate: 0.00635, Loss: 0.1351, Accuracy:0.968\nEpoch: 268, Loss: 0.1959, Accuracy:0.927, Val Loss: 0.3099, Val Accuracy: 0.867\nIteration: 8309, learning rate: 0.00635, Loss: 0.1904, Accuracy:0.922\nIteration: 8310, learning rate: 0.00635, Loss: 0.2150, Accuracy:0.945\nIteration: 8311, learning rate: 0.00635, Loss: 0.1788, Accuracy:0.930\nIteration: 8312, learning rate: 0.00635, Loss: 0.1491, Accuracy:0.961\nIteration: 8313, learning rate: 0.00635, Loss: 0.2632, Accuracy:0.883\nIteration: 8314, learning rate: 0.00635, Loss: 0.2372, Accuracy:0.898\nIteration: 8315, learning rate: 0.00635, Loss: 0.1456, Accuracy:0.945\nIteration: 8316, learning rate: 0.00635, Loss: 0.1742, Accuracy:0.914\nIteration: 8317, learning rate: 0.00635, Loss: 0.1961, Accuracy:0.914\nIteration: 8318, learning rate: 0.00635, Loss: 0.1944, Accuracy:0.906\nIteration: 8319, learning rate: 0.00635, Loss: 0.2659, Accuracy:0.891\nIteration: 8320, learning rate: 0.00635, Loss: 0.1232, Accuracy:0.969\nIteration: 8321, learning rate: 0.00635, Loss: 0.2294, Accuracy:0.891\nIteration: 8322, learning rate: 0.00635, Loss: 0.1290, Accuracy:0.945\nIteration: 8323, learning rate: 0.00635, Loss: 0.1281, Accuracy:0.953\nIteration: 8324, learning rate: 0.00635, Loss: 0.1878, Accuracy:0.938\nIteration: 8325, learning rate: 0.00635, Loss: 0.1588, Accuracy:0.922\nIteration: 8326, learning rate: 0.00635, Loss: 0.2291, Accuracy:0.922\nIteration: 8327, learning rate: 0.00635, Loss: 0.1857, Accuracy:0.914\nIteration: 8328, learning rate: 0.00635, Loss: 0.1173, Accuracy:0.961\nIteration: 8329, learning rate: 0.00635, Loss: 0.2014, Accuracy:0.914\nIteration: 8330, learning rate: 0.00635, Loss: 0.1541, Accuracy:0.922\nIteration: 8331, learning rate: 0.00635, Loss: 0.1985, Accuracy:0.938\nIteration: 8332, learning rate: 0.00635, Loss: 0.1406, Accuracy:0.961\nIteration: 8333, learning rate: 0.00635, Loss: 0.1454, Accuracy:0.938\nIteration: 8334, learning rate: 0.00635, Loss: 0.2639, Accuracy:0.875\nIteration: 8335, learning rate: 0.00635, Loss: 0.2221, Accuracy:0.914\nIteration: 8336, learning rate: 0.00635, Loss: 0.2185, Accuracy:0.922\nIteration: 8337, learning rate: 0.00635, Loss: 0.1574, Accuracy:0.930\nIteration: 8338, learning rate: 0.00635, Loss: 0.1891, Accuracy:0.945\nIteration: 8339, learning rate: 0.00635, Loss: 0.1568, Accuracy:0.946\nEpoch: 269, Loss: 0.1854, Accuracy:0.927, Val Loss: 0.2899, Val Accuracy: 0.873\nIteration: 8340, learning rate: 0.00635, Loss: 0.1146, Accuracy:0.953\nIteration: 8341, learning rate: 0.00635, Loss: 0.1843, Accuracy:0.914\nIteration: 8342, learning rate: 0.00635, Loss: 0.1643, Accuracy:0.938\nIteration: 8343, learning rate: 0.00634, Loss: 0.1420, Accuracy:0.953\nIteration: 8344, learning rate: 0.00634, Loss: 0.1315, Accuracy:0.969\nIteration: 8345, learning rate: 0.00634, Loss: 0.2089, Accuracy:0.922\nIteration: 8346, learning rate: 0.00634, Loss: 0.2081, Accuracy:0.930\nIteration: 8347, learning rate: 0.00634, Loss: 0.1438, Accuracy:0.961\nIteration: 8348, learning rate: 0.00634, Loss: 0.2072, Accuracy:0.914\nIteration: 8349, learning rate: 0.00634, Loss: 0.2092, Accuracy:0.930\nIteration: 8350, learning rate: 0.00634, Loss: 0.2586, Accuracy:0.891\nIteration: 8351, learning rate: 0.00634, Loss: 0.1835, Accuracy:0.930\nIteration: 8352, learning rate: 0.00634, Loss: 0.2245, Accuracy:0.891\nIteration: 8353, learning rate: 0.00634, Loss: 0.1241, Accuracy:0.977\nIteration: 8354, learning rate: 0.00634, Loss: 0.1583, Accuracy:0.969\nIteration: 8355, learning rate: 0.00634, Loss: 0.1752, Accuracy:0.930\nIteration: 8356, learning rate: 0.00634, Loss: 0.1769, Accuracy:0.953\nIteration: 8357, learning rate: 0.00634, Loss: 0.2383, Accuracy:0.891\nIteration: 8358, learning rate: 0.00634, Loss: 0.1447, Accuracy:0.930\nIteration: 8359, learning rate: 0.00634, Loss: 0.1236, Accuracy:0.961\nIteration: 8360, learning rate: 0.00634, Loss: 0.1917, Accuracy:0.938\nIteration: 8361, learning rate: 0.00634, Loss: 0.1697, Accuracy:0.945\nIteration: 8362, learning rate: 0.00634, Loss: 0.1791, Accuracy:0.930\nIteration: 8363, learning rate: 0.00634, Loss: 0.1762, Accuracy:0.953\nIteration: 8364, learning rate: 0.00634, Loss: 0.1810, Accuracy:0.945\nIteration: 8365, learning rate: 0.00634, Loss: 0.3133, Accuracy:0.883\nIteration: 8366, learning rate: 0.00634, Loss: 0.1444, Accuracy:0.969\nIteration: 8367, learning rate: 0.00634, Loss: 0.2097, Accuracy:0.922\nIteration: 8368, learning rate: 0.00634, Loss: 0.1995, Accuracy:0.914\nIteration: 8369, learning rate: 0.00634, Loss: 0.1869, Accuracy:0.914\nIteration: 8370, learning rate: 0.00634, Loss: 0.1523, Accuracy:0.935\nEpoch: 270, Loss: 0.1815, Accuracy:0.934, Val Loss: 0.3761, Val Accuracy: 0.845\nIteration: 8371, learning rate: 0.00634, Loss: 0.2719, Accuracy:0.883\nIteration: 8372, learning rate: 0.00634, Loss: 0.1091, Accuracy:0.961\nIteration: 8373, learning rate: 0.00634, Loss: 0.2468, Accuracy:0.883\nIteration: 8374, learning rate: 0.00634, Loss: 0.2083, Accuracy:0.906\nIteration: 8375, learning rate: 0.00634, Loss: 0.1753, Accuracy:0.945\nIteration: 8376, learning rate: 0.00634, Loss: 0.1397, Accuracy:0.969\nIteration: 8377, learning rate: 0.00634, Loss: 0.1782, Accuracy:0.922\nIteration: 8378, learning rate: 0.00634, Loss: 0.1918, Accuracy:0.930\nIteration: 8379, learning rate: 0.00634, Loss: 0.1926, Accuracy:0.891\nIteration: 8380, learning rate: 0.00634, Loss: 0.2235, Accuracy:0.914\nIteration: 8381, learning rate: 0.00633, Loss: 0.2006, Accuracy:0.945\nIteration: 8382, learning rate: 0.00633, Loss: 0.1772, Accuracy:0.922\nIteration: 8383, learning rate: 0.00633, Loss: 0.1820, Accuracy:0.945\nIteration: 8384, learning rate: 0.00633, Loss: 0.2106, Accuracy:0.906\nIteration: 8385, learning rate: 0.00633, Loss: 0.2061, Accuracy:0.875\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8386, learning rate: 0.00633, Loss: 0.1385, Accuracy:0.961\nIteration: 8387, learning rate: 0.00633, Loss: 0.1332, Accuracy:0.953\nIteration: 8388, learning rate: 0.00633, Loss: 0.2322, Accuracy:0.914\nIteration: 8389, learning rate: 0.00633, Loss: 0.1787, Accuracy:0.930\nIteration: 8390, learning rate: 0.00633, Loss: 0.1801, Accuracy:0.938\nIteration: 8391, learning rate: 0.00633, Loss: 0.1910, Accuracy:0.938\nIteration: 8392, learning rate: 0.00633, Loss: 0.2092, Accuracy:0.938\nIteration: 8393, learning rate: 0.00633, Loss: 0.1890, Accuracy:0.930\nIteration: 8394, learning rate: 0.00633, Loss: 0.2804, Accuracy:0.867\nIteration: 8395, learning rate: 0.00633, Loss: 0.1937, Accuracy:0.930\nIteration: 8396, learning rate: 0.00633, Loss: 0.2311, Accuracy:0.906\nIteration: 8397, learning rate: 0.00633, Loss: 0.2091, Accuracy:0.938\nIteration: 8398, learning rate: 0.00633, Loss: 0.2593, Accuracy:0.914\nIteration: 8399, learning rate: 0.00633, Loss: 0.1722, Accuracy:0.922\nIteration: 8400, learning rate: 0.00633, Loss: 0.2000, Accuracy:0.914\nIteration: 8401, learning rate: 0.00633, Loss: 0.1620, Accuracy:0.935\nEpoch: 271, Loss: 0.1959, Accuracy:0.923, Val Loss: 0.3108, Val Accuracy: 0.877\nIteration: 8402, learning rate: 0.00633, Loss: 0.2200, Accuracy:0.898\nIteration: 8403, learning rate: 0.00633, Loss: 0.1878, Accuracy:0.930\nIteration: 8404, learning rate: 0.00633, Loss: 0.0902, Accuracy:0.984\nIteration: 8405, learning rate: 0.00633, Loss: 0.1808, Accuracy:0.922\nIteration: 8406, learning rate: 0.00633, Loss: 0.1339, Accuracy:0.953\nIteration: 8407, learning rate: 0.00633, Loss: 0.1770, Accuracy:0.930\nIteration: 8408, learning rate: 0.00633, Loss: 0.1650, Accuracy:0.938\nIteration: 8409, learning rate: 0.00633, Loss: 0.1908, Accuracy:0.914\nIteration: 8410, learning rate: 0.00633, Loss: 0.2414, Accuracy:0.898\nIteration: 8411, learning rate: 0.00633, Loss: 0.2137, Accuracy:0.898\nIteration: 8412, learning rate: 0.00633, Loss: 0.2215, Accuracy:0.906\nIteration: 8413, learning rate: 0.00633, Loss: 0.1516, Accuracy:0.961\nIteration: 8414, learning rate: 0.00633, Loss: 0.2709, Accuracy:0.922\nIteration: 8415, learning rate: 0.00633, Loss: 0.1955, Accuracy:0.914\nIteration: 8416, learning rate: 0.00633, Loss: 0.2259, Accuracy:0.930\nIteration: 8417, learning rate: 0.00633, Loss: 0.1394, Accuracy:0.945\nIteration: 8418, learning rate: 0.00633, Loss: 0.1817, Accuracy:0.914\nIteration: 8419, learning rate: 0.00633, Loss: 0.1801, Accuracy:0.914\nIteration: 8420, learning rate: 0.00632, Loss: 0.1867, Accuracy:0.914\nIteration: 8421, learning rate: 0.00632, Loss: 0.1469, Accuracy:0.953\nIteration: 8422, learning rate: 0.00632, Loss: 0.1739, Accuracy:0.938\nIteration: 8423, learning rate: 0.00632, Loss: 0.1679, Accuracy:0.922\nIteration: 8424, learning rate: 0.00632, Loss: 0.1983, Accuracy:0.906\nIteration: 8425, learning rate: 0.00632, Loss: 0.1930, Accuracy:0.938\nIteration: 8426, learning rate: 0.00632, Loss: 0.1779, Accuracy:0.938\nIteration: 8427, learning rate: 0.00632, Loss: 0.2560, Accuracy:0.898\nIteration: 8428, learning rate: 0.00632, Loss: 0.2529, Accuracy:0.883\nIteration: 8429, learning rate: 0.00632, Loss: 0.1340, Accuracy:0.961\nIteration: 8430, learning rate: 0.00632, Loss: 0.1522, Accuracy:0.945\nIteration: 8431, learning rate: 0.00632, Loss: 0.1502, Accuracy:0.953\nIteration: 8432, learning rate: 0.00632, Loss: 0.1462, Accuracy:0.946\nEpoch: 272, Loss: 0.1840, Accuracy:0.928, Val Loss: 0.3713, Val Accuracy: 0.846\nIteration: 8433, learning rate: 0.00632, Loss: 0.1956, Accuracy:0.883\nIteration: 8434, learning rate: 0.00632, Loss: 0.1621, Accuracy:0.938\nIteration: 8435, learning rate: 0.00632, Loss: 0.1516, Accuracy:0.938\nIteration: 8436, learning rate: 0.00632, Loss: 0.2153, Accuracy:0.914\nIteration: 8437, learning rate: 0.00632, Loss: 0.2088, Accuracy:0.883\nIteration: 8438, learning rate: 0.00632, Loss: 0.1754, Accuracy:0.922\nIteration: 8439, learning rate: 0.00632, Loss: 0.2287, Accuracy:0.906\nIteration: 8440, learning rate: 0.00632, Loss: 0.1859, Accuracy:0.945\nIteration: 8441, learning rate: 0.00632, Loss: 0.1919, Accuracy:0.938\nIteration: 8442, learning rate: 0.00632, Loss: 0.1804, Accuracy:0.914\nIteration: 8443, learning rate: 0.00632, Loss: 0.1920, Accuracy:0.906\nIteration: 8444, learning rate: 0.00632, Loss: 0.1213, Accuracy:0.945\nIteration: 8445, learning rate: 0.00632, Loss: 0.1446, Accuracy:0.938\nIteration: 8446, learning rate: 0.00632, Loss: 0.2340, Accuracy:0.891\nIteration: 8447, learning rate: 0.00632, Loss: 0.2041, Accuracy:0.922\nIteration: 8448, learning rate: 0.00632, Loss: 0.1623, Accuracy:0.938\nIteration: 8449, learning rate: 0.00632, Loss: 0.2343, Accuracy:0.875\nIteration: 8450, learning rate: 0.00632, Loss: 0.3098, Accuracy:0.898\nIteration: 8451, learning rate: 0.00632, Loss: 0.2413, Accuracy:0.922\nIteration: 8452, learning rate: 0.00632, Loss: 0.2181, Accuracy:0.906\nIteration: 8453, learning rate: 0.00632, Loss: 0.1443, Accuracy:0.938\nIteration: 8454, learning rate: 0.00632, Loss: 0.2209, Accuracy:0.875\nIteration: 8455, learning rate: 0.00632, Loss: 0.2873, Accuracy:0.859\nIteration: 8456, learning rate: 0.00632, Loss: 0.1991, Accuracy:0.922\nIteration: 8457, learning rate: 0.00632, Loss: 0.1243, Accuracy:0.938\nIteration: 8458, learning rate: 0.00632, Loss: 0.1807, Accuracy:0.930\nIteration: 8459, learning rate: 0.00631, Loss: 0.1727, Accuracy:0.922\nIteration: 8460, learning rate: 0.00631, Loss: 0.1955, Accuracy:0.922\nIteration: 8461, learning rate: 0.00631, Loss: 0.2460, Accuracy:0.891\nIteration: 8462, learning rate: 0.00631, Loss: 0.1427, Accuracy:0.930\nIteration: 8463, learning rate: 0.00631, Loss: 0.1747, Accuracy:0.925\nEpoch: 273, Loss: 0.1950, Accuracy:0.915, Val Loss: 0.2897, Val Accuracy: 0.881\nIteration: 8464, learning rate: 0.00631, Loss: 0.1842, Accuracy:0.945\nIteration: 8465, learning rate: 0.00631, Loss: 0.2121, Accuracy:0.938\nIteration: 8466, learning rate: 0.00631, Loss: 0.1746, Accuracy:0.922\nIteration: 8467, learning rate: 0.00631, Loss: 0.1806, Accuracy:0.930\nIteration: 8468, learning rate: 0.00631, Loss: 0.2313, Accuracy:0.906\nIteration: 8469, learning rate: 0.00631, Loss: 0.1379, Accuracy:0.945\nIteration: 8470, learning rate: 0.00631, Loss: 0.2096, Accuracy:0.891\nIteration: 8471, learning rate: 0.00631, Loss: 0.2089, Accuracy:0.906\nIteration: 8472, learning rate: 0.00631, Loss: 0.1997, Accuracy:0.945\nIteration: 8473, learning rate: 0.00631, Loss: 0.1894, Accuracy:0.938\nIteration: 8474, learning rate: 0.00631, Loss: 0.1361, Accuracy:0.953\nIteration: 8475, learning rate: 0.00631, Loss: 0.2181, Accuracy:0.930\nIteration: 8476, learning rate: 0.00631, Loss: 0.2290, Accuracy:0.891\nIteration: 8477, learning rate: 0.00631, Loss: 0.2116, Accuracy:0.938\nIteration: 8478, learning rate: 0.00631, Loss: 0.2101, Accuracy:0.930\nIteration: 8479, learning rate: 0.00631, Loss: 0.2274, Accuracy:0.906\nIteration: 8480, learning rate: 0.00631, Loss: 0.1908, Accuracy:0.922\nIteration: 8481, learning rate: 0.00631, Loss: 0.1946, Accuracy:0.914\nIteration: 8482, learning rate: 0.00631, Loss: 0.2695, Accuracy:0.867\nIteration: 8483, learning rate: 0.00631, Loss: 0.1212, Accuracy:0.969\nIteration: 8484, learning rate: 0.00631, Loss: 0.2523, Accuracy:0.898\nIteration: 8485, learning rate: 0.00631, Loss: 0.1573, Accuracy:0.938\nIteration: 8486, learning rate: 0.00631, Loss: 0.2018, Accuracy:0.914\nIteration: 8487, learning rate: 0.00631, Loss: 0.1344, Accuracy:0.953\nIteration: 8488, learning rate: 0.00631, Loss: 0.2601, Accuracy:0.867\nIteration: 8489, learning rate: 0.00631, Loss: 0.1424, Accuracy:0.945\nIteration: 8490, learning rate: 0.00631, Loss: 0.2205, Accuracy:0.898\nIteration: 8491, learning rate: 0.00631, Loss: 0.2812, Accuracy:0.883\nIteration: 8492, learning rate: 0.00631, Loss: 0.1972, Accuracy:0.906\nIteration: 8493, learning rate: 0.00631, Loss: 0.1496, Accuracy:0.945\nIteration: 8494, learning rate: 0.00631, Loss: 0.1859, Accuracy:0.914\nEpoch: 274, Loss: 0.1974, Accuracy:0.921, Val Loss: 0.3037, Val Accuracy: 0.856\nIteration: 8495, learning rate: 0.00631, Loss: 0.1578, Accuracy:0.938\nIteration: 8496, learning rate: 0.00631, Loss: 0.2357, Accuracy:0.914\nIteration: 8497, learning rate: 0.00631, Loss: 0.1820, Accuracy:0.938\nIteration: 8498, learning rate: 0.00630, Loss: 0.1063, Accuracy:0.977\nIteration: 8499, learning rate: 0.00630, Loss: 0.1174, Accuracy:0.969\nIteration: 8500, learning rate: 0.00630, Loss: 0.2016, Accuracy:0.914\nIteration: 8501, learning rate: 0.00630, Loss: 0.1822, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8502, learning rate: 0.00630, Loss: 0.2255, Accuracy:0.898\nIteration: 8503, learning rate: 0.00630, Loss: 0.2976, Accuracy:0.883\nIteration: 8504, learning rate: 0.00630, Loss: 0.1818, Accuracy:0.914\nIteration: 8505, learning rate: 0.00630, Loss: 0.1879, Accuracy:0.922\nIteration: 8506, learning rate: 0.00630, Loss: 0.1501, Accuracy:0.969\nIteration: 8507, learning rate: 0.00630, Loss: 0.2896, Accuracy:0.891\nIteration: 8508, learning rate: 0.00630, Loss: 0.2875, Accuracy:0.883\nIteration: 8509, learning rate: 0.00630, Loss: 0.2155, Accuracy:0.930\nIteration: 8510, learning rate: 0.00630, Loss: 0.1551, Accuracy:0.945\nIteration: 8511, learning rate: 0.00630, Loss: 0.2861, Accuracy:0.875\nIteration: 8512, learning rate: 0.00630, Loss: 0.1742, Accuracy:0.930\nIteration: 8513, learning rate: 0.00630, Loss: 0.2185, Accuracy:0.914\nIteration: 8514, learning rate: 0.00630, Loss: 0.1349, Accuracy:0.945\nIteration: 8515, learning rate: 0.00630, Loss: 0.1887, Accuracy:0.930\nIteration: 8516, learning rate: 0.00630, Loss: 0.2563, Accuracy:0.891\nIteration: 8517, learning rate: 0.00630, Loss: 0.1394, Accuracy:0.961\nIteration: 8518, learning rate: 0.00630, Loss: 0.1374, Accuracy:0.961\nIteration: 8519, learning rate: 0.00630, Loss: 0.1884, Accuracy:0.938\nIteration: 8520, learning rate: 0.00630, Loss: 0.1994, Accuracy:0.914\nIteration: 8521, learning rate: 0.00630, Loss: 0.1559, Accuracy:0.945\nIteration: 8522, learning rate: 0.00630, Loss: 0.2515, Accuracy:0.914\nIteration: 8523, learning rate: 0.00630, Loss: 0.2192, Accuracy:0.898\nIteration: 8524, learning rate: 0.00630, Loss: 0.2130, Accuracy:0.922\nIteration: 8525, learning rate: 0.00630, Loss: 0.1423, Accuracy:0.946\nEpoch: 275, Loss: 0.1961, Accuracy:0.925, Val Loss: 0.2910, Val Accuracy: 0.875\nIteration: 8526, learning rate: 0.00630, Loss: 0.2109, Accuracy:0.898\nIteration: 8527, learning rate: 0.00630, Loss: 0.1358, Accuracy:0.961\nIteration: 8528, learning rate: 0.00630, Loss: 0.2085, Accuracy:0.914\nIteration: 8529, learning rate: 0.00630, Loss: 0.2466, Accuracy:0.906\nIteration: 8530, learning rate: 0.00630, Loss: 0.1470, Accuracy:0.945\nIteration: 8531, learning rate: 0.00630, Loss: 0.1513, Accuracy:0.953\nIteration: 8532, learning rate: 0.00630, Loss: 0.2133, Accuracy:0.898\nIteration: 8533, learning rate: 0.00630, Loss: 0.1883, Accuracy:0.945\nIteration: 8534, learning rate: 0.00630, Loss: 0.2321, Accuracy:0.906\nIteration: 8535, learning rate: 0.00630, Loss: 0.1591, Accuracy:0.938\nIteration: 8536, learning rate: 0.00630, Loss: 0.1116, Accuracy:0.945\nIteration: 8537, learning rate: 0.00629, Loss: 0.1854, Accuracy:0.914\nIteration: 8538, learning rate: 0.00629, Loss: 0.1969, Accuracy:0.930\nIteration: 8539, learning rate: 0.00629, Loss: 0.1715, Accuracy:0.938\nIteration: 8540, learning rate: 0.00629, Loss: 0.3183, Accuracy:0.891\nIteration: 8541, learning rate: 0.00629, Loss: 0.2498, Accuracy:0.898\nIteration: 8542, learning rate: 0.00629, Loss: 0.0887, Accuracy:0.977\nIteration: 8543, learning rate: 0.00629, Loss: 0.1493, Accuracy:0.930\nIteration: 8544, learning rate: 0.00629, Loss: 0.1721, Accuracy:0.922\nIteration: 8545, learning rate: 0.00629, Loss: 0.1989, Accuracy:0.930\nIteration: 8546, learning rate: 0.00629, Loss: 0.2012, Accuracy:0.906\nIteration: 8547, learning rate: 0.00629, Loss: 0.1397, Accuracy:0.953\nIteration: 8548, learning rate: 0.00629, Loss: 0.1395, Accuracy:0.945\nIteration: 8549, learning rate: 0.00629, Loss: 0.1827, Accuracy:0.945\nIteration: 8550, learning rate: 0.00629, Loss: 0.1910, Accuracy:0.953\nIteration: 8551, learning rate: 0.00629, Loss: 0.1595, Accuracy:0.938\nIteration: 8552, learning rate: 0.00629, Loss: 0.2547, Accuracy:0.914\nIteration: 8553, learning rate: 0.00629, Loss: 0.2865, Accuracy:0.883\nIteration: 8554, learning rate: 0.00629, Loss: 0.2283, Accuracy:0.906\nIteration: 8555, learning rate: 0.00629, Loss: 0.1545, Accuracy:0.953\nIteration: 8556, learning rate: 0.00629, Loss: 0.2087, Accuracy:0.914\nEpoch: 276, Loss: 0.1897, Accuracy:0.927, Val Loss: 0.3112, Val Accuracy: 0.850\nIteration: 8557, learning rate: 0.00629, Loss: 0.1958, Accuracy:0.906\nIteration: 8558, learning rate: 0.00629, Loss: 0.2563, Accuracy:0.914\nIteration: 8559, learning rate: 0.00629, Loss: 0.1971, Accuracy:0.930\nIteration: 8560, learning rate: 0.00629, Loss: 0.2756, Accuracy:0.875\nIteration: 8561, learning rate: 0.00629, Loss: 0.2480, Accuracy:0.906\nIteration: 8562, learning rate: 0.00629, Loss: 0.1565, Accuracy:0.945\nIteration: 8563, learning rate: 0.00629, Loss: 0.2284, Accuracy:0.922\nIteration: 8564, learning rate: 0.00629, Loss: 0.2697, Accuracy:0.891\nIteration: 8565, learning rate: 0.00629, Loss: 0.2532, Accuracy:0.898\nIteration: 8566, learning rate: 0.00629, Loss: 0.2570, Accuracy:0.898\nIteration: 8567, learning rate: 0.00629, Loss: 0.1390, Accuracy:0.961\nIteration: 8568, learning rate: 0.00629, Loss: 0.1716, Accuracy:0.930\nIteration: 8569, learning rate: 0.00629, Loss: 0.2311, Accuracy:0.906\nIteration: 8570, learning rate: 0.00629, Loss: 0.1851, Accuracy:0.922\nIteration: 8571, learning rate: 0.00629, Loss: 0.1504, Accuracy:0.945\nIteration: 8572, learning rate: 0.00629, Loss: 0.1684, Accuracy:0.953\nIteration: 8573, learning rate: 0.00629, Loss: 0.2222, Accuracy:0.891\nIteration: 8574, learning rate: 0.00629, Loss: 0.1644, Accuracy:0.938\nIteration: 8575, learning rate: 0.00629, Loss: 0.0588, Accuracy:0.977\nIteration: 8576, learning rate: 0.00628, Loss: 0.2688, Accuracy:0.922\nIteration: 8577, learning rate: 0.00628, Loss: 0.1671, Accuracy:0.938\nIteration: 8578, learning rate: 0.00628, Loss: 0.2404, Accuracy:0.891\nIteration: 8579, learning rate: 0.00628, Loss: 0.1987, Accuracy:0.883\nIteration: 8580, learning rate: 0.00628, Loss: 0.1159, Accuracy:0.969\nIteration: 8581, learning rate: 0.00628, Loss: 0.2097, Accuracy:0.922\nIteration: 8582, learning rate: 0.00628, Loss: 0.1721, Accuracy:0.930\nIteration: 8583, learning rate: 0.00628, Loss: 0.1933, Accuracy:0.906\nIteration: 8584, learning rate: 0.00628, Loss: 0.1858, Accuracy:0.906\nIteration: 8585, learning rate: 0.00628, Loss: 0.1917, Accuracy:0.930\nIteration: 8586, learning rate: 0.00628, Loss: 0.1913, Accuracy:0.914\nIteration: 8587, learning rate: 0.00628, Loss: 0.2097, Accuracy:0.914\nEpoch: 277, Loss: 0.1991, Accuracy:0.920, Val Loss: 0.3556, Val Accuracy: 0.861\nIteration: 8588, learning rate: 0.00628, Loss: 0.2300, Accuracy:0.898\nIteration: 8589, learning rate: 0.00628, Loss: 0.3608, Accuracy:0.867\nIteration: 8590, learning rate: 0.00628, Loss: 0.1409, Accuracy:0.953\nIteration: 8591, learning rate: 0.00628, Loss: 0.2131, Accuracy:0.922\nIteration: 8592, learning rate: 0.00628, Loss: 0.2181, Accuracy:0.898\nIteration: 8593, learning rate: 0.00628, Loss: 0.2595, Accuracy:0.898\nIteration: 8594, learning rate: 0.00628, Loss: 0.1980, Accuracy:0.961\nIteration: 8595, learning rate: 0.00628, Loss: 0.1868, Accuracy:0.930\nIteration: 8596, learning rate: 0.00628, Loss: 0.1868, Accuracy:0.922\nIteration: 8597, learning rate: 0.00628, Loss: 0.1737, Accuracy:0.930\nIteration: 8598, learning rate: 0.00628, Loss: 0.1707, Accuracy:0.945\nIteration: 8599, learning rate: 0.00628, Loss: 0.2400, Accuracy:0.906\nIteration: 8600, learning rate: 0.00628, Loss: 0.1076, Accuracy:0.969\nIteration: 8601, learning rate: 0.00628, Loss: 0.1515, Accuracy:0.938\nIteration: 8602, learning rate: 0.00628, Loss: 0.1663, Accuracy:0.938\nIteration: 8603, learning rate: 0.00628, Loss: 0.1421, Accuracy:0.930\nIteration: 8604, learning rate: 0.00628, Loss: 0.1777, Accuracy:0.930\nIteration: 8605, learning rate: 0.00628, Loss: 0.1757, Accuracy:0.938\nIteration: 8606, learning rate: 0.00628, Loss: 0.2147, Accuracy:0.938\nIteration: 8607, learning rate: 0.00628, Loss: 0.2150, Accuracy:0.906\nIteration: 8608, learning rate: 0.00628, Loss: 0.1801, Accuracy:0.898\nIteration: 8609, learning rate: 0.00628, Loss: 0.1635, Accuracy:0.945\nIteration: 8610, learning rate: 0.00628, Loss: 0.2263, Accuracy:0.875\nIteration: 8611, learning rate: 0.00628, Loss: 0.1803, Accuracy:0.922\nIteration: 8612, learning rate: 0.00628, Loss: 0.1786, Accuracy:0.922\nIteration: 8613, learning rate: 0.00628, Loss: 0.1619, Accuracy:0.938\nIteration: 8614, learning rate: 0.00628, Loss: 0.1614, Accuracy:0.930\nIteration: 8615, learning rate: 0.00628, Loss: 0.1683, Accuracy:0.938\nIteration: 8616, learning rate: 0.00627, Loss: 0.1503, Accuracy:0.953\nIteration: 8617, learning rate: 0.00627, Loss: 0.0943, Accuracy:0.969\nIteration: 8618, learning rate: 0.00627, Loss: 0.1824, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 278, Loss: 0.1863, Accuracy:0.927, Val Loss: 0.2900, Val Accuracy: 0.863\nIteration: 8619, learning rate: 0.00627, Loss: 0.1339, Accuracy:0.953\nIteration: 8620, learning rate: 0.00627, Loss: 0.2208, Accuracy:0.906\nIteration: 8621, learning rate: 0.00627, Loss: 0.1802, Accuracy:0.906\nIteration: 8622, learning rate: 0.00627, Loss: 0.1801, Accuracy:0.938\nIteration: 8623, learning rate: 0.00627, Loss: 0.1869, Accuracy:0.922\nIteration: 8624, learning rate: 0.00627, Loss: 0.1942, Accuracy:0.922\nIteration: 8625, learning rate: 0.00627, Loss: 0.1711, Accuracy:0.938\nIteration: 8626, learning rate: 0.00627, Loss: 0.1496, Accuracy:0.953\nIteration: 8627, learning rate: 0.00627, Loss: 0.1548, Accuracy:0.945\nIteration: 8628, learning rate: 0.00627, Loss: 0.2409, Accuracy:0.898\nIteration: 8629, learning rate: 0.00627, Loss: 0.1080, Accuracy:0.953\nIteration: 8630, learning rate: 0.00627, Loss: 0.2299, Accuracy:0.914\nIteration: 8631, learning rate: 0.00627, Loss: 0.2627, Accuracy:0.875\nIteration: 8632, learning rate: 0.00627, Loss: 0.1589, Accuracy:0.945\nIteration: 8633, learning rate: 0.00627, Loss: 0.2244, Accuracy:0.906\nIteration: 8634, learning rate: 0.00627, Loss: 0.1667, Accuracy:0.930\nIteration: 8635, learning rate: 0.00627, Loss: 0.1463, Accuracy:0.953\nIteration: 8636, learning rate: 0.00627, Loss: 0.2079, Accuracy:0.938\nIteration: 8637, learning rate: 0.00627, Loss: 0.1453, Accuracy:0.953\nIteration: 8638, learning rate: 0.00627, Loss: 0.2327, Accuracy:0.914\nIteration: 8639, learning rate: 0.00627, Loss: 0.1108, Accuracy:0.961\nIteration: 8640, learning rate: 0.00627, Loss: 0.1463, Accuracy:0.938\nIteration: 8641, learning rate: 0.00627, Loss: 0.1713, Accuracy:0.930\nIteration: 8642, learning rate: 0.00627, Loss: 0.1346, Accuracy:0.969\nIteration: 8643, learning rate: 0.00627, Loss: 0.2001, Accuracy:0.938\nIteration: 8644, learning rate: 0.00627, Loss: 0.1589, Accuracy:0.938\nIteration: 8645, learning rate: 0.00627, Loss: 0.1570, Accuracy:0.953\nIteration: 8646, learning rate: 0.00627, Loss: 0.1847, Accuracy:0.922\nIteration: 8647, learning rate: 0.00627, Loss: 0.1745, Accuracy:0.930\nIteration: 8648, learning rate: 0.00627, Loss: 0.2363, Accuracy:0.906\nIteration: 8649, learning rate: 0.00627, Loss: 0.1931, Accuracy:0.882\nEpoch: 279, Loss: 0.1794, Accuracy:0.930, Val Loss: 0.2902, Val Accuracy: 0.879\nIteration: 8650, learning rate: 0.00627, Loss: 0.2781, Accuracy:0.891\nIteration: 8651, learning rate: 0.00627, Loss: 0.1738, Accuracy:0.938\nIteration: 8652, learning rate: 0.00627, Loss: 0.2588, Accuracy:0.914\nIteration: 8653, learning rate: 0.00627, Loss: 0.1135, Accuracy:0.961\nIteration: 8654, learning rate: 0.00627, Loss: 0.2257, Accuracy:0.906\nIteration: 8655, learning rate: 0.00626, Loss: 0.2272, Accuracy:0.914\nIteration: 8656, learning rate: 0.00626, Loss: 0.2161, Accuracy:0.922\nIteration: 8657, learning rate: 0.00626, Loss: 0.1554, Accuracy:0.961\nIteration: 8658, learning rate: 0.00626, Loss: 0.1575, Accuracy:0.930\nIteration: 8659, learning rate: 0.00626, Loss: 0.1423, Accuracy:0.930\nIteration: 8660, learning rate: 0.00626, Loss: 0.1831, Accuracy:0.922\nIteration: 8661, learning rate: 0.00626, Loss: 0.2099, Accuracy:0.938\nIteration: 8662, learning rate: 0.00626, Loss: 0.2095, Accuracy:0.922\nIteration: 8663, learning rate: 0.00626, Loss: 0.1560, Accuracy:0.945\nIteration: 8664, learning rate: 0.00626, Loss: 0.1178, Accuracy:0.953\nIteration: 8665, learning rate: 0.00626, Loss: 0.1827, Accuracy:0.914\nIteration: 8666, learning rate: 0.00626, Loss: 0.1507, Accuracy:0.938\nIteration: 8667, learning rate: 0.00626, Loss: 0.2394, Accuracy:0.883\nIteration: 8668, learning rate: 0.00626, Loss: 0.2587, Accuracy:0.883\nIteration: 8669, learning rate: 0.00626, Loss: 0.1202, Accuracy:0.945\nIteration: 8670, learning rate: 0.00626, Loss: 0.1574, Accuracy:0.938\nIteration: 8671, learning rate: 0.00626, Loss: 0.1793, Accuracy:0.922\nIteration: 8672, learning rate: 0.00626, Loss: 0.2213, Accuracy:0.891\nIteration: 8673, learning rate: 0.00626, Loss: 0.1253, Accuracy:0.938\nIteration: 8674, learning rate: 0.00626, Loss: 0.2276, Accuracy:0.914\nIteration: 8675, learning rate: 0.00626, Loss: 0.2833, Accuracy:0.883\nIteration: 8676, learning rate: 0.00626, Loss: 0.2208, Accuracy:0.891\nIteration: 8677, learning rate: 0.00626, Loss: 0.2334, Accuracy:0.914\nIteration: 8678, learning rate: 0.00626, Loss: 0.2322, Accuracy:0.930\nIteration: 8679, learning rate: 0.00626, Loss: 0.3258, Accuracy:0.844\nIteration: 8680, learning rate: 0.00626, Loss: 0.1895, Accuracy:0.935\nEpoch: 280, Loss: 0.1991, Accuracy:0.920, Val Loss: 0.2912, Val Accuracy: 0.882\nIteration: 8681, learning rate: 0.00626, Loss: 0.2019, Accuracy:0.906\nIteration: 8682, learning rate: 0.00626, Loss: 0.2303, Accuracy:0.906\nIteration: 8683, learning rate: 0.00626, Loss: 0.1044, Accuracy:0.977\nIteration: 8684, learning rate: 0.00626, Loss: 0.1159, Accuracy:0.961\nIteration: 8685, learning rate: 0.00626, Loss: 0.2032, Accuracy:0.922\nIteration: 8686, learning rate: 0.00626, Loss: 0.1209, Accuracy:0.969\nIteration: 8687, learning rate: 0.00626, Loss: 0.2249, Accuracy:0.922\nIteration: 8688, learning rate: 0.00626, Loss: 0.2294, Accuracy:0.883\nIteration: 8689, learning rate: 0.00626, Loss: 0.2494, Accuracy:0.898\nIteration: 8690, learning rate: 0.00626, Loss: 0.1610, Accuracy:0.930\nIteration: 8691, learning rate: 0.00626, Loss: 0.1801, Accuracy:0.914\nIteration: 8692, learning rate: 0.00626, Loss: 0.1156, Accuracy:0.961\nIteration: 8693, learning rate: 0.00626, Loss: 0.2033, Accuracy:0.906\nIteration: 8694, learning rate: 0.00626, Loss: 0.1642, Accuracy:0.938\nIteration: 8695, learning rate: 0.00625, Loss: 0.2669, Accuracy:0.883\nIteration: 8696, learning rate: 0.00625, Loss: 0.2221, Accuracy:0.906\nIteration: 8697, learning rate: 0.00625, Loss: 0.1719, Accuracy:0.945\nIteration: 8698, learning rate: 0.00625, Loss: 0.1811, Accuracy:0.906\nIteration: 8699, learning rate: 0.00625, Loss: 0.1348, Accuracy:0.953\nIteration: 8700, learning rate: 0.00625, Loss: 0.1023, Accuracy:0.977\nIteration: 8701, learning rate: 0.00625, Loss: 0.1511, Accuracy:0.930\nIteration: 8702, learning rate: 0.00625, Loss: 0.1941, Accuracy:0.930\nIteration: 8703, learning rate: 0.00625, Loss: 0.2744, Accuracy:0.867\nIteration: 8704, learning rate: 0.00625, Loss: 0.1842, Accuracy:0.922\nIteration: 8705, learning rate: 0.00625, Loss: 0.1691, Accuracy:0.938\nIteration: 8706, learning rate: 0.00625, Loss: 0.1763, Accuracy:0.930\nIteration: 8707, learning rate: 0.00625, Loss: 0.2963, Accuracy:0.891\nIteration: 8708, learning rate: 0.00625, Loss: 0.1944, Accuracy:0.945\nIteration: 8709, learning rate: 0.00625, Loss: 0.1768, Accuracy:0.945\nIteration: 8710, learning rate: 0.00625, Loss: 0.1915, Accuracy:0.922\nIteration: 8711, learning rate: 0.00625, Loss: 0.1443, Accuracy:0.946\nEpoch: 281, Loss: 0.1850, Accuracy:0.927, Val Loss: 0.3429, Val Accuracy: 0.849\nIteration: 8712, learning rate: 0.00625, Loss: 0.1223, Accuracy:0.961\nIteration: 8713, learning rate: 0.00625, Loss: 0.1450, Accuracy:0.969\nIteration: 8714, learning rate: 0.00625, Loss: 0.1753, Accuracy:0.945\nIteration: 8715, learning rate: 0.00625, Loss: 0.1847, Accuracy:0.906\nIteration: 8716, learning rate: 0.00625, Loss: 0.1909, Accuracy:0.930\nIteration: 8717, learning rate: 0.00625, Loss: 0.1811, Accuracy:0.938\nIteration: 8718, learning rate: 0.00625, Loss: 0.1434, Accuracy:0.938\nIteration: 8719, learning rate: 0.00625, Loss: 0.1868, Accuracy:0.930\nIteration: 8720, learning rate: 0.00625, Loss: 0.1823, Accuracy:0.930\nIteration: 8721, learning rate: 0.00625, Loss: 0.2078, Accuracy:0.914\nIteration: 8722, learning rate: 0.00625, Loss: 0.1515, Accuracy:0.938\nIteration: 8723, learning rate: 0.00625, Loss: 0.2080, Accuracy:0.938\nIteration: 8724, learning rate: 0.00625, Loss: 0.1329, Accuracy:0.938\nIteration: 8725, learning rate: 0.00625, Loss: 0.2073, Accuracy:0.922\nIteration: 8726, learning rate: 0.00625, Loss: 0.1925, Accuracy:0.922\nIteration: 8727, learning rate: 0.00625, Loss: 0.2471, Accuracy:0.891\nIteration: 8728, learning rate: 0.00625, Loss: 0.1696, Accuracy:0.914\nIteration: 8729, learning rate: 0.00625, Loss: 0.2749, Accuracy:0.883\nIteration: 8730, learning rate: 0.00625, Loss: 0.1576, Accuracy:0.945\nIteration: 8731, learning rate: 0.00625, Loss: 0.1490, Accuracy:0.945\nIteration: 8732, learning rate: 0.00625, Loss: 0.1424, Accuracy:0.938\nIteration: 8733, learning rate: 0.00625, Loss: 0.1769, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8734, learning rate: 0.00625, Loss: 0.2671, Accuracy:0.898\nIteration: 8735, learning rate: 0.00624, Loss: 0.2171, Accuracy:0.922\nIteration: 8736, learning rate: 0.00624, Loss: 0.1502, Accuracy:0.945\nIteration: 8737, learning rate: 0.00624, Loss: 0.2876, Accuracy:0.875\nIteration: 8738, learning rate: 0.00624, Loss: 0.2247, Accuracy:0.914\nIteration: 8739, learning rate: 0.00624, Loss: 0.1860, Accuracy:0.930\nIteration: 8740, learning rate: 0.00624, Loss: 0.1509, Accuracy:0.922\nIteration: 8741, learning rate: 0.00624, Loss: 0.1500, Accuracy:0.945\nIteration: 8742, learning rate: 0.00624, Loss: 0.1997, Accuracy:0.946\nEpoch: 282, Loss: 0.1859, Accuracy:0.927, Val Loss: 0.3050, Val Accuracy: 0.875\nIteration: 8743, learning rate: 0.00624, Loss: 0.2118, Accuracy:0.922\nIteration: 8744, learning rate: 0.00624, Loss: 0.1710, Accuracy:0.930\nIteration: 8745, learning rate: 0.00624, Loss: 0.1821, Accuracy:0.938\nIteration: 8746, learning rate: 0.00624, Loss: 0.1639, Accuracy:0.930\nIteration: 8747, learning rate: 0.00624, Loss: 0.2249, Accuracy:0.898\nIteration: 8748, learning rate: 0.00624, Loss: 0.2449, Accuracy:0.906\nIteration: 8749, learning rate: 0.00624, Loss: 0.2144, Accuracy:0.891\nIteration: 8750, learning rate: 0.00624, Loss: 0.1661, Accuracy:0.938\nIteration: 8751, learning rate: 0.00624, Loss: 0.1750, Accuracy:0.922\nIteration: 8752, learning rate: 0.00624, Loss: 0.2046, Accuracy:0.922\nIteration: 8753, learning rate: 0.00624, Loss: 0.2378, Accuracy:0.891\nIteration: 8754, learning rate: 0.00624, Loss: 0.2192, Accuracy:0.891\nIteration: 8755, learning rate: 0.00624, Loss: 0.2921, Accuracy:0.875\nIteration: 8756, learning rate: 0.00624, Loss: 0.1846, Accuracy:0.914\nIteration: 8757, learning rate: 0.00624, Loss: 0.1278, Accuracy:0.953\nIteration: 8758, learning rate: 0.00624, Loss: 0.1945, Accuracy:0.906\nIteration: 8759, learning rate: 0.00624, Loss: 0.2485, Accuracy:0.883\nIteration: 8760, learning rate: 0.00624, Loss: 0.1338, Accuracy:0.953\nIteration: 8761, learning rate: 0.00624, Loss: 0.1734, Accuracy:0.953\nIteration: 8762, learning rate: 0.00624, Loss: 0.2263, Accuracy:0.898\nIteration: 8763, learning rate: 0.00624, Loss: 0.1849, Accuracy:0.930\nIteration: 8764, learning rate: 0.00624, Loss: 0.2517, Accuracy:0.898\nIteration: 8765, learning rate: 0.00624, Loss: 0.2384, Accuracy:0.906\nIteration: 8766, learning rate: 0.00624, Loss: 0.1456, Accuracy:0.938\nIteration: 8767, learning rate: 0.00624, Loss: 0.1130, Accuracy:0.953\nIteration: 8768, learning rate: 0.00624, Loss: 0.2015, Accuracy:0.906\nIteration: 8769, learning rate: 0.00624, Loss: 0.1123, Accuracy:0.953\nIteration: 8770, learning rate: 0.00624, Loss: 0.1833, Accuracy:0.914\nIteration: 8771, learning rate: 0.00624, Loss: 0.1408, Accuracy:0.945\nIteration: 8772, learning rate: 0.00624, Loss: 0.1868, Accuracy:0.906\nIteration: 8773, learning rate: 0.00624, Loss: 0.2411, Accuracy:0.914\nEpoch: 283, Loss: 0.1934, Accuracy:0.919, Val Loss: 0.3058, Val Accuracy: 0.860\nIteration: 8774, learning rate: 0.00624, Loss: 0.1293, Accuracy:0.953\nIteration: 8775, learning rate: 0.00623, Loss: 0.1309, Accuracy:0.969\nIteration: 8776, learning rate: 0.00623, Loss: 0.2030, Accuracy:0.922\nIteration: 8777, learning rate: 0.00623, Loss: 0.1875, Accuracy:0.906\nIteration: 8778, learning rate: 0.00623, Loss: 0.2467, Accuracy:0.891\nIteration: 8779, learning rate: 0.00623, Loss: 0.2251, Accuracy:0.922\nIteration: 8780, learning rate: 0.00623, Loss: 0.2155, Accuracy:0.930\nIteration: 8781, learning rate: 0.00623, Loss: 0.2028, Accuracy:0.922\nIteration: 8782, learning rate: 0.00623, Loss: 0.1383, Accuracy:0.961\nIteration: 8783, learning rate: 0.00623, Loss: 0.1503, Accuracy:0.945\nIteration: 8784, learning rate: 0.00623, Loss: 0.1871, Accuracy:0.945\nIteration: 8785, learning rate: 0.00623, Loss: 0.2433, Accuracy:0.914\nIteration: 8786, learning rate: 0.00623, Loss: 0.1202, Accuracy:0.961\nIteration: 8787, learning rate: 0.00623, Loss: 0.2056, Accuracy:0.914\nIteration: 8788, learning rate: 0.00623, Loss: 0.2791, Accuracy:0.898\nIteration: 8789, learning rate: 0.00623, Loss: 0.2024, Accuracy:0.898\nIteration: 8790, learning rate: 0.00623, Loss: 0.1587, Accuracy:0.922\nIteration: 8791, learning rate: 0.00623, Loss: 0.1541, Accuracy:0.953\nIteration: 8792, learning rate: 0.00623, Loss: 0.2049, Accuracy:0.938\nIteration: 8793, learning rate: 0.00623, Loss: 0.1757, Accuracy:0.938\nIteration: 8794, learning rate: 0.00623, Loss: 0.1217, Accuracy:0.969\nIteration: 8795, learning rate: 0.00623, Loss: 0.1722, Accuracy:0.930\nIteration: 8796, learning rate: 0.00623, Loss: 0.1703, Accuracy:0.938\nIteration: 8797, learning rate: 0.00623, Loss: 0.2373, Accuracy:0.906\nIteration: 8798, learning rate: 0.00623, Loss: 0.1769, Accuracy:0.930\nIteration: 8799, learning rate: 0.00623, Loss: 0.1566, Accuracy:0.945\nIteration: 8800, learning rate: 0.00623, Loss: 0.2722, Accuracy:0.906\nIteration: 8801, learning rate: 0.00623, Loss: 0.2184, Accuracy:0.914\nIteration: 8802, learning rate: 0.00623, Loss: 0.1103, Accuracy:0.984\nIteration: 8803, learning rate: 0.00623, Loss: 0.1623, Accuracy:0.938\nIteration: 8804, learning rate: 0.00623, Loss: 0.2708, Accuracy:0.892\nEpoch: 284, Loss: 0.1880, Accuracy:0.931, Val Loss: 0.3121, Val Accuracy: 0.867\nIteration: 8805, learning rate: 0.00623, Loss: 0.1329, Accuracy:0.953\nIteration: 8806, learning rate: 0.00623, Loss: 0.1827, Accuracy:0.930\nIteration: 8807, learning rate: 0.00623, Loss: 0.2030, Accuracy:0.898\nIteration: 8808, learning rate: 0.00623, Loss: 0.1967, Accuracy:0.922\nIteration: 8809, learning rate: 0.00623, Loss: 0.1793, Accuracy:0.961\nIteration: 8810, learning rate: 0.00623, Loss: 0.2890, Accuracy:0.891\nIteration: 8811, learning rate: 0.00623, Loss: 0.1510, Accuracy:0.938\nIteration: 8812, learning rate: 0.00623, Loss: 0.1943, Accuracy:0.930\nIteration: 8813, learning rate: 0.00623, Loss: 0.1982, Accuracy:0.930\nIteration: 8814, learning rate: 0.00623, Loss: 0.1636, Accuracy:0.938\nIteration: 8815, learning rate: 0.00622, Loss: 0.1734, Accuracy:0.906\nIteration: 8816, learning rate: 0.00622, Loss: 0.2009, Accuracy:0.898\nIteration: 8817, learning rate: 0.00622, Loss: 0.2363, Accuracy:0.930\nIteration: 8818, learning rate: 0.00622, Loss: 0.1612, Accuracy:0.938\nIteration: 8819, learning rate: 0.00622, Loss: 0.2186, Accuracy:0.945\nIteration: 8820, learning rate: 0.00622, Loss: 0.2685, Accuracy:0.875\nIteration: 8821, learning rate: 0.00622, Loss: 0.1664, Accuracy:0.945\nIteration: 8822, learning rate: 0.00622, Loss: 0.1338, Accuracy:0.953\nIteration: 8823, learning rate: 0.00622, Loss: 0.1629, Accuracy:0.930\nIteration: 8824, learning rate: 0.00622, Loss: 0.1892, Accuracy:0.898\nIteration: 8825, learning rate: 0.00622, Loss: 0.2028, Accuracy:0.930\nIteration: 8826, learning rate: 0.00622, Loss: 0.1575, Accuracy:0.945\nIteration: 8827, learning rate: 0.00622, Loss: 0.2018, Accuracy:0.930\nIteration: 8828, learning rate: 0.00622, Loss: 0.1680, Accuracy:0.930\nIteration: 8829, learning rate: 0.00622, Loss: 0.1957, Accuracy:0.922\nIteration: 8830, learning rate: 0.00622, Loss: 0.3141, Accuracy:0.891\nIteration: 8831, learning rate: 0.00622, Loss: 0.1933, Accuracy:0.930\nIteration: 8832, learning rate: 0.00622, Loss: 0.2568, Accuracy:0.898\nIteration: 8833, learning rate: 0.00622, Loss: 0.1513, Accuracy:0.945\nIteration: 8834, learning rate: 0.00622, Loss: 0.1298, Accuracy:0.945\nIteration: 8835, learning rate: 0.00622, Loss: 0.2077, Accuracy:0.914\nEpoch: 285, Loss: 0.1929, Accuracy:0.925, Val Loss: 0.3388, Val Accuracy: 0.860\nIteration: 8836, learning rate: 0.00622, Loss: 0.2603, Accuracy:0.891\nIteration: 8837, learning rate: 0.00622, Loss: 0.1586, Accuracy:0.938\nIteration: 8838, learning rate: 0.00622, Loss: 0.2175, Accuracy:0.922\nIteration: 8839, learning rate: 0.00622, Loss: 0.3042, Accuracy:0.859\nIteration: 8840, learning rate: 0.00622, Loss: 0.1452, Accuracy:0.938\nIteration: 8841, learning rate: 0.00622, Loss: 0.1160, Accuracy:0.953\nIteration: 8842, learning rate: 0.00622, Loss: 0.2098, Accuracy:0.914\nIteration: 8843, learning rate: 0.00622, Loss: 0.2050, Accuracy:0.938\nIteration: 8844, learning rate: 0.00622, Loss: 0.1853, Accuracy:0.922\nIteration: 8845, learning rate: 0.00622, Loss: 0.1859, Accuracy:0.938\nIteration: 8846, learning rate: 0.00622, Loss: 0.2335, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 8847, learning rate: 0.00622, Loss: 0.2295, Accuracy:0.914\nIteration: 8848, learning rate: 0.00622, Loss: 0.1715, Accuracy:0.922\nIteration: 8849, learning rate: 0.00622, Loss: 0.1593, Accuracy:0.961\nIteration: 8850, learning rate: 0.00622, Loss: 0.2376, Accuracy:0.898\nIteration: 8851, learning rate: 0.00622, Loss: 0.2037, Accuracy:0.898\nIteration: 8852, learning rate: 0.00622, Loss: 0.1797, Accuracy:0.945\nIteration: 8853, learning rate: 0.00622, Loss: 0.1520, Accuracy:0.945\nIteration: 8854, learning rate: 0.00622, Loss: 0.2149, Accuracy:0.914\nIteration: 8855, learning rate: 0.00622, Loss: 0.1673, Accuracy:0.945\nIteration: 8856, learning rate: 0.00621, Loss: 0.2273, Accuracy:0.922\nIteration: 8857, learning rate: 0.00621, Loss: 0.1611, Accuracy:0.953\nIteration: 8858, learning rate: 0.00621, Loss: 0.0961, Accuracy:0.969\nIteration: 8859, learning rate: 0.00621, Loss: 0.1809, Accuracy:0.930\nIteration: 8860, learning rate: 0.00621, Loss: 0.2051, Accuracy:0.914\nIteration: 8861, learning rate: 0.00621, Loss: 0.1125, Accuracy:0.969\nIteration: 8862, learning rate: 0.00621, Loss: 0.1872, Accuracy:0.945\nIteration: 8863, learning rate: 0.00621, Loss: 0.1257, Accuracy:0.953\nIteration: 8864, learning rate: 0.00621, Loss: 0.2108, Accuracy:0.898\nIteration: 8865, learning rate: 0.00621, Loss: 0.1632, Accuracy:0.938\nIteration: 8866, learning rate: 0.00621, Loss: 0.1070, Accuracy:0.957\nEpoch: 286, Loss: 0.1843, Accuracy:0.929, Val Loss: 0.2946, Val Accuracy: 0.871\nIteration: 8867, learning rate: 0.00621, Loss: 0.1441, Accuracy:0.930\nIteration: 8868, learning rate: 0.00621, Loss: 0.1671, Accuracy:0.922\nIteration: 8869, learning rate: 0.00621, Loss: 0.1329, Accuracy:0.961\nIteration: 8870, learning rate: 0.00621, Loss: 0.1940, Accuracy:0.898\nIteration: 8871, learning rate: 0.00621, Loss: 0.1976, Accuracy:0.930\nIteration: 8872, learning rate: 0.00621, Loss: 0.1642, Accuracy:0.953\nIteration: 8873, learning rate: 0.00621, Loss: 0.1550, Accuracy:0.938\nIteration: 8874, learning rate: 0.00621, Loss: 0.1251, Accuracy:0.953\nIteration: 8875, learning rate: 0.00621, Loss: 0.1512, Accuracy:0.945\nIteration: 8876, learning rate: 0.00621, Loss: 0.1781, Accuracy:0.930\nIteration: 8877, learning rate: 0.00621, Loss: 0.1951, Accuracy:0.914\nIteration: 8878, learning rate: 0.00621, Loss: 0.2554, Accuracy:0.875\nIteration: 8879, learning rate: 0.00621, Loss: 0.1207, Accuracy:0.977\nIteration: 8880, learning rate: 0.00621, Loss: 0.1970, Accuracy:0.914\nIteration: 8881, learning rate: 0.00621, Loss: 0.2588, Accuracy:0.906\nIteration: 8882, learning rate: 0.00621, Loss: 0.1930, Accuracy:0.938\nIteration: 8883, learning rate: 0.00621, Loss: 0.1671, Accuracy:0.945\nIteration: 8884, learning rate: 0.00621, Loss: 0.1308, Accuracy:0.953\nIteration: 8885, learning rate: 0.00621, Loss: 0.1572, Accuracy:0.938\nIteration: 8886, learning rate: 0.00621, Loss: 0.1495, Accuracy:0.938\nIteration: 8887, learning rate: 0.00621, Loss: 0.1297, Accuracy:0.938\nIteration: 8888, learning rate: 0.00621, Loss: 0.2450, Accuracy:0.906\nIteration: 8889, learning rate: 0.00621, Loss: 0.1154, Accuracy:0.969\nIteration: 8890, learning rate: 0.00621, Loss: 0.1648, Accuracy:0.953\nIteration: 8891, learning rate: 0.00621, Loss: 0.1773, Accuracy:0.914\nIteration: 8892, learning rate: 0.00621, Loss: 0.1852, Accuracy:0.930\nIteration: 8893, learning rate: 0.00621, Loss: 0.2246, Accuracy:0.898\nIteration: 8894, learning rate: 0.00621, Loss: 0.1194, Accuracy:0.945\nIteration: 8895, learning rate: 0.00621, Loss: 0.1467, Accuracy:0.945\nIteration: 8896, learning rate: 0.00620, Loss: 0.1604, Accuracy:0.922\nIteration: 8897, learning rate: 0.00620, Loss: 0.1630, Accuracy:0.925\nEpoch: 287, Loss: 0.1698, Accuracy:0.932, Val Loss: 0.2414, Val Accuracy: 0.902\nval_loss_decreased from 0.2545 to 0.2414, saving_checkpoint for epoch 287\nIteration: 8898, learning rate: 0.00620, Loss: 0.1781, Accuracy:0.930\nIteration: 8899, learning rate: 0.00620, Loss: 0.1722, Accuracy:0.930\nIteration: 8900, learning rate: 0.00620, Loss: 0.1249, Accuracy:0.969\nIteration: 8901, learning rate: 0.00620, Loss: 0.1901, Accuracy:0.914\nIteration: 8902, learning rate: 0.00620, Loss: 0.2385, Accuracy:0.914\nIteration: 8903, learning rate: 0.00620, Loss: 0.2231, Accuracy:0.906\nIteration: 8904, learning rate: 0.00620, Loss: 0.2177, Accuracy:0.906\nIteration: 8905, learning rate: 0.00620, Loss: 0.1330, Accuracy:0.945\nIteration: 8906, learning rate: 0.00620, Loss: 0.1807, Accuracy:0.922\nIteration: 8907, learning rate: 0.00620, Loss: 0.1662, Accuracy:0.930\nIteration: 8908, learning rate: 0.00620, Loss: 0.1443, Accuracy:0.953\nIteration: 8909, learning rate: 0.00620, Loss: 0.2293, Accuracy:0.922\nIteration: 8910, learning rate: 0.00620, Loss: 0.2467, Accuracy:0.898\nIteration: 8911, learning rate: 0.00620, Loss: 0.2354, Accuracy:0.906\nIteration: 8912, learning rate: 0.00620, Loss: 0.1099, Accuracy:0.961\nIteration: 8913, learning rate: 0.00620, Loss: 0.1757, Accuracy:0.914\nIteration: 8914, learning rate: 0.00620, Loss: 0.1470, Accuracy:0.938\nIteration: 8915, learning rate: 0.00620, Loss: 0.1857, Accuracy:0.922\nIteration: 8916, learning rate: 0.00620, Loss: 0.1306, Accuracy:0.969\nIteration: 8917, learning rate: 0.00620, Loss: 0.2530, Accuracy:0.898\nIteration: 8918, learning rate: 0.00620, Loss: 0.1468, Accuracy:0.938\nIteration: 8919, learning rate: 0.00620, Loss: 0.1828, Accuracy:0.922\nIteration: 8920, learning rate: 0.00620, Loss: 0.0840, Accuracy:0.977\nIteration: 8921, learning rate: 0.00620, Loss: 0.2196, Accuracy:0.891\nIteration: 8922, learning rate: 0.00620, Loss: 0.2391, Accuracy:0.922\nIteration: 8923, learning rate: 0.00620, Loss: 0.1719, Accuracy:0.930\nIteration: 8924, learning rate: 0.00620, Loss: 0.1752, Accuracy:0.930\nIteration: 8925, learning rate: 0.00620, Loss: 0.1904, Accuracy:0.930\nIteration: 8926, learning rate: 0.00620, Loss: 0.2053, Accuracy:0.930\nIteration: 8927, learning rate: 0.00620, Loss: 0.1689, Accuracy:0.930\nIteration: 8928, learning rate: 0.00620, Loss: 0.3040, Accuracy:0.849\nEpoch: 288, Loss: 0.1861, Accuracy:0.926, Val Loss: 0.2963, Val Accuracy: 0.872\nIteration: 8929, learning rate: 0.00620, Loss: 0.1902, Accuracy:0.922\nIteration: 8930, learning rate: 0.00620, Loss: 0.1852, Accuracy:0.938\nIteration: 8931, learning rate: 0.00620, Loss: 0.1248, Accuracy:0.961\nIteration: 8932, learning rate: 0.00620, Loss: 0.1372, Accuracy:0.922\nIteration: 8933, learning rate: 0.00620, Loss: 0.1753, Accuracy:0.922\nIteration: 8934, learning rate: 0.00620, Loss: 0.2004, Accuracy:0.938\nIteration: 8935, learning rate: 0.00620, Loss: 0.1952, Accuracy:0.898\nIteration: 8936, learning rate: 0.00620, Loss: 0.1851, Accuracy:0.922\nIteration: 8937, learning rate: 0.00619, Loss: 0.1991, Accuracy:0.906\nIteration: 8938, learning rate: 0.00619, Loss: 0.2166, Accuracy:0.922\nIteration: 8939, learning rate: 0.00619, Loss: 0.2224, Accuracy:0.922\nIteration: 8940, learning rate: 0.00619, Loss: 0.2097, Accuracy:0.914\nIteration: 8941, learning rate: 0.00619, Loss: 0.1135, Accuracy:0.953\nIteration: 8942, learning rate: 0.00619, Loss: 0.1831, Accuracy:0.945\nIteration: 8943, learning rate: 0.00619, Loss: 0.1649, Accuracy:0.906\nIteration: 8944, learning rate: 0.00619, Loss: 0.1780, Accuracy:0.930\nIteration: 8945, learning rate: 0.00619, Loss: 0.2739, Accuracy:0.891\nIteration: 8946, learning rate: 0.00619, Loss: 0.1652, Accuracy:0.930\nIteration: 8947, learning rate: 0.00619, Loss: 0.2246, Accuracy:0.922\nIteration: 8948, learning rate: 0.00619, Loss: 0.1612, Accuracy:0.953\nIteration: 8949, learning rate: 0.00619, Loss: 0.2252, Accuracy:0.945\nIteration: 8950, learning rate: 0.00619, Loss: 0.1461, Accuracy:0.945\nIteration: 8951, learning rate: 0.00619, Loss: 0.1429, Accuracy:0.961\nIteration: 8952, learning rate: 0.00619, Loss: 0.1555, Accuracy:0.945\nIteration: 8953, learning rate: 0.00619, Loss: 0.1615, Accuracy:0.938\nIteration: 8954, learning rate: 0.00619, Loss: 0.3169, Accuracy:0.852\nIteration: 8955, learning rate: 0.00619, Loss: 0.1774, Accuracy:0.930\nIteration: 8956, learning rate: 0.00619, Loss: 0.1920, Accuracy:0.922\nIteration: 8957, learning rate: 0.00619, Loss: 0.1613, Accuracy:0.953\nIteration: 8958, learning rate: 0.00619, Loss: 0.1709, Accuracy:0.953\nIteration: 8959, learning rate: 0.00619, Loss: 0.1588, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 289, Loss: 0.1843, Accuracy:0.929, Val Loss: 0.3075, Val Accuracy: 0.878\nIteration: 8960, learning rate: 0.00619, Loss: 0.1882, Accuracy:0.945\nIteration: 8961, learning rate: 0.00619, Loss: 0.1640, Accuracy:0.938\nIteration: 8962, learning rate: 0.00619, Loss: 0.2117, Accuracy:0.930\nIteration: 8963, learning rate: 0.00619, Loss: 0.2885, Accuracy:0.875\nIteration: 8964, learning rate: 0.00619, Loss: 0.2211, Accuracy:0.906\nIteration: 8965, learning rate: 0.00619, Loss: 0.1337, Accuracy:0.969\nIteration: 8966, learning rate: 0.00619, Loss: 0.1870, Accuracy:0.938\nIteration: 8967, learning rate: 0.00619, Loss: 0.1851, Accuracy:0.938\nIteration: 8968, learning rate: 0.00619, Loss: 0.2372, Accuracy:0.898\nIteration: 8969, learning rate: 0.00619, Loss: 0.1727, Accuracy:0.945\nIteration: 8970, learning rate: 0.00619, Loss: 0.2747, Accuracy:0.898\nIteration: 8971, learning rate: 0.00619, Loss: 0.1515, Accuracy:0.945\nIteration: 8972, learning rate: 0.00619, Loss: 0.1945, Accuracy:0.922\nIteration: 8973, learning rate: 0.00619, Loss: 0.1927, Accuracy:0.898\nIteration: 8974, learning rate: 0.00619, Loss: 0.2048, Accuracy:0.938\nIteration: 8975, learning rate: 0.00619, Loss: 0.1860, Accuracy:0.898\nIteration: 8976, learning rate: 0.00619, Loss: 0.1529, Accuracy:0.961\nIteration: 8977, learning rate: 0.00619, Loss: 0.1220, Accuracy:0.945\nIteration: 8978, learning rate: 0.00618, Loss: 0.1060, Accuracy:0.969\nIteration: 8979, learning rate: 0.00618, Loss: 0.1843, Accuracy:0.898\nIteration: 8980, learning rate: 0.00618, Loss: 0.1519, Accuracy:0.930\nIteration: 8981, learning rate: 0.00618, Loss: 0.2090, Accuracy:0.906\nIteration: 8982, learning rate: 0.00618, Loss: 0.1087, Accuracy:0.961\nIteration: 8983, learning rate: 0.00618, Loss: 0.2151, Accuracy:0.906\nIteration: 8984, learning rate: 0.00618, Loss: 0.1511, Accuracy:0.945\nIteration: 8985, learning rate: 0.00618, Loss: 0.2346, Accuracy:0.898\nIteration: 8986, learning rate: 0.00618, Loss: 0.1089, Accuracy:0.953\nIteration: 8987, learning rate: 0.00618, Loss: 0.1917, Accuracy:0.938\nIteration: 8988, learning rate: 0.00618, Loss: 0.1993, Accuracy:0.906\nIteration: 8989, learning rate: 0.00618, Loss: 0.1532, Accuracy:0.938\nIteration: 8990, learning rate: 0.00618, Loss: 0.2111, Accuracy:0.914\nEpoch: 290, Loss: 0.1837, Accuracy:0.927, Val Loss: 0.2674, Val Accuracy: 0.880\nIteration: 8991, learning rate: 0.00618, Loss: 0.1333, Accuracy:0.945\nIteration: 8992, learning rate: 0.00618, Loss: 0.1407, Accuracy:0.930\nIteration: 8993, learning rate: 0.00618, Loss: 0.1078, Accuracy:0.969\nIteration: 8994, learning rate: 0.00618, Loss: 0.1631, Accuracy:0.930\nIteration: 8995, learning rate: 0.00618, Loss: 0.2065, Accuracy:0.914\nIteration: 8996, learning rate: 0.00618, Loss: 0.1334, Accuracy:0.953\nIteration: 8997, learning rate: 0.00618, Loss: 0.1989, Accuracy:0.938\nIteration: 8998, learning rate: 0.00618, Loss: 0.1655, Accuracy:0.938\nIteration: 8999, learning rate: 0.00618, Loss: 0.2048, Accuracy:0.922\nIteration: 9000, learning rate: 0.00618, Loss: 0.1792, Accuracy:0.922\nIteration: 9001, learning rate: 0.00618, Loss: 0.1396, Accuracy:0.969\nIteration: 9002, learning rate: 0.00618, Loss: 0.1869, Accuracy:0.922\nIteration: 9003, learning rate: 0.00618, Loss: 0.1462, Accuracy:0.930\nIteration: 9004, learning rate: 0.00618, Loss: 0.1789, Accuracy:0.945\nIteration: 9005, learning rate: 0.00618, Loss: 0.1810, Accuracy:0.938\nIteration: 9006, learning rate: 0.00618, Loss: 0.1757, Accuracy:0.914\nIteration: 9007, learning rate: 0.00618, Loss: 0.1226, Accuracy:0.961\nIteration: 9008, learning rate: 0.00618, Loss: 0.1883, Accuracy:0.930\nIteration: 9009, learning rate: 0.00618, Loss: 0.1125, Accuracy:0.961\nIteration: 9010, learning rate: 0.00618, Loss: 0.1993, Accuracy:0.930\nIteration: 9011, learning rate: 0.00618, Loss: 0.2116, Accuracy:0.922\nIteration: 9012, learning rate: 0.00618, Loss: 0.1730, Accuracy:0.930\nIteration: 9013, learning rate: 0.00618, Loss: 0.2748, Accuracy:0.891\nIteration: 9014, learning rate: 0.00618, Loss: 0.2036, Accuracy:0.898\nIteration: 9015, learning rate: 0.00618, Loss: 0.1755, Accuracy:0.938\nIteration: 9016, learning rate: 0.00618, Loss: 0.1006, Accuracy:0.969\nIteration: 9017, learning rate: 0.00618, Loss: 0.1807, Accuracy:0.930\nIteration: 9018, learning rate: 0.00618, Loss: 0.2180, Accuracy:0.922\nIteration: 9019, learning rate: 0.00617, Loss: 0.1836, Accuracy:0.922\nIteration: 9020, learning rate: 0.00617, Loss: 0.1644, Accuracy:0.922\nIteration: 9021, learning rate: 0.00617, Loss: 0.1153, Accuracy:0.968\nEpoch: 291, Loss: 0.1699, Accuracy:0.934, Val Loss: 0.3730, Val Accuracy: 0.832\nIteration: 9022, learning rate: 0.00617, Loss: 0.1871, Accuracy:0.938\nIteration: 9023, learning rate: 0.00617, Loss: 0.1725, Accuracy:0.938\nIteration: 9024, learning rate: 0.00617, Loss: 0.1657, Accuracy:0.914\nIteration: 9025, learning rate: 0.00617, Loss: 0.1732, Accuracy:0.945\nIteration: 9026, learning rate: 0.00617, Loss: 0.2302, Accuracy:0.898\nIteration: 9027, learning rate: 0.00617, Loss: 0.1586, Accuracy:0.930\nIteration: 9028, learning rate: 0.00617, Loss: 0.1881, Accuracy:0.914\nIteration: 9029, learning rate: 0.00617, Loss: 0.2287, Accuracy:0.914\nIteration: 9030, learning rate: 0.00617, Loss: 0.2165, Accuracy:0.898\nIteration: 9031, learning rate: 0.00617, Loss: 0.1941, Accuracy:0.922\nIteration: 9032, learning rate: 0.00617, Loss: 0.1613, Accuracy:0.922\nIteration: 9033, learning rate: 0.00617, Loss: 0.1353, Accuracy:0.953\nIteration: 9034, learning rate: 0.00617, Loss: 0.1549, Accuracy:0.922\nIteration: 9035, learning rate: 0.00617, Loss: 0.2001, Accuracy:0.914\nIteration: 9036, learning rate: 0.00617, Loss: 0.1380, Accuracy:0.961\nIteration: 9037, learning rate: 0.00617, Loss: 0.1582, Accuracy:0.938\nIteration: 9038, learning rate: 0.00617, Loss: 0.2339, Accuracy:0.914\nIteration: 9039, learning rate: 0.00617, Loss: 0.1878, Accuracy:0.930\nIteration: 9040, learning rate: 0.00617, Loss: 0.1353, Accuracy:0.953\nIteration: 9041, learning rate: 0.00617, Loss: 0.1411, Accuracy:0.961\nIteration: 9042, learning rate: 0.00617, Loss: 0.1149, Accuracy:0.961\nIteration: 9043, learning rate: 0.00617, Loss: 0.1202, Accuracy:0.945\nIteration: 9044, learning rate: 0.00617, Loss: 0.1665, Accuracy:0.922\nIteration: 9045, learning rate: 0.00617, Loss: 0.1953, Accuracy:0.930\nIteration: 9046, learning rate: 0.00617, Loss: 0.0993, Accuracy:0.969\nIteration: 9047, learning rate: 0.00617, Loss: 0.1768, Accuracy:0.930\nIteration: 9048, learning rate: 0.00617, Loss: 0.1921, Accuracy:0.922\nIteration: 9049, learning rate: 0.00617, Loss: 0.2100, Accuracy:0.906\nIteration: 9050, learning rate: 0.00617, Loss: 0.1442, Accuracy:0.938\nIteration: 9051, learning rate: 0.00617, Loss: 0.1393, Accuracy:0.953\nIteration: 9052, learning rate: 0.00617, Loss: 0.1108, Accuracy:0.968\nEpoch: 292, Loss: 0.1687, Accuracy:0.933, Val Loss: 0.3423, Val Accuracy: 0.859\nIteration: 9053, learning rate: 0.00617, Loss: 0.1367, Accuracy:0.961\nIteration: 9054, learning rate: 0.00617, Loss: 0.1171, Accuracy:0.953\nIteration: 9055, learning rate: 0.00617, Loss: 0.2444, Accuracy:0.906\nIteration: 9056, learning rate: 0.00617, Loss: 0.2524, Accuracy:0.898\nIteration: 9057, learning rate: 0.00617, Loss: 0.2372, Accuracy:0.930\nIteration: 9058, learning rate: 0.00617, Loss: 0.1323, Accuracy:0.953\nIteration: 9059, learning rate: 0.00617, Loss: 0.1702, Accuracy:0.961\nIteration: 9060, learning rate: 0.00616, Loss: 0.1362, Accuracy:0.961\nIteration: 9061, learning rate: 0.00616, Loss: 0.1945, Accuracy:0.898\nIteration: 9062, learning rate: 0.00616, Loss: 0.2769, Accuracy:0.898\nIteration: 9063, learning rate: 0.00616, Loss: 0.1032, Accuracy:0.969\nIteration: 9064, learning rate: 0.00616, Loss: 0.1568, Accuracy:0.945\nIteration: 9065, learning rate: 0.00616, Loss: 0.1576, Accuracy:0.930\nIteration: 9066, learning rate: 0.00616, Loss: 0.2790, Accuracy:0.914\nIteration: 9067, learning rate: 0.00616, Loss: 0.1946, Accuracy:0.922\nIteration: 9068, learning rate: 0.00616, Loss: 0.1390, Accuracy:0.945\nIteration: 9069, learning rate: 0.00616, Loss: 0.2031, Accuracy:0.930\nIteration: 9070, learning rate: 0.00616, Loss: 0.1914, Accuracy:0.922\nIteration: 9071, learning rate: 0.00616, Loss: 0.1743, Accuracy:0.938\nIteration: 9072, learning rate: 0.00616, Loss: 0.2377, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9073, learning rate: 0.00616, Loss: 0.1324, Accuracy:0.938\nIteration: 9074, learning rate: 0.00616, Loss: 0.1544, Accuracy:0.938\nIteration: 9075, learning rate: 0.00616, Loss: 0.2255, Accuracy:0.914\nIteration: 9076, learning rate: 0.00616, Loss: 0.1726, Accuracy:0.922\nIteration: 9077, learning rate: 0.00616, Loss: 0.2520, Accuracy:0.898\nIteration: 9078, learning rate: 0.00616, Loss: 0.2036, Accuracy:0.898\nIteration: 9079, learning rate: 0.00616, Loss: 0.1662, Accuracy:0.945\nIteration: 9080, learning rate: 0.00616, Loss: 0.1801, Accuracy:0.914\nIteration: 9081, learning rate: 0.00616, Loss: 0.2045, Accuracy:0.922\nIteration: 9082, learning rate: 0.00616, Loss: 0.1533, Accuracy:0.930\nIteration: 9083, learning rate: 0.00616, Loss: 0.1208, Accuracy:0.946\nEpoch: 293, Loss: 0.1839, Accuracy:0.929, Val Loss: 0.3003, Val Accuracy: 0.871\nIteration: 9084, learning rate: 0.00616, Loss: 0.2248, Accuracy:0.922\nIteration: 9085, learning rate: 0.00616, Loss: 0.1097, Accuracy:0.953\nIteration: 9086, learning rate: 0.00616, Loss: 0.2856, Accuracy:0.898\nIteration: 9087, learning rate: 0.00616, Loss: 0.2252, Accuracy:0.906\nIteration: 9088, learning rate: 0.00616, Loss: 0.2144, Accuracy:0.891\nIteration: 9089, learning rate: 0.00616, Loss: 0.2390, Accuracy:0.914\nIteration: 9090, learning rate: 0.00616, Loss: 0.1373, Accuracy:0.930\nIteration: 9091, learning rate: 0.00616, Loss: 0.2078, Accuracy:0.922\nIteration: 9092, learning rate: 0.00616, Loss: 0.1399, Accuracy:0.930\nIteration: 9093, learning rate: 0.00616, Loss: 0.1636, Accuracy:0.922\nIteration: 9094, learning rate: 0.00616, Loss: 0.1798, Accuracy:0.945\nIteration: 9095, learning rate: 0.00616, Loss: 0.1661, Accuracy:0.938\nIteration: 9096, learning rate: 0.00616, Loss: 0.1755, Accuracy:0.938\nIteration: 9097, learning rate: 0.00616, Loss: 0.1791, Accuracy:0.945\nIteration: 9098, learning rate: 0.00616, Loss: 0.1617, Accuracy:0.938\nIteration: 9099, learning rate: 0.00616, Loss: 0.1416, Accuracy:0.953\nIteration: 9100, learning rate: 0.00616, Loss: 0.1784, Accuracy:0.930\nIteration: 9101, learning rate: 0.00615, Loss: 0.2127, Accuracy:0.930\nIteration: 9102, learning rate: 0.00615, Loss: 0.2210, Accuracy:0.875\nIteration: 9103, learning rate: 0.00615, Loss: 0.2014, Accuracy:0.906\nIteration: 9104, learning rate: 0.00615, Loss: 0.1825, Accuracy:0.922\nIteration: 9105, learning rate: 0.00615, Loss: 0.0996, Accuracy:0.961\nIteration: 9106, learning rate: 0.00615, Loss: 0.1821, Accuracy:0.922\nIteration: 9107, learning rate: 0.00615, Loss: 0.2196, Accuracy:0.906\nIteration: 9108, learning rate: 0.00615, Loss: 0.1478, Accuracy:0.953\nIteration: 9109, learning rate: 0.00615, Loss: 0.1214, Accuracy:0.953\nIteration: 9110, learning rate: 0.00615, Loss: 0.1570, Accuracy:0.930\nIteration: 9111, learning rate: 0.00615, Loss: 0.1507, Accuracy:0.945\nIteration: 9112, learning rate: 0.00615, Loss: 0.1344, Accuracy:0.922\nIteration: 9113, learning rate: 0.00615, Loss: 0.1462, Accuracy:0.938\nIteration: 9114, learning rate: 0.00615, Loss: 0.1694, Accuracy:0.914\nEpoch: 294, Loss: 0.1766, Accuracy:0.927, Val Loss: 0.2830, Val Accuracy: 0.882\nIteration: 9115, learning rate: 0.00615, Loss: 0.1678, Accuracy:0.938\nIteration: 9116, learning rate: 0.00615, Loss: 0.1743, Accuracy:0.930\nIteration: 9117, learning rate: 0.00615, Loss: 0.1531, Accuracy:0.938\nIteration: 9118, learning rate: 0.00615, Loss: 0.1635, Accuracy:0.953\nIteration: 9119, learning rate: 0.00615, Loss: 0.1858, Accuracy:0.930\nIteration: 9120, learning rate: 0.00615, Loss: 0.1461, Accuracy:0.945\nIteration: 9121, learning rate: 0.00615, Loss: 0.1426, Accuracy:0.938\nIteration: 9122, learning rate: 0.00615, Loss: 0.1470, Accuracy:0.945\nIteration: 9123, learning rate: 0.00615, Loss: 0.1685, Accuracy:0.938\nIteration: 9124, learning rate: 0.00615, Loss: 0.1411, Accuracy:0.930\nIteration: 9125, learning rate: 0.00615, Loss: 0.1318, Accuracy:0.953\nIteration: 9126, learning rate: 0.00615, Loss: 0.1378, Accuracy:0.953\nIteration: 9127, learning rate: 0.00615, Loss: 0.3052, Accuracy:0.906\nIteration: 9128, learning rate: 0.00615, Loss: 0.2331, Accuracy:0.891\nIteration: 9129, learning rate: 0.00615, Loss: 0.1055, Accuracy:0.969\nIteration: 9130, learning rate: 0.00615, Loss: 0.2391, Accuracy:0.891\nIteration: 9131, learning rate: 0.00615, Loss: 0.1305, Accuracy:0.938\nIteration: 9132, learning rate: 0.00615, Loss: 0.2583, Accuracy:0.914\nIteration: 9133, learning rate: 0.00615, Loss: 0.2115, Accuracy:0.930\nIteration: 9134, learning rate: 0.00615, Loss: 0.1442, Accuracy:0.953\nIteration: 9135, learning rate: 0.00615, Loss: 0.1639, Accuracy:0.945\nIteration: 9136, learning rate: 0.00615, Loss: 0.1669, Accuracy:0.953\nIteration: 9137, learning rate: 0.00615, Loss: 0.1697, Accuracy:0.930\nIteration: 9138, learning rate: 0.00615, Loss: 0.1123, Accuracy:0.969\nIteration: 9139, learning rate: 0.00615, Loss: 0.2142, Accuracy:0.930\nIteration: 9140, learning rate: 0.00615, Loss: 0.1853, Accuracy:0.930\nIteration: 9141, learning rate: 0.00615, Loss: 0.1758, Accuracy:0.938\nIteration: 9142, learning rate: 0.00615, Loss: 0.2354, Accuracy:0.898\nIteration: 9143, learning rate: 0.00614, Loss: 0.1833, Accuracy:0.930\nIteration: 9144, learning rate: 0.00614, Loss: 0.2068, Accuracy:0.914\nIteration: 9145, learning rate: 0.00614, Loss: 0.1574, Accuracy:0.925\nEpoch: 295, Loss: 0.1761, Accuracy:0.934, Val Loss: 0.3188, Val Accuracy: 0.870\nIteration: 9146, learning rate: 0.00614, Loss: 0.1809, Accuracy:0.938\nIteration: 9147, learning rate: 0.00614, Loss: 0.1375, Accuracy:0.938\nIteration: 9148, learning rate: 0.00614, Loss: 0.2354, Accuracy:0.898\nIteration: 9149, learning rate: 0.00614, Loss: 0.1720, Accuracy:0.930\nIteration: 9150, learning rate: 0.00614, Loss: 0.2328, Accuracy:0.891\nIteration: 9151, learning rate: 0.00614, Loss: 0.1790, Accuracy:0.906\nIteration: 9152, learning rate: 0.00614, Loss: 0.1918, Accuracy:0.914\nIteration: 9153, learning rate: 0.00614, Loss: 0.2757, Accuracy:0.883\nIteration: 9154, learning rate: 0.00614, Loss: 0.2074, Accuracy:0.914\nIteration: 9155, learning rate: 0.00614, Loss: 0.1505, Accuracy:0.945\nIteration: 9156, learning rate: 0.00614, Loss: 0.1579, Accuracy:0.945\nIteration: 9157, learning rate: 0.00614, Loss: 0.1951, Accuracy:0.883\nIteration: 9158, learning rate: 0.00614, Loss: 0.1806, Accuracy:0.930\nIteration: 9159, learning rate: 0.00614, Loss: 0.1992, Accuracy:0.945\nIteration: 9160, learning rate: 0.00614, Loss: 0.1705, Accuracy:0.938\nIteration: 9161, learning rate: 0.00614, Loss: 0.2162, Accuracy:0.898\nIteration: 9162, learning rate: 0.00614, Loss: 0.1614, Accuracy:0.945\nIteration: 9163, learning rate: 0.00614, Loss: 0.1661, Accuracy:0.914\nIteration: 9164, learning rate: 0.00614, Loss: 0.1519, Accuracy:0.922\nIteration: 9165, learning rate: 0.00614, Loss: 0.1357, Accuracy:0.945\nIteration: 9166, learning rate: 0.00614, Loss: 0.1151, Accuracy:0.953\nIteration: 9167, learning rate: 0.00614, Loss: 0.2074, Accuracy:0.922\nIteration: 9168, learning rate: 0.00614, Loss: 0.1452, Accuracy:0.938\nIteration: 9169, learning rate: 0.00614, Loss: 0.2435, Accuracy:0.906\nIteration: 9170, learning rate: 0.00614, Loss: 0.1709, Accuracy:0.938\nIteration: 9171, learning rate: 0.00614, Loss: 0.1200, Accuracy:0.969\nIteration: 9172, learning rate: 0.00614, Loss: 0.1703, Accuracy:0.938\nIteration: 9173, learning rate: 0.00614, Loss: 0.1647, Accuracy:0.945\nIteration: 9174, learning rate: 0.00614, Loss: 0.1952, Accuracy:0.898\nIteration: 9175, learning rate: 0.00614, Loss: 0.1160, Accuracy:0.961\nIteration: 9176, learning rate: 0.00614, Loss: 0.1726, Accuracy:0.946\nEpoch: 296, Loss: 0.1780, Accuracy:0.927, Val Loss: 0.3346, Val Accuracy: 0.864\nIteration: 9177, learning rate: 0.00614, Loss: 0.1652, Accuracy:0.938\nIteration: 9178, learning rate: 0.00614, Loss: 0.1114, Accuracy:0.945\nIteration: 9179, learning rate: 0.00614, Loss: 0.2309, Accuracy:0.914\nIteration: 9180, learning rate: 0.00614, Loss: 0.2027, Accuracy:0.914\nIteration: 9181, learning rate: 0.00614, Loss: 0.1365, Accuracy:0.945\nIteration: 9182, learning rate: 0.00614, Loss: 0.2051, Accuracy:0.922\nIteration: 9183, learning rate: 0.00614, Loss: 0.1358, Accuracy:0.953\nIteration: 9184, learning rate: 0.00613, Loss: 0.1773, Accuracy:0.922\nIteration: 9185, learning rate: 0.00613, Loss: 0.1779, Accuracy:0.930\nIteration: 9186, learning rate: 0.00613, Loss: 0.1491, Accuracy:0.953\nIteration: 9187, learning rate: 0.00613, Loss: 0.1936, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9188, learning rate: 0.00613, Loss: 0.2491, Accuracy:0.914\nIteration: 9189, learning rate: 0.00613, Loss: 0.1730, Accuracy:0.898\nIteration: 9190, learning rate: 0.00613, Loss: 0.1608, Accuracy:0.930\nIteration: 9191, learning rate: 0.00613, Loss: 0.2094, Accuracy:0.906\nIteration: 9192, learning rate: 0.00613, Loss: 0.1804, Accuracy:0.930\nIteration: 9193, learning rate: 0.00613, Loss: 0.2001, Accuracy:0.930\nIteration: 9194, learning rate: 0.00613, Loss: 0.2247, Accuracy:0.914\nIteration: 9195, learning rate: 0.00613, Loss: 0.2053, Accuracy:0.922\nIteration: 9196, learning rate: 0.00613, Loss: 0.1776, Accuracy:0.945\nIteration: 9197, learning rate: 0.00613, Loss: 0.1419, Accuracy:0.953\nIteration: 9198, learning rate: 0.00613, Loss: 0.2312, Accuracy:0.906\nIteration: 9199, learning rate: 0.00613, Loss: 0.2312, Accuracy:0.906\nIteration: 9200, learning rate: 0.00613, Loss: 0.1382, Accuracy:0.953\nIteration: 9201, learning rate: 0.00613, Loss: 0.1414, Accuracy:0.922\nIteration: 9202, learning rate: 0.00613, Loss: 0.1390, Accuracy:0.938\nIteration: 9203, learning rate: 0.00613, Loss: 0.1305, Accuracy:0.969\nIteration: 9204, learning rate: 0.00613, Loss: 0.1855, Accuracy:0.930\nIteration: 9205, learning rate: 0.00613, Loss: 0.2348, Accuracy:0.883\nIteration: 9206, learning rate: 0.00613, Loss: 0.1368, Accuracy:0.938\nIteration: 9207, learning rate: 0.00613, Loss: 0.1899, Accuracy:0.935\nEpoch: 297, Loss: 0.1795, Accuracy:0.928, Val Loss: 0.2595, Val Accuracy: 0.878\nIteration: 9208, learning rate: 0.00613, Loss: 0.1445, Accuracy:0.938\nIteration: 9209, learning rate: 0.00613, Loss: 0.2176, Accuracy:0.930\nIteration: 9210, learning rate: 0.00613, Loss: 0.1998, Accuracy:0.930\nIteration: 9211, learning rate: 0.00613, Loss: 0.2001, Accuracy:0.930\nIteration: 9212, learning rate: 0.00613, Loss: 0.2002, Accuracy:0.914\nIteration: 9213, learning rate: 0.00613, Loss: 0.1339, Accuracy:0.961\nIteration: 9214, learning rate: 0.00613, Loss: 0.2643, Accuracy:0.906\nIteration: 9215, learning rate: 0.00613, Loss: 0.1466, Accuracy:0.930\nIteration: 9216, learning rate: 0.00613, Loss: 0.1864, Accuracy:0.906\nIteration: 9217, learning rate: 0.00613, Loss: 0.1386, Accuracy:0.945\nIteration: 9218, learning rate: 0.00613, Loss: 0.2201, Accuracy:0.914\nIteration: 9219, learning rate: 0.00613, Loss: 0.2337, Accuracy:0.883\nIteration: 9220, learning rate: 0.00613, Loss: 0.2186, Accuracy:0.898\nIteration: 9221, learning rate: 0.00613, Loss: 0.2575, Accuracy:0.914\nIteration: 9222, learning rate: 0.00613, Loss: 0.1304, Accuracy:0.953\nIteration: 9223, learning rate: 0.00613, Loss: 0.1995, Accuracy:0.914\nIteration: 9224, learning rate: 0.00613, Loss: 0.2416, Accuracy:0.922\nIteration: 9225, learning rate: 0.00613, Loss: 0.1350, Accuracy:0.961\nIteration: 9226, learning rate: 0.00612, Loss: 0.1676, Accuracy:0.922\nIteration: 9227, learning rate: 0.00612, Loss: 0.1960, Accuracy:0.922\nIteration: 9228, learning rate: 0.00612, Loss: 0.1807, Accuracy:0.945\nIteration: 9229, learning rate: 0.00612, Loss: 0.1959, Accuracy:0.930\nIteration: 9230, learning rate: 0.00612, Loss: 0.1826, Accuracy:0.922\nIteration: 9231, learning rate: 0.00612, Loss: 0.1978, Accuracy:0.914\nIteration: 9232, learning rate: 0.00612, Loss: 0.1922, Accuracy:0.906\nIteration: 9233, learning rate: 0.00612, Loss: 0.1589, Accuracy:0.922\nIteration: 9234, learning rate: 0.00612, Loss: 0.2496, Accuracy:0.883\nIteration: 9235, learning rate: 0.00612, Loss: 0.1895, Accuracy:0.938\nIteration: 9236, learning rate: 0.00612, Loss: 0.1504, Accuracy:0.945\nIteration: 9237, learning rate: 0.00612, Loss: 0.0991, Accuracy:0.961\nIteration: 9238, learning rate: 0.00612, Loss: 0.1851, Accuracy:0.946\nEpoch: 298, Loss: 0.1875, Accuracy:0.926, Val Loss: 0.2868, Val Accuracy: 0.876\nIteration: 9239, learning rate: 0.00612, Loss: 0.1574, Accuracy:0.945\nIteration: 9240, learning rate: 0.00612, Loss: 0.1081, Accuracy:0.961\nIteration: 9241, learning rate: 0.00612, Loss: 0.1732, Accuracy:0.938\nIteration: 9242, learning rate: 0.00612, Loss: 0.1653, Accuracy:0.930\nIteration: 9243, learning rate: 0.00612, Loss: 0.1859, Accuracy:0.914\nIteration: 9244, learning rate: 0.00612, Loss: 0.1174, Accuracy:0.953\nIteration: 9245, learning rate: 0.00612, Loss: 0.1739, Accuracy:0.945\nIteration: 9246, learning rate: 0.00612, Loss: 0.1184, Accuracy:0.953\nIteration: 9247, learning rate: 0.00612, Loss: 0.1423, Accuracy:0.938\nIteration: 9248, learning rate: 0.00612, Loss: 0.1938, Accuracy:0.930\nIteration: 9249, learning rate: 0.00612, Loss: 0.2070, Accuracy:0.914\nIteration: 9250, learning rate: 0.00612, Loss: 0.2083, Accuracy:0.922\nIteration: 9251, learning rate: 0.00612, Loss: 0.1726, Accuracy:0.945\nIteration: 9252, learning rate: 0.00612, Loss: 0.2057, Accuracy:0.906\nIteration: 9253, learning rate: 0.00612, Loss: 0.1726, Accuracy:0.938\nIteration: 9254, learning rate: 0.00612, Loss: 0.1451, Accuracy:0.938\nIteration: 9255, learning rate: 0.00612, Loss: 0.2089, Accuracy:0.945\nIteration: 9256, learning rate: 0.00612, Loss: 0.1428, Accuracy:0.945\nIteration: 9257, learning rate: 0.00612, Loss: 0.1805, Accuracy:0.945\nIteration: 9258, learning rate: 0.00612, Loss: 0.2643, Accuracy:0.898\nIteration: 9259, learning rate: 0.00612, Loss: 0.2908, Accuracy:0.891\nIteration: 9260, learning rate: 0.00612, Loss: 0.2316, Accuracy:0.883\nIteration: 9261, learning rate: 0.00612, Loss: 0.1986, Accuracy:0.914\nIteration: 9262, learning rate: 0.00612, Loss: 0.1601, Accuracy:0.938\nIteration: 9263, learning rate: 0.00612, Loss: 0.1209, Accuracy:0.961\nIteration: 9264, learning rate: 0.00612, Loss: 0.1575, Accuracy:0.930\nIteration: 9265, learning rate: 0.00612, Loss: 0.1312, Accuracy:0.945\nIteration: 9266, learning rate: 0.00612, Loss: 0.1811, Accuracy:0.930\nIteration: 9267, learning rate: 0.00612, Loss: 0.2305, Accuracy:0.906\nIteration: 9268, learning rate: 0.00611, Loss: 0.1883, Accuracy:0.930\nIteration: 9269, learning rate: 0.00611, Loss: 0.1394, Accuracy:0.946\nEpoch: 299, Loss: 0.1766, Accuracy:0.931, Val Loss: 0.2873, Val Accuracy: 0.877\nIteration: 9270, learning rate: 0.00611, Loss: 0.1737, Accuracy:0.945\nIteration: 9271, learning rate: 0.00611, Loss: 0.2447, Accuracy:0.891\nIteration: 9272, learning rate: 0.00611, Loss: 0.1936, Accuracy:0.938\nIteration: 9273, learning rate: 0.00611, Loss: 0.1569, Accuracy:0.914\nIteration: 9274, learning rate: 0.00611, Loss: 0.1625, Accuracy:0.906\nIteration: 9275, learning rate: 0.00611, Loss: 0.1318, Accuracy:0.945\nIteration: 9276, learning rate: 0.00611, Loss: 0.1832, Accuracy:0.930\nIteration: 9277, learning rate: 0.00611, Loss: 0.1885, Accuracy:0.938\nIteration: 9278, learning rate: 0.00611, Loss: 0.2390, Accuracy:0.898\nIteration: 9279, learning rate: 0.00611, Loss: 0.1067, Accuracy:0.961\nIteration: 9280, learning rate: 0.00611, Loss: 0.2020, Accuracy:0.914\nIteration: 9281, learning rate: 0.00611, Loss: 0.1759, Accuracy:0.922\nIteration: 9282, learning rate: 0.00611, Loss: 0.2094, Accuracy:0.898\nIteration: 9283, learning rate: 0.00611, Loss: 0.2045, Accuracy:0.922\nIteration: 9284, learning rate: 0.00611, Loss: 0.1314, Accuracy:0.953\nIteration: 9285, learning rate: 0.00611, Loss: 0.1503, Accuracy:0.945\nIteration: 9286, learning rate: 0.00611, Loss: 0.2862, Accuracy:0.891\nIteration: 9287, learning rate: 0.00611, Loss: 0.1800, Accuracy:0.922\nIteration: 9288, learning rate: 0.00611, Loss: 0.1262, Accuracy:0.945\nIteration: 9289, learning rate: 0.00611, Loss: 0.1162, Accuracy:0.977\nIteration: 9290, learning rate: 0.00611, Loss: 0.1756, Accuracy:0.938\nIteration: 9291, learning rate: 0.00611, Loss: 0.2244, Accuracy:0.914\nIteration: 9292, learning rate: 0.00611, Loss: 0.1882, Accuracy:0.930\nIteration: 9293, learning rate: 0.00611, Loss: 0.2163, Accuracy:0.898\nIteration: 9294, learning rate: 0.00611, Loss: 0.2287, Accuracy:0.898\nIteration: 9295, learning rate: 0.00611, Loss: 0.2594, Accuracy:0.914\nIteration: 9296, learning rate: 0.00611, Loss: 0.2158, Accuracy:0.922\nIteration: 9297, learning rate: 0.00611, Loss: 0.1742, Accuracy:0.938\nIteration: 9298, learning rate: 0.00611, Loss: 0.1470, Accuracy:0.938\nIteration: 9299, learning rate: 0.00611, Loss: 0.1930, Accuracy:0.906\nIteration: 9300, learning rate: 0.00611, Loss: 0.1927, Accuracy:0.957\nEpoch: 300, Loss: 0.1864, Accuracy:0.926, Val Loss: 0.2792, Val Accuracy: 0.885\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9301, learning rate: 0.00611, Loss: 0.2225, Accuracy:0.922\nIteration: 9302, learning rate: 0.00611, Loss: 0.1729, Accuracy:0.938\nIteration: 9303, learning rate: 0.00611, Loss: 0.1524, Accuracy:0.945\nIteration: 9304, learning rate: 0.00611, Loss: 0.1535, Accuracy:0.938\nIteration: 9305, learning rate: 0.00611, Loss: 0.1637, Accuracy:0.930\nIteration: 9306, learning rate: 0.00611, Loss: 0.1727, Accuracy:0.930\nIteration: 9307, learning rate: 0.00611, Loss: 0.1782, Accuracy:0.938\nIteration: 9308, learning rate: 0.00611, Loss: 0.2166, Accuracy:0.930\nIteration: 9309, learning rate: 0.00611, Loss: 0.1296, Accuracy:0.945\nIteration: 9310, learning rate: 0.00610, Loss: 0.1311, Accuracy:0.969\nIteration: 9311, learning rate: 0.00610, Loss: 0.1220, Accuracy:0.961\nIteration: 9312, learning rate: 0.00610, Loss: 0.2019, Accuracy:0.938\nIteration: 9313, learning rate: 0.00610, Loss: 0.1730, Accuracy:0.906\nIteration: 9314, learning rate: 0.00610, Loss: 0.2176, Accuracy:0.906\nIteration: 9315, learning rate: 0.00610, Loss: 0.1451, Accuracy:0.945\nIteration: 9316, learning rate: 0.00610, Loss: 0.1257, Accuracy:0.938\nIteration: 9317, learning rate: 0.00610, Loss: 0.1775, Accuracy:0.930\nIteration: 9318, learning rate: 0.00610, Loss: 0.1936, Accuracy:0.922\nIteration: 9319, learning rate: 0.00610, Loss: 0.1530, Accuracy:0.938\nIteration: 9320, learning rate: 0.00610, Loss: 0.1247, Accuracy:0.938\nIteration: 9321, learning rate: 0.00610, Loss: 0.1633, Accuracy:0.938\nIteration: 9322, learning rate: 0.00610, Loss: 0.1502, Accuracy:0.953\nIteration: 9323, learning rate: 0.00610, Loss: 0.1916, Accuracy:0.914\nIteration: 9324, learning rate: 0.00610, Loss: 0.1493, Accuracy:0.945\nIteration: 9325, learning rate: 0.00610, Loss: 0.1976, Accuracy:0.930\nIteration: 9326, learning rate: 0.00610, Loss: 0.1905, Accuracy:0.922\nIteration: 9327, learning rate: 0.00610, Loss: 0.1438, Accuracy:0.938\nIteration: 9328, learning rate: 0.00610, Loss: 0.1923, Accuracy:0.914\nIteration: 9329, learning rate: 0.00610, Loss: 0.2238, Accuracy:0.930\nIteration: 9330, learning rate: 0.00610, Loss: 0.1623, Accuracy:0.953\nIteration: 9331, learning rate: 0.00610, Loss: 0.1571, Accuracy:0.925\nEpoch: 301, Loss: 0.1693, Accuracy:0.934, Val Loss: 0.2925, Val Accuracy: 0.868\nIteration: 9332, learning rate: 0.00610, Loss: 0.1765, Accuracy:0.930\nIteration: 9333, learning rate: 0.00610, Loss: 0.2177, Accuracy:0.914\nIteration: 9334, learning rate: 0.00610, Loss: 0.2232, Accuracy:0.898\nIteration: 9335, learning rate: 0.00610, Loss: 0.1306, Accuracy:0.945\nIteration: 9336, learning rate: 0.00610, Loss: 0.2399, Accuracy:0.891\nIteration: 9337, learning rate: 0.00610, Loss: 0.1780, Accuracy:0.938\nIteration: 9338, learning rate: 0.00610, Loss: 0.2531, Accuracy:0.898\nIteration: 9339, learning rate: 0.00610, Loss: 0.2242, Accuracy:0.914\nIteration: 9340, learning rate: 0.00610, Loss: 0.1744, Accuracy:0.953\nIteration: 9341, learning rate: 0.00610, Loss: 0.2779, Accuracy:0.883\nIteration: 9342, learning rate: 0.00610, Loss: 0.1649, Accuracy:0.930\nIteration: 9343, learning rate: 0.00610, Loss: 0.1951, Accuracy:0.898\nIteration: 9344, learning rate: 0.00610, Loss: 0.1431, Accuracy:0.961\nIteration: 9345, learning rate: 0.00610, Loss: 0.1746, Accuracy:0.945\nIteration: 9346, learning rate: 0.00610, Loss: 0.1799, Accuracy:0.906\nIteration: 9347, learning rate: 0.00610, Loss: 0.2253, Accuracy:0.938\nIteration: 9348, learning rate: 0.00610, Loss: 0.2296, Accuracy:0.922\nIteration: 9349, learning rate: 0.00610, Loss: 0.1537, Accuracy:0.930\nIteration: 9350, learning rate: 0.00610, Loss: 0.1383, Accuracy:0.953\nIteration: 9351, learning rate: 0.00610, Loss: 0.2330, Accuracy:0.930\nIteration: 9352, learning rate: 0.00609, Loss: 0.2008, Accuracy:0.922\nIteration: 9353, learning rate: 0.00609, Loss: 0.1628, Accuracy:0.930\nIteration: 9354, learning rate: 0.00609, Loss: 0.2239, Accuracy:0.914\nIteration: 9355, learning rate: 0.00609, Loss: 0.0910, Accuracy:0.969\nIteration: 9356, learning rate: 0.00609, Loss: 0.2080, Accuracy:0.906\nIteration: 9357, learning rate: 0.00609, Loss: 0.1443, Accuracy:0.938\nIteration: 9358, learning rate: 0.00609, Loss: 0.1439, Accuracy:0.938\nIteration: 9359, learning rate: 0.00609, Loss: 0.2106, Accuracy:0.914\nIteration: 9360, learning rate: 0.00609, Loss: 0.1989, Accuracy:0.930\nIteration: 9361, learning rate: 0.00609, Loss: 0.1303, Accuracy:0.961\nIteration: 9362, learning rate: 0.00609, Loss: 0.2613, Accuracy:0.892\nEpoch: 302, Loss: 0.1906, Accuracy:0.925, Val Loss: 0.2765, Val Accuracy: 0.886\nIteration: 9363, learning rate: 0.00609, Loss: 0.1391, Accuracy:0.938\nIteration: 9364, learning rate: 0.00609, Loss: 0.1488, Accuracy:0.922\nIteration: 9365, learning rate: 0.00609, Loss: 0.1355, Accuracy:0.953\nIteration: 9366, learning rate: 0.00609, Loss: 0.1227, Accuracy:0.938\nIteration: 9367, learning rate: 0.00609, Loss: 0.1957, Accuracy:0.898\nIteration: 9368, learning rate: 0.00609, Loss: 0.2254, Accuracy:0.922\nIteration: 9369, learning rate: 0.00609, Loss: 0.1480, Accuracy:0.938\nIteration: 9370, learning rate: 0.00609, Loss: 0.1141, Accuracy:0.969\nIteration: 9371, learning rate: 0.00609, Loss: 0.2193, Accuracy:0.922\nIteration: 9372, learning rate: 0.00609, Loss: 0.1717, Accuracy:0.953\nIteration: 9373, learning rate: 0.00609, Loss: 0.1619, Accuracy:0.906\nIteration: 9374, learning rate: 0.00609, Loss: 0.1414, Accuracy:0.938\nIteration: 9375, learning rate: 0.00609, Loss: 0.1928, Accuracy:0.938\nIteration: 9376, learning rate: 0.00609, Loss: 0.1458, Accuracy:0.953\nIteration: 9377, learning rate: 0.00609, Loss: 0.1561, Accuracy:0.930\nIteration: 9378, learning rate: 0.00609, Loss: 0.1034, Accuracy:0.977\nIteration: 9379, learning rate: 0.00609, Loss: 0.1503, Accuracy:0.953\nIteration: 9380, learning rate: 0.00609, Loss: 0.2043, Accuracy:0.914\nIteration: 9381, learning rate: 0.00609, Loss: 0.1719, Accuracy:0.938\nIteration: 9382, learning rate: 0.00609, Loss: 0.1689, Accuracy:0.945\nIteration: 9383, learning rate: 0.00609, Loss: 0.1677, Accuracy:0.945\nIteration: 9384, learning rate: 0.00609, Loss: 0.1512, Accuracy:0.938\nIteration: 9385, learning rate: 0.00609, Loss: 0.2359, Accuracy:0.914\nIteration: 9386, learning rate: 0.00609, Loss: 0.1984, Accuracy:0.930\nIteration: 9387, learning rate: 0.00609, Loss: 0.2380, Accuracy:0.891\nIteration: 9388, learning rate: 0.00609, Loss: 0.1657, Accuracy:0.938\nIteration: 9389, learning rate: 0.00609, Loss: 0.1490, Accuracy:0.945\nIteration: 9390, learning rate: 0.00609, Loss: 0.1770, Accuracy:0.938\nIteration: 9391, learning rate: 0.00609, Loss: 0.1775, Accuracy:0.938\nIteration: 9392, learning rate: 0.00609, Loss: 0.2237, Accuracy:0.883\nIteration: 9393, learning rate: 0.00609, Loss: 0.2076, Accuracy:0.935\nEpoch: 303, Loss: 0.1712, Accuracy:0.933, Val Loss: 0.3263, Val Accuracy: 0.865\nIteration: 9394, learning rate: 0.00609, Loss: 0.1986, Accuracy:0.938\nIteration: 9395, learning rate: 0.00608, Loss: 0.1436, Accuracy:0.953\nIteration: 9396, learning rate: 0.00608, Loss: 0.1743, Accuracy:0.914\nIteration: 9397, learning rate: 0.00608, Loss: 0.1080, Accuracy:0.953\nIteration: 9398, learning rate: 0.00608, Loss: 0.2211, Accuracy:0.906\nIteration: 9399, learning rate: 0.00608, Loss: 0.1209, Accuracy:0.969\nIteration: 9400, learning rate: 0.00608, Loss: 0.2058, Accuracy:0.914\nIteration: 9401, learning rate: 0.00608, Loss: 0.1113, Accuracy:0.945\nIteration: 9402, learning rate: 0.00608, Loss: 0.1792, Accuracy:0.930\nIteration: 9403, learning rate: 0.00608, Loss: 0.1922, Accuracy:0.930\nIteration: 9404, learning rate: 0.00608, Loss: 0.1272, Accuracy:0.945\nIteration: 9405, learning rate: 0.00608, Loss: 0.1607, Accuracy:0.953\nIteration: 9406, learning rate: 0.00608, Loss: 0.2075, Accuracy:0.922\nIteration: 9407, learning rate: 0.00608, Loss: 0.1442, Accuracy:0.953\nIteration: 9408, learning rate: 0.00608, Loss: 0.2694, Accuracy:0.891\nIteration: 9409, learning rate: 0.00608, Loss: 0.2006, Accuracy:0.922\nIteration: 9410, learning rate: 0.00608, Loss: 0.1706, Accuracy:0.922\nIteration: 9411, learning rate: 0.00608, Loss: 0.1671, Accuracy:0.930\nIteration: 9412, learning rate: 0.00608, Loss: 0.1844, Accuracy:0.906\nIteration: 9413, learning rate: 0.00608, Loss: 0.1712, Accuracy:0.930\nIteration: 9414, learning rate: 0.00608, Loss: 0.2424, Accuracy:0.898\nIteration: 9415, learning rate: 0.00608, Loss: 0.1371, Accuracy:0.961\nIteration: 9416, learning rate: 0.00608, Loss: 0.1277, Accuracy:0.938\nIteration: 9417, learning rate: 0.00608, Loss: 0.2536, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9418, learning rate: 0.00608, Loss: 0.1243, Accuracy:0.945\nIteration: 9419, learning rate: 0.00608, Loss: 0.1231, Accuracy:0.969\nIteration: 9420, learning rate: 0.00608, Loss: 0.2107, Accuracy:0.914\nIteration: 9421, learning rate: 0.00608, Loss: 0.1611, Accuracy:0.938\nIteration: 9422, learning rate: 0.00608, Loss: 0.2115, Accuracy:0.922\nIteration: 9423, learning rate: 0.00608, Loss: 0.2401, Accuracy:0.906\nIteration: 9424, learning rate: 0.00608, Loss: 0.1866, Accuracy:0.935\nEpoch: 304, Loss: 0.1767, Accuracy:0.932, Val Loss: 0.3258, Val Accuracy: 0.857\nIteration: 9425, learning rate: 0.00608, Loss: 0.2657, Accuracy:0.875\nIteration: 9426, learning rate: 0.00608, Loss: 0.2140, Accuracy:0.922\nIteration: 9427, learning rate: 0.00608, Loss: 0.1482, Accuracy:0.922\nIteration: 9428, learning rate: 0.00608, Loss: 0.2355, Accuracy:0.891\nIteration: 9429, learning rate: 0.00608, Loss: 0.1479, Accuracy:0.945\nIteration: 9430, learning rate: 0.00608, Loss: 0.1285, Accuracy:0.953\nIteration: 9431, learning rate: 0.00608, Loss: 0.3102, Accuracy:0.898\nIteration: 9432, learning rate: 0.00608, Loss: 0.1548, Accuracy:0.953\nIteration: 9433, learning rate: 0.00608, Loss: 0.2342, Accuracy:0.906\nIteration: 9434, learning rate: 0.00608, Loss: 0.1835, Accuracy:0.938\nIteration: 9435, learning rate: 0.00608, Loss: 0.1807, Accuracy:0.930\nIteration: 9436, learning rate: 0.00608, Loss: 0.1776, Accuracy:0.930\nIteration: 9437, learning rate: 0.00607, Loss: 0.2685, Accuracy:0.898\nIteration: 9438, learning rate: 0.00607, Loss: 0.1160, Accuracy:0.953\nIteration: 9439, learning rate: 0.00607, Loss: 0.2197, Accuracy:0.930\nIteration: 9440, learning rate: 0.00607, Loss: 0.1760, Accuracy:0.945\nIteration: 9441, learning rate: 0.00607, Loss: 0.2184, Accuracy:0.930\nIteration: 9442, learning rate: 0.00607, Loss: 0.1519, Accuracy:0.938\nIteration: 9443, learning rate: 0.00607, Loss: 0.2568, Accuracy:0.891\nIteration: 9444, learning rate: 0.00607, Loss: 0.1896, Accuracy:0.914\nIteration: 9445, learning rate: 0.00607, Loss: 0.1627, Accuracy:0.914\nIteration: 9446, learning rate: 0.00607, Loss: 0.2426, Accuracy:0.922\nIteration: 9447, learning rate: 0.00607, Loss: 0.1271, Accuracy:0.945\nIteration: 9448, learning rate: 0.00607, Loss: 0.2449, Accuracy:0.898\nIteration: 9449, learning rate: 0.00607, Loss: 0.1204, Accuracy:0.961\nIteration: 9450, learning rate: 0.00607, Loss: 0.2036, Accuracy:0.930\nIteration: 9451, learning rate: 0.00607, Loss: 0.1418, Accuracy:0.938\nIteration: 9452, learning rate: 0.00607, Loss: 0.2527, Accuracy:0.898\nIteration: 9453, learning rate: 0.00607, Loss: 0.1252, Accuracy:0.969\nIteration: 9454, learning rate: 0.00607, Loss: 0.1537, Accuracy:0.945\nIteration: 9455, learning rate: 0.00607, Loss: 0.1072, Accuracy:0.957\nEpoch: 305, Loss: 0.1890, Accuracy:0.927, Val Loss: 0.2687, Val Accuracy: 0.894\nIteration: 9456, learning rate: 0.00607, Loss: 0.1527, Accuracy:0.938\nIteration: 9457, learning rate: 0.00607, Loss: 0.2116, Accuracy:0.930\nIteration: 9458, learning rate: 0.00607, Loss: 0.1643, Accuracy:0.945\nIteration: 9459, learning rate: 0.00607, Loss: 0.1534, Accuracy:0.930\nIteration: 9460, learning rate: 0.00607, Loss: 0.2139, Accuracy:0.898\nIteration: 9461, learning rate: 0.00607, Loss: 0.2059, Accuracy:0.906\nIteration: 9462, learning rate: 0.00607, Loss: 0.1389, Accuracy:0.953\nIteration: 9463, learning rate: 0.00607, Loss: 0.2310, Accuracy:0.898\nIteration: 9464, learning rate: 0.00607, Loss: 0.1229, Accuracy:0.953\nIteration: 9465, learning rate: 0.00607, Loss: 0.1757, Accuracy:0.922\nIteration: 9466, learning rate: 0.00607, Loss: 0.1306, Accuracy:0.938\nIteration: 9467, learning rate: 0.00607, Loss: 0.1959, Accuracy:0.914\nIteration: 9468, learning rate: 0.00607, Loss: 0.1910, Accuracy:0.922\nIteration: 9469, learning rate: 0.00607, Loss: 0.1619, Accuracy:0.938\nIteration: 9470, learning rate: 0.00607, Loss: 0.2446, Accuracy:0.883\nIteration: 9471, learning rate: 0.00607, Loss: 0.2519, Accuracy:0.898\nIteration: 9472, learning rate: 0.00607, Loss: 0.1776, Accuracy:0.906\nIteration: 9473, learning rate: 0.00607, Loss: 0.1492, Accuracy:0.945\nIteration: 9474, learning rate: 0.00607, Loss: 0.1491, Accuracy:0.953\nIteration: 9475, learning rate: 0.00607, Loss: 0.1728, Accuracy:0.938\nIteration: 9476, learning rate: 0.00607, Loss: 0.1541, Accuracy:0.945\nIteration: 9477, learning rate: 0.00607, Loss: 0.2615, Accuracy:0.883\nIteration: 9478, learning rate: 0.00607, Loss: 0.1769, Accuracy:0.914\nIteration: 9479, learning rate: 0.00607, Loss: 0.1409, Accuracy:0.945\nIteration: 9480, learning rate: 0.00606, Loss: 0.1480, Accuracy:0.945\nIteration: 9481, learning rate: 0.00606, Loss: 0.2274, Accuracy:0.906\nIteration: 9482, learning rate: 0.00606, Loss: 0.1563, Accuracy:0.953\nIteration: 9483, learning rate: 0.00606, Loss: 0.1950, Accuracy:0.922\nIteration: 9484, learning rate: 0.00606, Loss: 0.1361, Accuracy:0.953\nIteration: 9485, learning rate: 0.00606, Loss: 0.1332, Accuracy:0.961\nIteration: 9486, learning rate: 0.00606, Loss: 0.1096, Accuracy:0.978\nEpoch: 306, Loss: 0.1753, Accuracy:0.929, Val Loss: 0.3255, Val Accuracy: 0.864\nIteration: 9487, learning rate: 0.00606, Loss: 0.2209, Accuracy:0.906\nIteration: 9488, learning rate: 0.00606, Loss: 0.1640, Accuracy:0.922\nIteration: 9489, learning rate: 0.00606, Loss: 0.1650, Accuracy:0.938\nIteration: 9490, learning rate: 0.00606, Loss: 0.2120, Accuracy:0.922\nIteration: 9491, learning rate: 0.00606, Loss: 0.2040, Accuracy:0.906\nIteration: 9492, learning rate: 0.00606, Loss: 0.1960, Accuracy:0.922\nIteration: 9493, learning rate: 0.00606, Loss: 0.1562, Accuracy:0.945\nIteration: 9494, learning rate: 0.00606, Loss: 0.1640, Accuracy:0.945\nIteration: 9495, learning rate: 0.00606, Loss: 0.1359, Accuracy:0.961\nIteration: 9496, learning rate: 0.00606, Loss: 0.1170, Accuracy:0.945\nIteration: 9497, learning rate: 0.00606, Loss: 0.1948, Accuracy:0.906\nIteration: 9498, learning rate: 0.00606, Loss: 0.1114, Accuracy:0.969\nIteration: 9499, learning rate: 0.00606, Loss: 0.1962, Accuracy:0.922\nIteration: 9500, learning rate: 0.00606, Loss: 0.2619, Accuracy:0.891\nIteration: 9501, learning rate: 0.00606, Loss: 0.1563, Accuracy:0.930\nIteration: 9502, learning rate: 0.00606, Loss: 0.1346, Accuracy:0.961\nIteration: 9503, learning rate: 0.00606, Loss: 0.1196, Accuracy:0.953\nIteration: 9504, learning rate: 0.00606, Loss: 0.1353, Accuracy:0.953\nIteration: 9505, learning rate: 0.00606, Loss: 0.1554, Accuracy:0.945\nIteration: 9506, learning rate: 0.00606, Loss: 0.1634, Accuracy:0.938\nIteration: 9507, learning rate: 0.00606, Loss: 0.1962, Accuracy:0.922\nIteration: 9508, learning rate: 0.00606, Loss: 0.1632, Accuracy:0.938\nIteration: 9509, learning rate: 0.00606, Loss: 0.1340, Accuracy:0.953\nIteration: 9510, learning rate: 0.00606, Loss: 0.0933, Accuracy:0.977\nIteration: 9511, learning rate: 0.00606, Loss: 0.1012, Accuracy:0.969\nIteration: 9512, learning rate: 0.00606, Loss: 0.1548, Accuracy:0.938\nIteration: 9513, learning rate: 0.00606, Loss: 0.1204, Accuracy:0.961\nIteration: 9514, learning rate: 0.00606, Loss: 0.1147, Accuracy:0.969\nIteration: 9515, learning rate: 0.00606, Loss: 0.2072, Accuracy:0.898\nIteration: 9516, learning rate: 0.00606, Loss: 0.2254, Accuracy:0.891\nIteration: 9517, learning rate: 0.00606, Loss: 0.1437, Accuracy:0.946\nEpoch: 307, Loss: 0.1619, Accuracy:0.937, Val Loss: 0.2972, Val Accuracy: 0.875\nIteration: 9518, learning rate: 0.00606, Loss: 0.1973, Accuracy:0.906\nIteration: 9519, learning rate: 0.00606, Loss: 0.2158, Accuracy:0.906\nIteration: 9520, learning rate: 0.00606, Loss: 0.1555, Accuracy:0.922\nIteration: 9521, learning rate: 0.00606, Loss: 0.2083, Accuracy:0.914\nIteration: 9522, learning rate: 0.00606, Loss: 0.1441, Accuracy:0.961\nIteration: 9523, learning rate: 0.00605, Loss: 0.2102, Accuracy:0.883\nIteration: 9524, learning rate: 0.00605, Loss: 0.1945, Accuracy:0.922\nIteration: 9525, learning rate: 0.00605, Loss: 0.1972, Accuracy:0.914\nIteration: 9526, learning rate: 0.00605, Loss: 0.1609, Accuracy:0.945\nIteration: 9527, learning rate: 0.00605, Loss: 0.1845, Accuracy:0.906\nIteration: 9528, learning rate: 0.00605, Loss: 0.1677, Accuracy:0.938\nIteration: 9529, learning rate: 0.00605, Loss: 0.2273, Accuracy:0.906\nIteration: 9530, learning rate: 0.00605, Loss: 0.1717, Accuracy:0.953\nIteration: 9531, learning rate: 0.00605, Loss: 0.1145, Accuracy:0.961\nIteration: 9532, learning rate: 0.00605, Loss: 0.1920, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9533, learning rate: 0.00605, Loss: 0.1669, Accuracy:0.945\nIteration: 9534, learning rate: 0.00605, Loss: 0.1986, Accuracy:0.914\nIteration: 9535, learning rate: 0.00605, Loss: 0.2104, Accuracy:0.898\nIteration: 9536, learning rate: 0.00605, Loss: 0.2158, Accuracy:0.914\nIteration: 9537, learning rate: 0.00605, Loss: 0.2610, Accuracy:0.898\nIteration: 9538, learning rate: 0.00605, Loss: 0.2118, Accuracy:0.914\nIteration: 9539, learning rate: 0.00605, Loss: 0.2108, Accuracy:0.930\nIteration: 9540, learning rate: 0.00605, Loss: 0.1988, Accuracy:0.906\nIteration: 9541, learning rate: 0.00605, Loss: 0.1413, Accuracy:0.961\nIteration: 9542, learning rate: 0.00605, Loss: 0.1650, Accuracy:0.953\nIteration: 9543, learning rate: 0.00605, Loss: 0.1486, Accuracy:0.922\nIteration: 9544, learning rate: 0.00605, Loss: 0.1150, Accuracy:0.961\nIteration: 9545, learning rate: 0.00605, Loss: 0.2272, Accuracy:0.883\nIteration: 9546, learning rate: 0.00605, Loss: 0.1677, Accuracy:0.922\nIteration: 9547, learning rate: 0.00605, Loss: 0.1852, Accuracy:0.922\nIteration: 9548, learning rate: 0.00605, Loss: 0.1311, Accuracy:0.968\nEpoch: 308, Loss: 0.1838, Accuracy:0.925, Val Loss: 0.3623, Val Accuracy: 0.846\nIteration: 9549, learning rate: 0.00605, Loss: 0.2275, Accuracy:0.914\nIteration: 9550, learning rate: 0.00605, Loss: 0.1838, Accuracy:0.938\nIteration: 9551, learning rate: 0.00605, Loss: 0.1517, Accuracy:0.945\nIteration: 9552, learning rate: 0.00605, Loss: 0.2539, Accuracy:0.867\nIteration: 9553, learning rate: 0.00605, Loss: 0.1367, Accuracy:0.953\nIteration: 9554, learning rate: 0.00605, Loss: 0.1854, Accuracy:0.914\nIteration: 9555, learning rate: 0.00605, Loss: 0.1638, Accuracy:0.914\nIteration: 9556, learning rate: 0.00605, Loss: 0.1769, Accuracy:0.938\nIteration: 9557, learning rate: 0.00605, Loss: 0.1494, Accuracy:0.922\nIteration: 9558, learning rate: 0.00605, Loss: 0.1449, Accuracy:0.953\nIteration: 9559, learning rate: 0.00605, Loss: 0.2115, Accuracy:0.922\nIteration: 9560, learning rate: 0.00605, Loss: 0.2080, Accuracy:0.898\nIteration: 9561, learning rate: 0.00605, Loss: 0.1449, Accuracy:0.938\nIteration: 9562, learning rate: 0.00605, Loss: 0.1871, Accuracy:0.914\nIteration: 9563, learning rate: 0.00605, Loss: 0.1586, Accuracy:0.938\nIteration: 9564, learning rate: 0.00605, Loss: 0.2937, Accuracy:0.875\nIteration: 9565, learning rate: 0.00605, Loss: 0.1905, Accuracy:0.938\nIteration: 9566, learning rate: 0.00604, Loss: 0.1390, Accuracy:0.945\nIteration: 9567, learning rate: 0.00604, Loss: 0.2219, Accuracy:0.922\nIteration: 9568, learning rate: 0.00604, Loss: 0.2171, Accuracy:0.930\nIteration: 9569, learning rate: 0.00604, Loss: 0.2164, Accuracy:0.906\nIteration: 9570, learning rate: 0.00604, Loss: 0.1611, Accuracy:0.938\nIteration: 9571, learning rate: 0.00604, Loss: 0.1942, Accuracy:0.930\nIteration: 9572, learning rate: 0.00604, Loss: 0.1983, Accuracy:0.930\nIteration: 9573, learning rate: 0.00604, Loss: 0.2340, Accuracy:0.906\nIteration: 9574, learning rate: 0.00604, Loss: 0.1714, Accuracy:0.953\nIteration: 9575, learning rate: 0.00604, Loss: 0.1663, Accuracy:0.914\nIteration: 9576, learning rate: 0.00604, Loss: 0.2235, Accuracy:0.891\nIteration: 9577, learning rate: 0.00604, Loss: 0.1796, Accuracy:0.930\nIteration: 9578, learning rate: 0.00604, Loss: 0.1927, Accuracy:0.930\nIteration: 9579, learning rate: 0.00604, Loss: 0.2299, Accuracy:0.914\nEpoch: 309, Loss: 0.1908, Accuracy:0.923, Val Loss: 0.3374, Val Accuracy: 0.870\nIteration: 9580, learning rate: 0.00604, Loss: 0.1552, Accuracy:0.930\nIteration: 9581, learning rate: 0.00604, Loss: 0.1968, Accuracy:0.930\nIteration: 9582, learning rate: 0.00604, Loss: 0.1645, Accuracy:0.906\nIteration: 9583, learning rate: 0.00604, Loss: 0.1392, Accuracy:0.945\nIteration: 9584, learning rate: 0.00604, Loss: 0.1565, Accuracy:0.938\nIteration: 9585, learning rate: 0.00604, Loss: 0.1801, Accuracy:0.930\nIteration: 9586, learning rate: 0.00604, Loss: 0.2309, Accuracy:0.891\nIteration: 9587, learning rate: 0.00604, Loss: 0.2009, Accuracy:0.945\nIteration: 9588, learning rate: 0.00604, Loss: 0.1999, Accuracy:0.930\nIteration: 9589, learning rate: 0.00604, Loss: 0.2552, Accuracy:0.891\nIteration: 9590, learning rate: 0.00604, Loss: 0.2110, Accuracy:0.914\nIteration: 9591, learning rate: 0.00604, Loss: 0.2352, Accuracy:0.883\nIteration: 9592, learning rate: 0.00604, Loss: 0.2204, Accuracy:0.930\nIteration: 9593, learning rate: 0.00604, Loss: 0.1896, Accuracy:0.945\nIteration: 9594, learning rate: 0.00604, Loss: 0.2282, Accuracy:0.914\nIteration: 9595, learning rate: 0.00604, Loss: 0.2295, Accuracy:0.883\nIteration: 9596, learning rate: 0.00604, Loss: 0.2068, Accuracy:0.898\nIteration: 9597, learning rate: 0.00604, Loss: 0.1448, Accuracy:0.961\nIteration: 9598, learning rate: 0.00604, Loss: 0.2353, Accuracy:0.906\nIteration: 9599, learning rate: 0.00604, Loss: 0.1662, Accuracy:0.938\nIteration: 9600, learning rate: 0.00604, Loss: 0.1908, Accuracy:0.938\nIteration: 9601, learning rate: 0.00604, Loss: 0.1575, Accuracy:0.930\nIteration: 9602, learning rate: 0.00604, Loss: 0.1408, Accuracy:0.953\nIteration: 9603, learning rate: 0.00604, Loss: 0.2193, Accuracy:0.914\nIteration: 9604, learning rate: 0.00604, Loss: 0.1928, Accuracy:0.906\nIteration: 9605, learning rate: 0.00604, Loss: 0.2104, Accuracy:0.922\nIteration: 9606, learning rate: 0.00604, Loss: 0.2438, Accuracy:0.914\nIteration: 9607, learning rate: 0.00604, Loss: 0.1376, Accuracy:0.961\nIteration: 9608, learning rate: 0.00604, Loss: 0.2567, Accuracy:0.906\nIteration: 9609, learning rate: 0.00603, Loss: 0.1975, Accuracy:0.930\nIteration: 9610, learning rate: 0.00603, Loss: 0.1911, Accuracy:0.914\nEpoch: 310, Loss: 0.1963, Accuracy:0.922, Val Loss: 0.3163, Val Accuracy: 0.857\nIteration: 9611, learning rate: 0.00603, Loss: 0.1216, Accuracy:0.969\nIteration: 9612, learning rate: 0.00603, Loss: 0.1248, Accuracy:0.953\nIteration: 9613, learning rate: 0.00603, Loss: 0.1978, Accuracy:0.930\nIteration: 9614, learning rate: 0.00603, Loss: 0.1858, Accuracy:0.914\nIteration: 9615, learning rate: 0.00603, Loss: 0.1962, Accuracy:0.914\nIteration: 9616, learning rate: 0.00603, Loss: 0.2310, Accuracy:0.914\nIteration: 9617, learning rate: 0.00603, Loss: 0.2450, Accuracy:0.898\nIteration: 9618, learning rate: 0.00603, Loss: 0.1984, Accuracy:0.922\nIteration: 9619, learning rate: 0.00603, Loss: 0.1636, Accuracy:0.938\nIteration: 9620, learning rate: 0.00603, Loss: 0.2131, Accuracy:0.914\nIteration: 9621, learning rate: 0.00603, Loss: 0.1419, Accuracy:0.930\nIteration: 9622, learning rate: 0.00603, Loss: 0.2360, Accuracy:0.914\nIteration: 9623, learning rate: 0.00603, Loss: 0.1726, Accuracy:0.930\nIteration: 9624, learning rate: 0.00603, Loss: 0.2276, Accuracy:0.906\nIteration: 9625, learning rate: 0.00603, Loss: 0.1761, Accuracy:0.914\nIteration: 9626, learning rate: 0.00603, Loss: 0.2047, Accuracy:0.945\nIteration: 9627, learning rate: 0.00603, Loss: 0.1695, Accuracy:0.922\nIteration: 9628, learning rate: 0.00603, Loss: 0.1905, Accuracy:0.930\nIteration: 9629, learning rate: 0.00603, Loss: 0.1842, Accuracy:0.891\nIteration: 9630, learning rate: 0.00603, Loss: 0.2178, Accuracy:0.883\nIteration: 9631, learning rate: 0.00603, Loss: 0.1227, Accuracy:0.953\nIteration: 9632, learning rate: 0.00603, Loss: 0.1956, Accuracy:0.938\nIteration: 9633, learning rate: 0.00603, Loss: 0.2113, Accuracy:0.891\nIteration: 9634, learning rate: 0.00603, Loss: 0.1637, Accuracy:0.945\nIteration: 9635, learning rate: 0.00603, Loss: 0.2137, Accuracy:0.906\nIteration: 9636, learning rate: 0.00603, Loss: 0.1963, Accuracy:0.906\nIteration: 9637, learning rate: 0.00603, Loss: 0.1684, Accuracy:0.930\nIteration: 9638, learning rate: 0.00603, Loss: 0.1478, Accuracy:0.961\nIteration: 9639, learning rate: 0.00603, Loss: 0.1846, Accuracy:0.930\nIteration: 9640, learning rate: 0.00603, Loss: 0.2225, Accuracy:0.906\nIteration: 9641, learning rate: 0.00603, Loss: 0.2355, Accuracy:0.914\nEpoch: 311, Loss: 0.1891, Accuracy:0.923, Val Loss: 0.3096, Val Accuracy: 0.875\nIteration: 9642, learning rate: 0.00603, Loss: 0.2220, Accuracy:0.914\nIteration: 9643, learning rate: 0.00603, Loss: 0.1210, Accuracy:0.953\nIteration: 9644, learning rate: 0.00603, Loss: 0.1532, Accuracy:0.930\nIteration: 9645, learning rate: 0.00603, Loss: 0.2332, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9646, learning rate: 0.00603, Loss: 0.2007, Accuracy:0.945\nIteration: 9647, learning rate: 0.00603, Loss: 0.2070, Accuracy:0.914\nIteration: 9648, learning rate: 0.00603, Loss: 0.1695, Accuracy:0.922\nIteration: 9649, learning rate: 0.00603, Loss: 0.1834, Accuracy:0.930\nIteration: 9650, learning rate: 0.00603, Loss: 0.1553, Accuracy:0.945\nIteration: 9651, learning rate: 0.00603, Loss: 0.2445, Accuracy:0.898\nIteration: 9652, learning rate: 0.00603, Loss: 0.1664, Accuracy:0.953\nIteration: 9653, learning rate: 0.00602, Loss: 0.1252, Accuracy:0.938\nIteration: 9654, learning rate: 0.00602, Loss: 0.1715, Accuracy:0.898\nIteration: 9655, learning rate: 0.00602, Loss: 0.2294, Accuracy:0.898\nIteration: 9656, learning rate: 0.00602, Loss: 0.1983, Accuracy:0.906\nIteration: 9657, learning rate: 0.00602, Loss: 0.1504, Accuracy:0.953\nIteration: 9658, learning rate: 0.00602, Loss: 0.1239, Accuracy:0.938\nIteration: 9659, learning rate: 0.00602, Loss: 0.1970, Accuracy:0.891\nIteration: 9660, learning rate: 0.00602, Loss: 0.1912, Accuracy:0.930\nIteration: 9661, learning rate: 0.00602, Loss: 0.2085, Accuracy:0.891\nIteration: 9662, learning rate: 0.00602, Loss: 0.1799, Accuracy:0.945\nIteration: 9663, learning rate: 0.00602, Loss: 0.1488, Accuracy:0.938\nIteration: 9664, learning rate: 0.00602, Loss: 0.1813, Accuracy:0.938\nIteration: 9665, learning rate: 0.00602, Loss: 0.1530, Accuracy:0.922\nIteration: 9666, learning rate: 0.00602, Loss: 0.1828, Accuracy:0.953\nIteration: 9667, learning rate: 0.00602, Loss: 0.1864, Accuracy:0.914\nIteration: 9668, learning rate: 0.00602, Loss: 0.1916, Accuracy:0.930\nIteration: 9669, learning rate: 0.00602, Loss: 0.2341, Accuracy:0.898\nIteration: 9670, learning rate: 0.00602, Loss: 0.1860, Accuracy:0.922\nIteration: 9671, learning rate: 0.00602, Loss: 0.1655, Accuracy:0.914\nIteration: 9672, learning rate: 0.00602, Loss: 0.1355, Accuracy:0.935\nEpoch: 312, Loss: 0.1805, Accuracy:0.925, Val Loss: 0.3044, Val Accuracy: 0.864\nIteration: 9673, learning rate: 0.00602, Loss: 0.2389, Accuracy:0.906\nIteration: 9674, learning rate: 0.00602, Loss: 0.2298, Accuracy:0.914\nIteration: 9675, learning rate: 0.00602, Loss: 0.1772, Accuracy:0.930\nIteration: 9676, learning rate: 0.00602, Loss: 0.2136, Accuracy:0.914\nIteration: 9677, learning rate: 0.00602, Loss: 0.2141, Accuracy:0.906\nIteration: 9678, learning rate: 0.00602, Loss: 0.1600, Accuracy:0.930\nIteration: 9679, learning rate: 0.00602, Loss: 0.1621, Accuracy:0.961\nIteration: 9680, learning rate: 0.00602, Loss: 0.2007, Accuracy:0.898\nIteration: 9681, learning rate: 0.00602, Loss: 0.2521, Accuracy:0.914\nIteration: 9682, learning rate: 0.00602, Loss: 0.1525, Accuracy:0.945\nIteration: 9683, learning rate: 0.00602, Loss: 0.1327, Accuracy:0.953\nIteration: 9684, learning rate: 0.00602, Loss: 0.1631, Accuracy:0.930\nIteration: 9685, learning rate: 0.00602, Loss: 0.1867, Accuracy:0.930\nIteration: 9686, learning rate: 0.00602, Loss: 0.1556, Accuracy:0.945\nIteration: 9687, learning rate: 0.00602, Loss: 0.2362, Accuracy:0.883\nIteration: 9688, learning rate: 0.00602, Loss: 0.1491, Accuracy:0.938\nIteration: 9689, learning rate: 0.00602, Loss: 0.1215, Accuracy:0.961\nIteration: 9690, learning rate: 0.00602, Loss: 0.0923, Accuracy:0.945\nIteration: 9691, learning rate: 0.00602, Loss: 0.1857, Accuracy:0.930\nIteration: 9692, learning rate: 0.00602, Loss: 0.1823, Accuracy:0.922\nIteration: 9693, learning rate: 0.00602, Loss: 0.1603, Accuracy:0.945\nIteration: 9694, learning rate: 0.00602, Loss: 0.1188, Accuracy:0.945\nIteration: 9695, learning rate: 0.00602, Loss: 0.1888, Accuracy:0.945\nIteration: 9696, learning rate: 0.00601, Loss: 0.2572, Accuracy:0.906\nIteration: 9697, learning rate: 0.00601, Loss: 0.1409, Accuracy:0.938\nIteration: 9698, learning rate: 0.00601, Loss: 0.0863, Accuracy:0.969\nIteration: 9699, learning rate: 0.00601, Loss: 0.1883, Accuracy:0.914\nIteration: 9700, learning rate: 0.00601, Loss: 0.1769, Accuracy:0.922\nIteration: 9701, learning rate: 0.00601, Loss: 0.0819, Accuracy:0.984\nIteration: 9702, learning rate: 0.00601, Loss: 0.1229, Accuracy:0.945\nIteration: 9703, learning rate: 0.00601, Loss: 0.1179, Accuracy:0.946\nEpoch: 313, Loss: 0.1692, Accuracy:0.933, Val Loss: 0.3377, Val Accuracy: 0.844\nIteration: 9704, learning rate: 0.00601, Loss: 0.1760, Accuracy:0.938\nIteration: 9705, learning rate: 0.00601, Loss: 0.1487, Accuracy:0.922\nIteration: 9706, learning rate: 0.00601, Loss: 0.2439, Accuracy:0.891\nIteration: 9707, learning rate: 0.00601, Loss: 0.2802, Accuracy:0.859\nIteration: 9708, learning rate: 0.00601, Loss: 0.1912, Accuracy:0.922\nIteration: 9709, learning rate: 0.00601, Loss: 0.1652, Accuracy:0.930\nIteration: 9710, learning rate: 0.00601, Loss: 0.1735, Accuracy:0.922\nIteration: 9711, learning rate: 0.00601, Loss: 0.1046, Accuracy:0.977\nIteration: 9712, learning rate: 0.00601, Loss: 0.1858, Accuracy:0.930\nIteration: 9713, learning rate: 0.00601, Loss: 0.1487, Accuracy:0.938\nIteration: 9714, learning rate: 0.00601, Loss: 0.1611, Accuracy:0.945\nIteration: 9715, learning rate: 0.00601, Loss: 0.2298, Accuracy:0.898\nIteration: 9716, learning rate: 0.00601, Loss: 0.2478, Accuracy:0.922\nIteration: 9717, learning rate: 0.00601, Loss: 0.2004, Accuracy:0.938\nIteration: 9718, learning rate: 0.00601, Loss: 0.1368, Accuracy:0.938\nIteration: 9719, learning rate: 0.00601, Loss: 0.0747, Accuracy:0.992\nIteration: 9720, learning rate: 0.00601, Loss: 0.2285, Accuracy:0.875\nIteration: 9721, learning rate: 0.00601, Loss: 0.1425, Accuracy:0.930\nIteration: 9722, learning rate: 0.00601, Loss: 0.1614, Accuracy:0.930\nIteration: 9723, learning rate: 0.00601, Loss: 0.1541, Accuracy:0.922\nIteration: 9724, learning rate: 0.00601, Loss: 0.1546, Accuracy:0.930\nIteration: 9725, learning rate: 0.00601, Loss: 0.1408, Accuracy:0.945\nIteration: 9726, learning rate: 0.00601, Loss: 0.1769, Accuracy:0.938\nIteration: 9727, learning rate: 0.00601, Loss: 0.2092, Accuracy:0.922\nIteration: 9728, learning rate: 0.00601, Loss: 0.1718, Accuracy:0.938\nIteration: 9729, learning rate: 0.00601, Loss: 0.1532, Accuracy:0.930\nIteration: 9730, learning rate: 0.00601, Loss: 0.0783, Accuracy:0.984\nIteration: 9731, learning rate: 0.00601, Loss: 0.1785, Accuracy:0.938\nIteration: 9732, learning rate: 0.00601, Loss: 0.1014, Accuracy:0.969\nIteration: 9733, learning rate: 0.00601, Loss: 0.1556, Accuracy:0.938\nIteration: 9734, learning rate: 0.00601, Loss: 0.2020, Accuracy:0.903\nEpoch: 314, Loss: 0.1702, Accuracy:0.931, Val Loss: 0.2588, Val Accuracy: 0.876\nIteration: 9735, learning rate: 0.00601, Loss: 0.1871, Accuracy:0.922\nIteration: 9736, learning rate: 0.00601, Loss: 0.1839, Accuracy:0.930\nIteration: 9737, learning rate: 0.00601, Loss: 0.1632, Accuracy:0.930\nIteration: 9738, learning rate: 0.00601, Loss: 0.0943, Accuracy:0.969\nIteration: 9739, learning rate: 0.00601, Loss: 0.1917, Accuracy:0.922\nIteration: 9740, learning rate: 0.00600, Loss: 0.1414, Accuracy:0.969\nIteration: 9741, learning rate: 0.00600, Loss: 0.2025, Accuracy:0.930\nIteration: 9742, learning rate: 0.00600, Loss: 0.1241, Accuracy:0.953\nIteration: 9743, learning rate: 0.00600, Loss: 0.1765, Accuracy:0.930\nIteration: 9744, learning rate: 0.00600, Loss: 0.1693, Accuracy:0.930\nIteration: 9745, learning rate: 0.00600, Loss: 0.2310, Accuracy:0.906\nIteration: 9746, learning rate: 0.00600, Loss: 0.1327, Accuracy:0.945\nIteration: 9747, learning rate: 0.00600, Loss: 0.1552, Accuracy:0.938\nIteration: 9748, learning rate: 0.00600, Loss: 0.2079, Accuracy:0.938\nIteration: 9749, learning rate: 0.00600, Loss: 0.1272, Accuracy:0.930\nIteration: 9750, learning rate: 0.00600, Loss: 0.2141, Accuracy:0.906\nIteration: 9751, learning rate: 0.00600, Loss: 0.1761, Accuracy:0.930\nIteration: 9752, learning rate: 0.00600, Loss: 0.1110, Accuracy:0.961\nIteration: 9753, learning rate: 0.00600, Loss: 0.1628, Accuracy:0.938\nIteration: 9754, learning rate: 0.00600, Loss: 0.1606, Accuracy:0.930\nIteration: 9755, learning rate: 0.00600, Loss: 0.1835, Accuracy:0.930\nIteration: 9756, learning rate: 0.00600, Loss: 0.1454, Accuracy:0.961\nIteration: 9757, learning rate: 0.00600, Loss: 0.1604, Accuracy:0.938\nIteration: 9758, learning rate: 0.00600, Loss: 0.2166, Accuracy:0.930\nIteration: 9759, learning rate: 0.00600, Loss: 0.1556, Accuracy:0.938\nIteration: 9760, learning rate: 0.00600, Loss: 0.1448, Accuracy:0.938\nIteration: 9761, learning rate: 0.00600, Loss: 0.1679, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9762, learning rate: 0.00600, Loss: 0.2281, Accuracy:0.922\nIteration: 9763, learning rate: 0.00600, Loss: 0.1562, Accuracy:0.945\nIteration: 9764, learning rate: 0.00600, Loss: 0.1629, Accuracy:0.930\nIteration: 9765, learning rate: 0.00600, Loss: 0.1259, Accuracy:0.957\nEpoch: 315, Loss: 0.1664, Accuracy:0.937, Val Loss: 0.2937, Val Accuracy: 0.886\nIteration: 9766, learning rate: 0.00600, Loss: 0.2088, Accuracy:0.898\nIteration: 9767, learning rate: 0.00600, Loss: 0.1801, Accuracy:0.914\nIteration: 9768, learning rate: 0.00600, Loss: 0.1699, Accuracy:0.906\nIteration: 9769, learning rate: 0.00600, Loss: 0.1556, Accuracy:0.930\nIteration: 9770, learning rate: 0.00600, Loss: 0.2230, Accuracy:0.898\nIteration: 9771, learning rate: 0.00600, Loss: 0.1549, Accuracy:0.938\nIteration: 9772, learning rate: 0.00600, Loss: 0.1617, Accuracy:0.953\nIteration: 9773, learning rate: 0.00600, Loss: 0.1593, Accuracy:0.945\nIteration: 9774, learning rate: 0.00600, Loss: 0.1485, Accuracy:0.945\nIteration: 9775, learning rate: 0.00600, Loss: 0.2080, Accuracy:0.906\nIteration: 9776, learning rate: 0.00600, Loss: 0.1572, Accuracy:0.961\nIteration: 9777, learning rate: 0.00600, Loss: 0.1259, Accuracy:0.945\nIteration: 9778, learning rate: 0.00600, Loss: 0.1699, Accuracy:0.945\nIteration: 9779, learning rate: 0.00600, Loss: 0.1067, Accuracy:0.953\nIteration: 9780, learning rate: 0.00600, Loss: 0.2218, Accuracy:0.914\nIteration: 9781, learning rate: 0.00600, Loss: 0.1325, Accuracy:0.953\nIteration: 9782, learning rate: 0.00600, Loss: 0.1217, Accuracy:0.953\nIteration: 9783, learning rate: 0.00600, Loss: 0.1926, Accuracy:0.922\nIteration: 9784, learning rate: 0.00599, Loss: 0.1222, Accuracy:0.961\nIteration: 9785, learning rate: 0.00599, Loss: 0.1557, Accuracy:0.945\nIteration: 9786, learning rate: 0.00599, Loss: 0.2299, Accuracy:0.883\nIteration: 9787, learning rate: 0.00599, Loss: 0.1637, Accuracy:0.953\nIteration: 9788, learning rate: 0.00599, Loss: 0.2622, Accuracy:0.922\nIteration: 9789, learning rate: 0.00599, Loss: 0.1329, Accuracy:0.953\nIteration: 9790, learning rate: 0.00599, Loss: 0.1662, Accuracy:0.930\nIteration: 9791, learning rate: 0.00599, Loss: 0.1750, Accuracy:0.938\nIteration: 9792, learning rate: 0.00599, Loss: 0.1627, Accuracy:0.914\nIteration: 9793, learning rate: 0.00599, Loss: 0.1743, Accuracy:0.938\nIteration: 9794, learning rate: 0.00599, Loss: 0.1306, Accuracy:0.938\nIteration: 9795, learning rate: 0.00599, Loss: 0.1791, Accuracy:0.930\nIteration: 9796, learning rate: 0.00599, Loss: 0.2536, Accuracy:0.914\nEpoch: 316, Loss: 0.1712, Accuracy:0.932, Val Loss: 0.3190, Val Accuracy: 0.876\nIteration: 9797, learning rate: 0.00599, Loss: 0.2121, Accuracy:0.930\nIteration: 9798, learning rate: 0.00599, Loss: 0.1862, Accuracy:0.930\nIteration: 9799, learning rate: 0.00599, Loss: 0.2011, Accuracy:0.914\nIteration: 9800, learning rate: 0.00599, Loss: 0.2000, Accuracy:0.938\nIteration: 9801, learning rate: 0.00599, Loss: 0.2014, Accuracy:0.914\nIteration: 9802, learning rate: 0.00599, Loss: 0.2659, Accuracy:0.891\nIteration: 9803, learning rate: 0.00599, Loss: 0.1536, Accuracy:0.945\nIteration: 9804, learning rate: 0.00599, Loss: 0.1330, Accuracy:0.945\nIteration: 9805, learning rate: 0.00599, Loss: 0.1738, Accuracy:0.930\nIteration: 9806, learning rate: 0.00599, Loss: 0.2066, Accuracy:0.906\nIteration: 9807, learning rate: 0.00599, Loss: 0.2268, Accuracy:0.906\nIteration: 9808, learning rate: 0.00599, Loss: 0.1496, Accuracy:0.953\nIteration: 9809, learning rate: 0.00599, Loss: 0.1742, Accuracy:0.938\nIteration: 9810, learning rate: 0.00599, Loss: 0.2600, Accuracy:0.898\nIteration: 9811, learning rate: 0.00599, Loss: 0.1661, Accuracy:0.945\nIteration: 9812, learning rate: 0.00599, Loss: 0.1772, Accuracy:0.922\nIteration: 9813, learning rate: 0.00599, Loss: 0.2249, Accuracy:0.898\nIteration: 9814, learning rate: 0.00599, Loss: 0.2191, Accuracy:0.891\nIteration: 9815, learning rate: 0.00599, Loss: 0.1744, Accuracy:0.938\nIteration: 9816, learning rate: 0.00599, Loss: 0.1754, Accuracy:0.953\nIteration: 9817, learning rate: 0.00599, Loss: 0.1478, Accuracy:0.945\nIteration: 9818, learning rate: 0.00599, Loss: 0.1049, Accuracy:0.961\nIteration: 9819, learning rate: 0.00599, Loss: 0.1373, Accuracy:0.938\nIteration: 9820, learning rate: 0.00599, Loss: 0.1539, Accuracy:0.945\nIteration: 9821, learning rate: 0.00599, Loss: 0.2079, Accuracy:0.922\nIteration: 9822, learning rate: 0.00599, Loss: 0.2392, Accuracy:0.898\nIteration: 9823, learning rate: 0.00599, Loss: 0.1645, Accuracy:0.906\nIteration: 9824, learning rate: 0.00599, Loss: 0.1552, Accuracy:0.953\nIteration: 9825, learning rate: 0.00599, Loss: 0.1779, Accuracy:0.922\nIteration: 9826, learning rate: 0.00599, Loss: 0.2757, Accuracy:0.914\nIteration: 9827, learning rate: 0.00599, Loss: 0.1452, Accuracy:0.935\nEpoch: 317, Loss: 0.1868, Accuracy:0.927, Val Loss: 0.3113, Val Accuracy: 0.854\nIteration: 9828, learning rate: 0.00598, Loss: 0.1320, Accuracy:0.945\nIteration: 9829, learning rate: 0.00598, Loss: 0.2334, Accuracy:0.898\nIteration: 9830, learning rate: 0.00598, Loss: 0.1918, Accuracy:0.938\nIteration: 9831, learning rate: 0.00598, Loss: 0.1483, Accuracy:0.914\nIteration: 9832, learning rate: 0.00598, Loss: 0.2000, Accuracy:0.906\nIteration: 9833, learning rate: 0.00598, Loss: 0.1760, Accuracy:0.922\nIteration: 9834, learning rate: 0.00598, Loss: 0.1619, Accuracy:0.938\nIteration: 9835, learning rate: 0.00598, Loss: 0.2032, Accuracy:0.930\nIteration: 9836, learning rate: 0.00598, Loss: 0.1359, Accuracy:0.938\nIteration: 9837, learning rate: 0.00598, Loss: 0.1700, Accuracy:0.945\nIteration: 9838, learning rate: 0.00598, Loss: 0.1920, Accuracy:0.906\nIteration: 9839, learning rate: 0.00598, Loss: 0.1352, Accuracy:0.953\nIteration: 9840, learning rate: 0.00598, Loss: 0.2010, Accuracy:0.898\nIteration: 9841, learning rate: 0.00598, Loss: 0.1671, Accuracy:0.953\nIteration: 9842, learning rate: 0.00598, Loss: 0.1880, Accuracy:0.938\nIteration: 9843, learning rate: 0.00598, Loss: 0.1676, Accuracy:0.938\nIteration: 9844, learning rate: 0.00598, Loss: 0.1692, Accuracy:0.953\nIteration: 9845, learning rate: 0.00598, Loss: 0.1497, Accuracy:0.930\nIteration: 9846, learning rate: 0.00598, Loss: 0.1249, Accuracy:0.961\nIteration: 9847, learning rate: 0.00598, Loss: 0.1211, Accuracy:0.961\nIteration: 9848, learning rate: 0.00598, Loss: 0.1915, Accuracy:0.953\nIteration: 9849, learning rate: 0.00598, Loss: 0.1959, Accuracy:0.914\nIteration: 9850, learning rate: 0.00598, Loss: 0.2259, Accuracy:0.906\nIteration: 9851, learning rate: 0.00598, Loss: 0.1816, Accuracy:0.922\nIteration: 9852, learning rate: 0.00598, Loss: 0.1218, Accuracy:0.953\nIteration: 9853, learning rate: 0.00598, Loss: 0.1893, Accuracy:0.938\nIteration: 9854, learning rate: 0.00598, Loss: 0.2103, Accuracy:0.922\nIteration: 9855, learning rate: 0.00598, Loss: 0.1371, Accuracy:0.961\nIteration: 9856, learning rate: 0.00598, Loss: 0.2328, Accuracy:0.898\nIteration: 9857, learning rate: 0.00598, Loss: 0.2395, Accuracy:0.914\nIteration: 9858, learning rate: 0.00598, Loss: 0.1400, Accuracy:0.968\nEpoch: 318, Loss: 0.1753, Accuracy:0.933, Val Loss: 0.3052, Val Accuracy: 0.877\nIteration: 9859, learning rate: 0.00598, Loss: 0.1619, Accuracy:0.938\nIteration: 9860, learning rate: 0.00598, Loss: 0.2192, Accuracy:0.883\nIteration: 9861, learning rate: 0.00598, Loss: 0.1859, Accuracy:0.906\nIteration: 9862, learning rate: 0.00598, Loss: 0.1340, Accuracy:0.953\nIteration: 9863, learning rate: 0.00598, Loss: 0.1943, Accuracy:0.930\nIteration: 9864, learning rate: 0.00598, Loss: 0.1175, Accuracy:0.945\nIteration: 9865, learning rate: 0.00598, Loss: 0.1631, Accuracy:0.922\nIteration: 9866, learning rate: 0.00598, Loss: 0.1861, Accuracy:0.898\nIteration: 9867, learning rate: 0.00598, Loss: 0.1882, Accuracy:0.914\nIteration: 9868, learning rate: 0.00598, Loss: 0.1820, Accuracy:0.945\nIteration: 9869, learning rate: 0.00598, Loss: 0.1387, Accuracy:0.938\nIteration: 9870, learning rate: 0.00598, Loss: 0.1009, Accuracy:0.961\nIteration: 9871, learning rate: 0.00598, Loss: 0.1580, Accuracy:0.961\nIteration: 9872, learning rate: 0.00597, Loss: 0.1520, Accuracy:0.938\nIteration: 9873, learning rate: 0.00597, Loss: 0.1297, Accuracy:0.953\nIteration: 9874, learning rate: 0.00597, Loss: 0.1510, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9875, learning rate: 0.00597, Loss: 0.2573, Accuracy:0.898\nIteration: 9876, learning rate: 0.00597, Loss: 0.2000, Accuracy:0.898\nIteration: 9877, learning rate: 0.00597, Loss: 0.1625, Accuracy:0.938\nIteration: 9878, learning rate: 0.00597, Loss: 0.1614, Accuracy:0.930\nIteration: 9879, learning rate: 0.00597, Loss: 0.1899, Accuracy:0.945\nIteration: 9880, learning rate: 0.00597, Loss: 0.1434, Accuracy:0.945\nIteration: 9881, learning rate: 0.00597, Loss: 0.1713, Accuracy:0.914\nIteration: 9882, learning rate: 0.00597, Loss: 0.1972, Accuracy:0.914\nIteration: 9883, learning rate: 0.00597, Loss: 0.1451, Accuracy:0.945\nIteration: 9884, learning rate: 0.00597, Loss: 0.1715, Accuracy:0.922\nIteration: 9885, learning rate: 0.00597, Loss: 0.0898, Accuracy:0.969\nIteration: 9886, learning rate: 0.00597, Loss: 0.2070, Accuracy:0.914\nIteration: 9887, learning rate: 0.00597, Loss: 0.0930, Accuracy:0.977\nIteration: 9888, learning rate: 0.00597, Loss: 0.1773, Accuracy:0.930\nIteration: 9889, learning rate: 0.00597, Loss: 0.1401, Accuracy:0.957\nEpoch: 319, Loss: 0.1635, Accuracy:0.934, Val Loss: 0.2708, Val Accuracy: 0.898\nIteration: 9890, learning rate: 0.00597, Loss: 0.2010, Accuracy:0.930\nIteration: 9891, learning rate: 0.00597, Loss: 0.1706, Accuracy:0.922\nIteration: 9892, learning rate: 0.00597, Loss: 0.1311, Accuracy:0.953\nIteration: 9893, learning rate: 0.00597, Loss: 0.2116, Accuracy:0.914\nIteration: 9894, learning rate: 0.00597, Loss: 0.2051, Accuracy:0.930\nIteration: 9895, learning rate: 0.00597, Loss: 0.1269, Accuracy:0.953\nIteration: 9896, learning rate: 0.00597, Loss: 0.1648, Accuracy:0.922\nIteration: 9897, learning rate: 0.00597, Loss: 0.1147, Accuracy:0.945\nIteration: 9898, learning rate: 0.00597, Loss: 0.1233, Accuracy:0.961\nIteration: 9899, learning rate: 0.00597, Loss: 0.2068, Accuracy:0.938\nIteration: 9900, learning rate: 0.00597, Loss: 0.1722, Accuracy:0.914\nIteration: 9901, learning rate: 0.00597, Loss: 0.2370, Accuracy:0.914\nIteration: 9902, learning rate: 0.00597, Loss: 0.1784, Accuracy:0.930\nIteration: 9903, learning rate: 0.00597, Loss: 0.1832, Accuracy:0.906\nIteration: 9904, learning rate: 0.00597, Loss: 0.1468, Accuracy:0.922\nIteration: 9905, learning rate: 0.00597, Loss: 0.1323, Accuracy:0.945\nIteration: 9906, learning rate: 0.00597, Loss: 0.1609, Accuracy:0.938\nIteration: 9907, learning rate: 0.00597, Loss: 0.1344, Accuracy:0.938\nIteration: 9908, learning rate: 0.00597, Loss: 0.1735, Accuracy:0.945\nIteration: 9909, learning rate: 0.00597, Loss: 0.1264, Accuracy:0.953\nIteration: 9910, learning rate: 0.00597, Loss: 0.1393, Accuracy:0.953\nIteration: 9911, learning rate: 0.00597, Loss: 0.1654, Accuracy:0.945\nIteration: 9912, learning rate: 0.00597, Loss: 0.2284, Accuracy:0.914\nIteration: 9913, learning rate: 0.00597, Loss: 0.1710, Accuracy:0.930\nIteration: 9914, learning rate: 0.00597, Loss: 0.1955, Accuracy:0.914\nIteration: 9915, learning rate: 0.00597, Loss: 0.2322, Accuracy:0.914\nIteration: 9916, learning rate: 0.00597, Loss: 0.1046, Accuracy:0.961\nIteration: 9917, learning rate: 0.00596, Loss: 0.1672, Accuracy:0.953\nIteration: 9918, learning rate: 0.00596, Loss: 0.1620, Accuracy:0.938\nIteration: 9919, learning rate: 0.00596, Loss: 0.1609, Accuracy:0.938\nIteration: 9920, learning rate: 0.00596, Loss: 0.1364, Accuracy:0.957\nEpoch: 320, Loss: 0.1666, Accuracy:0.935, Val Loss: 0.2669, Val Accuracy: 0.898\nIteration: 9921, learning rate: 0.00596, Loss: 0.1575, Accuracy:0.938\nIteration: 9922, learning rate: 0.00596, Loss: 0.1915, Accuracy:0.922\nIteration: 9923, learning rate: 0.00596, Loss: 0.1276, Accuracy:0.953\nIteration: 9924, learning rate: 0.00596, Loss: 0.1539, Accuracy:0.945\nIteration: 9925, learning rate: 0.00596, Loss: 0.2444, Accuracy:0.930\nIteration: 9926, learning rate: 0.00596, Loss: 0.1157, Accuracy:0.969\nIteration: 9927, learning rate: 0.00596, Loss: 0.1016, Accuracy:0.961\nIteration: 9928, learning rate: 0.00596, Loss: 0.1698, Accuracy:0.922\nIteration: 9929, learning rate: 0.00596, Loss: 0.1830, Accuracy:0.945\nIteration: 9930, learning rate: 0.00596, Loss: 0.2801, Accuracy:0.930\nIteration: 9931, learning rate: 0.00596, Loss: 0.1885, Accuracy:0.930\nIteration: 9932, learning rate: 0.00596, Loss: 0.1672, Accuracy:0.930\nIteration: 9933, learning rate: 0.00596, Loss: 0.1501, Accuracy:0.945\nIteration: 9934, learning rate: 0.00596, Loss: 0.1261, Accuracy:0.953\nIteration: 9935, learning rate: 0.00596, Loss: 0.1536, Accuracy:0.945\nIteration: 9936, learning rate: 0.00596, Loss: 0.2179, Accuracy:0.938\nIteration: 9937, learning rate: 0.00596, Loss: 0.2234, Accuracy:0.922\nIteration: 9938, learning rate: 0.00596, Loss: 0.3084, Accuracy:0.883\nIteration: 9939, learning rate: 0.00596, Loss: 0.2076, Accuracy:0.906\nIteration: 9940, learning rate: 0.00596, Loss: 0.2291, Accuracy:0.914\nIteration: 9941, learning rate: 0.00596, Loss: 0.1902, Accuracy:0.938\nIteration: 9942, learning rate: 0.00596, Loss: 0.1528, Accuracy:0.961\nIteration: 9943, learning rate: 0.00596, Loss: 0.1782, Accuracy:0.930\nIteration: 9944, learning rate: 0.00596, Loss: 0.1410, Accuracy:0.938\nIteration: 9945, learning rate: 0.00596, Loss: 0.1825, Accuracy:0.930\nIteration: 9946, learning rate: 0.00596, Loss: 0.1226, Accuracy:0.938\nIteration: 9947, learning rate: 0.00596, Loss: 0.1956, Accuracy:0.930\nIteration: 9948, learning rate: 0.00596, Loss: 0.2361, Accuracy:0.891\nIteration: 9949, learning rate: 0.00596, Loss: 0.1739, Accuracy:0.930\nIteration: 9950, learning rate: 0.00596, Loss: 0.2123, Accuracy:0.914\nIteration: 9951, learning rate: 0.00596, Loss: 0.1708, Accuracy:0.914\nEpoch: 321, Loss: 0.1824, Accuracy:0.932, Val Loss: 0.2689, Val Accuracy: 0.878\nIteration: 9952, learning rate: 0.00596, Loss: 0.0972, Accuracy:0.969\nIteration: 9953, learning rate: 0.00596, Loss: 0.2150, Accuracy:0.906\nIteration: 9954, learning rate: 0.00596, Loss: 0.1420, Accuracy:0.945\nIteration: 9955, learning rate: 0.00596, Loss: 0.2639, Accuracy:0.867\nIteration: 9956, learning rate: 0.00596, Loss: 0.1919, Accuracy:0.938\nIteration: 9957, learning rate: 0.00596, Loss: 0.1805, Accuracy:0.930\nIteration: 9958, learning rate: 0.00596, Loss: 0.1630, Accuracy:0.945\nIteration: 9959, learning rate: 0.00596, Loss: 0.1443, Accuracy:0.953\nIteration: 9960, learning rate: 0.00596, Loss: 0.2146, Accuracy:0.906\nIteration: 9961, learning rate: 0.00595, Loss: 0.1528, Accuracy:0.930\nIteration: 9962, learning rate: 0.00595, Loss: 0.1512, Accuracy:0.961\nIteration: 9963, learning rate: 0.00595, Loss: 0.1634, Accuracy:0.938\nIteration: 9964, learning rate: 0.00595, Loss: 0.1239, Accuracy:0.953\nIteration: 9965, learning rate: 0.00595, Loss: 0.0936, Accuracy:0.953\nIteration: 9966, learning rate: 0.00595, Loss: 0.2150, Accuracy:0.891\nIteration: 9967, learning rate: 0.00595, Loss: 0.1422, Accuracy:0.938\nIteration: 9968, learning rate: 0.00595, Loss: 0.2007, Accuracy:0.914\nIteration: 9969, learning rate: 0.00595, Loss: 0.1712, Accuracy:0.930\nIteration: 9970, learning rate: 0.00595, Loss: 0.2058, Accuracy:0.930\nIteration: 9971, learning rate: 0.00595, Loss: 0.1167, Accuracy:0.969\nIteration: 9972, learning rate: 0.00595, Loss: 0.1654, Accuracy:0.922\nIteration: 9973, learning rate: 0.00595, Loss: 0.1761, Accuracy:0.922\nIteration: 9974, learning rate: 0.00595, Loss: 0.1982, Accuracy:0.914\nIteration: 9975, learning rate: 0.00595, Loss: 0.1378, Accuracy:0.938\nIteration: 9976, learning rate: 0.00595, Loss: 0.2081, Accuracy:0.930\nIteration: 9977, learning rate: 0.00595, Loss: 0.1767, Accuracy:0.930\nIteration: 9978, learning rate: 0.00595, Loss: 0.2409, Accuracy:0.875\nIteration: 9979, learning rate: 0.00595, Loss: 0.1333, Accuracy:0.945\nIteration: 9980, learning rate: 0.00595, Loss: 0.1840, Accuracy:0.922\nIteration: 9981, learning rate: 0.00595, Loss: 0.1709, Accuracy:0.938\nIteration: 9982, learning rate: 0.00595, Loss: 0.1682, Accuracy:0.925\nEpoch: 322, Loss: 0.1712, Accuracy:0.930, Val Loss: 0.3070, Val Accuracy: 0.860\nIteration: 9983, learning rate: 0.00595, Loss: 0.1768, Accuracy:0.938\nIteration: 9984, learning rate: 0.00595, Loss: 0.1432, Accuracy:0.961\nIteration: 9985, learning rate: 0.00595, Loss: 0.1988, Accuracy:0.922\nIteration: 9986, learning rate: 0.00595, Loss: 0.1127, Accuracy:0.969\nIteration: 9987, learning rate: 0.00595, Loss: 0.2046, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 9988, learning rate: 0.00595, Loss: 0.2337, Accuracy:0.914\nIteration: 9989, learning rate: 0.00595, Loss: 0.2505, Accuracy:0.906\nIteration: 9990, learning rate: 0.00595, Loss: 0.1605, Accuracy:0.906\nIteration: 9991, learning rate: 0.00595, Loss: 0.1484, Accuracy:0.945\nIteration: 9992, learning rate: 0.00595, Loss: 0.1682, Accuracy:0.938\nIteration: 9993, learning rate: 0.00595, Loss: 0.1674, Accuracy:0.922\nIteration: 9994, learning rate: 0.00595, Loss: 0.2227, Accuracy:0.898\nIteration: 9995, learning rate: 0.00595, Loss: 0.1372, Accuracy:0.945\nIteration: 9996, learning rate: 0.00595, Loss: 0.1855, Accuracy:0.914\nIteration: 9997, learning rate: 0.00595, Loss: 0.1946, Accuracy:0.914\nIteration: 9998, learning rate: 0.00595, Loss: 0.2270, Accuracy:0.930\nIteration: 9999, learning rate: 0.00595, Loss: 0.2246, Accuracy:0.938\nIteration: 10000, learning rate: 0.00595, Loss: 0.1610, Accuracy:0.938\nIteration: 10001, learning rate: 0.00595, Loss: 0.1075, Accuracy:0.961\nIteration: 10002, learning rate: 0.00595, Loss: 0.1541, Accuracy:0.953\nIteration: 10003, learning rate: 0.00595, Loss: 0.1636, Accuracy:0.938\nIteration: 10004, learning rate: 0.00595, Loss: 0.2249, Accuracy:0.914\nIteration: 10005, learning rate: 0.00595, Loss: 0.2513, Accuracy:0.898\nIteration: 10006, learning rate: 0.00594, Loss: 0.1919, Accuracy:0.914\nIteration: 10007, learning rate: 0.00594, Loss: 0.2182, Accuracy:0.906\nIteration: 10008, learning rate: 0.00594, Loss: 0.1481, Accuracy:0.938\nIteration: 10009, learning rate: 0.00594, Loss: 0.1634, Accuracy:0.930\nIteration: 10010, learning rate: 0.00594, Loss: 0.1749, Accuracy:0.930\nIteration: 10011, learning rate: 0.00594, Loss: 0.1456, Accuracy:0.945\nIteration: 10012, learning rate: 0.00594, Loss: 0.1868, Accuracy:0.938\nIteration: 10013, learning rate: 0.00594, Loss: 0.1909, Accuracy:0.914\nEpoch: 323, Loss: 0.1819, Accuracy:0.929, Val Loss: 0.3021, Val Accuracy: 0.870\nIteration: 10014, learning rate: 0.00594, Loss: 0.1056, Accuracy:0.945\nIteration: 10015, learning rate: 0.00594, Loss: 0.1986, Accuracy:0.906\nIteration: 10016, learning rate: 0.00594, Loss: 0.2033, Accuracy:0.898\nIteration: 10017, learning rate: 0.00594, Loss: 0.1230, Accuracy:0.961\nIteration: 10018, learning rate: 0.00594, Loss: 0.1866, Accuracy:0.922\nIteration: 10019, learning rate: 0.00594, Loss: 0.1739, Accuracy:0.945\nIteration: 10020, learning rate: 0.00594, Loss: 0.1549, Accuracy:0.945\nIteration: 10021, learning rate: 0.00594, Loss: 0.1774, Accuracy:0.945\nIteration: 10022, learning rate: 0.00594, Loss: 0.1306, Accuracy:0.938\nIteration: 10023, learning rate: 0.00594, Loss: 0.1374, Accuracy:0.938\nIteration: 10024, learning rate: 0.00594, Loss: 0.1576, Accuracy:0.961\nIteration: 10025, learning rate: 0.00594, Loss: 0.1628, Accuracy:0.938\nIteration: 10026, learning rate: 0.00594, Loss: 0.1950, Accuracy:0.898\nIteration: 10027, learning rate: 0.00594, Loss: 0.2124, Accuracy:0.906\nIteration: 10028, learning rate: 0.00594, Loss: 0.1404, Accuracy:0.938\nIteration: 10029, learning rate: 0.00594, Loss: 0.1215, Accuracy:0.969\nIteration: 10030, learning rate: 0.00594, Loss: 0.1731, Accuracy:0.938\nIteration: 10031, learning rate: 0.00594, Loss: 0.1879, Accuracy:0.914\nIteration: 10032, learning rate: 0.00594, Loss: 0.1293, Accuracy:0.969\nIteration: 10033, learning rate: 0.00594, Loss: 0.1601, Accuracy:0.953\nIteration: 10034, learning rate: 0.00594, Loss: 0.1891, Accuracy:0.930\nIteration: 10035, learning rate: 0.00594, Loss: 0.1049, Accuracy:0.969\nIteration: 10036, learning rate: 0.00594, Loss: 0.1702, Accuracy:0.930\nIteration: 10037, learning rate: 0.00594, Loss: 0.1492, Accuracy:0.922\nIteration: 10038, learning rate: 0.00594, Loss: 0.1806, Accuracy:0.930\nIteration: 10039, learning rate: 0.00594, Loss: 0.1656, Accuracy:0.930\nIteration: 10040, learning rate: 0.00594, Loss: 0.1601, Accuracy:0.938\nIteration: 10041, learning rate: 0.00594, Loss: 0.0984, Accuracy:0.961\nIteration: 10042, learning rate: 0.00594, Loss: 0.2748, Accuracy:0.891\nIteration: 10043, learning rate: 0.00594, Loss: 0.1683, Accuracy:0.930\nIteration: 10044, learning rate: 0.00594, Loss: 0.1424, Accuracy:0.946\nEpoch: 324, Loss: 0.1624, Accuracy:0.936, Val Loss: 0.3436, Val Accuracy: 0.874\nIteration: 10045, learning rate: 0.00594, Loss: 0.2818, Accuracy:0.906\nIteration: 10046, learning rate: 0.00594, Loss: 0.1806, Accuracy:0.938\nIteration: 10047, learning rate: 0.00594, Loss: 0.1454, Accuracy:0.922\nIteration: 10048, learning rate: 0.00594, Loss: 0.1832, Accuracy:0.914\nIteration: 10049, learning rate: 0.00594, Loss: 0.1968, Accuracy:0.914\nIteration: 10050, learning rate: 0.00594, Loss: 0.2026, Accuracy:0.906\nIteration: 10051, learning rate: 0.00593, Loss: 0.1657, Accuracy:0.938\nIteration: 10052, learning rate: 0.00593, Loss: 0.1388, Accuracy:0.945\nIteration: 10053, learning rate: 0.00593, Loss: 0.1297, Accuracy:0.938\nIteration: 10054, learning rate: 0.00593, Loss: 0.1220, Accuracy:0.953\nIteration: 10055, learning rate: 0.00593, Loss: 0.1828, Accuracy:0.914\nIteration: 10056, learning rate: 0.00593, Loss: 0.1511, Accuracy:0.938\nIteration: 10057, learning rate: 0.00593, Loss: 0.1523, Accuracy:0.922\nIteration: 10058, learning rate: 0.00593, Loss: 0.1858, Accuracy:0.930\nIteration: 10059, learning rate: 0.00593, Loss: 0.2754, Accuracy:0.898\nIteration: 10060, learning rate: 0.00593, Loss: 0.2190, Accuracy:0.898\nIteration: 10061, learning rate: 0.00593, Loss: 0.1641, Accuracy:0.953\nIteration: 10062, learning rate: 0.00593, Loss: 0.2428, Accuracy:0.898\nIteration: 10063, learning rate: 0.00593, Loss: 0.1722, Accuracy:0.922\nIteration: 10064, learning rate: 0.00593, Loss: 0.1929, Accuracy:0.922\nIteration: 10065, learning rate: 0.00593, Loss: 0.1442, Accuracy:0.961\nIteration: 10066, learning rate: 0.00593, Loss: 0.2267, Accuracy:0.898\nIteration: 10067, learning rate: 0.00593, Loss: 0.2037, Accuracy:0.914\nIteration: 10068, learning rate: 0.00593, Loss: 0.1683, Accuracy:0.961\nIteration: 10069, learning rate: 0.00593, Loss: 0.1780, Accuracy:0.930\nIteration: 10070, learning rate: 0.00593, Loss: 0.1910, Accuracy:0.906\nIteration: 10071, learning rate: 0.00593, Loss: 0.0945, Accuracy:0.977\nIteration: 10072, learning rate: 0.00593, Loss: 0.1911, Accuracy:0.930\nIteration: 10073, learning rate: 0.00593, Loss: 0.1396, Accuracy:0.953\nIteration: 10074, learning rate: 0.00593, Loss: 0.0992, Accuracy:0.969\nIteration: 10075, learning rate: 0.00593, Loss: 0.1637, Accuracy:0.925\nEpoch: 325, Loss: 0.1769, Accuracy:0.929, Val Loss: 0.3166, Val Accuracy: 0.873\nIteration: 10076, learning rate: 0.00593, Loss: 0.1122, Accuracy:0.961\nIteration: 10077, learning rate: 0.00593, Loss: 0.2481, Accuracy:0.922\nIteration: 10078, learning rate: 0.00593, Loss: 0.2073, Accuracy:0.906\nIteration: 10079, learning rate: 0.00593, Loss: 0.1758, Accuracy:0.945\nIteration: 10080, learning rate: 0.00593, Loss: 0.2484, Accuracy:0.906\nIteration: 10081, learning rate: 0.00593, Loss: 0.1576, Accuracy:0.922\nIteration: 10082, learning rate: 0.00593, Loss: 0.1356, Accuracy:0.953\nIteration: 10083, learning rate: 0.00593, Loss: 0.1546, Accuracy:0.938\nIteration: 10084, learning rate: 0.00593, Loss: 0.1256, Accuracy:0.969\nIteration: 10085, learning rate: 0.00593, Loss: 0.1193, Accuracy:0.953\nIteration: 10086, learning rate: 0.00593, Loss: 0.1155, Accuracy:0.969\nIteration: 10087, learning rate: 0.00593, Loss: 0.1424, Accuracy:0.938\nIteration: 10088, learning rate: 0.00593, Loss: 0.2002, Accuracy:0.914\nIteration: 10089, learning rate: 0.00593, Loss: 0.2161, Accuracy:0.906\nIteration: 10090, learning rate: 0.00593, Loss: 0.1514, Accuracy:0.938\nIteration: 10091, learning rate: 0.00593, Loss: 0.1638, Accuracy:0.938\nIteration: 10092, learning rate: 0.00593, Loss: 0.1567, Accuracy:0.953\nIteration: 10093, learning rate: 0.00593, Loss: 0.1760, Accuracy:0.906\nIteration: 10094, learning rate: 0.00593, Loss: 0.2212, Accuracy:0.930\nIteration: 10095, learning rate: 0.00593, Loss: 0.1754, Accuracy:0.930\nIteration: 10096, learning rate: 0.00592, Loss: 0.1585, Accuracy:0.961\nIteration: 10097, learning rate: 0.00592, Loss: 0.1608, Accuracy:0.930\nIteration: 10098, learning rate: 0.00592, Loss: 0.1407, Accuracy:0.938\nIteration: 10099, learning rate: 0.00592, Loss: 0.1997, Accuracy:0.922\nIteration: 10100, learning rate: 0.00592, Loss: 0.2452, Accuracy:0.898\nIteration: 10101, learning rate: 0.00592, Loss: 0.1710, Accuracy:0.938\nIteration: 10102, learning rate: 0.00592, Loss: 0.1510, Accuracy:0.938\nIteration: 10103, learning rate: 0.00592, Loss: 0.1505, Accuracy:0.945\nIteration: 10104, learning rate: 0.00592, Loss: 0.1694, Accuracy:0.945\nIteration: 10105, learning rate: 0.00592, Loss: 0.1766, Accuracy:0.938\nIteration: 10106, learning rate: 0.00592, Loss: 0.2222, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 326, Loss: 0.1725, Accuracy:0.935, Val Loss: 0.3618, Val Accuracy: 0.852\nIteration: 10107, learning rate: 0.00592, Loss: 0.1733, Accuracy:0.930\nIteration: 10108, learning rate: 0.00592, Loss: 0.0900, Accuracy:0.977\nIteration: 10109, learning rate: 0.00592, Loss: 0.2030, Accuracy:0.922\nIteration: 10110, learning rate: 0.00592, Loss: 0.1370, Accuracy:0.945\nIteration: 10111, learning rate: 0.00592, Loss: 0.2437, Accuracy:0.898\nIteration: 10112, learning rate: 0.00592, Loss: 0.1765, Accuracy:0.938\nIteration: 10113, learning rate: 0.00592, Loss: 0.1891, Accuracy:0.930\nIteration: 10114, learning rate: 0.00592, Loss: 0.1815, Accuracy:0.938\nIteration: 10115, learning rate: 0.00592, Loss: 0.1385, Accuracy:0.922\nIteration: 10116, learning rate: 0.00592, Loss: 0.1173, Accuracy:0.961\nIteration: 10117, learning rate: 0.00592, Loss: 0.2128, Accuracy:0.914\nIteration: 10118, learning rate: 0.00592, Loss: 0.1631, Accuracy:0.891\nIteration: 10119, learning rate: 0.00592, Loss: 0.1058, Accuracy:0.969\nIteration: 10120, learning rate: 0.00592, Loss: 0.1276, Accuracy:0.945\nIteration: 10121, learning rate: 0.00592, Loss: 0.1402, Accuracy:0.938\nIteration: 10122, learning rate: 0.00592, Loss: 0.1768, Accuracy:0.945\nIteration: 10123, learning rate: 0.00592, Loss: 0.1493, Accuracy:0.945\nIteration: 10124, learning rate: 0.00592, Loss: 0.1921, Accuracy:0.930\nIteration: 10125, learning rate: 0.00592, Loss: 0.2027, Accuracy:0.930\nIteration: 10126, learning rate: 0.00592, Loss: 0.1667, Accuracy:0.922\nIteration: 10127, learning rate: 0.00592, Loss: 0.2089, Accuracy:0.898\nIteration: 10128, learning rate: 0.00592, Loss: 0.1286, Accuracy:0.969\nIteration: 10129, learning rate: 0.00592, Loss: 0.1238, Accuracy:0.961\nIteration: 10130, learning rate: 0.00592, Loss: 0.2153, Accuracy:0.898\nIteration: 10131, learning rate: 0.00592, Loss: 0.1440, Accuracy:0.945\nIteration: 10132, learning rate: 0.00592, Loss: 0.1617, Accuracy:0.930\nIteration: 10133, learning rate: 0.00592, Loss: 0.1602, Accuracy:0.930\nIteration: 10134, learning rate: 0.00592, Loss: 0.2551, Accuracy:0.883\nIteration: 10135, learning rate: 0.00592, Loss: 0.1683, Accuracy:0.953\nIteration: 10136, learning rate: 0.00592, Loss: 0.2547, Accuracy:0.883\nIteration: 10137, learning rate: 0.00592, Loss: 0.1827, Accuracy:0.935\nEpoch: 327, Loss: 0.1707, Accuracy:0.931, Val Loss: 0.2956, Val Accuracy: 0.874\nIteration: 10138, learning rate: 0.00592, Loss: 0.1893, Accuracy:0.930\nIteration: 10139, learning rate: 0.00592, Loss: 0.2205, Accuracy:0.906\nIteration: 10140, learning rate: 0.00592, Loss: 0.1431, Accuracy:0.961\nIteration: 10141, learning rate: 0.00592, Loss: 0.1178, Accuracy:0.953\nIteration: 10142, learning rate: 0.00591, Loss: 0.1577, Accuracy:0.922\nIteration: 10143, learning rate: 0.00591, Loss: 0.2459, Accuracy:0.898\nIteration: 10144, learning rate: 0.00591, Loss: 0.1849, Accuracy:0.914\nIteration: 10145, learning rate: 0.00591, Loss: 0.1860, Accuracy:0.945\nIteration: 10146, learning rate: 0.00591, Loss: 0.1736, Accuracy:0.945\nIteration: 10147, learning rate: 0.00591, Loss: 0.2766, Accuracy:0.852\nIteration: 10148, learning rate: 0.00591, Loss: 0.1692, Accuracy:0.922\nIteration: 10149, learning rate: 0.00591, Loss: 0.1418, Accuracy:0.930\nIteration: 10150, learning rate: 0.00591, Loss: 0.1579, Accuracy:0.953\nIteration: 10151, learning rate: 0.00591, Loss: 0.1737, Accuracy:0.930\nIteration: 10152, learning rate: 0.00591, Loss: 0.1544, Accuracy:0.945\nIteration: 10153, learning rate: 0.00591, Loss: 0.2032, Accuracy:0.891\nIteration: 10154, learning rate: 0.00591, Loss: 0.1374, Accuracy:0.953\nIteration: 10155, learning rate: 0.00591, Loss: 0.1554, Accuracy:0.930\nIteration: 10156, learning rate: 0.00591, Loss: 0.1442, Accuracy:0.938\nIteration: 10157, learning rate: 0.00591, Loss: 0.2078, Accuracy:0.914\nIteration: 10158, learning rate: 0.00591, Loss: 0.0988, Accuracy:0.961\nIteration: 10159, learning rate: 0.00591, Loss: 0.1909, Accuracy:0.930\nIteration: 10160, learning rate: 0.00591, Loss: 0.1631, Accuracy:0.953\nIteration: 10161, learning rate: 0.00591, Loss: 0.1155, Accuracy:0.977\nIteration: 10162, learning rate: 0.00591, Loss: 0.1315, Accuracy:0.945\nIteration: 10163, learning rate: 0.00591, Loss: 0.1747, Accuracy:0.938\nIteration: 10164, learning rate: 0.00591, Loss: 0.1300, Accuracy:0.953\nIteration: 10165, learning rate: 0.00591, Loss: 0.2022, Accuracy:0.930\nIteration: 10166, learning rate: 0.00591, Loss: 0.2150, Accuracy:0.914\nIteration: 10167, learning rate: 0.00591, Loss: 0.1895, Accuracy:0.930\nIteration: 10168, learning rate: 0.00591, Loss: 0.2772, Accuracy:0.892\nEpoch: 328, Loss: 0.1751, Accuracy:0.931, Val Loss: 0.3732, Val Accuracy: 0.840\nIteration: 10169, learning rate: 0.00591, Loss: 0.1278, Accuracy:0.953\nIteration: 10170, learning rate: 0.00591, Loss: 0.2430, Accuracy:0.906\nIteration: 10171, learning rate: 0.00591, Loss: 0.2542, Accuracy:0.930\nIteration: 10172, learning rate: 0.00591, Loss: 0.1391, Accuracy:0.930\nIteration: 10173, learning rate: 0.00591, Loss: 0.1976, Accuracy:0.930\nIteration: 10174, learning rate: 0.00591, Loss: 0.1778, Accuracy:0.945\nIteration: 10175, learning rate: 0.00591, Loss: 0.1566, Accuracy:0.938\nIteration: 10176, learning rate: 0.00591, Loss: 0.1898, Accuracy:0.922\nIteration: 10177, learning rate: 0.00591, Loss: 0.1684, Accuracy:0.922\nIteration: 10178, learning rate: 0.00591, Loss: 0.2216, Accuracy:0.883\nIteration: 10179, learning rate: 0.00591, Loss: 0.1412, Accuracy:0.945\nIteration: 10180, learning rate: 0.00591, Loss: 0.2037, Accuracy:0.914\nIteration: 10181, learning rate: 0.00591, Loss: 0.1594, Accuracy:0.953\nIteration: 10182, learning rate: 0.00591, Loss: 0.1773, Accuracy:0.922\nIteration: 10183, learning rate: 0.00591, Loss: 0.1407, Accuracy:0.945\nIteration: 10184, learning rate: 0.00591, Loss: 0.1822, Accuracy:0.922\nIteration: 10185, learning rate: 0.00591, Loss: 0.1860, Accuracy:0.938\nIteration: 10186, learning rate: 0.00591, Loss: 0.2285, Accuracy:0.914\nIteration: 10187, learning rate: 0.00590, Loss: 0.1468, Accuracy:0.953\nIteration: 10188, learning rate: 0.00590, Loss: 0.1229, Accuracy:0.969\nIteration: 10189, learning rate: 0.00590, Loss: 0.1854, Accuracy:0.930\nIteration: 10190, learning rate: 0.00590, Loss: 0.1770, Accuracy:0.945\nIteration: 10191, learning rate: 0.00590, Loss: 0.1869, Accuracy:0.914\nIteration: 10192, learning rate: 0.00590, Loss: 0.1427, Accuracy:0.953\nIteration: 10193, learning rate: 0.00590, Loss: 0.2345, Accuracy:0.922\nIteration: 10194, learning rate: 0.00590, Loss: 0.1498, Accuracy:0.930\nIteration: 10195, learning rate: 0.00590, Loss: 0.2465, Accuracy:0.906\nIteration: 10196, learning rate: 0.00590, Loss: 0.1672, Accuracy:0.922\nIteration: 10197, learning rate: 0.00590, Loss: 0.0887, Accuracy:0.953\nIteration: 10198, learning rate: 0.00590, Loss: 0.1791, Accuracy:0.930\nIteration: 10199, learning rate: 0.00590, Loss: 0.1398, Accuracy:0.946\nEpoch: 329, Loss: 0.1762, Accuracy:0.932, Val Loss: 0.2972, Val Accuracy: 0.872\nIteration: 10200, learning rate: 0.00590, Loss: 0.1508, Accuracy:0.938\nIteration: 10201, learning rate: 0.00590, Loss: 0.1610, Accuracy:0.938\nIteration: 10202, learning rate: 0.00590, Loss: 0.1746, Accuracy:0.930\nIteration: 10203, learning rate: 0.00590, Loss: 0.1727, Accuracy:0.914\nIteration: 10204, learning rate: 0.00590, Loss: 0.1987, Accuracy:0.930\nIteration: 10205, learning rate: 0.00590, Loss: 0.1838, Accuracy:0.922\nIteration: 10206, learning rate: 0.00590, Loss: 0.1672, Accuracy:0.945\nIteration: 10207, learning rate: 0.00590, Loss: 0.2283, Accuracy:0.914\nIteration: 10208, learning rate: 0.00590, Loss: 0.1558, Accuracy:0.945\nIteration: 10209, learning rate: 0.00590, Loss: 0.2169, Accuracy:0.930\nIteration: 10210, learning rate: 0.00590, Loss: 0.1426, Accuracy:0.938\nIteration: 10211, learning rate: 0.00590, Loss: 0.1848, Accuracy:0.938\nIteration: 10212, learning rate: 0.00590, Loss: 0.1768, Accuracy:0.914\nIteration: 10213, learning rate: 0.00590, Loss: 0.2016, Accuracy:0.922\nIteration: 10214, learning rate: 0.00590, Loss: 0.1858, Accuracy:0.914\nIteration: 10215, learning rate: 0.00590, Loss: 0.2236, Accuracy:0.922\nIteration: 10216, learning rate: 0.00590, Loss: 0.1963, Accuracy:0.930\nIteration: 10217, learning rate: 0.00590, Loss: 0.1429, Accuracy:0.930\nIteration: 10218, learning rate: 0.00590, Loss: 0.2277, Accuracy:0.922\nIteration: 10219, learning rate: 0.00590, Loss: 0.0769, Accuracy:0.969\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 10220, learning rate: 0.00590, Loss: 0.1930, Accuracy:0.914\nIteration: 10221, learning rate: 0.00590, Loss: 0.1190, Accuracy:0.969\nIteration: 10222, learning rate: 0.00590, Loss: 0.2024, Accuracy:0.906\nIteration: 10223, learning rate: 0.00590, Loss: 0.2322, Accuracy:0.875\nIteration: 10224, learning rate: 0.00590, Loss: 0.2318, Accuracy:0.922\nIteration: 10225, learning rate: 0.00590, Loss: 0.1475, Accuracy:0.945\nIteration: 10226, learning rate: 0.00590, Loss: 0.2159, Accuracy:0.938\nIteration: 10227, learning rate: 0.00590, Loss: 0.1776, Accuracy:0.945\nIteration: 10228, learning rate: 0.00590, Loss: 0.2142, Accuracy:0.914\nIteration: 10229, learning rate: 0.00590, Loss: 0.1521, Accuracy:0.953\nIteration: 10230, learning rate: 0.00590, Loss: 0.0522, Accuracy:1.000\nEpoch: 330, Loss: 0.1776, Accuracy:0.932, Val Loss: 0.2995, Val Accuracy: 0.879\nIteration: 10231, learning rate: 0.00590, Loss: 0.1963, Accuracy:0.930\nIteration: 10232, learning rate: 0.00590, Loss: 0.1238, Accuracy:0.953\nIteration: 10233, learning rate: 0.00589, Loss: 0.2488, Accuracy:0.922\nIteration: 10234, learning rate: 0.00589, Loss: 0.2743, Accuracy:0.883\nIteration: 10235, learning rate: 0.00589, Loss: 0.1951, Accuracy:0.914\nIteration: 10236, learning rate: 0.00589, Loss: 0.1790, Accuracy:0.930\nIteration: 10237, learning rate: 0.00589, Loss: 0.1500, Accuracy:0.953\nIteration: 10238, learning rate: 0.00589, Loss: 0.1463, Accuracy:0.930\nIteration: 10239, learning rate: 0.00589, Loss: 0.2479, Accuracy:0.898\nIteration: 10240, learning rate: 0.00589, Loss: 0.0926, Accuracy:0.961\nIteration: 10241, learning rate: 0.00589, Loss: 0.1485, Accuracy:0.922\nIteration: 10242, learning rate: 0.00589, Loss: 0.1816, Accuracy:0.922\nIteration: 10243, learning rate: 0.00589, Loss: 0.1413, Accuracy:0.953\nIteration: 10244, learning rate: 0.00589, Loss: 0.1903, Accuracy:0.914\nIteration: 10245, learning rate: 0.00589, Loss: 0.1698, Accuracy:0.930\nIteration: 10246, learning rate: 0.00589, Loss: 0.1446, Accuracy:0.938\nIteration: 10247, learning rate: 0.00589, Loss: 0.1537, Accuracy:0.938\nIteration: 10248, learning rate: 0.00589, Loss: 0.1841, Accuracy:0.922\nIteration: 10249, learning rate: 0.00589, Loss: 0.2017, Accuracy:0.922\nIteration: 10250, learning rate: 0.00589, Loss: 0.1402, Accuracy:0.953\nIteration: 10251, learning rate: 0.00589, Loss: 0.1751, Accuracy:0.930\nIteration: 10252, learning rate: 0.00589, Loss: 0.1099, Accuracy:0.945\nIteration: 10253, learning rate: 0.00589, Loss: 0.1509, Accuracy:0.969\nIteration: 10254, learning rate: 0.00589, Loss: 0.1618, Accuracy:0.938\nIteration: 10255, learning rate: 0.00589, Loss: 0.2220, Accuracy:0.938\nIteration: 10256, learning rate: 0.00589, Loss: 0.1819, Accuracy:0.930\nIteration: 10257, learning rate: 0.00589, Loss: 0.1365, Accuracy:0.945\nIteration: 10258, learning rate: 0.00589, Loss: 0.2038, Accuracy:0.914\nIteration: 10259, learning rate: 0.00589, Loss: 0.1297, Accuracy:0.945\nIteration: 10260, learning rate: 0.00589, Loss: 0.1665, Accuracy:0.930\nIteration: 10261, learning rate: 0.00589, Loss: 0.1269, Accuracy:0.935\nEpoch: 331, Loss: 0.1702, Accuracy:0.932, Val Loss: 0.2901, Val Accuracy: 0.888\nIteration: 10262, learning rate: 0.00589, Loss: 0.1187, Accuracy:0.961\nIteration: 10263, learning rate: 0.00589, Loss: 0.1340, Accuracy:0.961\nIteration: 10264, learning rate: 0.00589, Loss: 0.1890, Accuracy:0.922\nIteration: 10265, learning rate: 0.00589, Loss: 0.1758, Accuracy:0.930\nIteration: 10266, learning rate: 0.00589, Loss: 0.1274, Accuracy:0.945\nIteration: 10267, learning rate: 0.00589, Loss: 0.1145, Accuracy:0.945\nIteration: 10268, learning rate: 0.00589, Loss: 0.1557, Accuracy:0.930\nIteration: 10269, learning rate: 0.00589, Loss: 0.1433, Accuracy:0.945\nIteration: 10270, learning rate: 0.00589, Loss: 0.1625, Accuracy:0.945\nIteration: 10271, learning rate: 0.00589, Loss: 0.1007, Accuracy:0.953\nIteration: 10272, learning rate: 0.00589, Loss: 0.1775, Accuracy:0.938\nIteration: 10273, learning rate: 0.00589, Loss: 0.1746, Accuracy:0.930\nIteration: 10274, learning rate: 0.00589, Loss: 0.1485, Accuracy:0.938\nIteration: 10275, learning rate: 0.00589, Loss: 0.2343, Accuracy:0.922\nIteration: 10276, learning rate: 0.00589, Loss: 0.1821, Accuracy:0.930\nIteration: 10277, learning rate: 0.00589, Loss: 0.1795, Accuracy:0.930\nIteration: 10278, learning rate: 0.00589, Loss: 0.1705, Accuracy:0.922\nIteration: 10279, learning rate: 0.00588, Loss: 0.2187, Accuracy:0.914\nIteration: 10280, learning rate: 0.00588, Loss: 0.1825, Accuracy:0.922\nIteration: 10281, learning rate: 0.00588, Loss: 0.1113, Accuracy:0.953\nIteration: 10282, learning rate: 0.00588, Loss: 0.1698, Accuracy:0.938\nIteration: 10283, learning rate: 0.00588, Loss: 0.1395, Accuracy:0.945\nIteration: 10284, learning rate: 0.00588, Loss: 0.1520, Accuracy:0.922\nIteration: 10285, learning rate: 0.00588, Loss: 0.1469, Accuracy:0.961\nIteration: 10286, learning rate: 0.00588, Loss: 0.1684, Accuracy:0.930\nIteration: 10287, learning rate: 0.00588, Loss: 0.2210, Accuracy:0.930\nIteration: 10288, learning rate: 0.00588, Loss: 0.0983, Accuracy:0.953\nIteration: 10289, learning rate: 0.00588, Loss: 0.2134, Accuracy:0.922\nIteration: 10290, learning rate: 0.00588, Loss: 0.1843, Accuracy:0.922\nIteration: 10291, learning rate: 0.00588, Loss: 0.1584, Accuracy:0.938\nIteration: 10292, learning rate: 0.00588, Loss: 0.2086, Accuracy:0.925\nEpoch: 332, Loss: 0.1633, Accuracy:0.936, Val Loss: 0.3704, Val Accuracy: 0.839\nIteration: 10293, learning rate: 0.00588, Loss: 0.1773, Accuracy:0.922\nIteration: 10294, learning rate: 0.00588, Loss: 0.2520, Accuracy:0.914\nIteration: 10295, learning rate: 0.00588, Loss: 0.1217, Accuracy:0.961\nIteration: 10296, learning rate: 0.00588, Loss: 0.1306, Accuracy:0.953\nIteration: 10297, learning rate: 0.00588, Loss: 0.1639, Accuracy:0.945\nIteration: 10298, learning rate: 0.00588, Loss: 0.1965, Accuracy:0.922\nIteration: 10299, learning rate: 0.00588, Loss: 0.2032, Accuracy:0.922\nIteration: 10300, learning rate: 0.00588, Loss: 0.1710, Accuracy:0.930\nIteration: 10301, learning rate: 0.00588, Loss: 0.1724, Accuracy:0.930\nIteration: 10302, learning rate: 0.00588, Loss: 0.1027, Accuracy:0.977\nIteration: 10303, learning rate: 0.00588, Loss: 0.1436, Accuracy:0.969\nIteration: 10304, learning rate: 0.00588, Loss: 0.1308, Accuracy:0.953\nIteration: 10305, learning rate: 0.00588, Loss: 0.2382, Accuracy:0.898\nIteration: 10306, learning rate: 0.00588, Loss: 0.1757, Accuracy:0.906\nIteration: 10307, learning rate: 0.00588, Loss: 0.1665, Accuracy:0.898\nIteration: 10308, learning rate: 0.00588, Loss: 0.1753, Accuracy:0.922\nIteration: 10309, learning rate: 0.00588, Loss: 0.2650, Accuracy:0.898\nIteration: 10310, learning rate: 0.00588, Loss: 0.2314, Accuracy:0.922\nIteration: 10311, learning rate: 0.00588, Loss: 0.2268, Accuracy:0.914\nIteration: 10312, learning rate: 0.00588, Loss: 0.1172, Accuracy:0.961\nIteration: 10313, learning rate: 0.00588, Loss: 0.1275, Accuracy:0.945\nIteration: 10314, learning rate: 0.00588, Loss: 0.1287, Accuracy:0.945\nIteration: 10315, learning rate: 0.00588, Loss: 0.2619, Accuracy:0.891\nIteration: 10316, learning rate: 0.00588, Loss: 0.1806, Accuracy:0.922\nIteration: 10317, learning rate: 0.00588, Loss: 0.2472, Accuracy:0.914\nIteration: 10318, learning rate: 0.00588, Loss: 0.2292, Accuracy:0.906\nIteration: 10319, learning rate: 0.00588, Loss: 0.0976, Accuracy:0.969\nIteration: 10320, learning rate: 0.00588, Loss: 0.1250, Accuracy:0.938\nIteration: 10321, learning rate: 0.00588, Loss: 0.1503, Accuracy:0.922\nIteration: 10322, learning rate: 0.00588, Loss: 0.1215, Accuracy:0.953\nIteration: 10323, learning rate: 0.00588, Loss: 0.1304, Accuracy:0.978\nEpoch: 333, Loss: 0.1730, Accuracy:0.932, Val Loss: 0.2834, Val Accuracy: 0.878\nIteration: 10324, learning rate: 0.00588, Loss: 0.1731, Accuracy:0.938\nIteration: 10325, learning rate: 0.00587, Loss: 0.1712, Accuracy:0.922\nIteration: 10326, learning rate: 0.00587, Loss: 0.1441, Accuracy:0.945\nIteration: 10327, learning rate: 0.00587, Loss: 0.1332, Accuracy:0.961\nIteration: 10328, learning rate: 0.00587, Loss: 0.1864, Accuracy:0.938\nIteration: 10329, learning rate: 0.00587, Loss: 0.1688, Accuracy:0.945\nIteration: 10330, learning rate: 0.00587, Loss: 0.0920, Accuracy:0.992\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 10331, learning rate: 0.00587, Loss: 0.1643, Accuracy:0.930\nIteration: 10332, learning rate: 0.00587, Loss: 0.2016, Accuracy:0.914\nIteration: 10333, learning rate: 0.00587, Loss: 0.1154, Accuracy:0.953\nIteration: 10334, learning rate: 0.00587, Loss: 0.2043, Accuracy:0.922\nIteration: 10335, learning rate: 0.00587, Loss: 0.1075, Accuracy:0.961\nIteration: 10336, learning rate: 0.00587, Loss: 0.1550, Accuracy:0.938\nIteration: 10337, learning rate: 0.00587, Loss: 0.2355, Accuracy:0.930\nIteration: 10338, learning rate: 0.00587, Loss: 0.1371, Accuracy:0.945\nIteration: 10339, learning rate: 0.00587, Loss: 0.1846, Accuracy:0.945\nIteration: 10340, learning rate: 0.00587, Loss: 0.1478, Accuracy:0.961\nIteration: 10341, learning rate: 0.00587, Loss: 0.1813, Accuracy:0.930\nIteration: 10342, learning rate: 0.00587, Loss: 0.1454, Accuracy:0.922\nIteration: 10343, learning rate: 0.00587, Loss: 0.1098, Accuracy:0.961\nIteration: 10344, learning rate: 0.00587, Loss: 0.2210, Accuracy:0.930\nIteration: 10345, learning rate: 0.00587, Loss: 0.1074, Accuracy:0.969\nIteration: 10346, learning rate: 0.00587, Loss: 0.1462, Accuracy:0.945\nIteration: 10347, learning rate: 0.00587, Loss: 0.1957, Accuracy:0.922\nIteration: 10348, learning rate: 0.00587, Loss: 0.1615, Accuracy:0.922\nIteration: 10349, learning rate: 0.00587, Loss: 0.1206, Accuracy:0.945\nIteration: 10350, learning rate: 0.00587, Loss: 0.1601, Accuracy:0.953\nIteration: 10351, learning rate: 0.00587, Loss: 0.1412, Accuracy:0.930\nIteration: 10352, learning rate: 0.00587, Loss: 0.1280, Accuracy:0.945\nIteration: 10353, learning rate: 0.00587, Loss: 0.1892, Accuracy:0.945\nIteration: 10354, learning rate: 0.00587, Loss: 0.1926, Accuracy:0.946\nEpoch: 334, Loss: 0.1588, Accuracy:0.942, Val Loss: 0.3291, Val Accuracy: 0.860\nIteration: 10355, learning rate: 0.00587, Loss: 0.2528, Accuracy:0.891\nIteration: 10356, learning rate: 0.00587, Loss: 0.1552, Accuracy:0.953\nIteration: 10357, learning rate: 0.00587, Loss: 0.1472, Accuracy:0.953\nIteration: 10358, learning rate: 0.00587, Loss: 0.1715, Accuracy:0.938\nIteration: 10359, learning rate: 0.00587, Loss: 0.1518, Accuracy:0.938\nIteration: 10360, learning rate: 0.00587, Loss: 0.1842, Accuracy:0.922\nIteration: 10361, learning rate: 0.00587, Loss: 0.1510, Accuracy:0.930\nIteration: 10362, learning rate: 0.00587, Loss: 0.1613, Accuracy:0.945\nIteration: 10363, learning rate: 0.00587, Loss: 0.1886, Accuracy:0.930\nIteration: 10364, learning rate: 0.00587, Loss: 0.1334, Accuracy:0.945\nIteration: 10365, learning rate: 0.00587, Loss: 0.1170, Accuracy:0.953\nIteration: 10366, learning rate: 0.00587, Loss: 0.1341, Accuracy:0.945\nIteration: 10367, learning rate: 0.00587, Loss: 0.1261, Accuracy:0.945\nIteration: 10368, learning rate: 0.00587, Loss: 0.1578, Accuracy:0.938\nIteration: 10369, learning rate: 0.00587, Loss: 0.2818, Accuracy:0.891\nIteration: 10370, learning rate: 0.00587, Loss: 0.1334, Accuracy:0.945\nIteration: 10371, learning rate: 0.00586, Loss: 0.1239, Accuracy:0.945\nIteration: 10372, learning rate: 0.00586, Loss: 0.1337, Accuracy:0.953\nIteration: 10373, learning rate: 0.00586, Loss: 0.1508, Accuracy:0.922\nIteration: 10374, learning rate: 0.00586, Loss: 0.1334, Accuracy:0.953\nIteration: 10375, learning rate: 0.00586, Loss: 0.2061, Accuracy:0.891\nIteration: 10376, learning rate: 0.00586, Loss: 0.2060, Accuracy:0.891\nIteration: 10377, learning rate: 0.00586, Loss: 0.2085, Accuracy:0.922\nIteration: 10378, learning rate: 0.00586, Loss: 0.1478, Accuracy:0.945\nIteration: 10379, learning rate: 0.00586, Loss: 0.1591, Accuracy:0.953\nIteration: 10380, learning rate: 0.00586, Loss: 0.2023, Accuracy:0.945\nIteration: 10381, learning rate: 0.00586, Loss: 0.1635, Accuracy:0.930\nIteration: 10382, learning rate: 0.00586, Loss: 0.2029, Accuracy:0.922\nIteration: 10383, learning rate: 0.00586, Loss: 0.1510, Accuracy:0.945\nIteration: 10384, learning rate: 0.00586, Loss: 0.1377, Accuracy:0.938\nIteration: 10385, learning rate: 0.00586, Loss: 0.1630, Accuracy:0.935\nEpoch: 335, Loss: 0.1657, Accuracy:0.934, Val Loss: 0.3052, Val Accuracy: 0.878\nIteration: 10386, learning rate: 0.00586, Loss: 0.1477, Accuracy:0.945\nIteration: 10387, learning rate: 0.00586, Loss: 0.1239, Accuracy:0.930\nIteration: 10388, learning rate: 0.00586, Loss: 0.1732, Accuracy:0.938\nIteration: 10389, learning rate: 0.00586, Loss: 0.1328, Accuracy:0.953\nIteration: 10390, learning rate: 0.00586, Loss: 0.2105, Accuracy:0.898\nIteration: 10391, learning rate: 0.00586, Loss: 0.1163, Accuracy:0.953\nIteration: 10392, learning rate: 0.00586, Loss: 0.1889, Accuracy:0.922\nIteration: 10393, learning rate: 0.00586, Loss: 0.1978, Accuracy:0.914\nIteration: 10394, learning rate: 0.00586, Loss: 0.1250, Accuracy:0.961\nIteration: 10395, learning rate: 0.00586, Loss: 0.1606, Accuracy:0.945\nIteration: 10396, learning rate: 0.00586, Loss: 0.2442, Accuracy:0.914\nIteration: 10397, learning rate: 0.00586, Loss: 0.2789, Accuracy:0.906\nIteration: 10398, learning rate: 0.00586, Loss: 0.1529, Accuracy:0.945\nIteration: 10399, learning rate: 0.00586, Loss: 0.2306, Accuracy:0.898\nIteration: 10400, learning rate: 0.00586, Loss: 0.1711, Accuracy:0.938\nIteration: 10401, learning rate: 0.00586, Loss: 0.1365, Accuracy:0.945\nIteration: 10402, learning rate: 0.00586, Loss: 0.1170, Accuracy:0.961\nIteration: 10403, learning rate: 0.00586, Loss: 0.1446, Accuracy:0.938\nIteration: 10404, learning rate: 0.00586, Loss: 0.1699, Accuracy:0.930\nIteration: 10405, learning rate: 0.00586, Loss: 0.1510, Accuracy:0.953\nIteration: 10406, learning rate: 0.00586, Loss: 0.1854, Accuracy:0.914\nIteration: 10407, learning rate: 0.00586, Loss: 0.1758, Accuracy:0.930\nIteration: 10408, learning rate: 0.00586, Loss: 0.1563, Accuracy:0.953\nIteration: 10409, learning rate: 0.00586, Loss: 0.1128, Accuracy:0.969\nIteration: 10410, learning rate: 0.00586, Loss: 0.2081, Accuracy:0.922\nIteration: 10411, learning rate: 0.00586, Loss: 0.1983, Accuracy:0.922\nIteration: 10412, learning rate: 0.00586, Loss: 0.1503, Accuracy:0.945\nIteration: 10413, learning rate: 0.00586, Loss: 0.1474, Accuracy:0.930\nIteration: 10414, learning rate: 0.00586, Loss: 0.1081, Accuracy:0.961\nIteration: 10415, learning rate: 0.00586, Loss: 0.1443, Accuracy:0.961\nIteration: 10416, learning rate: 0.00586, Loss: 0.1728, Accuracy:0.914\nEpoch: 336, Loss: 0.1656, Accuracy:0.936, Val Loss: 0.3380, Val Accuracy: 0.852\nIteration: 10417, learning rate: 0.00585, Loss: 0.3465, Accuracy:0.859\nIteration: 10418, learning rate: 0.00585, Loss: 0.1908, Accuracy:0.930\nIteration: 10419, learning rate: 0.00585, Loss: 0.1599, Accuracy:0.945\nIteration: 10420, learning rate: 0.00585, Loss: 0.1694, Accuracy:0.922\nIteration: 10421, learning rate: 0.00585, Loss: 0.2373, Accuracy:0.906\nIteration: 10422, learning rate: 0.00585, Loss: 0.1863, Accuracy:0.930\nIteration: 10423, learning rate: 0.00585, Loss: 0.1786, Accuracy:0.945\nIteration: 10424, learning rate: 0.00585, Loss: 0.1102, Accuracy:0.945\nIteration: 10425, learning rate: 0.00585, Loss: 0.2091, Accuracy:0.922\nIteration: 10426, learning rate: 0.00585, Loss: 0.2367, Accuracy:0.891\nIteration: 10427, learning rate: 0.00585, Loss: 0.0888, Accuracy:0.977\nIteration: 10428, learning rate: 0.00585, Loss: 0.0890, Accuracy:0.977\nIteration: 10429, learning rate: 0.00585, Loss: 0.2236, Accuracy:0.922\nIteration: 10430, learning rate: 0.00585, Loss: 0.2987, Accuracy:0.867\nIteration: 10431, learning rate: 0.00585, Loss: 0.1491, Accuracy:0.961\nIteration: 10432, learning rate: 0.00585, Loss: 0.1623, Accuracy:0.938\nIteration: 10433, learning rate: 0.00585, Loss: 0.1709, Accuracy:0.945\nIteration: 10434, learning rate: 0.00585, Loss: 0.2041, Accuracy:0.914\nIteration: 10435, learning rate: 0.00585, Loss: 0.1243, Accuracy:0.961\nIteration: 10436, learning rate: 0.00585, Loss: 0.2231, Accuracy:0.867\nIteration: 10437, learning rate: 0.00585, Loss: 0.1808, Accuracy:0.922\nIteration: 10438, learning rate: 0.00585, Loss: 0.1939, Accuracy:0.914\nIteration: 10439, learning rate: 0.00585, Loss: 0.1350, Accuracy:0.938\nIteration: 10440, learning rate: 0.00585, Loss: 0.2167, Accuracy:0.922\nIteration: 10441, learning rate: 0.00585, Loss: 0.1479, Accuracy:0.961\nIteration: 10442, learning rate: 0.00585, Loss: 0.1106, Accuracy:0.969\nIteration: 10443, learning rate: 0.00585, Loss: 0.1828, Accuracy:0.914\nIteration: 10444, learning rate: 0.00585, Loss: 0.2265, Accuracy:0.875\nIteration: 10445, learning rate: 0.00585, Loss: 0.1600, Accuracy:0.945\nIteration: 10446, learning rate: 0.00585, Loss: 0.1906, Accuracy:0.922\nIteration: 10447, learning rate: 0.00585, Loss: 0.1954, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 337, Loss: 0.1838, Accuracy:0.927, Val Loss: 0.2706, Val Accuracy: 0.876\nIteration: 10448, learning rate: 0.00585, Loss: 0.1472, Accuracy:0.945\nIteration: 10449, learning rate: 0.00585, Loss: 0.1479, Accuracy:0.938\nIteration: 10450, learning rate: 0.00585, Loss: 0.2104, Accuracy:0.930\nIteration: 10451, learning rate: 0.00585, Loss: 0.2475, Accuracy:0.914\nIteration: 10452, learning rate: 0.00585, Loss: 0.2196, Accuracy:0.938\nIteration: 10453, learning rate: 0.00585, Loss: 0.2111, Accuracy:0.906\nIteration: 10454, learning rate: 0.00585, Loss: 0.0874, Accuracy:0.977\nIteration: 10455, learning rate: 0.00585, Loss: 0.1382, Accuracy:0.945\nIteration: 10456, learning rate: 0.00585, Loss: 0.2413, Accuracy:0.898\nIteration: 10457, learning rate: 0.00585, Loss: 0.1857, Accuracy:0.922\nIteration: 10458, learning rate: 0.00585, Loss: 0.1999, Accuracy:0.891\nIteration: 10459, learning rate: 0.00585, Loss: 0.1775, Accuracy:0.914\nIteration: 10460, learning rate: 0.00585, Loss: 0.1680, Accuracy:0.922\nIteration: 10461, learning rate: 0.00585, Loss: 0.1873, Accuracy:0.922\nIteration: 10462, learning rate: 0.00585, Loss: 0.1841, Accuracy:0.930\nIteration: 10463, learning rate: 0.00585, Loss: 0.1874, Accuracy:0.930\nIteration: 10464, learning rate: 0.00584, Loss: 0.1385, Accuracy:0.961\nIteration: 10465, learning rate: 0.00584, Loss: 0.2089, Accuracy:0.906\nIteration: 10466, learning rate: 0.00584, Loss: 0.1274, Accuracy:0.961\nIteration: 10467, learning rate: 0.00584, Loss: 0.1263, Accuracy:0.953\nIteration: 10468, learning rate: 0.00584, Loss: 0.1750, Accuracy:0.930\nIteration: 10469, learning rate: 0.00584, Loss: 0.1290, Accuracy:0.961\nIteration: 10470, learning rate: 0.00584, Loss: 0.1482, Accuracy:0.938\nIteration: 10471, learning rate: 0.00584, Loss: 0.1849, Accuracy:0.922\nIteration: 10472, learning rate: 0.00584, Loss: 0.2090, Accuracy:0.922\nIteration: 10473, learning rate: 0.00584, Loss: 0.1876, Accuracy:0.914\nIteration: 10474, learning rate: 0.00584, Loss: 0.1767, Accuracy:0.938\nIteration: 10475, learning rate: 0.00584, Loss: 0.1941, Accuracy:0.922\nIteration: 10476, learning rate: 0.00584, Loss: 0.1637, Accuracy:0.945\nIteration: 10477, learning rate: 0.00584, Loss: 0.2717, Accuracy:0.898\nIteration: 10478, learning rate: 0.00584, Loss: 0.1655, Accuracy:0.925\nEpoch: 338, Loss: 0.1789, Accuracy:0.930, Val Loss: 0.3100, Val Accuracy: 0.875\nIteration: 10479, learning rate: 0.00584, Loss: 0.1389, Accuracy:0.945\nIteration: 10480, learning rate: 0.00584, Loss: 0.1492, Accuracy:0.938\nIteration: 10481, learning rate: 0.00584, Loss: 0.1672, Accuracy:0.922\nIteration: 10482, learning rate: 0.00584, Loss: 0.1170, Accuracy:0.953\nIteration: 10483, learning rate: 0.00584, Loss: 0.1871, Accuracy:0.914\nIteration: 10484, learning rate: 0.00584, Loss: 0.1319, Accuracy:0.961\nIteration: 10485, learning rate: 0.00584, Loss: 0.1351, Accuracy:0.945\nIteration: 10486, learning rate: 0.00584, Loss: 0.1699, Accuracy:0.945\nIteration: 10487, learning rate: 0.00584, Loss: 0.2469, Accuracy:0.875\nIteration: 10488, learning rate: 0.00584, Loss: 0.1620, Accuracy:0.914\nIteration: 10489, learning rate: 0.00584, Loss: 0.1941, Accuracy:0.906\nIteration: 10490, learning rate: 0.00584, Loss: 0.2019, Accuracy:0.898\nIteration: 10491, learning rate: 0.00584, Loss: 0.1547, Accuracy:0.922\nIteration: 10492, learning rate: 0.00584, Loss: 0.2131, Accuracy:0.906\nIteration: 10493, learning rate: 0.00584, Loss: 0.1751, Accuracy:0.922\nIteration: 10494, learning rate: 0.00584, Loss: 0.1849, Accuracy:0.922\nIteration: 10495, learning rate: 0.00584, Loss: 0.1993, Accuracy:0.945\nIteration: 10496, learning rate: 0.00584, Loss: 0.1466, Accuracy:0.938\nIteration: 10497, learning rate: 0.00584, Loss: 0.1491, Accuracy:0.922\nIteration: 10498, learning rate: 0.00584, Loss: 0.1734, Accuracy:0.945\nIteration: 10499, learning rate: 0.00584, Loss: 0.1181, Accuracy:0.969\nIteration: 10500, learning rate: 0.00584, Loss: 0.0787, Accuracy:0.992\nIteration: 10501, learning rate: 0.00584, Loss: 0.1235, Accuracy:0.969\nIteration: 10502, learning rate: 0.00584, Loss: 0.2375, Accuracy:0.922\nIteration: 10503, learning rate: 0.00584, Loss: 0.0863, Accuracy:0.977\nIteration: 10504, learning rate: 0.00584, Loss: 0.2125, Accuracy:0.914\nIteration: 10505, learning rate: 0.00584, Loss: 0.1973, Accuracy:0.906\nIteration: 10506, learning rate: 0.00584, Loss: 0.2294, Accuracy:0.945\nIteration: 10507, learning rate: 0.00584, Loss: 0.2663, Accuracy:0.883\nIteration: 10508, learning rate: 0.00584, Loss: 0.1286, Accuracy:0.961\nIteration: 10509, learning rate: 0.00584, Loss: 0.1014, Accuracy:0.957\nEpoch: 339, Loss: 0.1670, Accuracy:0.933, Val Loss: 0.2847, Val Accuracy: 0.889\nIteration: 10510, learning rate: 0.00584, Loss: 0.1450, Accuracy:0.938\nIteration: 10511, learning rate: 0.00583, Loss: 0.1434, Accuracy:0.953\nIteration: 10512, learning rate: 0.00583, Loss: 0.2018, Accuracy:0.898\nIteration: 10513, learning rate: 0.00583, Loss: 0.2222, Accuracy:0.891\nIteration: 10514, learning rate: 0.00583, Loss: 0.2552, Accuracy:0.930\nIteration: 10515, learning rate: 0.00583, Loss: 0.1737, Accuracy:0.922\nIteration: 10516, learning rate: 0.00583, Loss: 0.0857, Accuracy:0.992\nIteration: 10517, learning rate: 0.00583, Loss: 0.2145, Accuracy:0.914\nIteration: 10518, learning rate: 0.00583, Loss: 0.1090, Accuracy:0.969\nIteration: 10519, learning rate: 0.00583, Loss: 0.1608, Accuracy:0.930\nIteration: 10520, learning rate: 0.00583, Loss: 0.2193, Accuracy:0.898\nIteration: 10521, learning rate: 0.00583, Loss: 0.1844, Accuracy:0.938\nIteration: 10522, learning rate: 0.00583, Loss: 0.2191, Accuracy:0.914\nIteration: 10523, learning rate: 0.00583, Loss: 0.1395, Accuracy:0.930\nIteration: 10524, learning rate: 0.00583, Loss: 0.1838, Accuracy:0.938\nIteration: 10525, learning rate: 0.00583, Loss: 0.1622, Accuracy:0.930\nIteration: 10526, learning rate: 0.00583, Loss: 0.1308, Accuracy:0.961\nIteration: 10527, learning rate: 0.00583, Loss: 0.2023, Accuracy:0.914\nIteration: 10528, learning rate: 0.00583, Loss: 0.0965, Accuracy:0.961\nIteration: 10529, learning rate: 0.00583, Loss: 0.1673, Accuracy:0.922\nIteration: 10530, learning rate: 0.00583, Loss: 0.1779, Accuracy:0.945\nIteration: 10531, learning rate: 0.00583, Loss: 0.1331, Accuracy:0.953\nIteration: 10532, learning rate: 0.00583, Loss: 0.2104, Accuracy:0.898\nIteration: 10533, learning rate: 0.00583, Loss: 0.2643, Accuracy:0.922\nIteration: 10534, learning rate: 0.00583, Loss: 0.1941, Accuracy:0.906\nIteration: 10535, learning rate: 0.00583, Loss: 0.2047, Accuracy:0.930\nIteration: 10536, learning rate: 0.00583, Loss: 0.1501, Accuracy:0.953\nIteration: 10537, learning rate: 0.00583, Loss: 0.1550, Accuracy:0.961\nIteration: 10538, learning rate: 0.00583, Loss: 0.1177, Accuracy:0.961\nIteration: 10539, learning rate: 0.00583, Loss: 0.1438, Accuracy:0.945\nIteration: 10540, learning rate: 0.00583, Loss: 0.2444, Accuracy:0.892\nEpoch: 340, Loss: 0.1746, Accuracy:0.933, Val Loss: 0.3343, Val Accuracy: 0.868\nIteration: 10541, learning rate: 0.00583, Loss: 0.1606, Accuracy:0.930\nIteration: 10542, learning rate: 0.00583, Loss: 0.1442, Accuracy:0.945\nIteration: 10543, learning rate: 0.00583, Loss: 0.1528, Accuracy:0.945\nIteration: 10544, learning rate: 0.00583, Loss: 0.1445, Accuracy:0.938\nIteration: 10545, learning rate: 0.00583, Loss: 0.1462, Accuracy:0.930\nIteration: 10546, learning rate: 0.00583, Loss: 0.2547, Accuracy:0.930\nIteration: 10547, learning rate: 0.00583, Loss: 0.1854, Accuracy:0.898\nIteration: 10548, learning rate: 0.00583, Loss: 0.1092, Accuracy:0.969\nIteration: 10549, learning rate: 0.00583, Loss: 0.2477, Accuracy:0.891\nIteration: 10550, learning rate: 0.00583, Loss: 0.1622, Accuracy:0.953\nIteration: 10551, learning rate: 0.00583, Loss: 0.1465, Accuracy:0.930\nIteration: 10552, learning rate: 0.00583, Loss: 0.2839, Accuracy:0.898\nIteration: 10553, learning rate: 0.00583, Loss: 0.1654, Accuracy:0.945\nIteration: 10554, learning rate: 0.00583, Loss: 0.1477, Accuracy:0.953\nIteration: 10555, learning rate: 0.00583, Loss: 0.1710, Accuracy:0.961\nIteration: 10556, learning rate: 0.00583, Loss: 0.1900, Accuracy:0.938\nIteration: 10557, learning rate: 0.00583, Loss: 0.1891, Accuracy:0.922\nIteration: 10558, learning rate: 0.00582, Loss: 0.1703, Accuracy:0.953\nIteration: 10559, learning rate: 0.00582, Loss: 0.1136, Accuracy:0.938\nIteration: 10560, learning rate: 0.00582, Loss: 0.2225, Accuracy:0.891\nIteration: 10561, learning rate: 0.00582, Loss: 0.0959, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 10562, learning rate: 0.00582, Loss: 0.0908, Accuracy:0.969\nIteration: 10563, learning rate: 0.00582, Loss: 0.1369, Accuracy:0.953\nIteration: 10564, learning rate: 0.00582, Loss: 0.2103, Accuracy:0.891\nIteration: 10565, learning rate: 0.00582, Loss: 0.1731, Accuracy:0.930\nIteration: 10566, learning rate: 0.00582, Loss: 0.1393, Accuracy:0.945\nIteration: 10567, learning rate: 0.00582, Loss: 0.2816, Accuracy:0.891\nIteration: 10568, learning rate: 0.00582, Loss: 0.1557, Accuracy:0.945\nIteration: 10569, learning rate: 0.00582, Loss: 0.2852, Accuracy:0.898\nIteration: 10570, learning rate: 0.00582, Loss: 0.1307, Accuracy:0.969\nIteration: 10571, learning rate: 0.00582, Loss: 0.1625, Accuracy:0.914\nEpoch: 341, Loss: 0.1732, Accuracy:0.933, Val Loss: 0.2843, Val Accuracy: 0.891\nIteration: 10572, learning rate: 0.00582, Loss: 0.1648, Accuracy:0.930\nIteration: 10573, learning rate: 0.00582, Loss: 0.1935, Accuracy:0.930\nIteration: 10574, learning rate: 0.00582, Loss: 0.1624, Accuracy:0.898\nIteration: 10575, learning rate: 0.00582, Loss: 0.2249, Accuracy:0.914\nIteration: 10576, learning rate: 0.00582, Loss: 0.2330, Accuracy:0.883\nIteration: 10577, learning rate: 0.00582, Loss: 0.1595, Accuracy:0.938\nIteration: 10578, learning rate: 0.00582, Loss: 0.1253, Accuracy:0.961\nIteration: 10579, learning rate: 0.00582, Loss: 0.1666, Accuracy:0.930\nIteration: 10580, learning rate: 0.00582, Loss: 0.2277, Accuracy:0.898\nIteration: 10581, learning rate: 0.00582, Loss: 0.1409, Accuracy:0.938\nIteration: 10582, learning rate: 0.00582, Loss: 0.1592, Accuracy:0.953\nIteration: 10583, learning rate: 0.00582, Loss: 0.1871, Accuracy:0.914\nIteration: 10584, learning rate: 0.00582, Loss: 0.1559, Accuracy:0.938\nIteration: 10585, learning rate: 0.00582, Loss: 0.2298, Accuracy:0.906\nIteration: 10586, learning rate: 0.00582, Loss: 0.1969, Accuracy:0.922\nIteration: 10587, learning rate: 0.00582, Loss: 0.1693, Accuracy:0.945\nIteration: 10588, learning rate: 0.00582, Loss: 0.1850, Accuracy:0.922\nIteration: 10589, learning rate: 0.00582, Loss: 0.1250, Accuracy:0.953\nIteration: 10590, learning rate: 0.00582, Loss: 0.1167, Accuracy:0.938\nIteration: 10591, learning rate: 0.00582, Loss: 0.1738, Accuracy:0.922\nIteration: 10592, learning rate: 0.00582, Loss: 0.2012, Accuracy:0.922\nIteration: 10593, learning rate: 0.00582, Loss: 0.1807, Accuracy:0.938\nIteration: 10594, learning rate: 0.00582, Loss: 0.1414, Accuracy:0.938\nIteration: 10595, learning rate: 0.00582, Loss: 0.1617, Accuracy:0.938\nIteration: 10596, learning rate: 0.00582, Loss: 0.2123, Accuracy:0.914\nIteration: 10597, learning rate: 0.00582, Loss: 0.1645, Accuracy:0.922\nIteration: 10598, learning rate: 0.00582, Loss: 0.1996, Accuracy:0.906\nIteration: 10599, learning rate: 0.00582, Loss: 0.1703, Accuracy:0.930\nIteration: 10600, learning rate: 0.00582, Loss: 0.1281, Accuracy:0.953\nIteration: 10601, learning rate: 0.00582, Loss: 0.1631, Accuracy:0.938\nIteration: 10602, learning rate: 0.00582, Loss: 0.1520, Accuracy:0.935\nEpoch: 342, Loss: 0.1733, Accuracy:0.928, Val Loss: 0.2451, Val Accuracy: 0.903\nIteration: 10603, learning rate: 0.00582, Loss: 0.0927, Accuracy:0.953\nIteration: 10604, learning rate: 0.00582, Loss: 0.2360, Accuracy:0.930\nIteration: 10605, learning rate: 0.00581, Loss: 0.1729, Accuracy:0.930\nIteration: 10606, learning rate: 0.00581, Loss: 0.1801, Accuracy:0.945\nIteration: 10607, learning rate: 0.00581, Loss: 0.2407, Accuracy:0.898\nIteration: 10608, learning rate: 0.00581, Loss: 0.1456, Accuracy:0.938\nIteration: 10609, learning rate: 0.00581, Loss: 0.1839, Accuracy:0.922\nIteration: 10610, learning rate: 0.00581, Loss: 0.1449, Accuracy:0.945\nIteration: 10611, learning rate: 0.00581, Loss: 0.1652, Accuracy:0.945\nIteration: 10612, learning rate: 0.00581, Loss: 0.1675, Accuracy:0.938\nIteration: 10613, learning rate: 0.00581, Loss: 0.1518, Accuracy:0.953\nIteration: 10614, learning rate: 0.00581, Loss: 0.1680, Accuracy:0.914\nIteration: 10615, learning rate: 0.00581, Loss: 0.2006, Accuracy:0.914\nIteration: 10616, learning rate: 0.00581, Loss: 0.2094, Accuracy:0.906\nIteration: 10617, learning rate: 0.00581, Loss: 0.1590, Accuracy:0.945\nIteration: 10618, learning rate: 0.00581, Loss: 0.1852, Accuracy:0.891\nIteration: 10619, learning rate: 0.00581, Loss: 0.1244, Accuracy:0.984\nIteration: 10620, learning rate: 0.00581, Loss: 0.2366, Accuracy:0.867\nIteration: 10621, learning rate: 0.00581, Loss: 0.1307, Accuracy:0.961\nIteration: 10622, learning rate: 0.00581, Loss: 0.1752, Accuracy:0.938\nIteration: 10623, learning rate: 0.00581, Loss: 0.1891, Accuracy:0.914\nIteration: 10624, learning rate: 0.00581, Loss: 0.2313, Accuracy:0.898\nIteration: 10625, learning rate: 0.00581, Loss: 0.1294, Accuracy:0.953\nIteration: 10626, learning rate: 0.00581, Loss: 0.2638, Accuracy:0.906\nIteration: 10627, learning rate: 0.00581, Loss: 0.1726, Accuracy:0.922\nIteration: 10628, learning rate: 0.00581, Loss: 0.1440, Accuracy:0.938\nIteration: 10629, learning rate: 0.00581, Loss: 0.1227, Accuracy:0.961\nIteration: 10630, learning rate: 0.00581, Loss: 0.2010, Accuracy:0.914\nIteration: 10631, learning rate: 0.00581, Loss: 0.1398, Accuracy:0.945\nIteration: 10632, learning rate: 0.00581, Loss: 0.1939, Accuracy:0.922\nIteration: 10633, learning rate: 0.00581, Loss: 0.1301, Accuracy:0.957\nEpoch: 343, Loss: 0.1738, Accuracy:0.931, Val Loss: 0.2638, Val Accuracy: 0.896\nIteration: 10634, learning rate: 0.00581, Loss: 0.1272, Accuracy:0.938\nIteration: 10635, learning rate: 0.00581, Loss: 0.1564, Accuracy:0.938\nIteration: 10636, learning rate: 0.00581, Loss: 0.1280, Accuracy:0.953\nIteration: 10637, learning rate: 0.00581, Loss: 0.1864, Accuracy:0.938\nIteration: 10638, learning rate: 0.00581, Loss: 0.2266, Accuracy:0.891\nIteration: 10639, learning rate: 0.00581, Loss: 0.1818, Accuracy:0.922\nIteration: 10640, learning rate: 0.00581, Loss: 0.1832, Accuracy:0.930\nIteration: 10641, learning rate: 0.00581, Loss: 0.1732, Accuracy:0.930\nIteration: 10642, learning rate: 0.00581, Loss: 0.1419, Accuracy:0.938\nIteration: 10643, learning rate: 0.00581, Loss: 0.1485, Accuracy:0.938\nIteration: 10644, learning rate: 0.00581, Loss: 0.1940, Accuracy:0.930\nIteration: 10645, learning rate: 0.00581, Loss: 0.1729, Accuracy:0.922\nIteration: 10646, learning rate: 0.00581, Loss: 0.0774, Accuracy:0.977\nIteration: 10647, learning rate: 0.00581, Loss: 0.1458, Accuracy:0.953\nIteration: 10648, learning rate: 0.00581, Loss: 0.1275, Accuracy:0.953\nIteration: 10649, learning rate: 0.00581, Loss: 0.2665, Accuracy:0.914\nIteration: 10650, learning rate: 0.00581, Loss: 0.1452, Accuracy:0.945\nIteration: 10651, learning rate: 0.00581, Loss: 0.2553, Accuracy:0.898\nIteration: 10652, learning rate: 0.00580, Loss: 0.2486, Accuracy:0.922\nIteration: 10653, learning rate: 0.00580, Loss: 0.1864, Accuracy:0.906\nIteration: 10654, learning rate: 0.00580, Loss: 0.1134, Accuracy:0.992\nIteration: 10655, learning rate: 0.00580, Loss: 0.2427, Accuracy:0.883\nIteration: 10656, learning rate: 0.00580, Loss: 0.1988, Accuracy:0.930\nIteration: 10657, learning rate: 0.00580, Loss: 0.1473, Accuracy:0.930\nIteration: 10658, learning rate: 0.00580, Loss: 0.2239, Accuracy:0.930\nIteration: 10659, learning rate: 0.00580, Loss: 0.1570, Accuracy:0.953\nIteration: 10660, learning rate: 0.00580, Loss: 0.2565, Accuracy:0.859\nIteration: 10661, learning rate: 0.00580, Loss: 0.0965, Accuracy:0.977\nIteration: 10662, learning rate: 0.00580, Loss: 0.1766, Accuracy:0.914\nIteration: 10663, learning rate: 0.00580, Loss: 0.2288, Accuracy:0.922\nIteration: 10664, learning rate: 0.00580, Loss: 0.2672, Accuracy:0.892\nEpoch: 344, Loss: 0.1800, Accuracy:0.929, Val Loss: 0.3011, Val Accuracy: 0.877\nIteration: 10665, learning rate: 0.00580, Loss: 0.1467, Accuracy:0.953\nIteration: 10666, learning rate: 0.00580, Loss: 0.1710, Accuracy:0.922\nIteration: 10667, learning rate: 0.00580, Loss: 0.1835, Accuracy:0.961\nIteration: 10668, learning rate: 0.00580, Loss: 0.1549, Accuracy:0.938\nIteration: 10669, learning rate: 0.00580, Loss: 0.0748, Accuracy:0.977\nIteration: 10670, learning rate: 0.00580, Loss: 0.1254, Accuracy:0.953\nIteration: 10671, learning rate: 0.00580, Loss: 0.1984, Accuracy:0.914\nIteration: 10672, learning rate: 0.00580, Loss: 0.1999, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 10673, learning rate: 0.00580, Loss: 0.1473, Accuracy:0.953\nIteration: 10674, learning rate: 0.00580, Loss: 0.2195, Accuracy:0.906\nIteration: 10675, learning rate: 0.00580, Loss: 0.1892, Accuracy:0.914\nIteration: 10676, learning rate: 0.00580, Loss: 0.1447, Accuracy:0.969\nIteration: 10677, learning rate: 0.00580, Loss: 0.2582, Accuracy:0.898\nIteration: 10678, learning rate: 0.00580, Loss: 0.1558, Accuracy:0.930\nIteration: 10679, learning rate: 0.00580, Loss: 0.1428, Accuracy:0.945\nIteration: 10680, learning rate: 0.00580, Loss: 0.2151, Accuracy:0.914\nIteration: 10681, learning rate: 0.00580, Loss: 0.1517, Accuracy:0.930\nIteration: 10682, learning rate: 0.00580, Loss: 0.1595, Accuracy:0.922\nIteration: 10683, learning rate: 0.00580, Loss: 0.1978, Accuracy:0.938\nIteration: 10684, learning rate: 0.00580, Loss: 0.2106, Accuracy:0.922\nIteration: 10685, learning rate: 0.00580, Loss: 0.1792, Accuracy:0.938\nIteration: 10686, learning rate: 0.00580, Loss: 0.2180, Accuracy:0.914\nIteration: 10687, learning rate: 0.00580, Loss: 0.1844, Accuracy:0.938\nIteration: 10688, learning rate: 0.00580, Loss: 0.1863, Accuracy:0.898\nIteration: 10689, learning rate: 0.00580, Loss: 0.1545, Accuracy:0.938\nIteration: 10690, learning rate: 0.00580, Loss: 0.2210, Accuracy:0.930\nIteration: 10691, learning rate: 0.00580, Loss: 0.1488, Accuracy:0.938\nIteration: 10692, learning rate: 0.00580, Loss: 0.1451, Accuracy:0.938\nIteration: 10693, learning rate: 0.00580, Loss: 0.1097, Accuracy:0.969\nIteration: 10694, learning rate: 0.00580, Loss: 0.1916, Accuracy:0.898\nIteration: 10695, learning rate: 0.00580, Loss: 0.1800, Accuracy:0.946\nEpoch: 345, Loss: 0.1731, Accuracy:0.933, Val Loss: 0.3152, Val Accuracy: 0.862\nIteration: 10696, learning rate: 0.00580, Loss: 0.1411, Accuracy:0.953\nIteration: 10697, learning rate: 0.00580, Loss: 0.1668, Accuracy:0.945\nIteration: 10698, learning rate: 0.00580, Loss: 0.1927, Accuracy:0.930\nIteration: 10699, learning rate: 0.00580, Loss: 0.2322, Accuracy:0.898\nIteration: 10700, learning rate: 0.00579, Loss: 0.1568, Accuracy:0.938\nIteration: 10701, learning rate: 0.00579, Loss: 0.2044, Accuracy:0.898\nIteration: 10702, learning rate: 0.00579, Loss: 0.1230, Accuracy:0.953\nIteration: 10703, learning rate: 0.00579, Loss: 0.1858, Accuracy:0.930\nIteration: 10704, learning rate: 0.00579, Loss: 0.1824, Accuracy:0.945\nIteration: 10705, learning rate: 0.00579, Loss: 0.2208, Accuracy:0.898\nIteration: 10706, learning rate: 0.00579, Loss: 0.1806, Accuracy:0.914\nIteration: 10707, learning rate: 0.00579, Loss: 0.1366, Accuracy:0.953\nIteration: 10708, learning rate: 0.00579, Loss: 0.1607, Accuracy:0.945\nIteration: 10709, learning rate: 0.00579, Loss: 0.1372, Accuracy:0.938\nIteration: 10710, learning rate: 0.00579, Loss: 0.1682, Accuracy:0.922\nIteration: 10711, learning rate: 0.00579, Loss: 0.1789, Accuracy:0.914\nIteration: 10712, learning rate: 0.00579, Loss: 0.1695, Accuracy:0.914\nIteration: 10713, learning rate: 0.00579, Loss: 0.1812, Accuracy:0.930\nIteration: 10714, learning rate: 0.00579, Loss: 0.1717, Accuracy:0.930\nIteration: 10715, learning rate: 0.00579, Loss: 0.2083, Accuracy:0.914\nIteration: 10716, learning rate: 0.00579, Loss: 0.1267, Accuracy:0.961\nIteration: 10717, learning rate: 0.00579, Loss: 0.1172, Accuracy:0.953\nIteration: 10718, learning rate: 0.00579, Loss: 0.2209, Accuracy:0.914\nIteration: 10719, learning rate: 0.00579, Loss: 0.1652, Accuracy:0.945\nIteration: 10720, learning rate: 0.00579, Loss: 0.1248, Accuracy:0.945\nIteration: 10721, learning rate: 0.00579, Loss: 0.1961, Accuracy:0.898\nIteration: 10722, learning rate: 0.00579, Loss: 0.1638, Accuracy:0.930\nIteration: 10723, learning rate: 0.00579, Loss: 0.3125, Accuracy:0.891\nIteration: 10724, learning rate: 0.00579, Loss: 0.1224, Accuracy:0.953\nIteration: 10725, learning rate: 0.00579, Loss: 0.1506, Accuracy:0.938\nIteration: 10726, learning rate: 0.00579, Loss: 0.1050, Accuracy:0.978\nEpoch: 346, Loss: 0.1711, Accuracy:0.931, Val Loss: 0.3288, Val Accuracy: 0.851\nIteration: 10727, learning rate: 0.00579, Loss: 0.1642, Accuracy:0.930\nIteration: 10728, learning rate: 0.00579, Loss: 0.1677, Accuracy:0.930\nIteration: 10729, learning rate: 0.00579, Loss: 0.0987, Accuracy:0.977\nIteration: 10730, learning rate: 0.00579, Loss: 0.2207, Accuracy:0.898\nIteration: 10731, learning rate: 0.00579, Loss: 0.1853, Accuracy:0.922\nIteration: 10732, learning rate: 0.00579, Loss: 0.1085, Accuracy:0.969\nIteration: 10733, learning rate: 0.00579, Loss: 0.2026, Accuracy:0.930\nIteration: 10734, learning rate: 0.00579, Loss: 0.0851, Accuracy:0.984\nIteration: 10735, learning rate: 0.00579, Loss: 0.1674, Accuracy:0.930\nIteration: 10736, learning rate: 0.00579, Loss: 0.1510, Accuracy:0.930\nIteration: 10737, learning rate: 0.00579, Loss: 0.2311, Accuracy:0.922\nIteration: 10738, learning rate: 0.00579, Loss: 0.1507, Accuracy:0.953\nIteration: 10739, learning rate: 0.00579, Loss: 0.1446, Accuracy:0.953\nIteration: 10740, learning rate: 0.00579, Loss: 0.1534, Accuracy:0.938\nIteration: 10741, learning rate: 0.00579, Loss: 0.2127, Accuracy:0.922\nIteration: 10742, learning rate: 0.00579, Loss: 0.1767, Accuracy:0.922\nIteration: 10743, learning rate: 0.00579, Loss: 0.1644, Accuracy:0.938\nIteration: 10744, learning rate: 0.00579, Loss: 0.2165, Accuracy:0.906\nIteration: 10745, learning rate: 0.00579, Loss: 0.1679, Accuracy:0.922\nIteration: 10746, learning rate: 0.00579, Loss: 0.1450, Accuracy:0.945\nIteration: 10747, learning rate: 0.00578, Loss: 0.1958, Accuracy:0.898\nIteration: 10748, learning rate: 0.00578, Loss: 0.1689, Accuracy:0.953\nIteration: 10749, learning rate: 0.00578, Loss: 0.2362, Accuracy:0.906\nIteration: 10750, learning rate: 0.00578, Loss: 0.1454, Accuracy:0.961\nIteration: 10751, learning rate: 0.00578, Loss: 0.1941, Accuracy:0.930\nIteration: 10752, learning rate: 0.00578, Loss: 0.0937, Accuracy:0.969\nIteration: 10753, learning rate: 0.00578, Loss: 0.1566, Accuracy:0.945\nIteration: 10754, learning rate: 0.00578, Loss: 0.2233, Accuracy:0.875\nIteration: 10755, learning rate: 0.00578, Loss: 0.2182, Accuracy:0.906\nIteration: 10756, learning rate: 0.00578, Loss: 0.1842, Accuracy:0.891\nIteration: 10757, learning rate: 0.00578, Loss: 0.1823, Accuracy:0.892\nEpoch: 347, Loss: 0.1714, Accuracy:0.931, Val Loss: 0.2738, Val Accuracy: 0.888\nIteration: 10758, learning rate: 0.00578, Loss: 0.1693, Accuracy:0.945\nIteration: 10759, learning rate: 0.00578, Loss: 0.1551, Accuracy:0.922\nIteration: 10760, learning rate: 0.00578, Loss: 0.1742, Accuracy:0.922\nIteration: 10761, learning rate: 0.00578, Loss: 0.1821, Accuracy:0.945\nIteration: 10762, learning rate: 0.00578, Loss: 0.1723, Accuracy:0.930\nIteration: 10763, learning rate: 0.00578, Loss: 0.1718, Accuracy:0.922\nIteration: 10764, learning rate: 0.00578, Loss: 0.1700, Accuracy:0.938\nIteration: 10765, learning rate: 0.00578, Loss: 0.1190, Accuracy:0.961\nIteration: 10766, learning rate: 0.00578, Loss: 0.2348, Accuracy:0.875\nIteration: 10767, learning rate: 0.00578, Loss: 0.2317, Accuracy:0.914\nIteration: 10768, learning rate: 0.00578, Loss: 0.2129, Accuracy:0.906\nIteration: 10769, learning rate: 0.00578, Loss: 0.1919, Accuracy:0.891\nIteration: 10770, learning rate: 0.00578, Loss: 0.1305, Accuracy:0.969\nIteration: 10771, learning rate: 0.00578, Loss: 0.2174, Accuracy:0.906\nIteration: 10772, learning rate: 0.00578, Loss: 0.1585, Accuracy:0.945\nIteration: 10773, learning rate: 0.00578, Loss: 0.1750, Accuracy:0.914\nIteration: 10774, learning rate: 0.00578, Loss: 0.1692, Accuracy:0.953\nIteration: 10775, learning rate: 0.00578, Loss: 0.1450, Accuracy:0.938\nIteration: 10776, learning rate: 0.00578, Loss: 0.1589, Accuracy:0.945\nIteration: 10777, learning rate: 0.00578, Loss: 0.1627, Accuracy:0.938\nIteration: 10778, learning rate: 0.00578, Loss: 0.1519, Accuracy:0.953\nIteration: 10779, learning rate: 0.00578, Loss: 0.2597, Accuracy:0.898\nIteration: 10780, learning rate: 0.00578, Loss: 0.2452, Accuracy:0.875\nIteration: 10781, learning rate: 0.00578, Loss: 0.1346, Accuracy:0.953\nIteration: 10782, learning rate: 0.00578, Loss: 0.1539, Accuracy:0.953\nIteration: 10783, learning rate: 0.00578, Loss: 0.1675, Accuracy:0.930\nIteration: 10784, learning rate: 0.00578, Loss: 0.2122, Accuracy:0.898\nIteration: 10785, learning rate: 0.00578, Loss: 0.2148, Accuracy:0.922\nIteration: 10786, learning rate: 0.00578, Loss: 0.1611, Accuracy:0.938\nIteration: 10787, learning rate: 0.00578, Loss: 0.1495, Accuracy:0.945\nIteration: 10788, learning rate: 0.00578, Loss: 0.1502, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 348, Loss: 0.1775, Accuracy:0.928, Val Loss: 0.2168, Val Accuracy: 0.906\nval_loss_decreased from 0.2414 to 0.2168, saving_checkpoint for epoch 348\nIteration: 10789, learning rate: 0.00578, Loss: 0.1201, Accuracy:0.953\nIteration: 10790, learning rate: 0.00578, Loss: 0.1907, Accuracy:0.906\nIteration: 10791, learning rate: 0.00578, Loss: 0.2211, Accuracy:0.922\nIteration: 10792, learning rate: 0.00578, Loss: 0.0988, Accuracy:0.961\nIteration: 10793, learning rate: 0.00578, Loss: 0.1527, Accuracy:0.953\nIteration: 10794, learning rate: 0.00578, Loss: 0.2268, Accuracy:0.922\nIteration: 10795, learning rate: 0.00577, Loss: 0.1622, Accuracy:0.961\nIteration: 10796, learning rate: 0.00577, Loss: 0.2827, Accuracy:0.906\nIteration: 10797, learning rate: 0.00577, Loss: 0.1265, Accuracy:0.945\nIteration: 10798, learning rate: 0.00577, Loss: 0.1846, Accuracy:0.914\nIteration: 10799, learning rate: 0.00577, Loss: 0.1406, Accuracy:0.945\nIteration: 10800, learning rate: 0.00577, Loss: 0.1060, Accuracy:0.969\nIteration: 10801, learning rate: 0.00577, Loss: 0.1314, Accuracy:0.953\nIteration: 10802, learning rate: 0.00577, Loss: 0.1764, Accuracy:0.922\nIteration: 10803, learning rate: 0.00577, Loss: 0.1740, Accuracy:0.945\nIteration: 10804, learning rate: 0.00577, Loss: 0.2215, Accuracy:0.922\nIteration: 10805, learning rate: 0.00577, Loss: 0.1908, Accuracy:0.914\nIteration: 10806, learning rate: 0.00577, Loss: 0.1140, Accuracy:0.969\nIteration: 10807, learning rate: 0.00577, Loss: 0.2246, Accuracy:0.930\nIteration: 10808, learning rate: 0.00577, Loss: 0.1170, Accuracy:0.953\nIteration: 10809, learning rate: 0.00577, Loss: 0.1894, Accuracy:0.922\nIteration: 10810, learning rate: 0.00577, Loss: 0.2099, Accuracy:0.906\nIteration: 10811, learning rate: 0.00577, Loss: 0.1212, Accuracy:0.953\nIteration: 10812, learning rate: 0.00577, Loss: 0.1779, Accuracy:0.922\nIteration: 10813, learning rate: 0.00577, Loss: 0.1645, Accuracy:0.922\nIteration: 10814, learning rate: 0.00577, Loss: 0.0591, Accuracy:0.984\nIteration: 10815, learning rate: 0.00577, Loss: 0.1394, Accuracy:0.961\nIteration: 10816, learning rate: 0.00577, Loss: 0.1219, Accuracy:0.953\nIteration: 10817, learning rate: 0.00577, Loss: 0.1934, Accuracy:0.922\nIteration: 10818, learning rate: 0.00577, Loss: 0.1652, Accuracy:0.930\nIteration: 10819, learning rate: 0.00577, Loss: 0.1330, Accuracy:0.946\nEpoch: 349, Loss: 0.1625, Accuracy:0.938, Val Loss: 0.2997, Val Accuracy: 0.857\nIteration: 10820, learning rate: 0.00577, Loss: 0.1384, Accuracy:0.938\nIteration: 10821, learning rate: 0.00577, Loss: 0.1833, Accuracy:0.945\nIteration: 10822, learning rate: 0.00577, Loss: 0.1210, Accuracy:0.961\nIteration: 10823, learning rate: 0.00577, Loss: 0.1515, Accuracy:0.930\nIteration: 10824, learning rate: 0.00577, Loss: 0.1312, Accuracy:0.945\nIteration: 10825, learning rate: 0.00577, Loss: 0.1216, Accuracy:0.945\nIteration: 10826, learning rate: 0.00577, Loss: 0.1366, Accuracy:0.938\nIteration: 10827, learning rate: 0.00577, Loss: 0.1370, Accuracy:0.945\nIteration: 10828, learning rate: 0.00577, Loss: 0.1271, Accuracy:0.930\nIteration: 10829, learning rate: 0.00577, Loss: 0.1600, Accuracy:0.953\nIteration: 10830, learning rate: 0.00577, Loss: 0.1426, Accuracy:0.938\nIteration: 10831, learning rate: 0.00577, Loss: 0.2211, Accuracy:0.922\nIteration: 10832, learning rate: 0.00577, Loss: 0.1348, Accuracy:0.945\nIteration: 10833, learning rate: 0.00577, Loss: 0.2526, Accuracy:0.898\nIteration: 10834, learning rate: 0.00577, Loss: 0.1250, Accuracy:0.953\nIteration: 10835, learning rate: 0.00577, Loss: 0.1787, Accuracy:0.906\nIteration: 10836, learning rate: 0.00577, Loss: 0.1193, Accuracy:0.961\nIteration: 10837, learning rate: 0.00577, Loss: 0.1670, Accuracy:0.938\nIteration: 10838, learning rate: 0.00577, Loss: 0.1640, Accuracy:0.938\nIteration: 10839, learning rate: 0.00577, Loss: 0.2202, Accuracy:0.914\nIteration: 10840, learning rate: 0.00577, Loss: 0.1663, Accuracy:0.930\nIteration: 10841, learning rate: 0.00577, Loss: 0.0805, Accuracy:0.984\nIteration: 10842, learning rate: 0.00577, Loss: 0.1962, Accuracy:0.922\nIteration: 10843, learning rate: 0.00576, Loss: 0.2036, Accuracy:0.906\nIteration: 10844, learning rate: 0.00576, Loss: 0.1604, Accuracy:0.930\nIteration: 10845, learning rate: 0.00576, Loss: 0.1237, Accuracy:0.953\nIteration: 10846, learning rate: 0.00576, Loss: 0.1919, Accuracy:0.906\nIteration: 10847, learning rate: 0.00576, Loss: 0.1848, Accuracy:0.953\nIteration: 10848, learning rate: 0.00576, Loss: 0.1189, Accuracy:0.961\nIteration: 10849, learning rate: 0.00576, Loss: 0.1979, Accuracy:0.930\nIteration: 10850, learning rate: 0.00576, Loss: 0.2161, Accuracy:0.914\nEpoch: 350, Loss: 0.1604, Accuracy:0.936, Val Loss: 0.2644, Val Accuracy: 0.890\nIteration: 10851, learning rate: 0.00576, Loss: 0.1669, Accuracy:0.938\nIteration: 10852, learning rate: 0.00576, Loss: 0.1618, Accuracy:0.938\nIteration: 10853, learning rate: 0.00576, Loss: 0.1539, Accuracy:0.945\nIteration: 10854, learning rate: 0.00576, Loss: 0.1384, Accuracy:0.961\nIteration: 10855, learning rate: 0.00576, Loss: 0.1276, Accuracy:0.961\nIteration: 10856, learning rate: 0.00576, Loss: 0.1843, Accuracy:0.938\nIteration: 10857, learning rate: 0.00576, Loss: 0.1933, Accuracy:0.930\nIteration: 10858, learning rate: 0.00576, Loss: 0.1108, Accuracy:0.969\nIteration: 10859, learning rate: 0.00576, Loss: 0.1849, Accuracy:0.930\nIteration: 10860, learning rate: 0.00576, Loss: 0.1493, Accuracy:0.922\nIteration: 10861, learning rate: 0.00576, Loss: 0.2386, Accuracy:0.891\nIteration: 10862, learning rate: 0.00576, Loss: 0.1876, Accuracy:0.922\nIteration: 10863, learning rate: 0.00576, Loss: 0.1953, Accuracy:0.891\nIteration: 10864, learning rate: 0.00576, Loss: 0.1438, Accuracy:0.969\nIteration: 10865, learning rate: 0.00576, Loss: 0.1736, Accuracy:0.906\nIteration: 10866, learning rate: 0.00576, Loss: 0.0867, Accuracy:0.953\nIteration: 10867, learning rate: 0.00576, Loss: 0.1346, Accuracy:0.945\nIteration: 10868, learning rate: 0.00576, Loss: 0.1815, Accuracy:0.938\nIteration: 10869, learning rate: 0.00576, Loss: 0.1793, Accuracy:0.938\nIteration: 10870, learning rate: 0.00576, Loss: 0.1261, Accuracy:0.953\nIteration: 10871, learning rate: 0.00576, Loss: 0.1150, Accuracy:0.961\nIteration: 10872, learning rate: 0.00576, Loss: 0.1855, Accuracy:0.938\nIteration: 10873, learning rate: 0.00576, Loss: 0.1956, Accuracy:0.914\nIteration: 10874, learning rate: 0.00576, Loss: 0.1523, Accuracy:0.953\nIteration: 10875, learning rate: 0.00576, Loss: 0.1279, Accuracy:0.953\nIteration: 10876, learning rate: 0.00576, Loss: 0.2745, Accuracy:0.875\nIteration: 10877, learning rate: 0.00576, Loss: 0.1751, Accuracy:0.945\nIteration: 10878, learning rate: 0.00576, Loss: 0.1482, Accuracy:0.961\nIteration: 10879, learning rate: 0.00576, Loss: 0.2461, Accuracy:0.922\nIteration: 10880, learning rate: 0.00576, Loss: 0.1893, Accuracy:0.930\nIteration: 10881, learning rate: 0.00576, Loss: 0.0968, Accuracy:0.957\nEpoch: 351, Loss: 0.1653, Accuracy:0.937, Val Loss: 0.3195, Val Accuracy: 0.878\nIteration: 10882, learning rate: 0.00576, Loss: 0.2144, Accuracy:0.891\nIteration: 10883, learning rate: 0.00576, Loss: 0.1714, Accuracy:0.953\nIteration: 10884, learning rate: 0.00576, Loss: 0.1602, Accuracy:0.961\nIteration: 10885, learning rate: 0.00576, Loss: 0.1191, Accuracy:0.938\nIteration: 10886, learning rate: 0.00576, Loss: 0.1876, Accuracy:0.914\nIteration: 10887, learning rate: 0.00576, Loss: 0.1363, Accuracy:0.953\nIteration: 10888, learning rate: 0.00576, Loss: 0.1307, Accuracy:0.969\nIteration: 10889, learning rate: 0.00576, Loss: 0.2068, Accuracy:0.922\nIteration: 10890, learning rate: 0.00576, Loss: 0.2274, Accuracy:0.930\nIteration: 10891, learning rate: 0.00576, Loss: 0.1662, Accuracy:0.930\nIteration: 10892, learning rate: 0.00575, Loss: 0.2718, Accuracy:0.914\nIteration: 10893, learning rate: 0.00575, Loss: 0.1890, Accuracy:0.906\nIteration: 10894, learning rate: 0.00575, Loss: 0.2208, Accuracy:0.930\nIteration: 10895, learning rate: 0.00575, Loss: 0.1379, Accuracy:0.961\nIteration: 10896, learning rate: 0.00575, Loss: 0.1392, Accuracy:0.922\nIteration: 10897, learning rate: 0.00575, Loss: 0.0910, Accuracy:0.969\nIteration: 10898, learning rate: 0.00575, Loss: 0.1577, Accuracy:0.938\nIteration: 10899, learning rate: 0.00575, Loss: 0.1715, Accuracy:0.914\nIteration: 10900, learning rate: 0.00575, Loss: 0.1684, Accuracy:0.922\nIteration: 10901, learning rate: 0.00575, Loss: 0.1873, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 10902, learning rate: 0.00575, Loss: 0.1463, Accuracy:0.930\nIteration: 10903, learning rate: 0.00575, Loss: 0.1102, Accuracy:0.961\nIteration: 10904, learning rate: 0.00575, Loss: 0.1791, Accuracy:0.938\nIteration: 10905, learning rate: 0.00575, Loss: 0.0982, Accuracy:0.961\nIteration: 10906, learning rate: 0.00575, Loss: 0.1939, Accuracy:0.922\nIteration: 10907, learning rate: 0.00575, Loss: 0.1617, Accuracy:0.922\nIteration: 10908, learning rate: 0.00575, Loss: 0.1325, Accuracy:0.961\nIteration: 10909, learning rate: 0.00575, Loss: 0.2403, Accuracy:0.883\nIteration: 10910, learning rate: 0.00575, Loss: 0.2237, Accuracy:0.922\nIteration: 10911, learning rate: 0.00575, Loss: 0.0945, Accuracy:0.977\nIteration: 10912, learning rate: 0.00575, Loss: 0.1763, Accuracy:0.935\nEpoch: 352, Loss: 0.1681, Accuracy:0.935, Val Loss: 0.3147, Val Accuracy: 0.866\nIteration: 10913, learning rate: 0.00575, Loss: 0.1617, Accuracy:0.906\nIteration: 10914, learning rate: 0.00575, Loss: 0.1199, Accuracy:0.938\nIteration: 10915, learning rate: 0.00575, Loss: 0.1916, Accuracy:0.922\nIteration: 10916, learning rate: 0.00575, Loss: 0.1936, Accuracy:0.891\nIteration: 10917, learning rate: 0.00575, Loss: 0.2459, Accuracy:0.891\nIteration: 10918, learning rate: 0.00575, Loss: 0.1541, Accuracy:0.922\nIteration: 10919, learning rate: 0.00575, Loss: 0.1701, Accuracy:0.945\nIteration: 10920, learning rate: 0.00575, Loss: 0.1607, Accuracy:0.930\nIteration: 10921, learning rate: 0.00575, Loss: 0.1511, Accuracy:0.953\nIteration: 10922, learning rate: 0.00575, Loss: 0.1307, Accuracy:0.961\nIteration: 10923, learning rate: 0.00575, Loss: 0.2009, Accuracy:0.898\nIteration: 10924, learning rate: 0.00575, Loss: 0.2024, Accuracy:0.922\nIteration: 10925, learning rate: 0.00575, Loss: 0.1478, Accuracy:0.938\nIteration: 10926, learning rate: 0.00575, Loss: 0.1527, Accuracy:0.961\nIteration: 10927, learning rate: 0.00575, Loss: 0.1422, Accuracy:0.953\nIteration: 10928, learning rate: 0.00575, Loss: 0.1581, Accuracy:0.961\nIteration: 10929, learning rate: 0.00575, Loss: 0.1338, Accuracy:0.953\nIteration: 10930, learning rate: 0.00575, Loss: 0.1757, Accuracy:0.930\nIteration: 10931, learning rate: 0.00575, Loss: 0.2573, Accuracy:0.883\nIteration: 10932, learning rate: 0.00575, Loss: 0.1748, Accuracy:0.914\nIteration: 10933, learning rate: 0.00575, Loss: 0.1407, Accuracy:0.953\nIteration: 10934, learning rate: 0.00575, Loss: 0.2083, Accuracy:0.922\nIteration: 10935, learning rate: 0.00575, Loss: 0.2451, Accuracy:0.906\nIteration: 10936, learning rate: 0.00575, Loss: 0.1601, Accuracy:0.945\nIteration: 10937, learning rate: 0.00575, Loss: 0.1866, Accuracy:0.922\nIteration: 10938, learning rate: 0.00575, Loss: 0.1309, Accuracy:0.961\nIteration: 10939, learning rate: 0.00575, Loss: 0.1503, Accuracy:0.945\nIteration: 10940, learning rate: 0.00574, Loss: 0.0863, Accuracy:0.984\nIteration: 10941, learning rate: 0.00574, Loss: 0.2350, Accuracy:0.922\nIteration: 10942, learning rate: 0.00574, Loss: 0.1636, Accuracy:0.922\nIteration: 10943, learning rate: 0.00574, Loss: 0.1397, Accuracy:0.957\nEpoch: 353, Loss: 0.1701, Accuracy:0.933, Val Loss: 0.3080, Val Accuracy: 0.866\nIteration: 10944, learning rate: 0.00574, Loss: 0.1628, Accuracy:0.938\nIteration: 10945, learning rate: 0.00574, Loss: 0.1672, Accuracy:0.953\nIteration: 10946, learning rate: 0.00574, Loss: 0.1361, Accuracy:0.930\nIteration: 10947, learning rate: 0.00574, Loss: 0.0993, Accuracy:0.945\nIteration: 10948, learning rate: 0.00574, Loss: 0.1826, Accuracy:0.930\nIteration: 10949, learning rate: 0.00574, Loss: 0.1831, Accuracy:0.938\nIteration: 10950, learning rate: 0.00574, Loss: 0.1062, Accuracy:0.961\nIteration: 10951, learning rate: 0.00574, Loss: 0.1386, Accuracy:0.961\nIteration: 10952, learning rate: 0.00574, Loss: 0.1692, Accuracy:0.945\nIteration: 10953, learning rate: 0.00574, Loss: 0.2105, Accuracy:0.906\nIteration: 10954, learning rate: 0.00574, Loss: 0.1508, Accuracy:0.945\nIteration: 10955, learning rate: 0.00574, Loss: 0.1403, Accuracy:0.969\nIteration: 10956, learning rate: 0.00574, Loss: 0.1230, Accuracy:0.961\nIteration: 10957, learning rate: 0.00574, Loss: 0.1930, Accuracy:0.914\nIteration: 10958, learning rate: 0.00574, Loss: 0.1417, Accuracy:0.930\nIteration: 10959, learning rate: 0.00574, Loss: 0.2273, Accuracy:0.906\nIteration: 10960, learning rate: 0.00574, Loss: 0.0690, Accuracy:0.992\nIteration: 10961, learning rate: 0.00574, Loss: 0.1624, Accuracy:0.938\nIteration: 10962, learning rate: 0.00574, Loss: 0.2043, Accuracy:0.938\nIteration: 10963, learning rate: 0.00574, Loss: 0.2253, Accuracy:0.922\nIteration: 10964, learning rate: 0.00574, Loss: 0.1512, Accuracy:0.922\nIteration: 10965, learning rate: 0.00574, Loss: 0.1868, Accuracy:0.922\nIteration: 10966, learning rate: 0.00574, Loss: 0.2023, Accuracy:0.922\nIteration: 10967, learning rate: 0.00574, Loss: 0.1684, Accuracy:0.953\nIteration: 10968, learning rate: 0.00574, Loss: 0.1632, Accuracy:0.922\nIteration: 10969, learning rate: 0.00574, Loss: 0.2013, Accuracy:0.891\nIteration: 10970, learning rate: 0.00574, Loss: 0.1728, Accuracy:0.930\nIteration: 10971, learning rate: 0.00574, Loss: 0.1605, Accuracy:0.930\nIteration: 10972, learning rate: 0.00574, Loss: 0.2153, Accuracy:0.938\nIteration: 10973, learning rate: 0.00574, Loss: 0.1088, Accuracy:0.953\nIteration: 10974, learning rate: 0.00574, Loss: 0.1510, Accuracy:0.925\nEpoch: 354, Loss: 0.1637, Accuracy:0.936, Val Loss: 0.2458, Val Accuracy: 0.894\nIteration: 10975, learning rate: 0.00574, Loss: 0.1714, Accuracy:0.922\nIteration: 10976, learning rate: 0.00574, Loss: 0.1771, Accuracy:0.922\nIteration: 10977, learning rate: 0.00574, Loss: 0.1973, Accuracy:0.914\nIteration: 10978, learning rate: 0.00574, Loss: 0.1351, Accuracy:0.953\nIteration: 10979, learning rate: 0.00574, Loss: 0.1863, Accuracy:0.930\nIteration: 10980, learning rate: 0.00574, Loss: 0.2418, Accuracy:0.930\nIteration: 10981, learning rate: 0.00574, Loss: 0.2176, Accuracy:0.906\nIteration: 10982, learning rate: 0.00574, Loss: 0.1085, Accuracy:0.961\nIteration: 10983, learning rate: 0.00574, Loss: 0.1439, Accuracy:0.914\nIteration: 10984, learning rate: 0.00574, Loss: 0.2091, Accuracy:0.930\nIteration: 10985, learning rate: 0.00574, Loss: 0.2445, Accuracy:0.938\nIteration: 10986, learning rate: 0.00574, Loss: 0.1305, Accuracy:0.945\nIteration: 10987, learning rate: 0.00574, Loss: 0.1774, Accuracy:0.914\nIteration: 10988, learning rate: 0.00574, Loss: 0.1942, Accuracy:0.922\nIteration: 10989, learning rate: 0.00573, Loss: 0.1451, Accuracy:0.945\nIteration: 10990, learning rate: 0.00573, Loss: 0.1247, Accuracy:0.961\nIteration: 10991, learning rate: 0.00573, Loss: 0.1728, Accuracy:0.930\nIteration: 10992, learning rate: 0.00573, Loss: 0.1727, Accuracy:0.922\nIteration: 10993, learning rate: 0.00573, Loss: 0.1353, Accuracy:0.938\nIteration: 10994, learning rate: 0.00573, Loss: 0.1231, Accuracy:0.953\nIteration: 10995, learning rate: 0.00573, Loss: 0.0849, Accuracy:0.977\nIteration: 10996, learning rate: 0.00573, Loss: 0.1244, Accuracy:0.961\nIteration: 10997, learning rate: 0.00573, Loss: 0.1651, Accuracy:0.938\nIteration: 10998, learning rate: 0.00573, Loss: 0.1439, Accuracy:0.945\nIteration: 10999, learning rate: 0.00573, Loss: 0.1791, Accuracy:0.945\nIteration: 11000, learning rate: 0.00573, Loss: 0.1073, Accuracy:0.961\nIteration: 11001, learning rate: 0.00573, Loss: 0.1391, Accuracy:0.945\nIteration: 11002, learning rate: 0.00573, Loss: 0.1480, Accuracy:0.938\nIteration: 11003, learning rate: 0.00573, Loss: 0.1260, Accuracy:0.938\nIteration: 11004, learning rate: 0.00573, Loss: 0.1715, Accuracy:0.938\nIteration: 11005, learning rate: 0.00573, Loss: 0.1257, Accuracy:0.946\nEpoch: 355, Loss: 0.1588, Accuracy:0.938, Val Loss: 0.2868, Val Accuracy: 0.876\nIteration: 11006, learning rate: 0.00573, Loss: 0.2737, Accuracy:0.906\nIteration: 11007, learning rate: 0.00573, Loss: 0.1047, Accuracy:0.961\nIteration: 11008, learning rate: 0.00573, Loss: 0.1388, Accuracy:0.953\nIteration: 11009, learning rate: 0.00573, Loss: 0.1659, Accuracy:0.922\nIteration: 11010, learning rate: 0.00573, Loss: 0.2431, Accuracy:0.938\nIteration: 11011, learning rate: 0.00573, Loss: 0.1660, Accuracy:0.945\nIteration: 11012, learning rate: 0.00573, Loss: 0.1970, Accuracy:0.898\nIteration: 11013, learning rate: 0.00573, Loss: 0.1827, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11014, learning rate: 0.00573, Loss: 0.2126, Accuracy:0.938\nIteration: 11015, learning rate: 0.00573, Loss: 0.2136, Accuracy:0.914\nIteration: 11016, learning rate: 0.00573, Loss: 0.1780, Accuracy:0.953\nIteration: 11017, learning rate: 0.00573, Loss: 0.1319, Accuracy:0.930\nIteration: 11018, learning rate: 0.00573, Loss: 0.1131, Accuracy:0.961\nIteration: 11019, learning rate: 0.00573, Loss: 0.1152, Accuracy:0.945\nIteration: 11020, learning rate: 0.00573, Loss: 0.1260, Accuracy:0.969\nIteration: 11021, learning rate: 0.00573, Loss: 0.1167, Accuracy:0.961\nIteration: 11022, learning rate: 0.00573, Loss: 0.1686, Accuracy:0.922\nIteration: 11023, learning rate: 0.00573, Loss: 0.2061, Accuracy:0.906\nIteration: 11024, learning rate: 0.00573, Loss: 0.2029, Accuracy:0.906\nIteration: 11025, learning rate: 0.00573, Loss: 0.2054, Accuracy:0.922\nIteration: 11026, learning rate: 0.00573, Loss: 0.1502, Accuracy:0.953\nIteration: 11027, learning rate: 0.00573, Loss: 0.1896, Accuracy:0.922\nIteration: 11028, learning rate: 0.00573, Loss: 0.1539, Accuracy:0.961\nIteration: 11029, learning rate: 0.00573, Loss: 0.1662, Accuracy:0.961\nIteration: 11030, learning rate: 0.00573, Loss: 0.1222, Accuracy:0.961\nIteration: 11031, learning rate: 0.00573, Loss: 0.1518, Accuracy:0.930\nIteration: 11032, learning rate: 0.00573, Loss: 0.1593, Accuracy:0.938\nIteration: 11033, learning rate: 0.00573, Loss: 0.1861, Accuracy:0.938\nIteration: 11034, learning rate: 0.00573, Loss: 0.1830, Accuracy:0.922\nIteration: 11035, learning rate: 0.00573, Loss: 0.1564, Accuracy:0.945\nIteration: 11036, learning rate: 0.00573, Loss: 0.1368, Accuracy:0.957\nEpoch: 356, Loss: 0.1683, Accuracy:0.938, Val Loss: 0.2873, Val Accuracy: 0.867\nIteration: 11037, learning rate: 0.00573, Loss: 0.1876, Accuracy:0.914\nIteration: 11038, learning rate: 0.00572, Loss: 0.1418, Accuracy:0.953\nIteration: 11039, learning rate: 0.00572, Loss: 0.1596, Accuracy:0.938\nIteration: 11040, learning rate: 0.00572, Loss: 0.1028, Accuracy:0.977\nIteration: 11041, learning rate: 0.00572, Loss: 0.1841, Accuracy:0.930\nIteration: 11042, learning rate: 0.00572, Loss: 0.1119, Accuracy:0.945\nIteration: 11043, learning rate: 0.00572, Loss: 0.1156, Accuracy:0.938\nIteration: 11044, learning rate: 0.00572, Loss: 0.1292, Accuracy:0.969\nIteration: 11045, learning rate: 0.00572, Loss: 0.0893, Accuracy:0.984\nIteration: 11046, learning rate: 0.00572, Loss: 0.2045, Accuracy:0.922\nIteration: 11047, learning rate: 0.00572, Loss: 0.0953, Accuracy:0.977\nIteration: 11048, learning rate: 0.00572, Loss: 0.2018, Accuracy:0.930\nIteration: 11049, learning rate: 0.00572, Loss: 0.1291, Accuracy:0.961\nIteration: 11050, learning rate: 0.00572, Loss: 0.1786, Accuracy:0.930\nIteration: 11051, learning rate: 0.00572, Loss: 0.1249, Accuracy:0.953\nIteration: 11052, learning rate: 0.00572, Loss: 0.1507, Accuracy:0.930\nIteration: 11053, learning rate: 0.00572, Loss: 0.1346, Accuracy:0.953\nIteration: 11054, learning rate: 0.00572, Loss: 0.1452, Accuracy:0.938\nIteration: 11055, learning rate: 0.00572, Loss: 0.1395, Accuracy:0.945\nIteration: 11056, learning rate: 0.00572, Loss: 0.1172, Accuracy:0.969\nIteration: 11057, learning rate: 0.00572, Loss: 0.1361, Accuracy:0.953\nIteration: 11058, learning rate: 0.00572, Loss: 0.0926, Accuracy:0.969\nIteration: 11059, learning rate: 0.00572, Loss: 0.1427, Accuracy:0.938\nIteration: 11060, learning rate: 0.00572, Loss: 0.1183, Accuracy:0.953\nIteration: 11061, learning rate: 0.00572, Loss: 0.1713, Accuracy:0.930\nIteration: 11062, learning rate: 0.00572, Loss: 0.1037, Accuracy:0.969\nIteration: 11063, learning rate: 0.00572, Loss: 0.1479, Accuracy:0.930\nIteration: 11064, learning rate: 0.00572, Loss: 0.1732, Accuracy:0.922\nIteration: 11065, learning rate: 0.00572, Loss: 0.1286, Accuracy:0.953\nIteration: 11066, learning rate: 0.00572, Loss: 0.1487, Accuracy:0.945\nIteration: 11067, learning rate: 0.00572, Loss: 0.1784, Accuracy:0.914\nEpoch: 357, Loss: 0.1414, Accuracy:0.946, Val Loss: 0.3291, Val Accuracy: 0.876\nIteration: 11068, learning rate: 0.00572, Loss: 0.1543, Accuracy:0.922\nIteration: 11069, learning rate: 0.00572, Loss: 0.1168, Accuracy:0.945\nIteration: 11070, learning rate: 0.00572, Loss: 0.0817, Accuracy:0.977\nIteration: 11071, learning rate: 0.00572, Loss: 0.2376, Accuracy:0.914\nIteration: 11072, learning rate: 0.00572, Loss: 0.0697, Accuracy:0.984\nIteration: 11073, learning rate: 0.00572, Loss: 0.1690, Accuracy:0.953\nIteration: 11074, learning rate: 0.00572, Loss: 0.1638, Accuracy:0.930\nIteration: 11075, learning rate: 0.00572, Loss: 0.1849, Accuracy:0.930\nIteration: 11076, learning rate: 0.00572, Loss: 0.1693, Accuracy:0.922\nIteration: 11077, learning rate: 0.00572, Loss: 0.2692, Accuracy:0.891\nIteration: 11078, learning rate: 0.00572, Loss: 0.1718, Accuracy:0.914\nIteration: 11079, learning rate: 0.00572, Loss: 0.1813, Accuracy:0.938\nIteration: 11080, learning rate: 0.00572, Loss: 0.1741, Accuracy:0.930\nIteration: 11081, learning rate: 0.00572, Loss: 0.1415, Accuracy:0.953\nIteration: 11082, learning rate: 0.00572, Loss: 0.1913, Accuracy:0.922\nIteration: 11083, learning rate: 0.00572, Loss: 0.1698, Accuracy:0.945\nIteration: 11084, learning rate: 0.00572, Loss: 0.1265, Accuracy:0.945\nIteration: 11085, learning rate: 0.00572, Loss: 0.1501, Accuracy:0.945\nIteration: 11086, learning rate: 0.00572, Loss: 0.1812, Accuracy:0.938\nIteration: 11087, learning rate: 0.00571, Loss: 0.1454, Accuracy:0.961\nIteration: 11088, learning rate: 0.00571, Loss: 0.1745, Accuracy:0.922\nIteration: 11089, learning rate: 0.00571, Loss: 0.1591, Accuracy:0.938\nIteration: 11090, learning rate: 0.00571, Loss: 0.1305, Accuracy:0.945\nIteration: 11091, learning rate: 0.00571, Loss: 0.1959, Accuracy:0.922\nIteration: 11092, learning rate: 0.00571, Loss: 0.1220, Accuracy:0.953\nIteration: 11093, learning rate: 0.00571, Loss: 0.2223, Accuracy:0.906\nIteration: 11094, learning rate: 0.00571, Loss: 0.1391, Accuracy:0.961\nIteration: 11095, learning rate: 0.00571, Loss: 0.1612, Accuracy:0.938\nIteration: 11096, learning rate: 0.00571, Loss: 0.1761, Accuracy:0.945\nIteration: 11097, learning rate: 0.00571, Loss: 0.1392, Accuracy:0.930\nIteration: 11098, learning rate: 0.00571, Loss: 0.1554, Accuracy:0.957\nEpoch: 358, Loss: 0.1621, Accuracy:0.938, Val Loss: 0.3875, Val Accuracy: 0.847\nIteration: 11099, learning rate: 0.00571, Loss: 0.1602, Accuracy:0.930\nIteration: 11100, learning rate: 0.00571, Loss: 0.1780, Accuracy:0.922\nIteration: 11101, learning rate: 0.00571, Loss: 0.1798, Accuracy:0.922\nIteration: 11102, learning rate: 0.00571, Loss: 0.2045, Accuracy:0.898\nIteration: 11103, learning rate: 0.00571, Loss: 0.1316, Accuracy:0.969\nIteration: 11104, learning rate: 0.00571, Loss: 0.1663, Accuracy:0.953\nIteration: 11105, learning rate: 0.00571, Loss: 0.1923, Accuracy:0.938\nIteration: 11106, learning rate: 0.00571, Loss: 0.1574, Accuracy:0.953\nIteration: 11107, learning rate: 0.00571, Loss: 0.1208, Accuracy:0.961\nIteration: 11108, learning rate: 0.00571, Loss: 0.2058, Accuracy:0.914\nIteration: 11109, learning rate: 0.00571, Loss: 0.2000, Accuracy:0.945\nIteration: 11110, learning rate: 0.00571, Loss: 0.1648, Accuracy:0.938\nIteration: 11111, learning rate: 0.00571, Loss: 0.1807, Accuracy:0.945\nIteration: 11112, learning rate: 0.00571, Loss: 0.1009, Accuracy:0.977\nIteration: 11113, learning rate: 0.00571, Loss: 0.2141, Accuracy:0.922\nIteration: 11114, learning rate: 0.00571, Loss: 0.1211, Accuracy:0.945\nIteration: 11115, learning rate: 0.00571, Loss: 0.0904, Accuracy:0.961\nIteration: 11116, learning rate: 0.00571, Loss: 0.1447, Accuracy:0.945\nIteration: 11117, learning rate: 0.00571, Loss: 0.1906, Accuracy:0.930\nIteration: 11118, learning rate: 0.00571, Loss: 0.1822, Accuracy:0.922\nIteration: 11119, learning rate: 0.00571, Loss: 0.1183, Accuracy:0.930\nIteration: 11120, learning rate: 0.00571, Loss: 0.1689, Accuracy:0.938\nIteration: 11121, learning rate: 0.00571, Loss: 0.2704, Accuracy:0.867\nIteration: 11122, learning rate: 0.00571, Loss: 0.2136, Accuracy:0.930\nIteration: 11123, learning rate: 0.00571, Loss: 0.1883, Accuracy:0.914\nIteration: 11124, learning rate: 0.00571, Loss: 0.1504, Accuracy:0.945\nIteration: 11125, learning rate: 0.00571, Loss: 0.2236, Accuracy:0.898\nIteration: 11126, learning rate: 0.00571, Loss: 0.2767, Accuracy:0.867\nIteration: 11127, learning rate: 0.00571, Loss: 0.2243, Accuracy:0.898\nIteration: 11128, learning rate: 0.00571, Loss: 0.1133, Accuracy:0.969\nIteration: 11129, learning rate: 0.00571, Loss: 0.1582, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 359, Loss: 0.1739, Accuracy:0.932, Val Loss: 0.3043, Val Accuracy: 0.872\nIteration: 11130, learning rate: 0.00571, Loss: 0.1481, Accuracy:0.938\nIteration: 11131, learning rate: 0.00571, Loss: 0.1183, Accuracy:0.969\nIteration: 11132, learning rate: 0.00571, Loss: 0.1779, Accuracy:0.938\nIteration: 11133, learning rate: 0.00571, Loss: 0.1929, Accuracy:0.961\nIteration: 11134, learning rate: 0.00571, Loss: 0.1048, Accuracy:0.969\nIteration: 11135, learning rate: 0.00571, Loss: 0.1756, Accuracy:0.938\nIteration: 11136, learning rate: 0.00570, Loss: 0.1581, Accuracy:0.938\nIteration: 11137, learning rate: 0.00570, Loss: 0.2229, Accuracy:0.898\nIteration: 11138, learning rate: 0.00570, Loss: 0.1130, Accuracy:0.969\nIteration: 11139, learning rate: 0.00570, Loss: 0.1151, Accuracy:0.961\nIteration: 11140, learning rate: 0.00570, Loss: 0.1397, Accuracy:0.930\nIteration: 11141, learning rate: 0.00570, Loss: 0.2243, Accuracy:0.914\nIteration: 11142, learning rate: 0.00570, Loss: 0.1639, Accuracy:0.938\nIteration: 11143, learning rate: 0.00570, Loss: 0.1338, Accuracy:0.961\nIteration: 11144, learning rate: 0.00570, Loss: 0.1752, Accuracy:0.914\nIteration: 11145, learning rate: 0.00570, Loss: 0.2054, Accuracy:0.922\nIteration: 11146, learning rate: 0.00570, Loss: 0.2048, Accuracy:0.906\nIteration: 11147, learning rate: 0.00570, Loss: 0.1083, Accuracy:0.961\nIteration: 11148, learning rate: 0.00570, Loss: 0.1707, Accuracy:0.938\nIteration: 11149, learning rate: 0.00570, Loss: 0.2361, Accuracy:0.906\nIteration: 11150, learning rate: 0.00570, Loss: 0.1694, Accuracy:0.922\nIteration: 11151, learning rate: 0.00570, Loss: 0.1518, Accuracy:0.945\nIteration: 11152, learning rate: 0.00570, Loss: 0.1361, Accuracy:0.961\nIteration: 11153, learning rate: 0.00570, Loss: 0.1551, Accuracy:0.922\nIteration: 11154, learning rate: 0.00570, Loss: 0.1263, Accuracy:0.984\nIteration: 11155, learning rate: 0.00570, Loss: 0.1317, Accuracy:0.922\nIteration: 11156, learning rate: 0.00570, Loss: 0.1174, Accuracy:0.969\nIteration: 11157, learning rate: 0.00570, Loss: 0.1704, Accuracy:0.938\nIteration: 11158, learning rate: 0.00570, Loss: 0.1792, Accuracy:0.922\nIteration: 11159, learning rate: 0.00570, Loss: 0.1768, Accuracy:0.938\nIteration: 11160, learning rate: 0.00570, Loss: 0.0987, Accuracy:0.968\nEpoch: 360, Loss: 0.1581, Accuracy:0.940, Val Loss: 0.2748, Val Accuracy: 0.888\nIteration: 11161, learning rate: 0.00570, Loss: 0.1418, Accuracy:0.938\nIteration: 11162, learning rate: 0.00570, Loss: 0.1933, Accuracy:0.922\nIteration: 11163, learning rate: 0.00570, Loss: 0.2172, Accuracy:0.938\nIteration: 11164, learning rate: 0.00570, Loss: 0.1106, Accuracy:0.969\nIteration: 11165, learning rate: 0.00570, Loss: 0.1460, Accuracy:0.930\nIteration: 11166, learning rate: 0.00570, Loss: 0.1436, Accuracy:0.922\nIteration: 11167, learning rate: 0.00570, Loss: 0.1868, Accuracy:0.930\nIteration: 11168, learning rate: 0.00570, Loss: 0.2157, Accuracy:0.922\nIteration: 11169, learning rate: 0.00570, Loss: 0.1361, Accuracy:0.953\nIteration: 11170, learning rate: 0.00570, Loss: 0.1675, Accuracy:0.945\nIteration: 11171, learning rate: 0.00570, Loss: 0.1915, Accuracy:0.922\nIteration: 11172, learning rate: 0.00570, Loss: 0.2292, Accuracy:0.914\nIteration: 11173, learning rate: 0.00570, Loss: 0.3711, Accuracy:0.875\nIteration: 11174, learning rate: 0.00570, Loss: 0.2218, Accuracy:0.914\nIteration: 11175, learning rate: 0.00570, Loss: 0.1467, Accuracy:0.938\nIteration: 11176, learning rate: 0.00570, Loss: 0.1820, Accuracy:0.922\nIteration: 11177, learning rate: 0.00570, Loss: 0.2390, Accuracy:0.914\nIteration: 11178, learning rate: 0.00570, Loss: 0.1580, Accuracy:0.953\nIteration: 11179, learning rate: 0.00570, Loss: 0.1800, Accuracy:0.938\nIteration: 11180, learning rate: 0.00570, Loss: 0.2084, Accuracy:0.938\nIteration: 11181, learning rate: 0.00570, Loss: 0.2036, Accuracy:0.914\nIteration: 11182, learning rate: 0.00570, Loss: 0.1205, Accuracy:0.961\nIteration: 11183, learning rate: 0.00570, Loss: 0.1661, Accuracy:0.938\nIteration: 11184, learning rate: 0.00570, Loss: 0.0789, Accuracy:0.984\nIteration: 11185, learning rate: 0.00570, Loss: 0.1632, Accuracy:0.953\nIteration: 11186, learning rate: 0.00569, Loss: 0.1445, Accuracy:0.938\nIteration: 11187, learning rate: 0.00569, Loss: 0.1384, Accuracy:0.945\nIteration: 11188, learning rate: 0.00569, Loss: 0.1256, Accuracy:0.945\nIteration: 11189, learning rate: 0.00569, Loss: 0.1303, Accuracy:0.961\nIteration: 11190, learning rate: 0.00569, Loss: 0.1467, Accuracy:0.953\nIteration: 11191, learning rate: 0.00569, Loss: 0.2634, Accuracy:0.892\nEpoch: 361, Loss: 0.1764, Accuracy:0.935, Val Loss: 0.3089, Val Accuracy: 0.883\nIteration: 11192, learning rate: 0.00569, Loss: 0.1547, Accuracy:0.938\nIteration: 11193, learning rate: 0.00569, Loss: 0.1718, Accuracy:0.914\nIteration: 11194, learning rate: 0.00569, Loss: 0.1661, Accuracy:0.930\nIteration: 11195, learning rate: 0.00569, Loss: 0.1757, Accuracy:0.953\nIteration: 11196, learning rate: 0.00569, Loss: 0.2516, Accuracy:0.922\nIteration: 11197, learning rate: 0.00569, Loss: 0.2215, Accuracy:0.930\nIteration: 11198, learning rate: 0.00569, Loss: 0.1633, Accuracy:0.945\nIteration: 11199, learning rate: 0.00569, Loss: 0.1593, Accuracy:0.938\nIteration: 11200, learning rate: 0.00569, Loss: 0.1449, Accuracy:0.938\nIteration: 11201, learning rate: 0.00569, Loss: 0.2062, Accuracy:0.906\nIteration: 11202, learning rate: 0.00569, Loss: 0.1154, Accuracy:0.945\nIteration: 11203, learning rate: 0.00569, Loss: 0.1708, Accuracy:0.945\nIteration: 11204, learning rate: 0.00569, Loss: 0.1332, Accuracy:0.953\nIteration: 11205, learning rate: 0.00569, Loss: 0.2184, Accuracy:0.898\nIteration: 11206, learning rate: 0.00569, Loss: 0.1862, Accuracy:0.938\nIteration: 11207, learning rate: 0.00569, Loss: 0.1845, Accuracy:0.930\nIteration: 11208, learning rate: 0.00569, Loss: 0.1614, Accuracy:0.938\nIteration: 11209, learning rate: 0.00569, Loss: 0.1475, Accuracy:0.953\nIteration: 11210, learning rate: 0.00569, Loss: 0.1669, Accuracy:0.922\nIteration: 11211, learning rate: 0.00569, Loss: 0.1433, Accuracy:0.938\nIteration: 11212, learning rate: 0.00569, Loss: 0.1946, Accuracy:0.914\nIteration: 11213, learning rate: 0.00569, Loss: 0.1137, Accuracy:0.969\nIteration: 11214, learning rate: 0.00569, Loss: 0.2092, Accuracy:0.906\nIteration: 11215, learning rate: 0.00569, Loss: 0.1832, Accuracy:0.930\nIteration: 11216, learning rate: 0.00569, Loss: 0.1389, Accuracy:0.961\nIteration: 11217, learning rate: 0.00569, Loss: 0.1205, Accuracy:0.953\nIteration: 11218, learning rate: 0.00569, Loss: 0.1693, Accuracy:0.938\nIteration: 11219, learning rate: 0.00569, Loss: 0.1525, Accuracy:0.922\nIteration: 11220, learning rate: 0.00569, Loss: 0.1392, Accuracy:0.969\nIteration: 11221, learning rate: 0.00569, Loss: 0.1243, Accuracy:0.953\nIteration: 11222, learning rate: 0.00569, Loss: 0.1725, Accuracy:0.935\nEpoch: 362, Loss: 0.1665, Accuracy:0.936, Val Loss: 0.3562, Val Accuracy: 0.871\nIteration: 11223, learning rate: 0.00569, Loss: 0.1950, Accuracy:0.922\nIteration: 11224, learning rate: 0.00569, Loss: 0.1857, Accuracy:0.945\nIteration: 11225, learning rate: 0.00569, Loss: 0.1679, Accuracy:0.938\nIteration: 11226, learning rate: 0.00569, Loss: 0.1705, Accuracy:0.953\nIteration: 11227, learning rate: 0.00569, Loss: 0.1239, Accuracy:0.961\nIteration: 11228, learning rate: 0.00569, Loss: 0.1881, Accuracy:0.914\nIteration: 11229, learning rate: 0.00569, Loss: 0.1156, Accuracy:0.961\nIteration: 11230, learning rate: 0.00569, Loss: 0.1659, Accuracy:0.945\nIteration: 11231, learning rate: 0.00569, Loss: 0.1677, Accuracy:0.906\nIteration: 11232, learning rate: 0.00569, Loss: 0.2109, Accuracy:0.891\nIteration: 11233, learning rate: 0.00569, Loss: 0.1643, Accuracy:0.945\nIteration: 11234, learning rate: 0.00569, Loss: 0.1562, Accuracy:0.945\nIteration: 11235, learning rate: 0.00568, Loss: 0.1479, Accuracy:0.953\nIteration: 11236, learning rate: 0.00568, Loss: 0.1691, Accuracy:0.953\nIteration: 11237, learning rate: 0.00568, Loss: 0.2141, Accuracy:0.914\nIteration: 11238, learning rate: 0.00568, Loss: 0.1851, Accuracy:0.930\nIteration: 11239, learning rate: 0.00568, Loss: 0.1175, Accuracy:0.953\nIteration: 11240, learning rate: 0.00568, Loss: 0.1512, Accuracy:0.938\nIteration: 11241, learning rate: 0.00568, Loss: 0.1863, Accuracy:0.938\nIteration: 11242, learning rate: 0.00568, Loss: 0.0913, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11243, learning rate: 0.00568, Loss: 0.2177, Accuracy:0.945\nIteration: 11244, learning rate: 0.00568, Loss: 0.2204, Accuracy:0.922\nIteration: 11245, learning rate: 0.00568, Loss: 0.1081, Accuracy:0.953\nIteration: 11246, learning rate: 0.00568, Loss: 0.2067, Accuracy:0.922\nIteration: 11247, learning rate: 0.00568, Loss: 0.1581, Accuracy:0.945\nIteration: 11248, learning rate: 0.00568, Loss: 0.1724, Accuracy:0.930\nIteration: 11249, learning rate: 0.00568, Loss: 0.1492, Accuracy:0.945\nIteration: 11250, learning rate: 0.00568, Loss: 0.1883, Accuracy:0.891\nIteration: 11251, learning rate: 0.00568, Loss: 0.1035, Accuracy:0.977\nIteration: 11252, learning rate: 0.00568, Loss: 0.2006, Accuracy:0.906\nIteration: 11253, learning rate: 0.00568, Loss: 0.1112, Accuracy:0.968\nEpoch: 363, Loss: 0.1648, Accuracy:0.938, Val Loss: 0.3222, Val Accuracy: 0.888\nIteration: 11254, learning rate: 0.00568, Loss: 0.1955, Accuracy:0.938\nIteration: 11255, learning rate: 0.00568, Loss: 0.0772, Accuracy:0.977\nIteration: 11256, learning rate: 0.00568, Loss: 0.1219, Accuracy:0.969\nIteration: 11257, learning rate: 0.00568, Loss: 0.1648, Accuracy:0.938\nIteration: 11258, learning rate: 0.00568, Loss: 0.2345, Accuracy:0.891\nIteration: 11259, learning rate: 0.00568, Loss: 0.1322, Accuracy:0.953\nIteration: 11260, learning rate: 0.00568, Loss: 0.1643, Accuracy:0.938\nIteration: 11261, learning rate: 0.00568, Loss: 0.1733, Accuracy:0.922\nIteration: 11262, learning rate: 0.00568, Loss: 0.1109, Accuracy:0.984\nIteration: 11263, learning rate: 0.00568, Loss: 0.1503, Accuracy:0.945\nIteration: 11264, learning rate: 0.00568, Loss: 0.1982, Accuracy:0.938\nIteration: 11265, learning rate: 0.00568, Loss: 0.1727, Accuracy:0.922\nIteration: 11266, learning rate: 0.00568, Loss: 0.1291, Accuracy:0.961\nIteration: 11267, learning rate: 0.00568, Loss: 0.1281, Accuracy:0.977\nIteration: 11268, learning rate: 0.00568, Loss: 0.1849, Accuracy:0.914\nIteration: 11269, learning rate: 0.00568, Loss: 0.2369, Accuracy:0.906\nIteration: 11270, learning rate: 0.00568, Loss: 0.1590, Accuracy:0.945\nIteration: 11271, learning rate: 0.00568, Loss: 0.0845, Accuracy:0.977\nIteration: 11272, learning rate: 0.00568, Loss: 0.1426, Accuracy:0.961\nIteration: 11273, learning rate: 0.00568, Loss: 0.2088, Accuracy:0.938\nIteration: 11274, learning rate: 0.00568, Loss: 0.1957, Accuracy:0.914\nIteration: 11275, learning rate: 0.00568, Loss: 0.1765, Accuracy:0.930\nIteration: 11276, learning rate: 0.00568, Loss: 0.1468, Accuracy:0.961\nIteration: 11277, learning rate: 0.00568, Loss: 0.1841, Accuracy:0.930\nIteration: 11278, learning rate: 0.00568, Loss: 0.1726, Accuracy:0.945\nIteration: 11279, learning rate: 0.00568, Loss: 0.1343, Accuracy:0.953\nIteration: 11280, learning rate: 0.00568, Loss: 0.1475, Accuracy:0.945\nIteration: 11281, learning rate: 0.00568, Loss: 0.1568, Accuracy:0.930\nIteration: 11282, learning rate: 0.00568, Loss: 0.1968, Accuracy:0.906\nIteration: 11283, learning rate: 0.00568, Loss: 0.1801, Accuracy:0.938\nIteration: 11284, learning rate: 0.00568, Loss: 0.2512, Accuracy:0.903\nEpoch: 364, Loss: 0.1649, Accuracy:0.940, Val Loss: 0.2715, Val Accuracy: 0.902\nIteration: 11285, learning rate: 0.00567, Loss: 0.2379, Accuracy:0.891\nIteration: 11286, learning rate: 0.00567, Loss: 0.2473, Accuracy:0.914\nIteration: 11287, learning rate: 0.00567, Loss: 0.1321, Accuracy:0.953\nIteration: 11288, learning rate: 0.00567, Loss: 0.1689, Accuracy:0.930\nIteration: 11289, learning rate: 0.00567, Loss: 0.1802, Accuracy:0.922\nIteration: 11290, learning rate: 0.00567, Loss: 0.1955, Accuracy:0.938\nIteration: 11291, learning rate: 0.00567, Loss: 0.1138, Accuracy:0.969\nIteration: 11292, learning rate: 0.00567, Loss: 0.0940, Accuracy:0.969\nIteration: 11293, learning rate: 0.00567, Loss: 0.1312, Accuracy:0.953\nIteration: 11294, learning rate: 0.00567, Loss: 0.1658, Accuracy:0.945\nIteration: 11295, learning rate: 0.00567, Loss: 0.2733, Accuracy:0.906\nIteration: 11296, learning rate: 0.00567, Loss: 0.2043, Accuracy:0.953\nIteration: 11297, learning rate: 0.00567, Loss: 0.2226, Accuracy:0.938\nIteration: 11298, learning rate: 0.00567, Loss: 0.1432, Accuracy:0.930\nIteration: 11299, learning rate: 0.00567, Loss: 0.1925, Accuracy:0.938\nIteration: 11300, learning rate: 0.00567, Loss: 0.1138, Accuracy:0.953\nIteration: 11301, learning rate: 0.00567, Loss: 0.1700, Accuracy:0.930\nIteration: 11302, learning rate: 0.00567, Loss: 0.2588, Accuracy:0.914\nIteration: 11303, learning rate: 0.00567, Loss: 0.1409, Accuracy:0.945\nIteration: 11304, learning rate: 0.00567, Loss: 0.1554, Accuracy:0.961\nIteration: 11305, learning rate: 0.00567, Loss: 0.0980, Accuracy:0.969\nIteration: 11306, learning rate: 0.00567, Loss: 0.1434, Accuracy:0.930\nIteration: 11307, learning rate: 0.00567, Loss: 0.2026, Accuracy:0.906\nIteration: 11308, learning rate: 0.00567, Loss: 0.1420, Accuracy:0.945\nIteration: 11309, learning rate: 0.00567, Loss: 0.2462, Accuracy:0.906\nIteration: 11310, learning rate: 0.00567, Loss: 0.1437, Accuracy:0.945\nIteration: 11311, learning rate: 0.00567, Loss: 0.1646, Accuracy:0.945\nIteration: 11312, learning rate: 0.00567, Loss: 0.1662, Accuracy:0.945\nIteration: 11313, learning rate: 0.00567, Loss: 0.1981, Accuracy:0.914\nIteration: 11314, learning rate: 0.00567, Loss: 0.2523, Accuracy:0.891\nIteration: 11315, learning rate: 0.00567, Loss: 0.2302, Accuracy:0.925\nEpoch: 365, Loss: 0.1783, Accuracy:0.935, Val Loss: 0.2840, Val Accuracy: 0.872\nIteration: 11316, learning rate: 0.00567, Loss: 0.1120, Accuracy:0.961\nIteration: 11317, learning rate: 0.00567, Loss: 0.2127, Accuracy:0.930\nIteration: 11318, learning rate: 0.00567, Loss: 0.2151, Accuracy:0.914\nIteration: 11319, learning rate: 0.00567, Loss: 0.1708, Accuracy:0.938\nIteration: 11320, learning rate: 0.00567, Loss: 0.1935, Accuracy:0.930\nIteration: 11321, learning rate: 0.00567, Loss: 0.0787, Accuracy:0.969\nIteration: 11322, learning rate: 0.00567, Loss: 0.1303, Accuracy:0.953\nIteration: 11323, learning rate: 0.00567, Loss: 0.1644, Accuracy:0.930\nIteration: 11324, learning rate: 0.00567, Loss: 0.1674, Accuracy:0.930\nIteration: 11325, learning rate: 0.00567, Loss: 0.0991, Accuracy:0.977\nIteration: 11326, learning rate: 0.00567, Loss: 0.1553, Accuracy:0.914\nIteration: 11327, learning rate: 0.00567, Loss: 0.1586, Accuracy:0.945\nIteration: 11328, learning rate: 0.00567, Loss: 0.1988, Accuracy:0.945\nIteration: 11329, learning rate: 0.00567, Loss: 0.1179, Accuracy:0.977\nIteration: 11330, learning rate: 0.00567, Loss: 0.1918, Accuracy:0.922\nIteration: 11331, learning rate: 0.00567, Loss: 0.1741, Accuracy:0.922\nIteration: 11332, learning rate: 0.00567, Loss: 0.2133, Accuracy:0.906\nIteration: 11333, learning rate: 0.00567, Loss: 0.1908, Accuracy:0.922\nIteration: 11334, learning rate: 0.00567, Loss: 0.1584, Accuracy:0.930\nIteration: 11335, learning rate: 0.00566, Loss: 0.1427, Accuracy:0.945\nIteration: 11336, learning rate: 0.00566, Loss: 0.1274, Accuracy:0.961\nIteration: 11337, learning rate: 0.00566, Loss: 0.2350, Accuracy:0.906\nIteration: 11338, learning rate: 0.00566, Loss: 0.1466, Accuracy:0.938\nIteration: 11339, learning rate: 0.00566, Loss: 0.1221, Accuracy:0.961\nIteration: 11340, learning rate: 0.00566, Loss: 0.2170, Accuracy:0.914\nIteration: 11341, learning rate: 0.00566, Loss: 0.1189, Accuracy:0.969\nIteration: 11342, learning rate: 0.00566, Loss: 0.1140, Accuracy:0.961\nIteration: 11343, learning rate: 0.00566, Loss: 0.1368, Accuracy:0.961\nIteration: 11344, learning rate: 0.00566, Loss: 0.1314, Accuracy:0.961\nIteration: 11345, learning rate: 0.00566, Loss: 0.1774, Accuracy:0.938\nIteration: 11346, learning rate: 0.00566, Loss: 0.1849, Accuracy:0.935\nEpoch: 366, Loss: 0.1599, Accuracy:0.941, Val Loss: 0.3079, Val Accuracy: 0.875\nIteration: 11347, learning rate: 0.00566, Loss: 0.1697, Accuracy:0.930\nIteration: 11348, learning rate: 0.00566, Loss: 0.2252, Accuracy:0.914\nIteration: 11349, learning rate: 0.00566, Loss: 0.1325, Accuracy:0.953\nIteration: 11350, learning rate: 0.00566, Loss: 0.1624, Accuracy:0.938\nIteration: 11351, learning rate: 0.00566, Loss: 0.1958, Accuracy:0.906\nIteration: 11352, learning rate: 0.00566, Loss: 0.2123, Accuracy:0.914\nIteration: 11353, learning rate: 0.00566, Loss: 0.0971, Accuracy:0.984\nIteration: 11354, learning rate: 0.00566, Loss: 0.1597, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11355, learning rate: 0.00566, Loss: 0.2105, Accuracy:0.914\nIteration: 11356, learning rate: 0.00566, Loss: 0.1962, Accuracy:0.914\nIteration: 11357, learning rate: 0.00566, Loss: 0.1167, Accuracy:0.961\nIteration: 11358, learning rate: 0.00566, Loss: 0.3141, Accuracy:0.891\nIteration: 11359, learning rate: 0.00566, Loss: 0.1574, Accuracy:0.945\nIteration: 11360, learning rate: 0.00566, Loss: 0.1484, Accuracy:0.969\nIteration: 11361, learning rate: 0.00566, Loss: 0.1553, Accuracy:0.945\nIteration: 11362, learning rate: 0.00566, Loss: 0.2153, Accuracy:0.922\nIteration: 11363, learning rate: 0.00566, Loss: 0.1801, Accuracy:0.930\nIteration: 11364, learning rate: 0.00566, Loss: 0.1978, Accuracy:0.938\nIteration: 11365, learning rate: 0.00566, Loss: 0.1673, Accuracy:0.906\nIteration: 11366, learning rate: 0.00566, Loss: 0.1853, Accuracy:0.938\nIteration: 11367, learning rate: 0.00566, Loss: 0.1260, Accuracy:0.938\nIteration: 11368, learning rate: 0.00566, Loss: 0.2313, Accuracy:0.922\nIteration: 11369, learning rate: 0.00566, Loss: 0.1904, Accuracy:0.930\nIteration: 11370, learning rate: 0.00566, Loss: 0.1651, Accuracy:0.938\nIteration: 11371, learning rate: 0.00566, Loss: 0.1493, Accuracy:0.945\nIteration: 11372, learning rate: 0.00566, Loss: 0.1679, Accuracy:0.945\nIteration: 11373, learning rate: 0.00566, Loss: 0.2134, Accuracy:0.922\nIteration: 11374, learning rate: 0.00566, Loss: 0.1902, Accuracy:0.914\nIteration: 11375, learning rate: 0.00566, Loss: 0.1662, Accuracy:0.938\nIteration: 11376, learning rate: 0.00566, Loss: 0.1944, Accuracy:0.906\nIteration: 11377, learning rate: 0.00566, Loss: 0.0880, Accuracy:0.978\nEpoch: 367, Loss: 0.1768, Accuracy:0.933, Val Loss: 0.3007, Val Accuracy: 0.883\nIteration: 11378, learning rate: 0.00566, Loss: 0.1880, Accuracy:0.906\nIteration: 11379, learning rate: 0.00566, Loss: 0.1051, Accuracy:0.961\nIteration: 11380, learning rate: 0.00566, Loss: 0.1450, Accuracy:0.938\nIteration: 11381, learning rate: 0.00566, Loss: 0.1044, Accuracy:0.961\nIteration: 11382, learning rate: 0.00566, Loss: 0.1735, Accuracy:0.938\nIteration: 11383, learning rate: 0.00566, Loss: 0.1381, Accuracy:0.961\nIteration: 11384, learning rate: 0.00566, Loss: 0.1759, Accuracy:0.914\nIteration: 11385, learning rate: 0.00566, Loss: 0.1576, Accuracy:0.930\nIteration: 11386, learning rate: 0.00565, Loss: 0.1502, Accuracy:0.945\nIteration: 11387, learning rate: 0.00565, Loss: 0.1379, Accuracy:0.930\nIteration: 11388, learning rate: 0.00565, Loss: 0.1383, Accuracy:0.969\nIteration: 11389, learning rate: 0.00565, Loss: 0.1743, Accuracy:0.930\nIteration: 11390, learning rate: 0.00565, Loss: 0.1919, Accuracy:0.930\nIteration: 11391, learning rate: 0.00565, Loss: 0.1093, Accuracy:0.977\nIteration: 11392, learning rate: 0.00565, Loss: 0.1596, Accuracy:0.930\nIteration: 11393, learning rate: 0.00565, Loss: 0.1132, Accuracy:0.969\nIteration: 11394, learning rate: 0.00565, Loss: 0.1467, Accuracy:0.938\nIteration: 11395, learning rate: 0.00565, Loss: 0.1055, Accuracy:0.945\nIteration: 11396, learning rate: 0.00565, Loss: 0.2529, Accuracy:0.898\nIteration: 11397, learning rate: 0.00565, Loss: 0.2024, Accuracy:0.930\nIteration: 11398, learning rate: 0.00565, Loss: 0.2629, Accuracy:0.906\nIteration: 11399, learning rate: 0.00565, Loss: 0.1085, Accuracy:0.945\nIteration: 11400, learning rate: 0.00565, Loss: 0.1367, Accuracy:0.953\nIteration: 11401, learning rate: 0.00565, Loss: 0.1760, Accuracy:0.930\nIteration: 11402, learning rate: 0.00565, Loss: 0.1110, Accuracy:0.961\nIteration: 11403, learning rate: 0.00565, Loss: 0.0882, Accuracy:0.977\nIteration: 11404, learning rate: 0.00565, Loss: 0.1098, Accuracy:0.953\nIteration: 11405, learning rate: 0.00565, Loss: 0.1942, Accuracy:0.930\nIteration: 11406, learning rate: 0.00565, Loss: 0.2234, Accuracy:0.891\nIteration: 11407, learning rate: 0.00565, Loss: 0.1697, Accuracy:0.930\nIteration: 11408, learning rate: 0.00565, Loss: 0.1025, Accuracy:0.968\nEpoch: 368, Loss: 0.1533, Accuracy:0.940, Val Loss: 0.2844, Val Accuracy: 0.885\nIteration: 11409, learning rate: 0.00565, Loss: 0.1964, Accuracy:0.930\nIteration: 11410, learning rate: 0.00565, Loss: 0.1825, Accuracy:0.953\nIteration: 11411, learning rate: 0.00565, Loss: 0.1458, Accuracy:0.953\nIteration: 11412, learning rate: 0.00565, Loss: 0.2046, Accuracy:0.922\nIteration: 11413, learning rate: 0.00565, Loss: 0.1814, Accuracy:0.930\nIteration: 11414, learning rate: 0.00565, Loss: 0.1708, Accuracy:0.945\nIteration: 11415, learning rate: 0.00565, Loss: 0.2320, Accuracy:0.883\nIteration: 11416, learning rate: 0.00565, Loss: 0.2226, Accuracy:0.914\nIteration: 11417, learning rate: 0.00565, Loss: 0.1117, Accuracy:0.961\nIteration: 11418, learning rate: 0.00565, Loss: 0.1943, Accuracy:0.906\nIteration: 11419, learning rate: 0.00565, Loss: 0.1897, Accuracy:0.898\nIteration: 11420, learning rate: 0.00565, Loss: 0.1778, Accuracy:0.938\nIteration: 11421, learning rate: 0.00565, Loss: 0.1312, Accuracy:0.938\nIteration: 11422, learning rate: 0.00565, Loss: 0.2044, Accuracy:0.945\nIteration: 11423, learning rate: 0.00565, Loss: 0.0992, Accuracy:0.961\nIteration: 11424, learning rate: 0.00565, Loss: 0.1240, Accuracy:0.953\nIteration: 11425, learning rate: 0.00565, Loss: 0.2109, Accuracy:0.922\nIteration: 11426, learning rate: 0.00565, Loss: 0.2023, Accuracy:0.922\nIteration: 11427, learning rate: 0.00565, Loss: 0.1435, Accuracy:0.930\nIteration: 11428, learning rate: 0.00565, Loss: 0.1498, Accuracy:0.938\nIteration: 11429, learning rate: 0.00565, Loss: 0.1426, Accuracy:0.953\nIteration: 11430, learning rate: 0.00565, Loss: 0.2142, Accuracy:0.938\nIteration: 11431, learning rate: 0.00565, Loss: 0.1760, Accuracy:0.938\nIteration: 11432, learning rate: 0.00565, Loss: 0.1368, Accuracy:0.938\nIteration: 11433, learning rate: 0.00565, Loss: 0.2189, Accuracy:0.906\nIteration: 11434, learning rate: 0.00565, Loss: 0.1676, Accuracy:0.938\nIteration: 11435, learning rate: 0.00565, Loss: 0.1478, Accuracy:0.945\nIteration: 11436, learning rate: 0.00564, Loss: 0.1888, Accuracy:0.906\nIteration: 11437, learning rate: 0.00564, Loss: 0.1769, Accuracy:0.930\nIteration: 11438, learning rate: 0.00564, Loss: 0.1337, Accuracy:0.961\nIteration: 11439, learning rate: 0.00564, Loss: 0.1504, Accuracy:0.946\nEpoch: 369, Loss: 0.1719, Accuracy:0.933, Val Loss: 0.2671, Val Accuracy: 0.890\nIteration: 11440, learning rate: 0.00564, Loss: 0.1083, Accuracy:0.977\nIteration: 11441, learning rate: 0.00564, Loss: 0.1382, Accuracy:0.969\nIteration: 11442, learning rate: 0.00564, Loss: 0.1623, Accuracy:0.945\nIteration: 11443, learning rate: 0.00564, Loss: 0.1533, Accuracy:0.961\nIteration: 11444, learning rate: 0.00564, Loss: 0.1161, Accuracy:0.961\nIteration: 11445, learning rate: 0.00564, Loss: 0.1711, Accuracy:0.938\nIteration: 11446, learning rate: 0.00564, Loss: 0.1813, Accuracy:0.930\nIteration: 11447, learning rate: 0.00564, Loss: 0.1341, Accuracy:0.953\nIteration: 11448, learning rate: 0.00564, Loss: 0.2714, Accuracy:0.898\nIteration: 11449, learning rate: 0.00564, Loss: 0.2116, Accuracy:0.938\nIteration: 11450, learning rate: 0.00564, Loss: 0.1184, Accuracy:0.961\nIteration: 11451, learning rate: 0.00564, Loss: 0.1065, Accuracy:0.953\nIteration: 11452, learning rate: 0.00564, Loss: 0.1039, Accuracy:0.961\nIteration: 11453, learning rate: 0.00564, Loss: 0.1966, Accuracy:0.898\nIteration: 11454, learning rate: 0.00564, Loss: 0.0926, Accuracy:0.961\nIteration: 11455, learning rate: 0.00564, Loss: 0.2064, Accuracy:0.930\nIteration: 11456, learning rate: 0.00564, Loss: 0.1188, Accuracy:0.961\nIteration: 11457, learning rate: 0.00564, Loss: 0.1181, Accuracy:0.953\nIteration: 11458, learning rate: 0.00564, Loss: 0.1526, Accuracy:0.953\nIteration: 11459, learning rate: 0.00564, Loss: 0.1824, Accuracy:0.930\nIteration: 11460, learning rate: 0.00564, Loss: 0.2509, Accuracy:0.906\nIteration: 11461, learning rate: 0.00564, Loss: 0.1616, Accuracy:0.938\nIteration: 11462, learning rate: 0.00564, Loss: 0.1771, Accuracy:0.938\nIteration: 11463, learning rate: 0.00564, Loss: 0.1379, Accuracy:0.945\nIteration: 11464, learning rate: 0.00564, Loss: 0.1637, Accuracy:0.938\nIteration: 11465, learning rate: 0.00564, Loss: 0.1593, Accuracy:0.945\nIteration: 11466, learning rate: 0.00564, Loss: 0.1411, Accuracy:0.961\nIteration: 11467, learning rate: 0.00564, Loss: 0.1598, Accuracy:0.945\nIteration: 11468, learning rate: 0.00564, Loss: 0.1943, Accuracy:0.930\nIteration: 11469, learning rate: 0.00564, Loss: 0.2111, Accuracy:0.922\nIteration: 11470, learning rate: 0.00564, Loss: 0.1351, Accuracy:0.935\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 370, Loss: 0.1592, Accuracy:0.943, Val Loss: 0.3146, Val Accuracy: 0.864\nIteration: 11471, learning rate: 0.00564, Loss: 0.1600, Accuracy:0.938\nIteration: 11472, learning rate: 0.00564, Loss: 0.0958, Accuracy:0.984\nIteration: 11473, learning rate: 0.00564, Loss: 0.1775, Accuracy:0.922\nIteration: 11474, learning rate: 0.00564, Loss: 0.1752, Accuracy:0.914\nIteration: 11475, learning rate: 0.00564, Loss: 0.1189, Accuracy:0.961\nIteration: 11476, learning rate: 0.00564, Loss: 0.1928, Accuracy:0.922\nIteration: 11477, learning rate: 0.00564, Loss: 0.1919, Accuracy:0.906\nIteration: 11478, learning rate: 0.00564, Loss: 0.1065, Accuracy:0.953\nIteration: 11479, learning rate: 0.00564, Loss: 0.1584, Accuracy:0.922\nIteration: 11480, learning rate: 0.00564, Loss: 0.1455, Accuracy:0.945\nIteration: 11481, learning rate: 0.00564, Loss: 0.2011, Accuracy:0.930\nIteration: 11482, learning rate: 0.00564, Loss: 0.1359, Accuracy:0.938\nIteration: 11483, learning rate: 0.00564, Loss: 0.1717, Accuracy:0.922\nIteration: 11484, learning rate: 0.00564, Loss: 0.2269, Accuracy:0.922\nIteration: 11485, learning rate: 0.00564, Loss: 0.1612, Accuracy:0.930\nIteration: 11486, learning rate: 0.00564, Loss: 0.1753, Accuracy:0.938\nIteration: 11487, learning rate: 0.00563, Loss: 0.2207, Accuracy:0.930\nIteration: 11488, learning rate: 0.00563, Loss: 0.2075, Accuracy:0.906\nIteration: 11489, learning rate: 0.00563, Loss: 0.1327, Accuracy:0.969\nIteration: 11490, learning rate: 0.00563, Loss: 0.1034, Accuracy:0.969\nIteration: 11491, learning rate: 0.00563, Loss: 0.1529, Accuracy:0.945\nIteration: 11492, learning rate: 0.00563, Loss: 0.2206, Accuracy:0.891\nIteration: 11493, learning rate: 0.00563, Loss: 0.1377, Accuracy:0.961\nIteration: 11494, learning rate: 0.00563, Loss: 0.1153, Accuracy:0.977\nIteration: 11495, learning rate: 0.00563, Loss: 0.1229, Accuracy:0.977\nIteration: 11496, learning rate: 0.00563, Loss: 0.1417, Accuracy:0.938\nIteration: 11497, learning rate: 0.00563, Loss: 0.2044, Accuracy:0.906\nIteration: 11498, learning rate: 0.00563, Loss: 0.1378, Accuracy:0.953\nIteration: 11499, learning rate: 0.00563, Loss: 0.1110, Accuracy:0.977\nIteration: 11500, learning rate: 0.00563, Loss: 0.1851, Accuracy:0.930\nIteration: 11501, learning rate: 0.00563, Loss: 0.1098, Accuracy:0.968\nEpoch: 371, Loss: 0.1580, Accuracy:0.940, Val Loss: 0.2926, Val Accuracy: 0.881\nIteration: 11502, learning rate: 0.00563, Loss: 0.2034, Accuracy:0.906\nIteration: 11503, learning rate: 0.00563, Loss: 0.1400, Accuracy:0.930\nIteration: 11504, learning rate: 0.00563, Loss: 0.1372, Accuracy:0.945\nIteration: 11505, learning rate: 0.00563, Loss: 0.1475, Accuracy:0.938\nIteration: 11506, learning rate: 0.00563, Loss: 0.1514, Accuracy:0.945\nIteration: 11507, learning rate: 0.00563, Loss: 0.1794, Accuracy:0.906\nIteration: 11508, learning rate: 0.00563, Loss: 0.0951, Accuracy:0.984\nIteration: 11509, learning rate: 0.00563, Loss: 0.1189, Accuracy:0.938\nIteration: 11510, learning rate: 0.00563, Loss: 0.1073, Accuracy:0.969\nIteration: 11511, learning rate: 0.00563, Loss: 0.2064, Accuracy:0.922\nIteration: 11512, learning rate: 0.00563, Loss: 0.1496, Accuracy:0.930\nIteration: 11513, learning rate: 0.00563, Loss: 0.2348, Accuracy:0.914\nIteration: 11514, learning rate: 0.00563, Loss: 0.1194, Accuracy:0.953\nIteration: 11515, learning rate: 0.00563, Loss: 0.1238, Accuracy:0.969\nIteration: 11516, learning rate: 0.00563, Loss: 0.1289, Accuracy:0.953\nIteration: 11517, learning rate: 0.00563, Loss: 0.1684, Accuracy:0.945\nIteration: 11518, learning rate: 0.00563, Loss: 0.1357, Accuracy:0.930\nIteration: 11519, learning rate: 0.00563, Loss: 0.1878, Accuracy:0.938\nIteration: 11520, learning rate: 0.00563, Loss: 0.1407, Accuracy:0.945\nIteration: 11521, learning rate: 0.00563, Loss: 0.1264, Accuracy:0.961\nIteration: 11522, learning rate: 0.00563, Loss: 0.1483, Accuracy:0.922\nIteration: 11523, learning rate: 0.00563, Loss: 0.1235, Accuracy:0.938\nIteration: 11524, learning rate: 0.00563, Loss: 0.1146, Accuracy:0.953\nIteration: 11525, learning rate: 0.00563, Loss: 0.0713, Accuracy:0.977\nIteration: 11526, learning rate: 0.00563, Loss: 0.1295, Accuracy:0.953\nIteration: 11527, learning rate: 0.00563, Loss: 0.1433, Accuracy:0.961\nIteration: 11528, learning rate: 0.00563, Loss: 0.1901, Accuracy:0.914\nIteration: 11529, learning rate: 0.00563, Loss: 0.1446, Accuracy:0.945\nIteration: 11530, learning rate: 0.00563, Loss: 0.1561, Accuracy:0.930\nIteration: 11531, learning rate: 0.00563, Loss: 0.2004, Accuracy:0.914\nIteration: 11532, learning rate: 0.00563, Loss: 0.1101, Accuracy:0.957\nEpoch: 372, Loss: 0.1462, Accuracy:0.941, Val Loss: 0.3154, Val Accuracy: 0.871\nIteration: 11533, learning rate: 0.00563, Loss: 0.1564, Accuracy:0.961\nIteration: 11534, learning rate: 0.00563, Loss: 0.1055, Accuracy:0.977\nIteration: 11535, learning rate: 0.00563, Loss: 0.1596, Accuracy:0.922\nIteration: 11536, learning rate: 0.00563, Loss: 0.2260, Accuracy:0.922\nIteration: 11537, learning rate: 0.00563, Loss: 0.1495, Accuracy:0.945\nIteration: 11538, learning rate: 0.00562, Loss: 0.1777, Accuracy:0.930\nIteration: 11539, learning rate: 0.00562, Loss: 0.1867, Accuracy:0.914\nIteration: 11540, learning rate: 0.00562, Loss: 0.1983, Accuracy:0.914\nIteration: 11541, learning rate: 0.00562, Loss: 0.1353, Accuracy:0.945\nIteration: 11542, learning rate: 0.00562, Loss: 0.1646, Accuracy:0.914\nIteration: 11543, learning rate: 0.00562, Loss: 0.1458, Accuracy:0.953\nIteration: 11544, learning rate: 0.00562, Loss: 0.0974, Accuracy:0.984\nIteration: 11545, learning rate: 0.00562, Loss: 0.1846, Accuracy:0.930\nIteration: 11546, learning rate: 0.00562, Loss: 0.1029, Accuracy:0.969\nIteration: 11547, learning rate: 0.00562, Loss: 0.1011, Accuracy:0.969\nIteration: 11548, learning rate: 0.00562, Loss: 0.2401, Accuracy:0.906\nIteration: 11549, learning rate: 0.00562, Loss: 0.1505, Accuracy:0.961\nIteration: 11550, learning rate: 0.00562, Loss: 0.1504, Accuracy:0.938\nIteration: 11551, learning rate: 0.00562, Loss: 0.1492, Accuracy:0.953\nIteration: 11552, learning rate: 0.00562, Loss: 0.1682, Accuracy:0.898\nIteration: 11553, learning rate: 0.00562, Loss: 0.1402, Accuracy:0.953\nIteration: 11554, learning rate: 0.00562, Loss: 0.1247, Accuracy:0.961\nIteration: 11555, learning rate: 0.00562, Loss: 0.1407, Accuracy:0.938\nIteration: 11556, learning rate: 0.00562, Loss: 0.1201, Accuracy:0.953\nIteration: 11557, learning rate: 0.00562, Loss: 0.2602, Accuracy:0.898\nIteration: 11558, learning rate: 0.00562, Loss: 0.1554, Accuracy:0.914\nIteration: 11559, learning rate: 0.00562, Loss: 0.1139, Accuracy:0.961\nIteration: 11560, learning rate: 0.00562, Loss: 0.1457, Accuracy:0.953\nIteration: 11561, learning rate: 0.00562, Loss: 0.1964, Accuracy:0.914\nIteration: 11562, learning rate: 0.00562, Loss: 0.1081, Accuracy:0.977\nIteration: 11563, learning rate: 0.00562, Loss: 0.1882, Accuracy:0.914\nEpoch: 373, Loss: 0.1562, Accuracy:0.940, Val Loss: 0.2683, Val Accuracy: 0.891\nIteration: 11564, learning rate: 0.00562, Loss: 0.1690, Accuracy:0.938\nIteration: 11565, learning rate: 0.00562, Loss: 0.1601, Accuracy:0.930\nIteration: 11566, learning rate: 0.00562, Loss: 0.1496, Accuracy:0.945\nIteration: 11567, learning rate: 0.00562, Loss: 0.1434, Accuracy:0.930\nIteration: 11568, learning rate: 0.00562, Loss: 0.1463, Accuracy:0.953\nIteration: 11569, learning rate: 0.00562, Loss: 0.1739, Accuracy:0.938\nIteration: 11570, learning rate: 0.00562, Loss: 0.1656, Accuracy:0.930\nIteration: 11571, learning rate: 0.00562, Loss: 0.1102, Accuracy:0.977\nIteration: 11572, learning rate: 0.00562, Loss: 0.1802, Accuracy:0.930\nIteration: 11573, learning rate: 0.00562, Loss: 0.1910, Accuracy:0.945\nIteration: 11574, learning rate: 0.00562, Loss: 0.1125, Accuracy:0.945\nIteration: 11575, learning rate: 0.00562, Loss: 0.1524, Accuracy:0.953\nIteration: 11576, learning rate: 0.00562, Loss: 0.1788, Accuracy:0.922\nIteration: 11577, learning rate: 0.00562, Loss: 0.2008, Accuracy:0.938\nIteration: 11578, learning rate: 0.00562, Loss: 0.2504, Accuracy:0.906\nIteration: 11579, learning rate: 0.00562, Loss: 0.1329, Accuracy:0.953\nIteration: 11580, learning rate: 0.00562, Loss: 0.1906, Accuracy:0.922\nIteration: 11581, learning rate: 0.00562, Loss: 0.1796, Accuracy:0.906\nIteration: 11582, learning rate: 0.00562, Loss: 0.1472, Accuracy:0.938\nIteration: 11583, learning rate: 0.00562, Loss: 0.1835, Accuracy:0.922\nIteration: 11584, learning rate: 0.00562, Loss: 0.0867, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11585, learning rate: 0.00562, Loss: 0.1385, Accuracy:0.945\nIteration: 11586, learning rate: 0.00562, Loss: 0.2741, Accuracy:0.883\nIteration: 11587, learning rate: 0.00562, Loss: 0.1317, Accuracy:0.961\nIteration: 11588, learning rate: 0.00562, Loss: 0.1412, Accuracy:0.938\nIteration: 11589, learning rate: 0.00561, Loss: 0.1764, Accuracy:0.930\nIteration: 11590, learning rate: 0.00561, Loss: 0.1094, Accuracy:0.969\nIteration: 11591, learning rate: 0.00561, Loss: 0.1601, Accuracy:0.938\nIteration: 11592, learning rate: 0.00561, Loss: 0.1985, Accuracy:0.938\nIteration: 11593, learning rate: 0.00561, Loss: 0.2106, Accuracy:0.930\nIteration: 11594, learning rate: 0.00561, Loss: 0.1516, Accuracy:0.957\nEpoch: 374, Loss: 0.1644, Accuracy:0.938, Val Loss: 0.3184, Val Accuracy: 0.872\nIteration: 11595, learning rate: 0.00561, Loss: 0.1943, Accuracy:0.906\nIteration: 11596, learning rate: 0.00561, Loss: 0.0763, Accuracy:0.977\nIteration: 11597, learning rate: 0.00561, Loss: 0.1026, Accuracy:0.961\nIteration: 11598, learning rate: 0.00561, Loss: 0.1138, Accuracy:0.945\nIteration: 11599, learning rate: 0.00561, Loss: 0.2002, Accuracy:0.930\nIteration: 11600, learning rate: 0.00561, Loss: 0.2269, Accuracy:0.883\nIteration: 11601, learning rate: 0.00561, Loss: 0.2129, Accuracy:0.922\nIteration: 11602, learning rate: 0.00561, Loss: 0.1479, Accuracy:0.938\nIteration: 11603, learning rate: 0.00561, Loss: 0.1662, Accuracy:0.930\nIteration: 11604, learning rate: 0.00561, Loss: 0.1592, Accuracy:0.938\nIteration: 11605, learning rate: 0.00561, Loss: 0.1572, Accuracy:0.961\nIteration: 11606, learning rate: 0.00561, Loss: 0.1568, Accuracy:0.953\nIteration: 11607, learning rate: 0.00561, Loss: 0.1560, Accuracy:0.945\nIteration: 11608, learning rate: 0.00561, Loss: 0.1063, Accuracy:0.953\nIteration: 11609, learning rate: 0.00561, Loss: 0.2064, Accuracy:0.914\nIteration: 11610, learning rate: 0.00561, Loss: 0.1046, Accuracy:0.969\nIteration: 11611, learning rate: 0.00561, Loss: 0.2149, Accuracy:0.906\nIteration: 11612, learning rate: 0.00561, Loss: 0.1218, Accuracy:0.953\nIteration: 11613, learning rate: 0.00561, Loss: 0.1502, Accuracy:0.938\nIteration: 11614, learning rate: 0.00561, Loss: 0.1731, Accuracy:0.922\nIteration: 11615, learning rate: 0.00561, Loss: 0.1637, Accuracy:0.945\nIteration: 11616, learning rate: 0.00561, Loss: 0.1776, Accuracy:0.922\nIteration: 11617, learning rate: 0.00561, Loss: 0.1777, Accuracy:0.922\nIteration: 11618, learning rate: 0.00561, Loss: 0.1188, Accuracy:0.938\nIteration: 11619, learning rate: 0.00561, Loss: 0.1159, Accuracy:0.961\nIteration: 11620, learning rate: 0.00561, Loss: 0.1584, Accuracy:0.945\nIteration: 11621, learning rate: 0.00561, Loss: 0.1109, Accuracy:0.969\nIteration: 11622, learning rate: 0.00561, Loss: 0.2774, Accuracy:0.867\nIteration: 11623, learning rate: 0.00561, Loss: 0.1454, Accuracy:0.953\nIteration: 11624, learning rate: 0.00561, Loss: 0.1124, Accuracy:0.961\nIteration: 11625, learning rate: 0.00561, Loss: 0.2155, Accuracy:0.914\nEpoch: 375, Loss: 0.1588, Accuracy:0.937, Val Loss: 0.3158, Val Accuracy: 0.868\nIteration: 11626, learning rate: 0.00561, Loss: 0.1671, Accuracy:0.953\nIteration: 11627, learning rate: 0.00561, Loss: 0.1981, Accuracy:0.922\nIteration: 11628, learning rate: 0.00561, Loss: 0.2360, Accuracy:0.891\nIteration: 11629, learning rate: 0.00561, Loss: 0.1592, Accuracy:0.930\nIteration: 11630, learning rate: 0.00561, Loss: 0.1618, Accuracy:0.922\nIteration: 11631, learning rate: 0.00561, Loss: 0.1294, Accuracy:0.961\nIteration: 11632, learning rate: 0.00561, Loss: 0.1262, Accuracy:0.945\nIteration: 11633, learning rate: 0.00561, Loss: 0.2277, Accuracy:0.938\nIteration: 11634, learning rate: 0.00561, Loss: 0.1992, Accuracy:0.922\nIteration: 11635, learning rate: 0.00561, Loss: 0.2165, Accuracy:0.922\nIteration: 11636, learning rate: 0.00561, Loss: 0.1208, Accuracy:0.961\nIteration: 11637, learning rate: 0.00561, Loss: 0.1488, Accuracy:0.922\nIteration: 11638, learning rate: 0.00561, Loss: 0.1402, Accuracy:0.945\nIteration: 11639, learning rate: 0.00561, Loss: 0.1886, Accuracy:0.930\nIteration: 11640, learning rate: 0.00560, Loss: 0.1509, Accuracy:0.953\nIteration: 11641, learning rate: 0.00560, Loss: 0.2010, Accuracy:0.922\nIteration: 11642, learning rate: 0.00560, Loss: 0.1978, Accuracy:0.930\nIteration: 11643, learning rate: 0.00560, Loss: 0.1974, Accuracy:0.906\nIteration: 11644, learning rate: 0.00560, Loss: 0.1116, Accuracy:0.953\nIteration: 11645, learning rate: 0.00560, Loss: 0.1354, Accuracy:0.953\nIteration: 11646, learning rate: 0.00560, Loss: 0.1404, Accuracy:0.938\nIteration: 11647, learning rate: 0.00560, Loss: 0.1698, Accuracy:0.945\nIteration: 11648, learning rate: 0.00560, Loss: 0.1469, Accuracy:0.953\nIteration: 11649, learning rate: 0.00560, Loss: 0.1677, Accuracy:0.945\nIteration: 11650, learning rate: 0.00560, Loss: 0.1779, Accuracy:0.938\nIteration: 11651, learning rate: 0.00560, Loss: 0.1321, Accuracy:0.953\nIteration: 11652, learning rate: 0.00560, Loss: 0.1657, Accuracy:0.922\nIteration: 11653, learning rate: 0.00560, Loss: 0.1575, Accuracy:0.945\nIteration: 11654, learning rate: 0.00560, Loss: 0.1641, Accuracy:0.953\nIteration: 11655, learning rate: 0.00560, Loss: 0.1386, Accuracy:0.938\nIteration: 11656, learning rate: 0.00560, Loss: 0.1878, Accuracy:0.925\nEpoch: 376, Loss: 0.1665, Accuracy:0.937, Val Loss: 0.2924, Val Accuracy: 0.881\nIteration: 11657, learning rate: 0.00560, Loss: 0.1278, Accuracy:0.938\nIteration: 11658, learning rate: 0.00560, Loss: 0.1852, Accuracy:0.938\nIteration: 11659, learning rate: 0.00560, Loss: 0.1566, Accuracy:0.945\nIteration: 11660, learning rate: 0.00560, Loss: 0.2779, Accuracy:0.891\nIteration: 11661, learning rate: 0.00560, Loss: 0.1205, Accuracy:0.961\nIteration: 11662, learning rate: 0.00560, Loss: 0.1604, Accuracy:0.945\nIteration: 11663, learning rate: 0.00560, Loss: 0.2404, Accuracy:0.898\nIteration: 11664, learning rate: 0.00560, Loss: 0.1352, Accuracy:0.945\nIteration: 11665, learning rate: 0.00560, Loss: 0.1279, Accuracy:0.969\nIteration: 11666, learning rate: 0.00560, Loss: 0.2402, Accuracy:0.906\nIteration: 11667, learning rate: 0.00560, Loss: 0.2260, Accuracy:0.906\nIteration: 11668, learning rate: 0.00560, Loss: 0.1246, Accuracy:0.961\nIteration: 11669, learning rate: 0.00560, Loss: 0.2318, Accuracy:0.914\nIteration: 11670, learning rate: 0.00560, Loss: 0.1797, Accuracy:0.953\nIteration: 11671, learning rate: 0.00560, Loss: 0.1171, Accuracy:0.961\nIteration: 11672, learning rate: 0.00560, Loss: 0.1134, Accuracy:0.969\nIteration: 11673, learning rate: 0.00560, Loss: 0.1000, Accuracy:0.977\nIteration: 11674, learning rate: 0.00560, Loss: 0.2299, Accuracy:0.906\nIteration: 11675, learning rate: 0.00560, Loss: 0.1356, Accuracy:0.977\nIteration: 11676, learning rate: 0.00560, Loss: 0.2657, Accuracy:0.906\nIteration: 11677, learning rate: 0.00560, Loss: 0.1684, Accuracy:0.938\nIteration: 11678, learning rate: 0.00560, Loss: 0.1446, Accuracy:0.945\nIteration: 11679, learning rate: 0.00560, Loss: 0.1551, Accuracy:0.930\nIteration: 11680, learning rate: 0.00560, Loss: 0.1946, Accuracy:0.930\nIteration: 11681, learning rate: 0.00560, Loss: 0.1573, Accuracy:0.938\nIteration: 11682, learning rate: 0.00560, Loss: 0.1311, Accuracy:0.930\nIteration: 11683, learning rate: 0.00560, Loss: 0.1488, Accuracy:0.938\nIteration: 11684, learning rate: 0.00560, Loss: 0.1738, Accuracy:0.930\nIteration: 11685, learning rate: 0.00560, Loss: 0.1437, Accuracy:0.938\nIteration: 11686, learning rate: 0.00560, Loss: 0.1364, Accuracy:0.945\nIteration: 11687, learning rate: 0.00560, Loss: 0.0905, Accuracy:0.968\nEpoch: 377, Loss: 0.1658, Accuracy:0.938, Val Loss: 0.3271, Val Accuracy: 0.871\nIteration: 11688, learning rate: 0.00560, Loss: 0.1799, Accuracy:0.930\nIteration: 11689, learning rate: 0.00560, Loss: 0.1716, Accuracy:0.922\nIteration: 11690, learning rate: 0.00560, Loss: 0.1362, Accuracy:0.953\nIteration: 11691, learning rate: 0.00560, Loss: 0.1675, Accuracy:0.930\nIteration: 11692, learning rate: 0.00559, Loss: 0.2265, Accuracy:0.906\nIteration: 11693, learning rate: 0.00559, Loss: 0.2907, Accuracy:0.883\nIteration: 11694, learning rate: 0.00559, Loss: 0.2041, Accuracy:0.945\nIteration: 11695, learning rate: 0.00559, Loss: 0.1391, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11696, learning rate: 0.00559, Loss: 0.1420, Accuracy:0.953\nIteration: 11697, learning rate: 0.00559, Loss: 0.1555, Accuracy:0.906\nIteration: 11698, learning rate: 0.00559, Loss: 0.2814, Accuracy:0.906\nIteration: 11699, learning rate: 0.00559, Loss: 0.1065, Accuracy:0.953\nIteration: 11700, learning rate: 0.00559, Loss: 0.1695, Accuracy:0.930\nIteration: 11701, learning rate: 0.00559, Loss: 0.1676, Accuracy:0.938\nIteration: 11702, learning rate: 0.00559, Loss: 0.1117, Accuracy:0.953\nIteration: 11703, learning rate: 0.00559, Loss: 0.1195, Accuracy:0.977\nIteration: 11704, learning rate: 0.00559, Loss: 0.1854, Accuracy:0.930\nIteration: 11705, learning rate: 0.00559, Loss: 0.1952, Accuracy:0.938\nIteration: 11706, learning rate: 0.00559, Loss: 0.1253, Accuracy:0.945\nIteration: 11707, learning rate: 0.00559, Loss: 0.1842, Accuracy:0.914\nIteration: 11708, learning rate: 0.00559, Loss: 0.1551, Accuracy:0.938\nIteration: 11709, learning rate: 0.00559, Loss: 0.2409, Accuracy:0.891\nIteration: 11710, learning rate: 0.00559, Loss: 0.0896, Accuracy:0.977\nIteration: 11711, learning rate: 0.00559, Loss: 0.1829, Accuracy:0.930\nIteration: 11712, learning rate: 0.00559, Loss: 0.1399, Accuracy:0.953\nIteration: 11713, learning rate: 0.00559, Loss: 0.1425, Accuracy:0.930\nIteration: 11714, learning rate: 0.00559, Loss: 0.1543, Accuracy:0.938\nIteration: 11715, learning rate: 0.00559, Loss: 0.1994, Accuracy:0.922\nIteration: 11716, learning rate: 0.00559, Loss: 0.1687, Accuracy:0.922\nIteration: 11717, learning rate: 0.00559, Loss: 0.1703, Accuracy:0.930\nIteration: 11718, learning rate: 0.00559, Loss: 0.1834, Accuracy:0.935\nEpoch: 378, Loss: 0.1705, Accuracy:0.933, Val Loss: 0.3186, Val Accuracy: 0.876\nIteration: 11719, learning rate: 0.00559, Loss: 0.1205, Accuracy:0.938\nIteration: 11720, learning rate: 0.00559, Loss: 0.1587, Accuracy:0.938\nIteration: 11721, learning rate: 0.00559, Loss: 0.1728, Accuracy:0.938\nIteration: 11722, learning rate: 0.00559, Loss: 0.2157, Accuracy:0.906\nIteration: 11723, learning rate: 0.00559, Loss: 0.1661, Accuracy:0.945\nIteration: 11724, learning rate: 0.00559, Loss: 0.1411, Accuracy:0.930\nIteration: 11725, learning rate: 0.00559, Loss: 0.0978, Accuracy:0.961\nIteration: 11726, learning rate: 0.00559, Loss: 0.1946, Accuracy:0.930\nIteration: 11727, learning rate: 0.00559, Loss: 0.1042, Accuracy:0.961\nIteration: 11728, learning rate: 0.00559, Loss: 0.2180, Accuracy:0.906\nIteration: 11729, learning rate: 0.00559, Loss: 0.1276, Accuracy:0.930\nIteration: 11730, learning rate: 0.00559, Loss: 0.1706, Accuracy:0.930\nIteration: 11731, learning rate: 0.00559, Loss: 0.1800, Accuracy:0.922\nIteration: 11732, learning rate: 0.00559, Loss: 0.1656, Accuracy:0.906\nIteration: 11733, learning rate: 0.00559, Loss: 0.0955, Accuracy:0.969\nIteration: 11734, learning rate: 0.00559, Loss: 0.1854, Accuracy:0.953\nIteration: 11735, learning rate: 0.00559, Loss: 0.1424, Accuracy:0.945\nIteration: 11736, learning rate: 0.00559, Loss: 0.1268, Accuracy:0.969\nIteration: 11737, learning rate: 0.00559, Loss: 0.1302, Accuracy:0.945\nIteration: 11738, learning rate: 0.00559, Loss: 0.1736, Accuracy:0.914\nIteration: 11739, learning rate: 0.00559, Loss: 0.1802, Accuracy:0.938\nIteration: 11740, learning rate: 0.00559, Loss: 0.1465, Accuracy:0.953\nIteration: 11741, learning rate: 0.00559, Loss: 0.1786, Accuracy:0.930\nIteration: 11742, learning rate: 0.00559, Loss: 0.1369, Accuracy:0.930\nIteration: 11743, learning rate: 0.00559, Loss: 0.1613, Accuracy:0.953\nIteration: 11744, learning rate: 0.00558, Loss: 0.2031, Accuracy:0.922\nIteration: 11745, learning rate: 0.00558, Loss: 0.1447, Accuracy:0.953\nIteration: 11746, learning rate: 0.00558, Loss: 0.1967, Accuracy:0.922\nIteration: 11747, learning rate: 0.00558, Loss: 0.1270, Accuracy:0.953\nIteration: 11748, learning rate: 0.00558, Loss: 0.1287, Accuracy:0.945\nIteration: 11749, learning rate: 0.00558, Loss: 0.3015, Accuracy:0.892\nEpoch: 379, Loss: 0.1611, Accuracy:0.936, Val Loss: 0.3669, Val Accuracy: 0.854\nIteration: 11750, learning rate: 0.00558, Loss: 0.1946, Accuracy:0.938\nIteration: 11751, learning rate: 0.00558, Loss: 0.2051, Accuracy:0.906\nIteration: 11752, learning rate: 0.00558, Loss: 0.1883, Accuracy:0.930\nIteration: 11753, learning rate: 0.00558, Loss: 0.1844, Accuracy:0.930\nIteration: 11754, learning rate: 0.00558, Loss: 0.1352, Accuracy:0.945\nIteration: 11755, learning rate: 0.00558, Loss: 0.0954, Accuracy:0.977\nIteration: 11756, learning rate: 0.00558, Loss: 0.1066, Accuracy:0.969\nIteration: 11757, learning rate: 0.00558, Loss: 0.2146, Accuracy:0.898\nIteration: 11758, learning rate: 0.00558, Loss: 0.1071, Accuracy:0.969\nIteration: 11759, learning rate: 0.00558, Loss: 0.1233, Accuracy:0.953\nIteration: 11760, learning rate: 0.00558, Loss: 0.1659, Accuracy:0.922\nIteration: 11761, learning rate: 0.00558, Loss: 0.1870, Accuracy:0.906\nIteration: 11762, learning rate: 0.00558, Loss: 0.2227, Accuracy:0.938\nIteration: 11763, learning rate: 0.00558, Loss: 0.1370, Accuracy:0.938\nIteration: 11764, learning rate: 0.00558, Loss: 0.1313, Accuracy:0.969\nIteration: 11765, learning rate: 0.00558, Loss: 0.1265, Accuracy:0.953\nIteration: 11766, learning rate: 0.00558, Loss: 0.1617, Accuracy:0.938\nIteration: 11767, learning rate: 0.00558, Loss: 0.1021, Accuracy:0.969\nIteration: 11768, learning rate: 0.00558, Loss: 0.0991, Accuracy:0.977\nIteration: 11769, learning rate: 0.00558, Loss: 0.1726, Accuracy:0.930\nIteration: 11770, learning rate: 0.00558, Loss: 0.1625, Accuracy:0.930\nIteration: 11771, learning rate: 0.00558, Loss: 0.1794, Accuracy:0.914\nIteration: 11772, learning rate: 0.00558, Loss: 0.1677, Accuracy:0.938\nIteration: 11773, learning rate: 0.00558, Loss: 0.2619, Accuracy:0.906\nIteration: 11774, learning rate: 0.00558, Loss: 0.1122, Accuracy:0.953\nIteration: 11775, learning rate: 0.00558, Loss: 0.2318, Accuracy:0.914\nIteration: 11776, learning rate: 0.00558, Loss: 0.2152, Accuracy:0.914\nIteration: 11777, learning rate: 0.00558, Loss: 0.1823, Accuracy:0.930\nIteration: 11778, learning rate: 0.00558, Loss: 0.2450, Accuracy:0.898\nIteration: 11779, learning rate: 0.00558, Loss: 0.1368, Accuracy:0.938\nIteration: 11780, learning rate: 0.00558, Loss: 0.1783, Accuracy:0.935\nEpoch: 380, Loss: 0.1656, Accuracy:0.936, Val Loss: 0.2809, Val Accuracy: 0.887\nIteration: 11781, learning rate: 0.00558, Loss: 0.2351, Accuracy:0.914\nIteration: 11782, learning rate: 0.00558, Loss: 0.1097, Accuracy:0.961\nIteration: 11783, learning rate: 0.00558, Loss: 0.1678, Accuracy:0.930\nIteration: 11784, learning rate: 0.00558, Loss: 0.2158, Accuracy:0.930\nIteration: 11785, learning rate: 0.00558, Loss: 0.1508, Accuracy:0.945\nIteration: 11786, learning rate: 0.00558, Loss: 0.2054, Accuracy:0.938\nIteration: 11787, learning rate: 0.00558, Loss: 0.1709, Accuracy:0.953\nIteration: 11788, learning rate: 0.00558, Loss: 0.2314, Accuracy:0.891\nIteration: 11789, learning rate: 0.00558, Loss: 0.1649, Accuracy:0.938\nIteration: 11790, learning rate: 0.00558, Loss: 0.2686, Accuracy:0.898\nIteration: 11791, learning rate: 0.00558, Loss: 0.1545, Accuracy:0.945\nIteration: 11792, learning rate: 0.00558, Loss: 0.1274, Accuracy:0.961\nIteration: 11793, learning rate: 0.00558, Loss: 0.1663, Accuracy:0.961\nIteration: 11794, learning rate: 0.00558, Loss: 0.1510, Accuracy:0.945\nIteration: 11795, learning rate: 0.00558, Loss: 0.1552, Accuracy:0.945\nIteration: 11796, learning rate: 0.00557, Loss: 0.1262, Accuracy:0.961\nIteration: 11797, learning rate: 0.00557, Loss: 0.1119, Accuracy:0.969\nIteration: 11798, learning rate: 0.00557, Loss: 0.1833, Accuracy:0.953\nIteration: 11799, learning rate: 0.00557, Loss: 0.1083, Accuracy:0.953\nIteration: 11800, learning rate: 0.00557, Loss: 0.1179, Accuracy:0.945\nIteration: 11801, learning rate: 0.00557, Loss: 0.1432, Accuracy:0.930\nIteration: 11802, learning rate: 0.00557, Loss: 0.1318, Accuracy:0.953\nIteration: 11803, learning rate: 0.00557, Loss: 0.2282, Accuracy:0.906\nIteration: 11804, learning rate: 0.00557, Loss: 0.1811, Accuracy:0.922\nIteration: 11805, learning rate: 0.00557, Loss: 0.1981, Accuracy:0.922\nIteration: 11806, learning rate: 0.00557, Loss: 0.1309, Accuracy:0.930\nIteration: 11807, learning rate: 0.00557, Loss: 0.2926, Accuracy:0.883\nIteration: 11808, learning rate: 0.00557, Loss: 0.1506, Accuracy:0.961\nIteration: 11809, learning rate: 0.00557, Loss: 0.1998, Accuracy:0.914\nIteration: 11810, learning rate: 0.00557, Loss: 0.1264, Accuracy:0.953\nIteration: 11811, learning rate: 0.00557, Loss: 0.0559, Accuracy:1.000\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 381, Loss: 0.1665, Accuracy:0.939, Val Loss: 0.3092, Val Accuracy: 0.874\nIteration: 11812, learning rate: 0.00557, Loss: 0.1466, Accuracy:0.961\nIteration: 11813, learning rate: 0.00557, Loss: 0.1424, Accuracy:0.953\nIteration: 11814, learning rate: 0.00557, Loss: 0.1543, Accuracy:0.930\nIteration: 11815, learning rate: 0.00557, Loss: 0.1470, Accuracy:0.961\nIteration: 11816, learning rate: 0.00557, Loss: 0.2231, Accuracy:0.906\nIteration: 11817, learning rate: 0.00557, Loss: 0.1461, Accuracy:0.930\nIteration: 11818, learning rate: 0.00557, Loss: 0.1743, Accuracy:0.922\nIteration: 11819, learning rate: 0.00557, Loss: 0.2270, Accuracy:0.898\nIteration: 11820, learning rate: 0.00557, Loss: 0.1586, Accuracy:0.938\nIteration: 11821, learning rate: 0.00557, Loss: 0.0955, Accuracy:0.961\nIteration: 11822, learning rate: 0.00557, Loss: 0.1228, Accuracy:0.969\nIteration: 11823, learning rate: 0.00557, Loss: 0.1268, Accuracy:0.953\nIteration: 11824, learning rate: 0.00557, Loss: 0.1315, Accuracy:0.961\nIteration: 11825, learning rate: 0.00557, Loss: 0.2152, Accuracy:0.906\nIteration: 11826, learning rate: 0.00557, Loss: 0.2033, Accuracy:0.883\nIteration: 11827, learning rate: 0.00557, Loss: 0.0808, Accuracy:0.977\nIteration: 11828, learning rate: 0.00557, Loss: 0.1041, Accuracy:0.977\nIteration: 11829, learning rate: 0.00557, Loss: 0.1362, Accuracy:0.938\nIteration: 11830, learning rate: 0.00557, Loss: 0.0854, Accuracy:0.969\nIteration: 11831, learning rate: 0.00557, Loss: 0.1796, Accuracy:0.930\nIteration: 11832, learning rate: 0.00557, Loss: 0.1335, Accuracy:0.938\nIteration: 11833, learning rate: 0.00557, Loss: 0.1407, Accuracy:0.938\nIteration: 11834, learning rate: 0.00557, Loss: 0.0857, Accuracy:0.969\nIteration: 11835, learning rate: 0.00557, Loss: 0.2304, Accuracy:0.906\nIteration: 11836, learning rate: 0.00557, Loss: 0.2086, Accuracy:0.898\nIteration: 11837, learning rate: 0.00557, Loss: 0.1803, Accuracy:0.922\nIteration: 11838, learning rate: 0.00557, Loss: 0.1564, Accuracy:0.961\nIteration: 11839, learning rate: 0.00557, Loss: 0.1253, Accuracy:0.961\nIteration: 11840, learning rate: 0.00557, Loss: 0.2015, Accuracy:0.922\nIteration: 11841, learning rate: 0.00557, Loss: 0.2112, Accuracy:0.922\nIteration: 11842, learning rate: 0.00557, Loss: 0.2004, Accuracy:0.914\nEpoch: 382, Loss: 0.1572, Accuracy:0.938, Val Loss: 0.2727, Val Accuracy: 0.892\nIteration: 11843, learning rate: 0.00557, Loss: 0.1342, Accuracy:0.930\nIteration: 11844, learning rate: 0.00557, Loss: 0.1850, Accuracy:0.930\nIteration: 11845, learning rate: 0.00557, Loss: 0.1519, Accuracy:0.953\nIteration: 11846, learning rate: 0.00557, Loss: 0.1399, Accuracy:0.977\nIteration: 11847, learning rate: 0.00557, Loss: 0.0994, Accuracy:0.953\nIteration: 11848, learning rate: 0.00556, Loss: 0.2363, Accuracy:0.898\nIteration: 11849, learning rate: 0.00556, Loss: 0.1562, Accuracy:0.938\nIteration: 11850, learning rate: 0.00556, Loss: 0.1516, Accuracy:0.938\nIteration: 11851, learning rate: 0.00556, Loss: 0.1198, Accuracy:0.953\nIteration: 11852, learning rate: 0.00556, Loss: 0.1713, Accuracy:0.953\nIteration: 11853, learning rate: 0.00556, Loss: 0.2210, Accuracy:0.906\nIteration: 11854, learning rate: 0.00556, Loss: 0.1684, Accuracy:0.945\nIteration: 11855, learning rate: 0.00556, Loss: 0.1094, Accuracy:0.961\nIteration: 11856, learning rate: 0.00556, Loss: 0.2963, Accuracy:0.891\nIteration: 11857, learning rate: 0.00556, Loss: 0.1592, Accuracy:0.938\nIteration: 11858, learning rate: 0.00556, Loss: 0.1457, Accuracy:0.945\nIteration: 11859, learning rate: 0.00556, Loss: 0.1468, Accuracy:0.945\nIteration: 11860, learning rate: 0.00556, Loss: 0.1828, Accuracy:0.930\nIteration: 11861, learning rate: 0.00556, Loss: 0.1625, Accuracy:0.930\nIteration: 11862, learning rate: 0.00556, Loss: 0.1249, Accuracy:0.961\nIteration: 11863, learning rate: 0.00556, Loss: 0.2233, Accuracy:0.906\nIteration: 11864, learning rate: 0.00556, Loss: 0.2228, Accuracy:0.922\nIteration: 11865, learning rate: 0.00556, Loss: 0.1421, Accuracy:0.961\nIteration: 11866, learning rate: 0.00556, Loss: 0.1415, Accuracy:0.953\nIteration: 11867, learning rate: 0.00556, Loss: 0.1327, Accuracy:0.961\nIteration: 11868, learning rate: 0.00556, Loss: 0.1340, Accuracy:0.945\nIteration: 11869, learning rate: 0.00556, Loss: 0.2766, Accuracy:0.883\nIteration: 11870, learning rate: 0.00556, Loss: 0.1691, Accuracy:0.930\nIteration: 11871, learning rate: 0.00556, Loss: 0.1100, Accuracy:0.953\nIteration: 11872, learning rate: 0.00556, Loss: 0.1650, Accuracy:0.938\nIteration: 11873, learning rate: 0.00556, Loss: 0.1195, Accuracy:0.978\nEpoch: 383, Loss: 0.1645, Accuracy:0.939, Val Loss: 0.3496, Val Accuracy: 0.872\nIteration: 11874, learning rate: 0.00556, Loss: 0.1102, Accuracy:0.922\nIteration: 11875, learning rate: 0.00556, Loss: 0.2101, Accuracy:0.898\nIteration: 11876, learning rate: 0.00556, Loss: 0.1284, Accuracy:0.953\nIteration: 11877, learning rate: 0.00556, Loss: 0.1694, Accuracy:0.930\nIteration: 11878, learning rate: 0.00556, Loss: 0.1023, Accuracy:0.969\nIteration: 11879, learning rate: 0.00556, Loss: 0.1564, Accuracy:0.938\nIteration: 11880, learning rate: 0.00556, Loss: 0.2785, Accuracy:0.898\nIteration: 11881, learning rate: 0.00556, Loss: 0.1671, Accuracy:0.945\nIteration: 11882, learning rate: 0.00556, Loss: 0.1025, Accuracy:0.977\nIteration: 11883, learning rate: 0.00556, Loss: 0.1251, Accuracy:0.938\nIteration: 11884, learning rate: 0.00556, Loss: 0.2547, Accuracy:0.906\nIteration: 11885, learning rate: 0.00556, Loss: 0.1193, Accuracy:0.945\nIteration: 11886, learning rate: 0.00556, Loss: 0.1326, Accuracy:0.930\nIteration: 11887, learning rate: 0.00556, Loss: 0.1630, Accuracy:0.938\nIteration: 11888, learning rate: 0.00556, Loss: 0.1331, Accuracy:0.961\nIteration: 11889, learning rate: 0.00556, Loss: 0.1128, Accuracy:0.961\nIteration: 11890, learning rate: 0.00556, Loss: 0.1052, Accuracy:0.953\nIteration: 11891, learning rate: 0.00556, Loss: 0.1233, Accuracy:0.953\nIteration: 11892, learning rate: 0.00556, Loss: 0.1352, Accuracy:0.961\nIteration: 11893, learning rate: 0.00556, Loss: 0.1008, Accuracy:0.969\nIteration: 11894, learning rate: 0.00556, Loss: 0.1502, Accuracy:0.961\nIteration: 11895, learning rate: 0.00556, Loss: 0.2412, Accuracy:0.914\nIteration: 11896, learning rate: 0.00556, Loss: 0.2008, Accuracy:0.945\nIteration: 11897, learning rate: 0.00556, Loss: 0.1561, Accuracy:0.938\nIteration: 11898, learning rate: 0.00556, Loss: 0.1194, Accuracy:0.945\nIteration: 11899, learning rate: 0.00556, Loss: 0.1629, Accuracy:0.945\nIteration: 11900, learning rate: 0.00555, Loss: 0.1127, Accuracy:0.938\nIteration: 11901, learning rate: 0.00555, Loss: 0.1268, Accuracy:0.961\nIteration: 11902, learning rate: 0.00555, Loss: 0.1990, Accuracy:0.898\nIteration: 11903, learning rate: 0.00555, Loss: 0.1600, Accuracy:0.930\nIteration: 11904, learning rate: 0.00555, Loss: 0.2361, Accuracy:0.914\nEpoch: 384, Loss: 0.1547, Accuracy:0.940, Val Loss: 0.2689, Val Accuracy: 0.890\nIteration: 11905, learning rate: 0.00555, Loss: 0.1262, Accuracy:0.961\nIteration: 11906, learning rate: 0.00555, Loss: 0.1762, Accuracy:0.922\nIteration: 11907, learning rate: 0.00555, Loss: 0.1556, Accuracy:0.969\nIteration: 11908, learning rate: 0.00555, Loss: 0.1712, Accuracy:0.922\nIteration: 11909, learning rate: 0.00555, Loss: 0.2470, Accuracy:0.898\nIteration: 11910, learning rate: 0.00555, Loss: 0.1605, Accuracy:0.930\nIteration: 11911, learning rate: 0.00555, Loss: 0.2280, Accuracy:0.914\nIteration: 11912, learning rate: 0.00555, Loss: 0.1994, Accuracy:0.945\nIteration: 11913, learning rate: 0.00555, Loss: 0.1328, Accuracy:0.953\nIteration: 11914, learning rate: 0.00555, Loss: 0.1721, Accuracy:0.930\nIteration: 11915, learning rate: 0.00555, Loss: 0.2079, Accuracy:0.914\nIteration: 11916, learning rate: 0.00555, Loss: 0.1840, Accuracy:0.906\nIteration: 11917, learning rate: 0.00555, Loss: 0.1517, Accuracy:0.938\nIteration: 11918, learning rate: 0.00555, Loss: 0.2151, Accuracy:0.898\nIteration: 11919, learning rate: 0.00555, Loss: 0.1614, Accuracy:0.930\nIteration: 11920, learning rate: 0.00555, Loss: 0.1103, Accuracy:0.953\nIteration: 11921, learning rate: 0.00555, Loss: 0.2323, Accuracy:0.883\nIteration: 11922, learning rate: 0.00555, Loss: 0.1365, Accuracy:0.945\nIteration: 11923, learning rate: 0.00555, Loss: 0.1111, Accuracy:0.953\nIteration: 11924, learning rate: 0.00555, Loss: 0.0925, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 11925, learning rate: 0.00555, Loss: 0.1698, Accuracy:0.945\nIteration: 11926, learning rate: 0.00555, Loss: 0.1143, Accuracy:0.969\nIteration: 11927, learning rate: 0.00555, Loss: 0.1762, Accuracy:0.938\nIteration: 11928, learning rate: 0.00555, Loss: 0.1914, Accuracy:0.930\nIteration: 11929, learning rate: 0.00555, Loss: 0.1803, Accuracy:0.914\nIteration: 11930, learning rate: 0.00555, Loss: 0.1199, Accuracy:0.969\nIteration: 11931, learning rate: 0.00555, Loss: 0.1988, Accuracy:0.914\nIteration: 11932, learning rate: 0.00555, Loss: 0.1066, Accuracy:0.961\nIteration: 11933, learning rate: 0.00555, Loss: 0.2380, Accuracy:0.914\nIteration: 11934, learning rate: 0.00555, Loss: 0.1535, Accuracy:0.930\nIteration: 11935, learning rate: 0.00555, Loss: 0.1663, Accuracy:0.968\nEpoch: 385, Loss: 0.1673, Accuracy:0.935, Val Loss: 0.2489, Val Accuracy: 0.890\nIteration: 11936, learning rate: 0.00555, Loss: 0.1415, Accuracy:0.938\nIteration: 11937, learning rate: 0.00555, Loss: 0.1401, Accuracy:0.945\nIteration: 11938, learning rate: 0.00555, Loss: 0.0790, Accuracy:0.961\nIteration: 11939, learning rate: 0.00555, Loss: 0.1568, Accuracy:0.961\nIteration: 11940, learning rate: 0.00555, Loss: 0.2127, Accuracy:0.906\nIteration: 11941, learning rate: 0.00555, Loss: 0.1500, Accuracy:0.930\nIteration: 11942, learning rate: 0.00555, Loss: 0.2038, Accuracy:0.914\nIteration: 11943, learning rate: 0.00555, Loss: 0.1876, Accuracy:0.906\nIteration: 11944, learning rate: 0.00555, Loss: 0.2272, Accuracy:0.922\nIteration: 11945, learning rate: 0.00555, Loss: 0.1064, Accuracy:0.953\nIteration: 11946, learning rate: 0.00555, Loss: 0.1247, Accuracy:0.945\nIteration: 11947, learning rate: 0.00555, Loss: 0.1519, Accuracy:0.938\nIteration: 11948, learning rate: 0.00555, Loss: 0.2031, Accuracy:0.914\nIteration: 11949, learning rate: 0.00555, Loss: 0.1289, Accuracy:0.945\nIteration: 11950, learning rate: 0.00555, Loss: 0.1666, Accuracy:0.930\nIteration: 11951, learning rate: 0.00555, Loss: 0.1331, Accuracy:0.961\nIteration: 11952, learning rate: 0.00555, Loss: 0.1343, Accuracy:0.953\nIteration: 11953, learning rate: 0.00554, Loss: 0.1830, Accuracy:0.938\nIteration: 11954, learning rate: 0.00554, Loss: 0.1332, Accuracy:0.953\nIteration: 11955, learning rate: 0.00554, Loss: 0.1968, Accuracy:0.922\nIteration: 11956, learning rate: 0.00554, Loss: 0.1284, Accuracy:0.953\nIteration: 11957, learning rate: 0.00554, Loss: 0.1256, Accuracy:0.945\nIteration: 11958, learning rate: 0.00554, Loss: 0.1240, Accuracy:0.953\nIteration: 11959, learning rate: 0.00554, Loss: 0.1630, Accuracy:0.938\nIteration: 11960, learning rate: 0.00554, Loss: 0.1322, Accuracy:0.961\nIteration: 11961, learning rate: 0.00554, Loss: 0.1192, Accuracy:0.977\nIteration: 11962, learning rate: 0.00554, Loss: 0.1743, Accuracy:0.945\nIteration: 11963, learning rate: 0.00554, Loss: 0.1838, Accuracy:0.930\nIteration: 11964, learning rate: 0.00554, Loss: 0.1000, Accuracy:0.961\nIteration: 11965, learning rate: 0.00554, Loss: 0.1735, Accuracy:0.953\nIteration: 11966, learning rate: 0.00554, Loss: 0.0889, Accuracy:0.957\nEpoch: 386, Loss: 0.1508, Accuracy:0.942, Val Loss: 0.2617, Val Accuracy: 0.895\nIteration: 11967, learning rate: 0.00554, Loss: 0.1330, Accuracy:0.945\nIteration: 11968, learning rate: 0.00554, Loss: 0.1204, Accuracy:0.953\nIteration: 11969, learning rate: 0.00554, Loss: 0.1892, Accuracy:0.922\nIteration: 11970, learning rate: 0.00554, Loss: 0.1921, Accuracy:0.906\nIteration: 11971, learning rate: 0.00554, Loss: 0.1351, Accuracy:0.953\nIteration: 11972, learning rate: 0.00554, Loss: 0.2031, Accuracy:0.898\nIteration: 11973, learning rate: 0.00554, Loss: 0.1617, Accuracy:0.953\nIteration: 11974, learning rate: 0.00554, Loss: 0.1573, Accuracy:0.953\nIteration: 11975, learning rate: 0.00554, Loss: 0.1387, Accuracy:0.930\nIteration: 11976, learning rate: 0.00554, Loss: 0.0880, Accuracy:0.984\nIteration: 11977, learning rate: 0.00554, Loss: 0.0965, Accuracy:0.961\nIteration: 11978, learning rate: 0.00554, Loss: 0.1799, Accuracy:0.930\nIteration: 11979, learning rate: 0.00554, Loss: 0.1644, Accuracy:0.930\nIteration: 11980, learning rate: 0.00554, Loss: 0.1498, Accuracy:0.922\nIteration: 11981, learning rate: 0.00554, Loss: 0.2471, Accuracy:0.914\nIteration: 11982, learning rate: 0.00554, Loss: 0.1820, Accuracy:0.930\nIteration: 11983, learning rate: 0.00554, Loss: 0.1254, Accuracy:0.938\nIteration: 11984, learning rate: 0.00554, Loss: 0.1578, Accuracy:0.930\nIteration: 11985, learning rate: 0.00554, Loss: 0.1091, Accuracy:0.969\nIteration: 11986, learning rate: 0.00554, Loss: 0.1120, Accuracy:0.969\nIteration: 11987, learning rate: 0.00554, Loss: 0.1488, Accuracy:0.930\nIteration: 11988, learning rate: 0.00554, Loss: 0.1734, Accuracy:0.930\nIteration: 11989, learning rate: 0.00554, Loss: 0.1684, Accuracy:0.930\nIteration: 11990, learning rate: 0.00554, Loss: 0.2048, Accuracy:0.922\nIteration: 11991, learning rate: 0.00554, Loss: 0.1573, Accuracy:0.953\nIteration: 11992, learning rate: 0.00554, Loss: 0.1562, Accuracy:0.930\nIteration: 11993, learning rate: 0.00554, Loss: 0.0915, Accuracy:0.984\nIteration: 11994, learning rate: 0.00554, Loss: 0.1410, Accuracy:0.953\nIteration: 11995, learning rate: 0.00554, Loss: 0.1320, Accuracy:0.953\nIteration: 11996, learning rate: 0.00554, Loss: 0.0752, Accuracy:0.984\nIteration: 11997, learning rate: 0.00554, Loss: 0.1870, Accuracy:0.957\nEpoch: 387, Loss: 0.1509, Accuracy:0.942, Val Loss: 0.2701, Val Accuracy: 0.889\nIteration: 11998, learning rate: 0.00554, Loss: 0.2122, Accuracy:0.906\nIteration: 11999, learning rate: 0.00554, Loss: 0.1495, Accuracy:0.938\nIteration: 12000, learning rate: 0.00554, Loss: 0.1501, Accuracy:0.914\nIteration: 12001, learning rate: 0.00554, Loss: 0.2539, Accuracy:0.891\nIteration: 12002, learning rate: 0.00554, Loss: 0.1225, Accuracy:0.977\nIteration: 12003, learning rate: 0.00554, Loss: 0.1854, Accuracy:0.922\nIteration: 12004, learning rate: 0.00554, Loss: 0.0813, Accuracy:0.969\nIteration: 12005, learning rate: 0.00554, Loss: 0.1699, Accuracy:0.953\nIteration: 12006, learning rate: 0.00553, Loss: 0.1328, Accuracy:0.953\nIteration: 12007, learning rate: 0.00553, Loss: 0.1383, Accuracy:0.930\nIteration: 12008, learning rate: 0.00553, Loss: 0.2158, Accuracy:0.898\nIteration: 12009, learning rate: 0.00553, Loss: 0.1003, Accuracy:0.953\nIteration: 12010, learning rate: 0.00553, Loss: 0.1350, Accuracy:0.945\nIteration: 12011, learning rate: 0.00553, Loss: 0.1076, Accuracy:0.953\nIteration: 12012, learning rate: 0.00553, Loss: 0.2082, Accuracy:0.930\nIteration: 12013, learning rate: 0.00553, Loss: 0.1464, Accuracy:0.945\nIteration: 12014, learning rate: 0.00553, Loss: 0.1789, Accuracy:0.945\nIteration: 12015, learning rate: 0.00553, Loss: 0.0996, Accuracy:0.945\nIteration: 12016, learning rate: 0.00553, Loss: 0.1040, Accuracy:0.977\nIteration: 12017, learning rate: 0.00553, Loss: 0.1652, Accuracy:0.930\nIteration: 12018, learning rate: 0.00553, Loss: 0.1834, Accuracy:0.930\nIteration: 12019, learning rate: 0.00553, Loss: 0.1275, Accuracy:0.938\nIteration: 12020, learning rate: 0.00553, Loss: 0.0796, Accuracy:0.984\nIteration: 12021, learning rate: 0.00553, Loss: 0.1279, Accuracy:0.945\nIteration: 12022, learning rate: 0.00553, Loss: 0.1435, Accuracy:0.953\nIteration: 12023, learning rate: 0.00553, Loss: 0.1646, Accuracy:0.930\nIteration: 12024, learning rate: 0.00553, Loss: 0.1791, Accuracy:0.930\nIteration: 12025, learning rate: 0.00553, Loss: 0.1714, Accuracy:0.938\nIteration: 12026, learning rate: 0.00553, Loss: 0.0939, Accuracy:0.969\nIteration: 12027, learning rate: 0.00553, Loss: 0.2102, Accuracy:0.914\nIteration: 12028, learning rate: 0.00553, Loss: 0.1912, Accuracy:0.925\nEpoch: 388, Loss: 0.1526, Accuracy:0.940, Val Loss: 0.2715, Val Accuracy: 0.878\nIteration: 12029, learning rate: 0.00553, Loss: 0.1262, Accuracy:0.961\nIteration: 12030, learning rate: 0.00553, Loss: 0.1484, Accuracy:0.953\nIteration: 12031, learning rate: 0.00553, Loss: 0.1462, Accuracy:0.953\nIteration: 12032, learning rate: 0.00553, Loss: 0.1224, Accuracy:0.969\nIteration: 12033, learning rate: 0.00553, Loss: 0.1635, Accuracy:0.930\nIteration: 12034, learning rate: 0.00553, Loss: 0.1334, Accuracy:0.930\nIteration: 12035, learning rate: 0.00553, Loss: 0.1533, Accuracy:0.945\nIteration: 12036, learning rate: 0.00553, Loss: 0.1133, Accuracy:0.969\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12037, learning rate: 0.00553, Loss: 0.1903, Accuracy:0.922\nIteration: 12038, learning rate: 0.00553, Loss: 0.1250, Accuracy:0.969\nIteration: 12039, learning rate: 0.00553, Loss: 0.1611, Accuracy:0.922\nIteration: 12040, learning rate: 0.00553, Loss: 0.1880, Accuracy:0.930\nIteration: 12041, learning rate: 0.00553, Loss: 0.1610, Accuracy:0.930\nIteration: 12042, learning rate: 0.00553, Loss: 0.1592, Accuracy:0.930\nIteration: 12043, learning rate: 0.00553, Loss: 0.1109, Accuracy:0.961\nIteration: 12044, learning rate: 0.00553, Loss: 0.1696, Accuracy:0.922\nIteration: 12045, learning rate: 0.00553, Loss: 0.1630, Accuracy:0.938\nIteration: 12046, learning rate: 0.00553, Loss: 0.1621, Accuracy:0.938\nIteration: 12047, learning rate: 0.00553, Loss: 0.2282, Accuracy:0.891\nIteration: 12048, learning rate: 0.00553, Loss: 0.1360, Accuracy:0.961\nIteration: 12049, learning rate: 0.00553, Loss: 0.1371, Accuracy:0.953\nIteration: 12050, learning rate: 0.00553, Loss: 0.1893, Accuracy:0.906\nIteration: 12051, learning rate: 0.00553, Loss: 0.0768, Accuracy:0.992\nIteration: 12052, learning rate: 0.00553, Loss: 0.1037, Accuracy:0.961\nIteration: 12053, learning rate: 0.00553, Loss: 0.1235, Accuracy:0.969\nIteration: 12054, learning rate: 0.00553, Loss: 0.1294, Accuracy:0.961\nIteration: 12055, learning rate: 0.00553, Loss: 0.0904, Accuracy:0.961\nIteration: 12056, learning rate: 0.00553, Loss: 0.2368, Accuracy:0.898\nIteration: 12057, learning rate: 0.00553, Loss: 0.1486, Accuracy:0.945\nIteration: 12058, learning rate: 0.00553, Loss: 0.2600, Accuracy:0.867\nIteration: 12059, learning rate: 0.00552, Loss: 0.1905, Accuracy:0.914\nEpoch: 389, Loss: 0.1531, Accuracy:0.940, Val Loss: 0.3271, Val Accuracy: 0.879\nIteration: 12060, learning rate: 0.00552, Loss: 0.1289, Accuracy:0.938\nIteration: 12061, learning rate: 0.00552, Loss: 0.1147, Accuracy:0.945\nIteration: 12062, learning rate: 0.00552, Loss: 0.1625, Accuracy:0.953\nIteration: 12063, learning rate: 0.00552, Loss: 0.1449, Accuracy:0.938\nIteration: 12064, learning rate: 0.00552, Loss: 0.1286, Accuracy:0.953\nIteration: 12065, learning rate: 0.00552, Loss: 0.1546, Accuracy:0.938\nIteration: 12066, learning rate: 0.00552, Loss: 0.1151, Accuracy:0.938\nIteration: 12067, learning rate: 0.00552, Loss: 0.1782, Accuracy:0.930\nIteration: 12068, learning rate: 0.00552, Loss: 0.1922, Accuracy:0.914\nIteration: 12069, learning rate: 0.00552, Loss: 0.2014, Accuracy:0.922\nIteration: 12070, learning rate: 0.00552, Loss: 0.1189, Accuracy:0.953\nIteration: 12071, learning rate: 0.00552, Loss: 0.2353, Accuracy:0.906\nIteration: 12072, learning rate: 0.00552, Loss: 0.1672, Accuracy:0.922\nIteration: 12073, learning rate: 0.00552, Loss: 0.1665, Accuracy:0.945\nIteration: 12074, learning rate: 0.00552, Loss: 0.1072, Accuracy:0.945\nIteration: 12075, learning rate: 0.00552, Loss: 0.1785, Accuracy:0.938\nIteration: 12076, learning rate: 0.00552, Loss: 0.1014, Accuracy:0.953\nIteration: 12077, learning rate: 0.00552, Loss: 0.1193, Accuracy:0.953\nIteration: 12078, learning rate: 0.00552, Loss: 0.1442, Accuracy:0.961\nIteration: 12079, learning rate: 0.00552, Loss: 0.1598, Accuracy:0.930\nIteration: 12080, learning rate: 0.00552, Loss: 0.1648, Accuracy:0.945\nIteration: 12081, learning rate: 0.00552, Loss: 0.2072, Accuracy:0.930\nIteration: 12082, learning rate: 0.00552, Loss: 0.1394, Accuracy:0.945\nIteration: 12083, learning rate: 0.00552, Loss: 0.1954, Accuracy:0.922\nIteration: 12084, learning rate: 0.00552, Loss: 0.1411, Accuracy:0.969\nIteration: 12085, learning rate: 0.00552, Loss: 0.1552, Accuracy:0.945\nIteration: 12086, learning rate: 0.00552, Loss: 0.1373, Accuracy:0.930\nIteration: 12087, learning rate: 0.00552, Loss: 0.2232, Accuracy:0.914\nIteration: 12088, learning rate: 0.00552, Loss: 0.2067, Accuracy:0.945\nIteration: 12089, learning rate: 0.00552, Loss: 0.1516, Accuracy:0.945\nIteration: 12090, learning rate: 0.00552, Loss: 0.1065, Accuracy:0.957\nEpoch: 390, Loss: 0.1564, Accuracy:0.939, Val Loss: 0.2487, Val Accuracy: 0.903\nIteration: 12091, learning rate: 0.00552, Loss: 0.2087, Accuracy:0.938\nIteration: 12092, learning rate: 0.00552, Loss: 0.1282, Accuracy:0.945\nIteration: 12093, learning rate: 0.00552, Loss: 0.1978, Accuracy:0.891\nIteration: 12094, learning rate: 0.00552, Loss: 0.1516, Accuracy:0.945\nIteration: 12095, learning rate: 0.00552, Loss: 0.1301, Accuracy:0.961\nIteration: 12096, learning rate: 0.00552, Loss: 0.0932, Accuracy:0.977\nIteration: 12097, learning rate: 0.00552, Loss: 0.1378, Accuracy:0.945\nIteration: 12098, learning rate: 0.00552, Loss: 0.1566, Accuracy:0.945\nIteration: 12099, learning rate: 0.00552, Loss: 0.1585, Accuracy:0.930\nIteration: 12100, learning rate: 0.00552, Loss: 0.1410, Accuracy:0.945\nIteration: 12101, learning rate: 0.00552, Loss: 0.1562, Accuracy:0.930\nIteration: 12102, learning rate: 0.00552, Loss: 0.1257, Accuracy:0.953\nIteration: 12103, learning rate: 0.00552, Loss: 0.1525, Accuracy:0.945\nIteration: 12104, learning rate: 0.00552, Loss: 0.1320, Accuracy:0.945\nIteration: 12105, learning rate: 0.00552, Loss: 0.1291, Accuracy:0.953\nIteration: 12106, learning rate: 0.00552, Loss: 0.1468, Accuracy:0.930\nIteration: 12107, learning rate: 0.00552, Loss: 0.1873, Accuracy:0.922\nIteration: 12108, learning rate: 0.00552, Loss: 0.1446, Accuracy:0.953\nIteration: 12109, learning rate: 0.00552, Loss: 0.1887, Accuracy:0.945\nIteration: 12110, learning rate: 0.00552, Loss: 0.1880, Accuracy:0.922\nIteration: 12111, learning rate: 0.00552, Loss: 0.1210, Accuracy:0.969\nIteration: 12112, learning rate: 0.00551, Loss: 0.1604, Accuracy:0.938\nIteration: 12113, learning rate: 0.00551, Loss: 0.2204, Accuracy:0.930\nIteration: 12114, learning rate: 0.00551, Loss: 0.1374, Accuracy:0.945\nIteration: 12115, learning rate: 0.00551, Loss: 0.1460, Accuracy:0.961\nIteration: 12116, learning rate: 0.00551, Loss: 0.1622, Accuracy:0.914\nIteration: 12117, learning rate: 0.00551, Loss: 0.1908, Accuracy:0.945\nIteration: 12118, learning rate: 0.00551, Loss: 0.1559, Accuracy:0.938\nIteration: 12119, learning rate: 0.00551, Loss: 0.1621, Accuracy:0.930\nIteration: 12120, learning rate: 0.00551, Loss: 0.1546, Accuracy:0.953\nIteration: 12121, learning rate: 0.00551, Loss: 0.0546, Accuracy:1.000\nEpoch: 391, Loss: 0.1522, Accuracy:0.943, Val Loss: 0.2927, Val Accuracy: 0.886\nIteration: 12122, learning rate: 0.00551, Loss: 0.1192, Accuracy:0.961\nIteration: 12123, learning rate: 0.00551, Loss: 0.2147, Accuracy:0.938\nIteration: 12124, learning rate: 0.00551, Loss: 0.2527, Accuracy:0.898\nIteration: 12125, learning rate: 0.00551, Loss: 0.2944, Accuracy:0.867\nIteration: 12126, learning rate: 0.00551, Loss: 0.1837, Accuracy:0.906\nIteration: 12127, learning rate: 0.00551, Loss: 0.1695, Accuracy:0.938\nIteration: 12128, learning rate: 0.00551, Loss: 0.1592, Accuracy:0.945\nIteration: 12129, learning rate: 0.00551, Loss: 0.1987, Accuracy:0.906\nIteration: 12130, learning rate: 0.00551, Loss: 0.1489, Accuracy:0.945\nIteration: 12131, learning rate: 0.00551, Loss: 0.1681, Accuracy:0.914\nIteration: 12132, learning rate: 0.00551, Loss: 0.2235, Accuracy:0.938\nIteration: 12133, learning rate: 0.00551, Loss: 0.2125, Accuracy:0.914\nIteration: 12134, learning rate: 0.00551, Loss: 0.1976, Accuracy:0.938\nIteration: 12135, learning rate: 0.00551, Loss: 0.2635, Accuracy:0.883\nIteration: 12136, learning rate: 0.00551, Loss: 0.1381, Accuracy:0.938\nIteration: 12137, learning rate: 0.00551, Loss: 0.1147, Accuracy:0.945\nIteration: 12138, learning rate: 0.00551, Loss: 0.1992, Accuracy:0.898\nIteration: 12139, learning rate: 0.00551, Loss: 0.1340, Accuracy:0.953\nIteration: 12140, learning rate: 0.00551, Loss: 0.1095, Accuracy:0.969\nIteration: 12141, learning rate: 0.00551, Loss: 0.2381, Accuracy:0.938\nIteration: 12142, learning rate: 0.00551, Loss: 0.1707, Accuracy:0.922\nIteration: 12143, learning rate: 0.00551, Loss: 0.0777, Accuracy:0.984\nIteration: 12144, learning rate: 0.00551, Loss: 0.1173, Accuracy:0.969\nIteration: 12145, learning rate: 0.00551, Loss: 0.1697, Accuracy:0.922\nIteration: 12146, learning rate: 0.00551, Loss: 0.2088, Accuracy:0.922\nIteration: 12147, learning rate: 0.00551, Loss: 0.2504, Accuracy:0.922\nIteration: 12148, learning rate: 0.00551, Loss: 0.1208, Accuracy:0.938\nIteration: 12149, learning rate: 0.00551, Loss: 0.1375, Accuracy:0.961\nIteration: 12150, learning rate: 0.00551, Loss: 0.2876, Accuracy:0.891\nIteration: 12151, learning rate: 0.00551, Loss: 0.1319, Accuracy:0.953\nIteration: 12152, learning rate: 0.00551, Loss: 0.1238, Accuracy:0.968\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 392, Loss: 0.1786, Accuracy:0.932, Val Loss: 0.2812, Val Accuracy: 0.875\nIteration: 12153, learning rate: 0.00551, Loss: 0.1805, Accuracy:0.922\nIteration: 12154, learning rate: 0.00551, Loss: 0.1514, Accuracy:0.953\nIteration: 12155, learning rate: 0.00551, Loss: 0.2181, Accuracy:0.922\nIteration: 12156, learning rate: 0.00551, Loss: 0.1575, Accuracy:0.945\nIteration: 12157, learning rate: 0.00551, Loss: 0.1967, Accuracy:0.914\nIteration: 12158, learning rate: 0.00551, Loss: 0.2155, Accuracy:0.922\nIteration: 12159, learning rate: 0.00551, Loss: 0.1244, Accuracy:0.945\nIteration: 12160, learning rate: 0.00551, Loss: 0.1402, Accuracy:0.914\nIteration: 12161, learning rate: 0.00551, Loss: 0.0950, Accuracy:0.977\nIteration: 12162, learning rate: 0.00551, Loss: 0.2326, Accuracy:0.891\nIteration: 12163, learning rate: 0.00551, Loss: 0.1011, Accuracy:0.961\nIteration: 12164, learning rate: 0.00551, Loss: 0.1616, Accuracy:0.930\nIteration: 12165, learning rate: 0.00551, Loss: 0.1139, Accuracy:0.969\nIteration: 12166, learning rate: 0.00550, Loss: 0.1874, Accuracy:0.922\nIteration: 12167, learning rate: 0.00550, Loss: 0.1565, Accuracy:0.961\nIteration: 12168, learning rate: 0.00550, Loss: 0.1374, Accuracy:0.953\nIteration: 12169, learning rate: 0.00550, Loss: 0.1568, Accuracy:0.938\nIteration: 12170, learning rate: 0.00550, Loss: 0.1131, Accuracy:0.953\nIteration: 12171, learning rate: 0.00550, Loss: 0.1720, Accuracy:0.945\nIteration: 12172, learning rate: 0.00550, Loss: 0.1787, Accuracy:0.930\nIteration: 12173, learning rate: 0.00550, Loss: 0.1454, Accuracy:0.945\nIteration: 12174, learning rate: 0.00550, Loss: 0.1152, Accuracy:0.945\nIteration: 12175, learning rate: 0.00550, Loss: 0.1150, Accuracy:0.961\nIteration: 12176, learning rate: 0.00550, Loss: 0.1608, Accuracy:0.953\nIteration: 12177, learning rate: 0.00550, Loss: 0.2021, Accuracy:0.914\nIteration: 12178, learning rate: 0.00550, Loss: 0.1564, Accuracy:0.945\nIteration: 12179, learning rate: 0.00550, Loss: 0.1214, Accuracy:0.969\nIteration: 12180, learning rate: 0.00550, Loss: 0.2412, Accuracy:0.906\nIteration: 12181, learning rate: 0.00550, Loss: 0.1516, Accuracy:0.930\nIteration: 12182, learning rate: 0.00550, Loss: 0.1778, Accuracy:0.930\nIteration: 12183, learning rate: 0.00550, Loss: 0.1737, Accuracy:0.914\nEpoch: 393, Loss: 0.1597, Accuracy:0.938, Val Loss: 0.3193, Val Accuracy: 0.887\nIteration: 12184, learning rate: 0.00550, Loss: 0.1314, Accuracy:0.945\nIteration: 12185, learning rate: 0.00550, Loss: 0.2318, Accuracy:0.906\nIteration: 12186, learning rate: 0.00550, Loss: 0.0894, Accuracy:0.977\nIteration: 12187, learning rate: 0.00550, Loss: 0.1607, Accuracy:0.922\nIteration: 12188, learning rate: 0.00550, Loss: 0.1231, Accuracy:0.969\nIteration: 12189, learning rate: 0.00550, Loss: 0.2099, Accuracy:0.906\nIteration: 12190, learning rate: 0.00550, Loss: 0.1298, Accuracy:0.961\nIteration: 12191, learning rate: 0.00550, Loss: 0.2047, Accuracy:0.930\nIteration: 12192, learning rate: 0.00550, Loss: 0.1567, Accuracy:0.914\nIteration: 12193, learning rate: 0.00550, Loss: 0.1625, Accuracy:0.922\nIteration: 12194, learning rate: 0.00550, Loss: 0.1215, Accuracy:0.961\nIteration: 12195, learning rate: 0.00550, Loss: 0.1830, Accuracy:0.922\nIteration: 12196, learning rate: 0.00550, Loss: 0.1478, Accuracy:0.938\nIteration: 12197, learning rate: 0.00550, Loss: 0.2091, Accuracy:0.938\nIteration: 12198, learning rate: 0.00550, Loss: 0.1326, Accuracy:0.945\nIteration: 12199, learning rate: 0.00550, Loss: 0.1160, Accuracy:0.961\nIteration: 12200, learning rate: 0.00550, Loss: 0.1630, Accuracy:0.945\nIteration: 12201, learning rate: 0.00550, Loss: 0.2054, Accuracy:0.938\nIteration: 12202, learning rate: 0.00550, Loss: 0.2043, Accuracy:0.930\nIteration: 12203, learning rate: 0.00550, Loss: 0.1219, Accuracy:0.953\nIteration: 12204, learning rate: 0.00550, Loss: 0.1347, Accuracy:0.961\nIteration: 12205, learning rate: 0.00550, Loss: 0.1437, Accuracy:0.961\nIteration: 12206, learning rate: 0.00550, Loss: 0.1243, Accuracy:0.953\nIteration: 12207, learning rate: 0.00550, Loss: 0.1410, Accuracy:0.938\nIteration: 12208, learning rate: 0.00550, Loss: 0.1584, Accuracy:0.938\nIteration: 12209, learning rate: 0.00550, Loss: 0.2966, Accuracy:0.891\nIteration: 12210, learning rate: 0.00550, Loss: 0.1386, Accuracy:0.945\nIteration: 12211, learning rate: 0.00550, Loss: 0.1505, Accuracy:0.930\nIteration: 12212, learning rate: 0.00550, Loss: 0.1576, Accuracy:0.938\nIteration: 12213, learning rate: 0.00550, Loss: 0.1700, Accuracy:0.930\nIteration: 12214, learning rate: 0.00550, Loss: 0.2184, Accuracy:0.925\nEpoch: 394, Loss: 0.1625, Accuracy:0.938, Val Loss: 0.2757, Val Accuracy: 0.886\nIteration: 12215, learning rate: 0.00550, Loss: 0.1088, Accuracy:0.953\nIteration: 12216, learning rate: 0.00550, Loss: 0.1440, Accuracy:0.953\nIteration: 12217, learning rate: 0.00550, Loss: 0.1996, Accuracy:0.922\nIteration: 12218, learning rate: 0.00550, Loss: 0.1284, Accuracy:0.953\nIteration: 12219, learning rate: 0.00550, Loss: 0.1843, Accuracy:0.914\nIteration: 12220, learning rate: 0.00549, Loss: 0.2472, Accuracy:0.906\nIteration: 12221, learning rate: 0.00549, Loss: 0.1865, Accuracy:0.922\nIteration: 12222, learning rate: 0.00549, Loss: 0.2039, Accuracy:0.930\nIteration: 12223, learning rate: 0.00549, Loss: 0.2278, Accuracy:0.914\nIteration: 12224, learning rate: 0.00549, Loss: 0.1552, Accuracy:0.953\nIteration: 12225, learning rate: 0.00549, Loss: 0.1156, Accuracy:0.961\nIteration: 12226, learning rate: 0.00549, Loss: 0.1365, Accuracy:0.953\nIteration: 12227, learning rate: 0.00549, Loss: 0.1981, Accuracy:0.938\nIteration: 12228, learning rate: 0.00549, Loss: 0.1426, Accuracy:0.953\nIteration: 12229, learning rate: 0.00549, Loss: 0.1274, Accuracy:0.945\nIteration: 12230, learning rate: 0.00549, Loss: 0.0823, Accuracy:0.977\nIteration: 12231, learning rate: 0.00549, Loss: 0.2187, Accuracy:0.914\nIteration: 12232, learning rate: 0.00549, Loss: 0.2095, Accuracy:0.930\nIteration: 12233, learning rate: 0.00549, Loss: 0.1449, Accuracy:0.961\nIteration: 12234, learning rate: 0.00549, Loss: 0.1003, Accuracy:0.953\nIteration: 12235, learning rate: 0.00549, Loss: 0.1471, Accuracy:0.953\nIteration: 12236, learning rate: 0.00549, Loss: 0.1868, Accuracy:0.938\nIteration: 12237, learning rate: 0.00549, Loss: 0.2191, Accuracy:0.914\nIteration: 12238, learning rate: 0.00549, Loss: 0.1041, Accuracy:0.961\nIteration: 12239, learning rate: 0.00549, Loss: 0.1817, Accuracy:0.938\nIteration: 12240, learning rate: 0.00549, Loss: 0.1638, Accuracy:0.945\nIteration: 12241, learning rate: 0.00549, Loss: 0.1668, Accuracy:0.906\nIteration: 12242, learning rate: 0.00549, Loss: 0.2051, Accuracy:0.891\nIteration: 12243, learning rate: 0.00549, Loss: 0.1251, Accuracy:0.945\nIteration: 12244, learning rate: 0.00549, Loss: 0.1600, Accuracy:0.945\nIteration: 12245, learning rate: 0.00549, Loss: 0.1151, Accuracy:0.968\nEpoch: 395, Loss: 0.1625, Accuracy:0.939, Val Loss: 0.3038, Val Accuracy: 0.875\nIteration: 12246, learning rate: 0.00549, Loss: 0.1492, Accuracy:0.945\nIteration: 12247, learning rate: 0.00549, Loss: 0.1593, Accuracy:0.922\nIteration: 12248, learning rate: 0.00549, Loss: 0.1014, Accuracy:0.953\nIteration: 12249, learning rate: 0.00549, Loss: 0.1712, Accuracy:0.930\nIteration: 12250, learning rate: 0.00549, Loss: 0.0894, Accuracy:0.969\nIteration: 12251, learning rate: 0.00549, Loss: 0.1253, Accuracy:0.961\nIteration: 12252, learning rate: 0.00549, Loss: 0.1101, Accuracy:0.953\nIteration: 12253, learning rate: 0.00549, Loss: 0.1294, Accuracy:0.938\nIteration: 12254, learning rate: 0.00549, Loss: 0.1548, Accuracy:0.961\nIteration: 12255, learning rate: 0.00549, Loss: 0.1129, Accuracy:0.961\nIteration: 12256, learning rate: 0.00549, Loss: 0.1419, Accuracy:0.938\nIteration: 12257, learning rate: 0.00549, Loss: 0.1721, Accuracy:0.945\nIteration: 12258, learning rate: 0.00549, Loss: 0.2726, Accuracy:0.891\nIteration: 12259, learning rate: 0.00549, Loss: 0.1728, Accuracy:0.961\nIteration: 12260, learning rate: 0.00549, Loss: 0.1979, Accuracy:0.922\nIteration: 12261, learning rate: 0.00549, Loss: 0.1433, Accuracy:0.938\nIteration: 12262, learning rate: 0.00549, Loss: 0.1088, Accuracy:0.961\nIteration: 12263, learning rate: 0.00549, Loss: 0.1350, Accuracy:0.938\nIteration: 12264, learning rate: 0.00549, Loss: 0.0996, Accuracy:0.969\nIteration: 12265, learning rate: 0.00549, Loss: 0.1148, Accuracy:0.953\nIteration: 12266, learning rate: 0.00549, Loss: 0.1695, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12267, learning rate: 0.00549, Loss: 0.1602, Accuracy:0.938\nIteration: 12268, learning rate: 0.00549, Loss: 0.1507, Accuracy:0.930\nIteration: 12269, learning rate: 0.00549, Loss: 0.1378, Accuracy:0.953\nIteration: 12270, learning rate: 0.00549, Loss: 0.1710, Accuracy:0.922\nIteration: 12271, learning rate: 0.00549, Loss: 0.1697, Accuracy:0.945\nIteration: 12272, learning rate: 0.00549, Loss: 0.0810, Accuracy:0.984\nIteration: 12273, learning rate: 0.00549, Loss: 0.1228, Accuracy:0.961\nIteration: 12274, learning rate: 0.00548, Loss: 0.1708, Accuracy:0.961\nIteration: 12275, learning rate: 0.00548, Loss: 0.1579, Accuracy:0.961\nIteration: 12276, learning rate: 0.00548, Loss: 0.1816, Accuracy:0.946\nEpoch: 396, Loss: 0.1463, Accuracy:0.947, Val Loss: 0.3196, Val Accuracy: 0.867\nIteration: 12277, learning rate: 0.00548, Loss: 0.2239, Accuracy:0.914\nIteration: 12278, learning rate: 0.00548, Loss: 0.1447, Accuracy:0.945\nIteration: 12279, learning rate: 0.00548, Loss: 0.0974, Accuracy:0.977\nIteration: 12280, learning rate: 0.00548, Loss: 0.1350, Accuracy:0.953\nIteration: 12281, learning rate: 0.00548, Loss: 0.1242, Accuracy:0.977\nIteration: 12282, learning rate: 0.00548, Loss: 0.1059, Accuracy:0.984\nIteration: 12283, learning rate: 0.00548, Loss: 0.1568, Accuracy:0.945\nIteration: 12284, learning rate: 0.00548, Loss: 0.1390, Accuracy:0.930\nIteration: 12285, learning rate: 0.00548, Loss: 0.1765, Accuracy:0.938\nIteration: 12286, learning rate: 0.00548, Loss: 0.0916, Accuracy:0.977\nIteration: 12287, learning rate: 0.00548, Loss: 0.0744, Accuracy:0.984\nIteration: 12288, learning rate: 0.00548, Loss: 0.1683, Accuracy:0.930\nIteration: 12289, learning rate: 0.00548, Loss: 0.2323, Accuracy:0.891\nIteration: 12290, learning rate: 0.00548, Loss: 0.1860, Accuracy:0.914\nIteration: 12291, learning rate: 0.00548, Loss: 0.2436, Accuracy:0.930\nIteration: 12292, learning rate: 0.00548, Loss: 0.1162, Accuracy:0.938\nIteration: 12293, learning rate: 0.00548, Loss: 0.1312, Accuracy:0.945\nIteration: 12294, learning rate: 0.00548, Loss: 0.1405, Accuracy:0.953\nIteration: 12295, learning rate: 0.00548, Loss: 0.0886, Accuracy:0.977\nIteration: 12296, learning rate: 0.00548, Loss: 0.2325, Accuracy:0.898\nIteration: 12297, learning rate: 0.00548, Loss: 0.1387, Accuracy:0.953\nIteration: 12298, learning rate: 0.00548, Loss: 0.1381, Accuracy:0.953\nIteration: 12299, learning rate: 0.00548, Loss: 0.1016, Accuracy:0.969\nIteration: 12300, learning rate: 0.00548, Loss: 0.1342, Accuracy:0.945\nIteration: 12301, learning rate: 0.00548, Loss: 0.1439, Accuracy:0.945\nIteration: 12302, learning rate: 0.00548, Loss: 0.1806, Accuracy:0.930\nIteration: 12303, learning rate: 0.00548, Loss: 0.1284, Accuracy:0.961\nIteration: 12304, learning rate: 0.00548, Loss: 0.1389, Accuracy:0.969\nIteration: 12305, learning rate: 0.00548, Loss: 0.0947, Accuracy:0.961\nIteration: 12306, learning rate: 0.00548, Loss: 0.2568, Accuracy:0.883\nIteration: 12307, learning rate: 0.00548, Loss: 0.1373, Accuracy:0.957\nEpoch: 397, Loss: 0.1484, Accuracy:0.946, Val Loss: 0.2838, Val Accuracy: 0.888\nIteration: 12308, learning rate: 0.00548, Loss: 0.1435, Accuracy:0.938\nIteration: 12309, learning rate: 0.00548, Loss: 0.2090, Accuracy:0.906\nIteration: 12310, learning rate: 0.00548, Loss: 0.0970, Accuracy:0.969\nIteration: 12311, learning rate: 0.00548, Loss: 0.1663, Accuracy:0.922\nIteration: 12312, learning rate: 0.00548, Loss: 0.1499, Accuracy:0.938\nIteration: 12313, learning rate: 0.00548, Loss: 0.2012, Accuracy:0.914\nIteration: 12314, learning rate: 0.00548, Loss: 0.0918, Accuracy:0.953\nIteration: 12315, learning rate: 0.00548, Loss: 0.1593, Accuracy:0.938\nIteration: 12316, learning rate: 0.00548, Loss: 0.1448, Accuracy:0.938\nIteration: 12317, learning rate: 0.00548, Loss: 0.1627, Accuracy:0.922\nIteration: 12318, learning rate: 0.00548, Loss: 0.1137, Accuracy:0.938\nIteration: 12319, learning rate: 0.00548, Loss: 0.2211, Accuracy:0.898\nIteration: 12320, learning rate: 0.00548, Loss: 0.1872, Accuracy:0.922\nIteration: 12321, learning rate: 0.00548, Loss: 0.1870, Accuracy:0.938\nIteration: 12322, learning rate: 0.00548, Loss: 0.1761, Accuracy:0.938\nIteration: 12323, learning rate: 0.00548, Loss: 0.1498, Accuracy:0.922\nIteration: 12324, learning rate: 0.00548, Loss: 0.1954, Accuracy:0.930\nIteration: 12325, learning rate: 0.00548, Loss: 0.1653, Accuracy:0.938\nIteration: 12326, learning rate: 0.00548, Loss: 0.2515, Accuracy:0.922\nIteration: 12327, learning rate: 0.00548, Loss: 0.1650, Accuracy:0.945\nIteration: 12328, learning rate: 0.00547, Loss: 0.1717, Accuracy:0.922\nIteration: 12329, learning rate: 0.00547, Loss: 0.1330, Accuracy:0.961\nIteration: 12330, learning rate: 0.00547, Loss: 0.1718, Accuracy:0.930\nIteration: 12331, learning rate: 0.00547, Loss: 0.1931, Accuracy:0.906\nIteration: 12332, learning rate: 0.00547, Loss: 0.2243, Accuracy:0.891\nIteration: 12333, learning rate: 0.00547, Loss: 0.0981, Accuracy:0.984\nIteration: 12334, learning rate: 0.00547, Loss: 0.1710, Accuracy:0.945\nIteration: 12335, learning rate: 0.00547, Loss: 0.2689, Accuracy:0.883\nIteration: 12336, learning rate: 0.00547, Loss: 0.1060, Accuracy:0.961\nIteration: 12337, learning rate: 0.00547, Loss: 0.1352, Accuracy:0.961\nIteration: 12338, learning rate: 0.00547, Loss: 0.1593, Accuracy:0.946\nEpoch: 398, Loss: 0.1668, Accuracy:0.933, Val Loss: 0.2655, Val Accuracy: 0.882\nIteration: 12339, learning rate: 0.00547, Loss: 0.1228, Accuracy:0.945\nIteration: 12340, learning rate: 0.00547, Loss: 0.0735, Accuracy:1.000\nIteration: 12341, learning rate: 0.00547, Loss: 0.1509, Accuracy:0.945\nIteration: 12342, learning rate: 0.00547, Loss: 0.1357, Accuracy:0.969\nIteration: 12343, learning rate: 0.00547, Loss: 0.1629, Accuracy:0.930\nIteration: 12344, learning rate: 0.00547, Loss: 0.2448, Accuracy:0.914\nIteration: 12345, learning rate: 0.00547, Loss: 0.1255, Accuracy:0.945\nIteration: 12346, learning rate: 0.00547, Loss: 0.1238, Accuracy:0.953\nIteration: 12347, learning rate: 0.00547, Loss: 0.1413, Accuracy:0.945\nIteration: 12348, learning rate: 0.00547, Loss: 0.1613, Accuracy:0.945\nIteration: 12349, learning rate: 0.00547, Loss: 0.1301, Accuracy:0.961\nIteration: 12350, learning rate: 0.00547, Loss: 0.1214, Accuracy:0.961\nIteration: 12351, learning rate: 0.00547, Loss: 0.1816, Accuracy:0.914\nIteration: 12352, learning rate: 0.00547, Loss: 0.1514, Accuracy:0.953\nIteration: 12353, learning rate: 0.00547, Loss: 0.0837, Accuracy:0.984\nIteration: 12354, learning rate: 0.00547, Loss: 0.1902, Accuracy:0.922\nIteration: 12355, learning rate: 0.00547, Loss: 0.1590, Accuracy:0.930\nIteration: 12356, learning rate: 0.00547, Loss: 0.2005, Accuracy:0.930\nIteration: 12357, learning rate: 0.00547, Loss: 0.1032, Accuracy:0.961\nIteration: 12358, learning rate: 0.00547, Loss: 0.2291, Accuracy:0.922\nIteration: 12359, learning rate: 0.00547, Loss: 0.1756, Accuracy:0.930\nIteration: 12360, learning rate: 0.00547, Loss: 0.1462, Accuracy:0.945\nIteration: 12361, learning rate: 0.00547, Loss: 0.0928, Accuracy:0.961\nIteration: 12362, learning rate: 0.00547, Loss: 0.1527, Accuracy:0.945\nIteration: 12363, learning rate: 0.00547, Loss: 0.1348, Accuracy:0.961\nIteration: 12364, learning rate: 0.00547, Loss: 0.1870, Accuracy:0.930\nIteration: 12365, learning rate: 0.00547, Loss: 0.1617, Accuracy:0.953\nIteration: 12366, learning rate: 0.00547, Loss: 0.0864, Accuracy:0.977\nIteration: 12367, learning rate: 0.00547, Loss: 0.1403, Accuracy:0.938\nIteration: 12368, learning rate: 0.00547, Loss: 0.1076, Accuracy:0.961\nIteration: 12369, learning rate: 0.00547, Loss: 0.1699, Accuracy:0.946\nEpoch: 399, Loss: 0.1467, Accuracy:0.948, Val Loss: 0.2994, Val Accuracy: 0.874\nIteration: 12370, learning rate: 0.00547, Loss: 0.2017, Accuracy:0.922\nIteration: 12371, learning rate: 0.00547, Loss: 0.1871, Accuracy:0.930\nIteration: 12372, learning rate: 0.00547, Loss: 0.1438, Accuracy:0.945\nIteration: 12373, learning rate: 0.00547, Loss: 0.1569, Accuracy:0.938\nIteration: 12374, learning rate: 0.00547, Loss: 0.1568, Accuracy:0.938\nIteration: 12375, learning rate: 0.00547, Loss: 0.1254, Accuracy:0.945\nIteration: 12376, learning rate: 0.00547, Loss: 0.0914, Accuracy:0.961\nIteration: 12377, learning rate: 0.00547, Loss: 0.1463, Accuracy:0.945\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12378, learning rate: 0.00547, Loss: 0.1634, Accuracy:0.938\nIteration: 12379, learning rate: 0.00547, Loss: 0.1887, Accuracy:0.930\nIteration: 12380, learning rate: 0.00547, Loss: 0.1355, Accuracy:0.938\nIteration: 12381, learning rate: 0.00547, Loss: 0.1600, Accuracy:0.953\nIteration: 12382, learning rate: 0.00547, Loss: 0.1629, Accuracy:0.945\nIteration: 12383, learning rate: 0.00546, Loss: 0.1684, Accuracy:0.930\nIteration: 12384, learning rate: 0.00546, Loss: 0.1041, Accuracy:0.953\nIteration: 12385, learning rate: 0.00546, Loss: 0.2140, Accuracy:0.883\nIteration: 12386, learning rate: 0.00546, Loss: 0.2336, Accuracy:0.891\nIteration: 12387, learning rate: 0.00546, Loss: 0.1829, Accuracy:0.914\nIteration: 12388, learning rate: 0.00546, Loss: 0.1538, Accuracy:0.953\nIteration: 12389, learning rate: 0.00546, Loss: 0.1594, Accuracy:0.938\nIteration: 12390, learning rate: 0.00546, Loss: 0.1186, Accuracy:0.945\nIteration: 12391, learning rate: 0.00546, Loss: 0.1589, Accuracy:0.930\nIteration: 12392, learning rate: 0.00546, Loss: 0.1601, Accuracy:0.938\nIteration: 12393, learning rate: 0.00546, Loss: 0.2782, Accuracy:0.883\nIteration: 12394, learning rate: 0.00546, Loss: 0.2216, Accuracy:0.914\nIteration: 12395, learning rate: 0.00546, Loss: 0.2175, Accuracy:0.914\nIteration: 12396, learning rate: 0.00546, Loss: 0.1758, Accuracy:0.945\nIteration: 12397, learning rate: 0.00546, Loss: 0.1669, Accuracy:0.945\nIteration: 12398, learning rate: 0.00546, Loss: 0.1077, Accuracy:0.961\nIteration: 12399, learning rate: 0.00546, Loss: 0.2328, Accuracy:0.922\nIteration: 12400, learning rate: 0.00546, Loss: 0.1503, Accuracy:0.935\nEpoch: 400, Loss: 0.1685, Accuracy:0.933, Val Loss: 0.2834, Val Accuracy: 0.882\nIteration: 12401, learning rate: 0.00546, Loss: 0.1631, Accuracy:0.922\nIteration: 12402, learning rate: 0.00546, Loss: 0.1245, Accuracy:0.953\nIteration: 12403, learning rate: 0.00546, Loss: 0.1290, Accuracy:0.930\nIteration: 12404, learning rate: 0.00546, Loss: 0.1651, Accuracy:0.930\nIteration: 12405, learning rate: 0.00546, Loss: 0.1460, Accuracy:0.938\nIteration: 12406, learning rate: 0.00546, Loss: 0.1763, Accuracy:0.953\nIteration: 12407, learning rate: 0.00546, Loss: 0.1476, Accuracy:0.945\nIteration: 12408, learning rate: 0.00546, Loss: 0.2107, Accuracy:0.906\nIteration: 12409, learning rate: 0.00546, Loss: 0.2126, Accuracy:0.914\nIteration: 12410, learning rate: 0.00546, Loss: 0.1832, Accuracy:0.930\nIteration: 12411, learning rate: 0.00546, Loss: 0.1736, Accuracy:0.945\nIteration: 12412, learning rate: 0.00546, Loss: 0.1848, Accuracy:0.938\nIteration: 12413, learning rate: 0.00546, Loss: 0.1453, Accuracy:0.938\nIteration: 12414, learning rate: 0.00546, Loss: 0.1487, Accuracy:0.945\nIteration: 12415, learning rate: 0.00546, Loss: 0.1466, Accuracy:0.953\nIteration: 12416, learning rate: 0.00546, Loss: 0.1337, Accuracy:0.953\nIteration: 12417, learning rate: 0.00546, Loss: 0.2463, Accuracy:0.883\nIteration: 12418, learning rate: 0.00546, Loss: 0.1183, Accuracy:0.953\nIteration: 12419, learning rate: 0.00546, Loss: 0.1520, Accuracy:0.945\nIteration: 12420, learning rate: 0.00546, Loss: 0.1415, Accuracy:0.938\nIteration: 12421, learning rate: 0.00546, Loss: 0.2242, Accuracy:0.898\nIteration: 12422, learning rate: 0.00546, Loss: 0.0871, Accuracy:0.977\nIteration: 12423, learning rate: 0.00546, Loss: 0.1822, Accuracy:0.922\nIteration: 12424, learning rate: 0.00546, Loss: 0.1858, Accuracy:0.930\nIteration: 12425, learning rate: 0.00546, Loss: 0.0592, Accuracy:0.977\nIteration: 12426, learning rate: 0.00546, Loss: 0.0807, Accuracy:0.992\nIteration: 12427, learning rate: 0.00546, Loss: 0.1361, Accuracy:0.961\nIteration: 12428, learning rate: 0.00546, Loss: 0.2534, Accuracy:0.898\nIteration: 12429, learning rate: 0.00546, Loss: 0.1684, Accuracy:0.938\nIteration: 12430, learning rate: 0.00546, Loss: 0.1655, Accuracy:0.969\nIteration: 12431, learning rate: 0.00546, Loss: 0.1160, Accuracy:0.968\nEpoch: 401, Loss: 0.1583, Accuracy:0.940, Val Loss: 0.2932, Val Accuracy: 0.873\nIteration: 12432, learning rate: 0.00546, Loss: 0.2278, Accuracy:0.914\nIteration: 12433, learning rate: 0.00546, Loss: 0.2047, Accuracy:0.914\nIteration: 12434, learning rate: 0.00546, Loss: 0.1391, Accuracy:0.953\nIteration: 12435, learning rate: 0.00546, Loss: 0.0882, Accuracy:0.969\nIteration: 12436, learning rate: 0.00546, Loss: 0.1789, Accuracy:0.930\nIteration: 12437, learning rate: 0.00545, Loss: 0.1699, Accuracy:0.930\nIteration: 12438, learning rate: 0.00545, Loss: 0.1545, Accuracy:0.922\nIteration: 12439, learning rate: 0.00545, Loss: 0.1599, Accuracy:0.922\nIteration: 12440, learning rate: 0.00545, Loss: 0.1275, Accuracy:0.953\nIteration: 12441, learning rate: 0.00545, Loss: 0.1444, Accuracy:0.961\nIteration: 12442, learning rate: 0.00545, Loss: 0.1365, Accuracy:0.938\nIteration: 12443, learning rate: 0.00545, Loss: 0.1494, Accuracy:0.930\nIteration: 12444, learning rate: 0.00545, Loss: 0.1278, Accuracy:0.961\nIteration: 12445, learning rate: 0.00545, Loss: 0.1837, Accuracy:0.914\nIteration: 12446, learning rate: 0.00545, Loss: 0.2039, Accuracy:0.922\nIteration: 12447, learning rate: 0.00545, Loss: 0.1627, Accuracy:0.898\nIteration: 12448, learning rate: 0.00545, Loss: 0.1314, Accuracy:0.953\nIteration: 12449, learning rate: 0.00545, Loss: 0.2214, Accuracy:0.898\nIteration: 12450, learning rate: 0.00545, Loss: 0.2800, Accuracy:0.891\nIteration: 12451, learning rate: 0.00545, Loss: 0.1706, Accuracy:0.945\nIteration: 12452, learning rate: 0.00545, Loss: 0.1726, Accuracy:0.930\nIteration: 12453, learning rate: 0.00545, Loss: 0.1402, Accuracy:0.938\nIteration: 12454, learning rate: 0.00545, Loss: 0.1428, Accuracy:0.945\nIteration: 12455, learning rate: 0.00545, Loss: 0.1486, Accuracy:0.953\nIteration: 12456, learning rate: 0.00545, Loss: 0.1301, Accuracy:0.945\nIteration: 12457, learning rate: 0.00545, Loss: 0.1773, Accuracy:0.922\nIteration: 12458, learning rate: 0.00545, Loss: 0.1455, Accuracy:0.953\nIteration: 12459, learning rate: 0.00545, Loss: 0.1205, Accuracy:0.953\nIteration: 12460, learning rate: 0.00545, Loss: 0.1951, Accuracy:0.930\nIteration: 12461, learning rate: 0.00545, Loss: 0.1864, Accuracy:0.945\nIteration: 12462, learning rate: 0.00545, Loss: 0.1585, Accuracy:0.914\nEpoch: 402, Loss: 0.1639, Accuracy:0.934, Val Loss: 0.2731, Val Accuracy: 0.892\nIteration: 12463, learning rate: 0.00545, Loss: 0.1484, Accuracy:0.953\nIteration: 12464, learning rate: 0.00545, Loss: 0.1593, Accuracy:0.930\nIteration: 12465, learning rate: 0.00545, Loss: 0.1422, Accuracy:0.945\nIteration: 12466, learning rate: 0.00545, Loss: 0.1565, Accuracy:0.953\nIteration: 12467, learning rate: 0.00545, Loss: 0.1972, Accuracy:0.922\nIteration: 12468, learning rate: 0.00545, Loss: 0.2151, Accuracy:0.914\nIteration: 12469, learning rate: 0.00545, Loss: 0.1314, Accuracy:0.961\nIteration: 12470, learning rate: 0.00545, Loss: 0.2113, Accuracy:0.922\nIteration: 12471, learning rate: 0.00545, Loss: 0.1494, Accuracy:0.922\nIteration: 12472, learning rate: 0.00545, Loss: 0.1706, Accuracy:0.922\nIteration: 12473, learning rate: 0.00545, Loss: 0.1089, Accuracy:0.969\nIteration: 12474, learning rate: 0.00545, Loss: 0.1673, Accuracy:0.930\nIteration: 12475, learning rate: 0.00545, Loss: 0.1732, Accuracy:0.945\nIteration: 12476, learning rate: 0.00545, Loss: 0.1537, Accuracy:0.938\nIteration: 12477, learning rate: 0.00545, Loss: 0.0821, Accuracy:0.977\nIteration: 12478, learning rate: 0.00545, Loss: 0.1711, Accuracy:0.945\nIteration: 12479, learning rate: 0.00545, Loss: 0.1455, Accuracy:0.938\nIteration: 12480, learning rate: 0.00545, Loss: 0.1552, Accuracy:0.961\nIteration: 12481, learning rate: 0.00545, Loss: 0.2037, Accuracy:0.906\nIteration: 12482, learning rate: 0.00545, Loss: 0.1517, Accuracy:0.953\nIteration: 12483, learning rate: 0.00545, Loss: 0.1451, Accuracy:0.930\nIteration: 12484, learning rate: 0.00545, Loss: 0.1579, Accuracy:0.945\nIteration: 12485, learning rate: 0.00545, Loss: 0.2359, Accuracy:0.906\nIteration: 12486, learning rate: 0.00545, Loss: 0.1126, Accuracy:0.969\nIteration: 12487, learning rate: 0.00545, Loss: 0.0990, Accuracy:0.961\nIteration: 12488, learning rate: 0.00545, Loss: 0.2018, Accuracy:0.930\nIteration: 12489, learning rate: 0.00545, Loss: 0.0956, Accuracy:0.961\nIteration: 12490, learning rate: 0.00545, Loss: 0.1865, Accuracy:0.945\nIteration: 12491, learning rate: 0.00545, Loss: 0.1228, Accuracy:0.953\nIteration: 12492, learning rate: 0.00544, Loss: 0.1440, Accuracy:0.953\nIteration: 12493, learning rate: 0.00544, Loss: 0.1807, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 403, Loss: 0.1573, Accuracy:0.942, Val Loss: 0.3080, Val Accuracy: 0.865\nIteration: 12494, learning rate: 0.00544, Loss: 0.1942, Accuracy:0.930\nIteration: 12495, learning rate: 0.00544, Loss: 0.1339, Accuracy:0.969\nIteration: 12496, learning rate: 0.00544, Loss: 0.1223, Accuracy:0.961\nIteration: 12497, learning rate: 0.00544, Loss: 0.1288, Accuracy:0.961\nIteration: 12498, learning rate: 0.00544, Loss: 0.0919, Accuracy:0.969\nIteration: 12499, learning rate: 0.00544, Loss: 0.2259, Accuracy:0.898\nIteration: 12500, learning rate: 0.00544, Loss: 0.1880, Accuracy:0.898\nIteration: 12501, learning rate: 0.00544, Loss: 0.1282, Accuracy:0.945\nIteration: 12502, learning rate: 0.00544, Loss: 0.1706, Accuracy:0.930\nIteration: 12503, learning rate: 0.00544, Loss: 0.1448, Accuracy:0.953\nIteration: 12504, learning rate: 0.00544, Loss: 0.1735, Accuracy:0.922\nIteration: 12505, learning rate: 0.00544, Loss: 0.1742, Accuracy:0.945\nIteration: 12506, learning rate: 0.00544, Loss: 0.1398, Accuracy:0.953\nIteration: 12507, learning rate: 0.00544, Loss: 0.1409, Accuracy:0.945\nIteration: 12508, learning rate: 0.00544, Loss: 0.1433, Accuracy:0.922\nIteration: 12509, learning rate: 0.00544, Loss: 0.1333, Accuracy:0.945\nIteration: 12510, learning rate: 0.00544, Loss: 0.1592, Accuracy:0.930\nIteration: 12511, learning rate: 0.00544, Loss: 0.1685, Accuracy:0.914\nIteration: 12512, learning rate: 0.00544, Loss: 0.1686, Accuracy:0.922\nIteration: 12513, learning rate: 0.00544, Loss: 0.1476, Accuracy:0.914\nIteration: 12514, learning rate: 0.00544, Loss: 0.1982, Accuracy:0.930\nIteration: 12515, learning rate: 0.00544, Loss: 0.1378, Accuracy:0.938\nIteration: 12516, learning rate: 0.00544, Loss: 0.0971, Accuracy:0.961\nIteration: 12517, learning rate: 0.00544, Loss: 0.1099, Accuracy:0.961\nIteration: 12518, learning rate: 0.00544, Loss: 0.1655, Accuracy:0.930\nIteration: 12519, learning rate: 0.00544, Loss: 0.1429, Accuracy:0.930\nIteration: 12520, learning rate: 0.00544, Loss: 0.2531, Accuracy:0.875\nIteration: 12521, learning rate: 0.00544, Loss: 0.1866, Accuracy:0.922\nIteration: 12522, learning rate: 0.00544, Loss: 0.1654, Accuracy:0.953\nIteration: 12523, learning rate: 0.00544, Loss: 0.1405, Accuracy:0.945\nIteration: 12524, learning rate: 0.00544, Loss: 0.1214, Accuracy:0.957\nEpoch: 404, Loss: 0.1547, Accuracy:0.936, Val Loss: 0.2954, Val Accuracy: 0.878\nIteration: 12525, learning rate: 0.00544, Loss: 0.1236, Accuracy:0.945\nIteration: 12526, learning rate: 0.00544, Loss: 0.1256, Accuracy:0.961\nIteration: 12527, learning rate: 0.00544, Loss: 0.2254, Accuracy:0.898\nIteration: 12528, learning rate: 0.00544, Loss: 0.1688, Accuracy:0.938\nIteration: 12529, learning rate: 0.00544, Loss: 0.0984, Accuracy:0.969\nIteration: 12530, learning rate: 0.00544, Loss: 0.1457, Accuracy:0.961\nIteration: 12531, learning rate: 0.00544, Loss: 0.1103, Accuracy:0.969\nIteration: 12532, learning rate: 0.00544, Loss: 0.1694, Accuracy:0.930\nIteration: 12533, learning rate: 0.00544, Loss: 0.1914, Accuracy:0.883\nIteration: 12534, learning rate: 0.00544, Loss: 0.1070, Accuracy:0.945\nIteration: 12535, learning rate: 0.00544, Loss: 0.1843, Accuracy:0.922\nIteration: 12536, learning rate: 0.00544, Loss: 0.1284, Accuracy:0.969\nIteration: 12537, learning rate: 0.00544, Loss: 0.1704, Accuracy:0.930\nIteration: 12538, learning rate: 0.00544, Loss: 0.1182, Accuracy:0.938\nIteration: 12539, learning rate: 0.00544, Loss: 0.1358, Accuracy:0.953\nIteration: 12540, learning rate: 0.00544, Loss: 0.1381, Accuracy:0.938\nIteration: 12541, learning rate: 0.00544, Loss: 0.1975, Accuracy:0.938\nIteration: 12542, learning rate: 0.00544, Loss: 0.0979, Accuracy:0.961\nIteration: 12543, learning rate: 0.00544, Loss: 0.1110, Accuracy:0.969\nIteration: 12544, learning rate: 0.00544, Loss: 0.1870, Accuracy:0.922\nIteration: 12545, learning rate: 0.00544, Loss: 0.1439, Accuracy:0.953\nIteration: 12546, learning rate: 0.00544, Loss: 0.2848, Accuracy:0.906\nIteration: 12547, learning rate: 0.00543, Loss: 0.1602, Accuracy:0.930\nIteration: 12548, learning rate: 0.00543, Loss: 0.2366, Accuracy:0.891\nIteration: 12549, learning rate: 0.00543, Loss: 0.1555, Accuracy:0.938\nIteration: 12550, learning rate: 0.00543, Loss: 0.1915, Accuracy:0.922\nIteration: 12551, learning rate: 0.00543, Loss: 0.1753, Accuracy:0.906\nIteration: 12552, learning rate: 0.00543, Loss: 0.1218, Accuracy:0.961\nIteration: 12553, learning rate: 0.00543, Loss: 0.2065, Accuracy:0.938\nIteration: 12554, learning rate: 0.00543, Loss: 0.1514, Accuracy:0.914\nIteration: 12555, learning rate: 0.00543, Loss: 0.1355, Accuracy:0.957\nEpoch: 405, Loss: 0.1580, Accuracy:0.937, Val Loss: 0.3413, Val Accuracy: 0.859\nIteration: 12556, learning rate: 0.00543, Loss: 0.1168, Accuracy:0.953\nIteration: 12557, learning rate: 0.00543, Loss: 0.1897, Accuracy:0.938\nIteration: 12558, learning rate: 0.00543, Loss: 0.0949, Accuracy:0.961\nIteration: 12559, learning rate: 0.00543, Loss: 0.1352, Accuracy:0.938\nIteration: 12560, learning rate: 0.00543, Loss: 0.1365, Accuracy:0.961\nIteration: 12561, learning rate: 0.00543, Loss: 0.1431, Accuracy:0.953\nIteration: 12562, learning rate: 0.00543, Loss: 0.1180, Accuracy:0.977\nIteration: 12563, learning rate: 0.00543, Loss: 0.2146, Accuracy:0.930\nIteration: 12564, learning rate: 0.00543, Loss: 0.1827, Accuracy:0.922\nIteration: 12565, learning rate: 0.00543, Loss: 0.1732, Accuracy:0.945\nIteration: 12566, learning rate: 0.00543, Loss: 0.2140, Accuracy:0.906\nIteration: 12567, learning rate: 0.00543, Loss: 0.1378, Accuracy:0.953\nIteration: 12568, learning rate: 0.00543, Loss: 0.0992, Accuracy:0.984\nIteration: 12569, learning rate: 0.00543, Loss: 0.1870, Accuracy:0.922\nIteration: 12570, learning rate: 0.00543, Loss: 0.1204, Accuracy:0.953\nIteration: 12571, learning rate: 0.00543, Loss: 0.1884, Accuracy:0.914\nIteration: 12572, learning rate: 0.00543, Loss: 0.1847, Accuracy:0.938\nIteration: 12573, learning rate: 0.00543, Loss: 0.1158, Accuracy:0.969\nIteration: 12574, learning rate: 0.00543, Loss: 0.0987, Accuracy:0.953\nIteration: 12575, learning rate: 0.00543, Loss: 0.0942, Accuracy:0.953\nIteration: 12576, learning rate: 0.00543, Loss: 0.1026, Accuracy:0.977\nIteration: 12577, learning rate: 0.00543, Loss: 0.1195, Accuracy:0.953\nIteration: 12578, learning rate: 0.00543, Loss: 0.1584, Accuracy:0.938\nIteration: 12579, learning rate: 0.00543, Loss: 0.1087, Accuracy:0.969\nIteration: 12580, learning rate: 0.00543, Loss: 0.1025, Accuracy:0.977\nIteration: 12581, learning rate: 0.00543, Loss: 0.0953, Accuracy:0.969\nIteration: 12582, learning rate: 0.00543, Loss: 0.1216, Accuracy:0.945\nIteration: 12583, learning rate: 0.00543, Loss: 0.1681, Accuracy:0.945\nIteration: 12584, learning rate: 0.00543, Loss: 0.2430, Accuracy:0.883\nIteration: 12585, learning rate: 0.00543, Loss: 0.2036, Accuracy:0.891\nIteration: 12586, learning rate: 0.00543, Loss: 0.1172, Accuracy:0.935\nEpoch: 406, Loss: 0.1447, Accuracy:0.945, Val Loss: 0.2882, Val Accuracy: 0.875\nIteration: 12587, learning rate: 0.00543, Loss: 0.1205, Accuracy:0.961\nIteration: 12588, learning rate: 0.00543, Loss: 0.0908, Accuracy:0.977\nIteration: 12589, learning rate: 0.00543, Loss: 0.1267, Accuracy:0.969\nIteration: 12590, learning rate: 0.00543, Loss: 0.1013, Accuracy:0.953\nIteration: 12591, learning rate: 0.00543, Loss: 0.1601, Accuracy:0.922\nIteration: 12592, learning rate: 0.00543, Loss: 0.2032, Accuracy:0.953\nIteration: 12593, learning rate: 0.00543, Loss: 0.2144, Accuracy:0.922\nIteration: 12594, learning rate: 0.00543, Loss: 0.1550, Accuracy:0.953\nIteration: 12595, learning rate: 0.00543, Loss: 0.1376, Accuracy:0.938\nIteration: 12596, learning rate: 0.00543, Loss: 0.1842, Accuracy:0.945\nIteration: 12597, learning rate: 0.00543, Loss: 0.1115, Accuracy:0.969\nIteration: 12598, learning rate: 0.00543, Loss: 0.1297, Accuracy:0.969\nIteration: 12599, learning rate: 0.00543, Loss: 0.1636, Accuracy:0.922\nIteration: 12600, learning rate: 0.00543, Loss: 0.1534, Accuracy:0.953\nIteration: 12601, learning rate: 0.00543, Loss: 0.1466, Accuracy:0.953\nIteration: 12602, learning rate: 0.00543, Loss: 0.1437, Accuracy:0.945\nIteration: 12603, learning rate: 0.00542, Loss: 0.1102, Accuracy:0.961\nIteration: 12604, learning rate: 0.00542, Loss: 0.1844, Accuracy:0.922\nIteration: 12605, learning rate: 0.00542, Loss: 0.1625, Accuracy:0.938\nIteration: 12606, learning rate: 0.00542, Loss: 0.1929, Accuracy:0.938\nIteration: 12607, learning rate: 0.00542, Loss: 0.1483, Accuracy:0.969\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12608, learning rate: 0.00542, Loss: 0.1169, Accuracy:0.961\nIteration: 12609, learning rate: 0.00542, Loss: 0.1558, Accuracy:0.922\nIteration: 12610, learning rate: 0.00542, Loss: 0.0967, Accuracy:0.945\nIteration: 12611, learning rate: 0.00542, Loss: 0.0939, Accuracy:0.984\nIteration: 12612, learning rate: 0.00542, Loss: 0.2298, Accuracy:0.906\nIteration: 12613, learning rate: 0.00542, Loss: 0.1786, Accuracy:0.930\nIteration: 12614, learning rate: 0.00542, Loss: 0.1702, Accuracy:0.922\nIteration: 12615, learning rate: 0.00542, Loss: 0.1164, Accuracy:0.953\nIteration: 12616, learning rate: 0.00542, Loss: 0.1249, Accuracy:0.953\nIteration: 12617, learning rate: 0.00542, Loss: 0.1583, Accuracy:0.957\nEpoch: 407, Loss: 0.1478, Accuracy:0.947, Val Loss: 0.3772, Val Accuracy: 0.829\nIteration: 12618, learning rate: 0.00542, Loss: 0.1459, Accuracy:0.930\nIteration: 12619, learning rate: 0.00542, Loss: 0.1773, Accuracy:0.945\nIteration: 12620, learning rate: 0.00542, Loss: 0.1451, Accuracy:0.938\nIteration: 12621, learning rate: 0.00542, Loss: 0.1099, Accuracy:0.961\nIteration: 12622, learning rate: 0.00542, Loss: 0.1113, Accuracy:0.969\nIteration: 12623, learning rate: 0.00542, Loss: 0.1683, Accuracy:0.930\nIteration: 12624, learning rate: 0.00542, Loss: 0.1070, Accuracy:0.953\nIteration: 12625, learning rate: 0.00542, Loss: 0.1489, Accuracy:0.953\nIteration: 12626, learning rate: 0.00542, Loss: 0.1340, Accuracy:0.953\nIteration: 12627, learning rate: 0.00542, Loss: 0.1179, Accuracy:0.961\nIteration: 12628, learning rate: 0.00542, Loss: 0.1602, Accuracy:0.914\nIteration: 12629, learning rate: 0.00542, Loss: 0.1505, Accuracy:0.938\nIteration: 12630, learning rate: 0.00542, Loss: 0.1235, Accuracy:0.953\nIteration: 12631, learning rate: 0.00542, Loss: 0.1993, Accuracy:0.922\nIteration: 12632, learning rate: 0.00542, Loss: 0.2088, Accuracy:0.914\nIteration: 12633, learning rate: 0.00542, Loss: 0.1292, Accuracy:0.938\nIteration: 12634, learning rate: 0.00542, Loss: 0.1685, Accuracy:0.945\nIteration: 12635, learning rate: 0.00542, Loss: 0.1467, Accuracy:0.961\nIteration: 12636, learning rate: 0.00542, Loss: 0.1679, Accuracy:0.938\nIteration: 12637, learning rate: 0.00542, Loss: 0.1536, Accuracy:0.922\nIteration: 12638, learning rate: 0.00542, Loss: 0.2001, Accuracy:0.922\nIteration: 12639, learning rate: 0.00542, Loss: 0.0894, Accuracy:0.961\nIteration: 12640, learning rate: 0.00542, Loss: 0.1406, Accuracy:0.938\nIteration: 12641, learning rate: 0.00542, Loss: 0.0677, Accuracy:0.977\nIteration: 12642, learning rate: 0.00542, Loss: 0.2164, Accuracy:0.898\nIteration: 12643, learning rate: 0.00542, Loss: 0.1107, Accuracy:0.945\nIteration: 12644, learning rate: 0.00542, Loss: 0.1829, Accuracy:0.914\nIteration: 12645, learning rate: 0.00542, Loss: 0.1044, Accuracy:0.953\nIteration: 12646, learning rate: 0.00542, Loss: 0.1001, Accuracy:0.969\nIteration: 12647, learning rate: 0.00542, Loss: 0.0989, Accuracy:0.977\nIteration: 12648, learning rate: 0.00542, Loss: 0.1423, Accuracy:0.935\nEpoch: 408, Loss: 0.1428, Accuracy:0.943, Val Loss: 0.3089, Val Accuracy: 0.873\nIteration: 12649, learning rate: 0.00542, Loss: 0.1924, Accuracy:0.938\nIteration: 12650, learning rate: 0.00542, Loss: 0.1547, Accuracy:0.930\nIteration: 12651, learning rate: 0.00542, Loss: 0.1869, Accuracy:0.938\nIteration: 12652, learning rate: 0.00542, Loss: 0.1542, Accuracy:0.945\nIteration: 12653, learning rate: 0.00542, Loss: 0.1590, Accuracy:0.961\nIteration: 12654, learning rate: 0.00542, Loss: 0.1259, Accuracy:0.953\nIteration: 12655, learning rate: 0.00542, Loss: 0.1232, Accuracy:0.961\nIteration: 12656, learning rate: 0.00542, Loss: 0.1440, Accuracy:0.938\nIteration: 12657, learning rate: 0.00542, Loss: 0.1633, Accuracy:0.938\nIteration: 12658, learning rate: 0.00541, Loss: 0.1010, Accuracy:0.953\nIteration: 12659, learning rate: 0.00541, Loss: 0.1885, Accuracy:0.914\nIteration: 12660, learning rate: 0.00541, Loss: 0.1736, Accuracy:0.938\nIteration: 12661, learning rate: 0.00541, Loss: 0.1052, Accuracy:0.969\nIteration: 12662, learning rate: 0.00541, Loss: 0.1407, Accuracy:0.930\nIteration: 12663, learning rate: 0.00541, Loss: 0.0961, Accuracy:0.977\nIteration: 12664, learning rate: 0.00541, Loss: 0.1660, Accuracy:0.930\nIteration: 12665, learning rate: 0.00541, Loss: 0.1567, Accuracy:0.914\nIteration: 12666, learning rate: 0.00541, Loss: 0.1787, Accuracy:0.930\nIteration: 12667, learning rate: 0.00541, Loss: 0.1097, Accuracy:0.945\nIteration: 12668, learning rate: 0.00541, Loss: 0.1471, Accuracy:0.945\nIteration: 12669, learning rate: 0.00541, Loss: 0.1449, Accuracy:0.953\nIteration: 12670, learning rate: 0.00541, Loss: 0.1268, Accuracy:0.945\nIteration: 12671, learning rate: 0.00541, Loss: 0.0973, Accuracy:0.961\nIteration: 12672, learning rate: 0.00541, Loss: 0.1021, Accuracy:0.953\nIteration: 12673, learning rate: 0.00541, Loss: 0.2087, Accuracy:0.922\nIteration: 12674, learning rate: 0.00541, Loss: 0.0885, Accuracy:0.961\nIteration: 12675, learning rate: 0.00541, Loss: 0.0716, Accuracy:0.992\nIteration: 12676, learning rate: 0.00541, Loss: 0.0928, Accuracy:0.961\nIteration: 12677, learning rate: 0.00541, Loss: 0.1962, Accuracy:0.906\nIteration: 12678, learning rate: 0.00541, Loss: 0.1081, Accuracy:0.961\nIteration: 12679, learning rate: 0.00541, Loss: 0.1256, Accuracy:0.946\nEpoch: 409, Loss: 0.1397, Accuracy:0.945, Val Loss: 0.2920, Val Accuracy: 0.871\nIteration: 12680, learning rate: 0.00541, Loss: 0.1957, Accuracy:0.922\nIteration: 12681, learning rate: 0.00541, Loss: 0.0954, Accuracy:0.945\nIteration: 12682, learning rate: 0.00541, Loss: 0.1897, Accuracy:0.914\nIteration: 12683, learning rate: 0.00541, Loss: 0.0815, Accuracy:0.969\nIteration: 12684, learning rate: 0.00541, Loss: 0.0990, Accuracy:0.977\nIteration: 12685, learning rate: 0.00541, Loss: 0.1043, Accuracy:0.969\nIteration: 12686, learning rate: 0.00541, Loss: 0.1794, Accuracy:0.930\nIteration: 12687, learning rate: 0.00541, Loss: 0.1387, Accuracy:0.938\nIteration: 12688, learning rate: 0.00541, Loss: 0.1446, Accuracy:0.945\nIteration: 12689, learning rate: 0.00541, Loss: 0.1060, Accuracy:0.953\nIteration: 12690, learning rate: 0.00541, Loss: 0.1362, Accuracy:0.945\nIteration: 12691, learning rate: 0.00541, Loss: 0.1754, Accuracy:0.922\nIteration: 12692, learning rate: 0.00541, Loss: 0.1108, Accuracy:0.969\nIteration: 12693, learning rate: 0.00541, Loss: 0.1231, Accuracy:0.953\nIteration: 12694, learning rate: 0.00541, Loss: 0.1581, Accuracy:0.945\nIteration: 12695, learning rate: 0.00541, Loss: 0.2342, Accuracy:0.914\nIteration: 12696, learning rate: 0.00541, Loss: 0.1543, Accuracy:0.945\nIteration: 12697, learning rate: 0.00541, Loss: 0.1286, Accuracy:0.953\nIteration: 12698, learning rate: 0.00541, Loss: 0.1842, Accuracy:0.930\nIteration: 12699, learning rate: 0.00541, Loss: 0.0759, Accuracy:0.977\nIteration: 12700, learning rate: 0.00541, Loss: 0.0981, Accuracy:0.977\nIteration: 12701, learning rate: 0.00541, Loss: 0.1085, Accuracy:0.969\nIteration: 12702, learning rate: 0.00541, Loss: 0.1269, Accuracy:0.945\nIteration: 12703, learning rate: 0.00541, Loss: 0.1494, Accuracy:0.953\nIteration: 12704, learning rate: 0.00541, Loss: 0.1798, Accuracy:0.914\nIteration: 12705, learning rate: 0.00541, Loss: 0.1587, Accuracy:0.922\nIteration: 12706, learning rate: 0.00541, Loss: 0.1234, Accuracy:0.945\nIteration: 12707, learning rate: 0.00541, Loss: 0.2019, Accuracy:0.930\nIteration: 12708, learning rate: 0.00541, Loss: 0.1939, Accuracy:0.914\nIteration: 12709, learning rate: 0.00541, Loss: 0.1270, Accuracy:0.945\nIteration: 12710, learning rate: 0.00541, Loss: 0.1479, Accuracy:0.946\nEpoch: 410, Loss: 0.1429, Accuracy:0.944, Val Loss: 0.3410, Val Accuracy: 0.857\nIteration: 12711, learning rate: 0.00541, Loss: 0.2786, Accuracy:0.898\nIteration: 12712, learning rate: 0.00541, Loss: 0.1184, Accuracy:0.961\nIteration: 12713, learning rate: 0.00541, Loss: 0.1570, Accuracy:0.945\nIteration: 12714, learning rate: 0.00540, Loss: 0.1473, Accuracy:0.930\nIteration: 12715, learning rate: 0.00540, Loss: 0.1392, Accuracy:0.961\nIteration: 12716, learning rate: 0.00540, Loss: 0.1663, Accuracy:0.953\nIteration: 12717, learning rate: 0.00540, Loss: 0.1392, Accuracy:0.961\nIteration: 12718, learning rate: 0.00540, Loss: 0.1942, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12719, learning rate: 0.00540, Loss: 0.3358, Accuracy:0.859\nIteration: 12720, learning rate: 0.00540, Loss: 0.1915, Accuracy:0.906\nIteration: 12721, learning rate: 0.00540, Loss: 0.1276, Accuracy:0.953\nIteration: 12722, learning rate: 0.00540, Loss: 0.1644, Accuracy:0.906\nIteration: 12723, learning rate: 0.00540, Loss: 0.1434, Accuracy:0.938\nIteration: 12724, learning rate: 0.00540, Loss: 0.1136, Accuracy:0.961\nIteration: 12725, learning rate: 0.00540, Loss: 0.2115, Accuracy:0.875\nIteration: 12726, learning rate: 0.00540, Loss: 0.1780, Accuracy:0.922\nIteration: 12727, learning rate: 0.00540, Loss: 0.1560, Accuracy:0.945\nIteration: 12728, learning rate: 0.00540, Loss: 0.0976, Accuracy:0.953\nIteration: 12729, learning rate: 0.00540, Loss: 0.2115, Accuracy:0.922\nIteration: 12730, learning rate: 0.00540, Loss: 0.1992, Accuracy:0.906\nIteration: 12731, learning rate: 0.00540, Loss: 0.1531, Accuracy:0.945\nIteration: 12732, learning rate: 0.00540, Loss: 0.1546, Accuracy:0.922\nIteration: 12733, learning rate: 0.00540, Loss: 0.1634, Accuracy:0.953\nIteration: 12734, learning rate: 0.00540, Loss: 0.1328, Accuracy:0.945\nIteration: 12735, learning rate: 0.00540, Loss: 0.1151, Accuracy:0.953\nIteration: 12736, learning rate: 0.00540, Loss: 0.2417, Accuracy:0.930\nIteration: 12737, learning rate: 0.00540, Loss: 0.2639, Accuracy:0.906\nIteration: 12738, learning rate: 0.00540, Loss: 0.0726, Accuracy:0.977\nIteration: 12739, learning rate: 0.00540, Loss: 0.1751, Accuracy:0.922\nIteration: 12740, learning rate: 0.00540, Loss: 0.1961, Accuracy:0.914\nIteration: 12741, learning rate: 0.00540, Loss: 0.1010, Accuracy:0.957\nEpoch: 411, Loss: 0.1690, Accuracy:0.933, Val Loss: 0.2948, Val Accuracy: 0.879\nIteration: 12742, learning rate: 0.00540, Loss: 0.1646, Accuracy:0.953\nIteration: 12743, learning rate: 0.00540, Loss: 0.2018, Accuracy:0.922\nIteration: 12744, learning rate: 0.00540, Loss: 0.1255, Accuracy:0.969\nIteration: 12745, learning rate: 0.00540, Loss: 0.1405, Accuracy:0.930\nIteration: 12746, learning rate: 0.00540, Loss: 0.1175, Accuracy:0.961\nIteration: 12747, learning rate: 0.00540, Loss: 0.1411, Accuracy:0.945\nIteration: 12748, learning rate: 0.00540, Loss: 0.1240, Accuracy:0.945\nIteration: 12749, learning rate: 0.00540, Loss: 0.1449, Accuracy:0.961\nIteration: 12750, learning rate: 0.00540, Loss: 0.1596, Accuracy:0.922\nIteration: 12751, learning rate: 0.00540, Loss: 0.1672, Accuracy:0.938\nIteration: 12752, learning rate: 0.00540, Loss: 0.1608, Accuracy:0.930\nIteration: 12753, learning rate: 0.00540, Loss: 0.0957, Accuracy:0.969\nIteration: 12754, learning rate: 0.00540, Loss: 0.1939, Accuracy:0.922\nIteration: 12755, learning rate: 0.00540, Loss: 0.1138, Accuracy:0.945\nIteration: 12756, learning rate: 0.00540, Loss: 0.1090, Accuracy:0.977\nIteration: 12757, learning rate: 0.00540, Loss: 0.2257, Accuracy:0.914\nIteration: 12758, learning rate: 0.00540, Loss: 0.1374, Accuracy:0.945\nIteration: 12759, learning rate: 0.00540, Loss: 0.1904, Accuracy:0.922\nIteration: 12760, learning rate: 0.00540, Loss: 0.1414, Accuracy:0.930\nIteration: 12761, learning rate: 0.00540, Loss: 0.1909, Accuracy:0.922\nIteration: 12762, learning rate: 0.00540, Loss: 0.1717, Accuracy:0.922\nIteration: 12763, learning rate: 0.00540, Loss: 0.1445, Accuracy:0.945\nIteration: 12764, learning rate: 0.00540, Loss: 0.1265, Accuracy:0.969\nIteration: 12765, learning rate: 0.00540, Loss: 0.1650, Accuracy:0.922\nIteration: 12766, learning rate: 0.00540, Loss: 0.1216, Accuracy:0.945\nIteration: 12767, learning rate: 0.00540, Loss: 0.1178, Accuracy:0.961\nIteration: 12768, learning rate: 0.00540, Loss: 0.1272, Accuracy:0.961\nIteration: 12769, learning rate: 0.00540, Loss: 0.2027, Accuracy:0.922\nIteration: 12770, learning rate: 0.00540, Loss: 0.1349, Accuracy:0.953\nIteration: 12771, learning rate: 0.00539, Loss: 0.1892, Accuracy:0.938\nIteration: 12772, learning rate: 0.00539, Loss: 0.1591, Accuracy:0.935\nEpoch: 412, Loss: 0.1518, Accuracy:0.942, Val Loss: 0.2975, Val Accuracy: 0.873\nIteration: 12773, learning rate: 0.00539, Loss: 0.1595, Accuracy:0.938\nIteration: 12774, learning rate: 0.00539, Loss: 0.1962, Accuracy:0.930\nIteration: 12775, learning rate: 0.00539, Loss: 0.2147, Accuracy:0.945\nIteration: 12776, learning rate: 0.00539, Loss: 0.1213, Accuracy:0.945\nIteration: 12777, learning rate: 0.00539, Loss: 0.1488, Accuracy:0.930\nIteration: 12778, learning rate: 0.00539, Loss: 0.0973, Accuracy:0.969\nIteration: 12779, learning rate: 0.00539, Loss: 0.1408, Accuracy:0.945\nIteration: 12780, learning rate: 0.00539, Loss: 0.1881, Accuracy:0.930\nIteration: 12781, learning rate: 0.00539, Loss: 0.1101, Accuracy:0.961\nIteration: 12782, learning rate: 0.00539, Loss: 0.1489, Accuracy:0.953\nIteration: 12783, learning rate: 0.00539, Loss: 0.1394, Accuracy:0.938\nIteration: 12784, learning rate: 0.00539, Loss: 0.2165, Accuracy:0.930\nIteration: 12785, learning rate: 0.00539, Loss: 0.1178, Accuracy:0.984\nIteration: 12786, learning rate: 0.00539, Loss: 0.1480, Accuracy:0.953\nIteration: 12787, learning rate: 0.00539, Loss: 0.1324, Accuracy:0.953\nIteration: 12788, learning rate: 0.00539, Loss: 0.2103, Accuracy:0.922\nIteration: 12789, learning rate: 0.00539, Loss: 0.1961, Accuracy:0.906\nIteration: 12790, learning rate: 0.00539, Loss: 0.1551, Accuracy:0.945\nIteration: 12791, learning rate: 0.00539, Loss: 0.1885, Accuracy:0.922\nIteration: 12792, learning rate: 0.00539, Loss: 0.1688, Accuracy:0.938\nIteration: 12793, learning rate: 0.00539, Loss: 0.1516, Accuracy:0.938\nIteration: 12794, learning rate: 0.00539, Loss: 0.1589, Accuracy:0.938\nIteration: 12795, learning rate: 0.00539, Loss: 0.1868, Accuracy:0.930\nIteration: 12796, learning rate: 0.00539, Loss: 0.1911, Accuracy:0.922\nIteration: 12797, learning rate: 0.00539, Loss: 0.1438, Accuracy:0.953\nIteration: 12798, learning rate: 0.00539, Loss: 0.2424, Accuracy:0.906\nIteration: 12799, learning rate: 0.00539, Loss: 0.1063, Accuracy:0.977\nIteration: 12800, learning rate: 0.00539, Loss: 0.1340, Accuracy:0.961\nIteration: 12801, learning rate: 0.00539, Loss: 0.1420, Accuracy:0.969\nIteration: 12802, learning rate: 0.00539, Loss: 0.1296, Accuracy:0.961\nIteration: 12803, learning rate: 0.00539, Loss: 0.1315, Accuracy:0.957\nEpoch: 413, Loss: 0.1586, Accuracy:0.943, Val Loss: 0.3222, Val Accuracy: 0.864\nIteration: 12804, learning rate: 0.00539, Loss: 0.1748, Accuracy:0.938\nIteration: 12805, learning rate: 0.00539, Loss: 0.1857, Accuracy:0.945\nIteration: 12806, learning rate: 0.00539, Loss: 0.1518, Accuracy:0.938\nIteration: 12807, learning rate: 0.00539, Loss: 0.1660, Accuracy:0.945\nIteration: 12808, learning rate: 0.00539, Loss: 0.1683, Accuracy:0.961\nIteration: 12809, learning rate: 0.00539, Loss: 0.1454, Accuracy:0.938\nIteration: 12810, learning rate: 0.00539, Loss: 0.1321, Accuracy:0.938\nIteration: 12811, learning rate: 0.00539, Loss: 0.0998, Accuracy:0.953\nIteration: 12812, learning rate: 0.00539, Loss: 0.1303, Accuracy:0.961\nIteration: 12813, learning rate: 0.00539, Loss: 0.1501, Accuracy:0.930\nIteration: 12814, learning rate: 0.00539, Loss: 0.1056, Accuracy:0.945\nIteration: 12815, learning rate: 0.00539, Loss: 0.1725, Accuracy:0.945\nIteration: 12816, learning rate: 0.00539, Loss: 0.1397, Accuracy:0.930\nIteration: 12817, learning rate: 0.00539, Loss: 0.1579, Accuracy:0.938\nIteration: 12818, learning rate: 0.00539, Loss: 0.1167, Accuracy:0.953\nIteration: 12819, learning rate: 0.00539, Loss: 0.1097, Accuracy:0.969\nIteration: 12820, learning rate: 0.00539, Loss: 0.2035, Accuracy:0.938\nIteration: 12821, learning rate: 0.00539, Loss: 0.1972, Accuracy:0.930\nIteration: 12822, learning rate: 0.00539, Loss: 0.1194, Accuracy:0.953\nIteration: 12823, learning rate: 0.00539, Loss: 0.1407, Accuracy:0.938\nIteration: 12824, learning rate: 0.00539, Loss: 0.1595, Accuracy:0.930\nIteration: 12825, learning rate: 0.00539, Loss: 0.1328, Accuracy:0.945\nIteration: 12826, learning rate: 0.00539, Loss: 0.1803, Accuracy:0.906\nIteration: 12827, learning rate: 0.00538, Loss: 0.1205, Accuracy:0.938\nIteration: 12828, learning rate: 0.00538, Loss: 0.0990, Accuracy:0.961\nIteration: 12829, learning rate: 0.00538, Loss: 0.1493, Accuracy:0.930\nIteration: 12830, learning rate: 0.00538, Loss: 0.1193, Accuracy:0.969\nIteration: 12831, learning rate: 0.00538, Loss: 0.1793, Accuracy:0.906\nIteration: 12832, learning rate: 0.00538, Loss: 0.1874, Accuracy:0.938\nIteration: 12833, learning rate: 0.00538, Loss: 0.1624, Accuracy:0.945\nIteration: 12834, learning rate: 0.00538, Loss: 0.2300, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 414, Loss: 0.1512, Accuracy:0.941, Val Loss: 0.3051, Val Accuracy: 0.875\nIteration: 12835, learning rate: 0.00538, Loss: 0.0935, Accuracy:0.961\nIteration: 12836, learning rate: 0.00538, Loss: 0.1129, Accuracy:0.945\nIteration: 12837, learning rate: 0.00538, Loss: 0.1829, Accuracy:0.938\nIteration: 12838, learning rate: 0.00538, Loss: 0.1358, Accuracy:0.953\nIteration: 12839, learning rate: 0.00538, Loss: 0.1150, Accuracy:0.961\nIteration: 12840, learning rate: 0.00538, Loss: 0.2195, Accuracy:0.922\nIteration: 12841, learning rate: 0.00538, Loss: 0.2180, Accuracy:0.914\nIteration: 12842, learning rate: 0.00538, Loss: 0.1638, Accuracy:0.914\nIteration: 12843, learning rate: 0.00538, Loss: 0.2060, Accuracy:0.922\nIteration: 12844, learning rate: 0.00538, Loss: 0.1923, Accuracy:0.914\nIteration: 12845, learning rate: 0.00538, Loss: 0.1729, Accuracy:0.930\nIteration: 12846, learning rate: 0.00538, Loss: 0.1577, Accuracy:0.930\nIteration: 12847, learning rate: 0.00538, Loss: 0.2263, Accuracy:0.891\nIteration: 12848, learning rate: 0.00538, Loss: 0.1069, Accuracy:0.953\nIteration: 12849, learning rate: 0.00538, Loss: 0.1244, Accuracy:0.953\nIteration: 12850, learning rate: 0.00538, Loss: 0.1866, Accuracy:0.938\nIteration: 12851, learning rate: 0.00538, Loss: 0.0952, Accuracy:0.969\nIteration: 12852, learning rate: 0.00538, Loss: 0.1583, Accuracy:0.945\nIteration: 12853, learning rate: 0.00538, Loss: 0.1361, Accuracy:0.953\nIteration: 12854, learning rate: 0.00538, Loss: 0.1229, Accuracy:0.969\nIteration: 12855, learning rate: 0.00538, Loss: 0.1312, Accuracy:0.953\nIteration: 12856, learning rate: 0.00538, Loss: 0.1215, Accuracy:0.961\nIteration: 12857, learning rate: 0.00538, Loss: 0.1965, Accuracy:0.922\nIteration: 12858, learning rate: 0.00538, Loss: 0.1567, Accuracy:0.945\nIteration: 12859, learning rate: 0.00538, Loss: 0.0855, Accuracy:0.984\nIteration: 12860, learning rate: 0.00538, Loss: 0.1886, Accuracy:0.930\nIteration: 12861, learning rate: 0.00538, Loss: 0.1758, Accuracy:0.938\nIteration: 12862, learning rate: 0.00538, Loss: 0.1698, Accuracy:0.930\nIteration: 12863, learning rate: 0.00538, Loss: 0.1758, Accuracy:0.938\nIteration: 12864, learning rate: 0.00538, Loss: 0.1053, Accuracy:0.953\nIteration: 12865, learning rate: 0.00538, Loss: 0.1409, Accuracy:0.914\nEpoch: 415, Loss: 0.1540, Accuracy:0.940, Val Loss: 0.2808, Val Accuracy: 0.879\nIteration: 12866, learning rate: 0.00538, Loss: 0.1303, Accuracy:0.953\nIteration: 12867, learning rate: 0.00538, Loss: 0.1378, Accuracy:0.953\nIteration: 12868, learning rate: 0.00538, Loss: 0.0996, Accuracy:0.969\nIteration: 12869, learning rate: 0.00538, Loss: 0.1413, Accuracy:0.945\nIteration: 12870, learning rate: 0.00538, Loss: 0.1489, Accuracy:0.938\nIteration: 12871, learning rate: 0.00538, Loss: 0.1353, Accuracy:0.938\nIteration: 12872, learning rate: 0.00538, Loss: 0.1158, Accuracy:0.961\nIteration: 12873, learning rate: 0.00538, Loss: 0.1684, Accuracy:0.922\nIteration: 12874, learning rate: 0.00538, Loss: 0.1119, Accuracy:0.977\nIteration: 12875, learning rate: 0.00538, Loss: 0.2129, Accuracy:0.898\nIteration: 12876, learning rate: 0.00538, Loss: 0.2084, Accuracy:0.922\nIteration: 12877, learning rate: 0.00538, Loss: 0.2057, Accuracy:0.922\nIteration: 12878, learning rate: 0.00538, Loss: 0.1037, Accuracy:0.977\nIteration: 12879, learning rate: 0.00538, Loss: 0.1768, Accuracy:0.898\nIteration: 12880, learning rate: 0.00538, Loss: 0.1745, Accuracy:0.922\nIteration: 12881, learning rate: 0.00538, Loss: 0.1717, Accuracy:0.930\nIteration: 12882, learning rate: 0.00538, Loss: 0.1275, Accuracy:0.961\nIteration: 12883, learning rate: 0.00538, Loss: 0.1315, Accuracy:0.953\nIteration: 12884, learning rate: 0.00537, Loss: 0.2057, Accuracy:0.898\nIteration: 12885, learning rate: 0.00537, Loss: 0.1610, Accuracy:0.930\nIteration: 12886, learning rate: 0.00537, Loss: 0.0907, Accuracy:0.969\nIteration: 12887, learning rate: 0.00537, Loss: 0.1271, Accuracy:0.961\nIteration: 12888, learning rate: 0.00537, Loss: 0.1264, Accuracy:0.969\nIteration: 12889, learning rate: 0.00537, Loss: 0.2680, Accuracy:0.875\nIteration: 12890, learning rate: 0.00537, Loss: 0.1563, Accuracy:0.945\nIteration: 12891, learning rate: 0.00537, Loss: 0.1457, Accuracy:0.938\nIteration: 12892, learning rate: 0.00537, Loss: 0.1611, Accuracy:0.945\nIteration: 12893, learning rate: 0.00537, Loss: 0.2162, Accuracy:0.914\nIteration: 12894, learning rate: 0.00537, Loss: 0.1861, Accuracy:0.922\nIteration: 12895, learning rate: 0.00537, Loss: 0.0851, Accuracy:0.969\nIteration: 12896, learning rate: 0.00537, Loss: 0.2013, Accuracy:0.935\nEpoch: 416, Loss: 0.1559, Accuracy:0.939, Val Loss: 0.3262, Val Accuracy: 0.857\nIteration: 12897, learning rate: 0.00537, Loss: 0.1704, Accuracy:0.953\nIteration: 12898, learning rate: 0.00537, Loss: 0.2655, Accuracy:0.930\nIteration: 12899, learning rate: 0.00537, Loss: 0.1944, Accuracy:0.906\nIteration: 12900, learning rate: 0.00537, Loss: 0.1574, Accuracy:0.945\nIteration: 12901, learning rate: 0.00537, Loss: 0.1807, Accuracy:0.953\nIteration: 12902, learning rate: 0.00537, Loss: 0.1053, Accuracy:0.961\nIteration: 12903, learning rate: 0.00537, Loss: 0.1921, Accuracy:0.938\nIteration: 12904, learning rate: 0.00537, Loss: 0.1723, Accuracy:0.922\nIteration: 12905, learning rate: 0.00537, Loss: 0.1438, Accuracy:0.938\nIteration: 12906, learning rate: 0.00537, Loss: 0.1579, Accuracy:0.953\nIteration: 12907, learning rate: 0.00537, Loss: 0.1923, Accuracy:0.930\nIteration: 12908, learning rate: 0.00537, Loss: 0.1559, Accuracy:0.938\nIteration: 12909, learning rate: 0.00537, Loss: 0.1762, Accuracy:0.945\nIteration: 12910, learning rate: 0.00537, Loss: 0.1456, Accuracy:0.938\nIteration: 12911, learning rate: 0.00537, Loss: 0.1428, Accuracy:0.938\nIteration: 12912, learning rate: 0.00537, Loss: 0.0933, Accuracy:0.977\nIteration: 12913, learning rate: 0.00537, Loss: 0.1060, Accuracy:0.953\nIteration: 12914, learning rate: 0.00537, Loss: 0.2039, Accuracy:0.906\nIteration: 12915, learning rate: 0.00537, Loss: 0.1744, Accuracy:0.922\nIteration: 12916, learning rate: 0.00537, Loss: 0.1286, Accuracy:0.945\nIteration: 12917, learning rate: 0.00537, Loss: 0.1555, Accuracy:0.953\nIteration: 12918, learning rate: 0.00537, Loss: 0.1799, Accuracy:0.914\nIteration: 12919, learning rate: 0.00537, Loss: 0.1630, Accuracy:0.906\nIteration: 12920, learning rate: 0.00537, Loss: 0.1257, Accuracy:0.945\nIteration: 12921, learning rate: 0.00537, Loss: 0.1458, Accuracy:0.922\nIteration: 12922, learning rate: 0.00537, Loss: 0.1283, Accuracy:0.953\nIteration: 12923, learning rate: 0.00537, Loss: 0.1457, Accuracy:0.945\nIteration: 12924, learning rate: 0.00537, Loss: 0.1509, Accuracy:0.945\nIteration: 12925, learning rate: 0.00537, Loss: 0.0861, Accuracy:0.977\nIteration: 12926, learning rate: 0.00537, Loss: 0.1879, Accuracy:0.922\nIteration: 12927, learning rate: 0.00537, Loss: 0.1774, Accuracy:0.925\nEpoch: 417, Loss: 0.1582, Accuracy:0.939, Val Loss: 0.2682, Val Accuracy: 0.895\nIteration: 12928, learning rate: 0.00537, Loss: 0.2141, Accuracy:0.938\nIteration: 12929, learning rate: 0.00537, Loss: 0.1583, Accuracy:0.930\nIteration: 12930, learning rate: 0.00537, Loss: 0.1871, Accuracy:0.938\nIteration: 12931, learning rate: 0.00537, Loss: 0.1757, Accuracy:0.938\nIteration: 12932, learning rate: 0.00537, Loss: 0.1535, Accuracy:0.945\nIteration: 12933, learning rate: 0.00537, Loss: 0.2243, Accuracy:0.922\nIteration: 12934, learning rate: 0.00537, Loss: 0.1890, Accuracy:0.914\nIteration: 12935, learning rate: 0.00537, Loss: 0.2426, Accuracy:0.914\nIteration: 12936, learning rate: 0.00537, Loss: 0.1471, Accuracy:0.945\nIteration: 12937, learning rate: 0.00537, Loss: 0.1719, Accuracy:0.953\nIteration: 12938, learning rate: 0.00537, Loss: 0.1550, Accuracy:0.945\nIteration: 12939, learning rate: 0.00537, Loss: 0.1530, Accuracy:0.922\nIteration: 12940, learning rate: 0.00536, Loss: 0.1606, Accuracy:0.930\nIteration: 12941, learning rate: 0.00536, Loss: 0.1813, Accuracy:0.922\nIteration: 12942, learning rate: 0.00536, Loss: 0.1343, Accuracy:0.961\nIteration: 12943, learning rate: 0.00536, Loss: 0.1748, Accuracy:0.930\nIteration: 12944, learning rate: 0.00536, Loss: 0.1666, Accuracy:0.938\nIteration: 12945, learning rate: 0.00536, Loss: 0.1897, Accuracy:0.930\nIteration: 12946, learning rate: 0.00536, Loss: 0.1327, Accuracy:0.953\nIteration: 12947, learning rate: 0.00536, Loss: 0.1526, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 12948, learning rate: 0.00536, Loss: 0.1396, Accuracy:0.969\nIteration: 12949, learning rate: 0.00536, Loss: 0.2297, Accuracy:0.906\nIteration: 12950, learning rate: 0.00536, Loss: 0.1378, Accuracy:0.953\nIteration: 12951, learning rate: 0.00536, Loss: 0.1641, Accuracy:0.938\nIteration: 12952, learning rate: 0.00536, Loss: 0.1152, Accuracy:0.969\nIteration: 12953, learning rate: 0.00536, Loss: 0.1269, Accuracy:0.938\nIteration: 12954, learning rate: 0.00536, Loss: 0.1696, Accuracy:0.938\nIteration: 12955, learning rate: 0.00536, Loss: 0.2496, Accuracy:0.891\nIteration: 12956, learning rate: 0.00536, Loss: 0.1795, Accuracy:0.930\nIteration: 12957, learning rate: 0.00536, Loss: 0.1158, Accuracy:0.961\nIteration: 12958, learning rate: 0.00536, Loss: 0.1629, Accuracy:0.925\nEpoch: 418, Loss: 0.1695, Accuracy:0.937, Val Loss: 0.2940, Val Accuracy: 0.870\nIteration: 12959, learning rate: 0.00536, Loss: 0.1888, Accuracy:0.922\nIteration: 12960, learning rate: 0.00536, Loss: 0.1271, Accuracy:0.969\nIteration: 12961, learning rate: 0.00536, Loss: 0.1804, Accuracy:0.930\nIteration: 12962, learning rate: 0.00536, Loss: 0.1419, Accuracy:0.938\nIteration: 12963, learning rate: 0.00536, Loss: 0.1656, Accuracy:0.914\nIteration: 12964, learning rate: 0.00536, Loss: 0.1923, Accuracy:0.922\nIteration: 12965, learning rate: 0.00536, Loss: 0.1226, Accuracy:0.953\nIteration: 12966, learning rate: 0.00536, Loss: 0.1968, Accuracy:0.914\nIteration: 12967, learning rate: 0.00536, Loss: 0.2363, Accuracy:0.906\nIteration: 12968, learning rate: 0.00536, Loss: 0.1290, Accuracy:0.969\nIteration: 12969, learning rate: 0.00536, Loss: 0.1339, Accuracy:0.930\nIteration: 12970, learning rate: 0.00536, Loss: 0.2101, Accuracy:0.922\nIteration: 12971, learning rate: 0.00536, Loss: 0.0821, Accuracy:0.984\nIteration: 12972, learning rate: 0.00536, Loss: 0.1769, Accuracy:0.945\nIteration: 12973, learning rate: 0.00536, Loss: 0.1067, Accuracy:0.953\nIteration: 12974, learning rate: 0.00536, Loss: 0.1104, Accuracy:0.961\nIteration: 12975, learning rate: 0.00536, Loss: 0.1494, Accuracy:0.945\nIteration: 12976, learning rate: 0.00536, Loss: 0.1077, Accuracy:0.961\nIteration: 12977, learning rate: 0.00536, Loss: 0.1323, Accuracy:0.969\nIteration: 12978, learning rate: 0.00536, Loss: 0.1015, Accuracy:0.953\nIteration: 12979, learning rate: 0.00536, Loss: 0.0886, Accuracy:0.977\nIteration: 12980, learning rate: 0.00536, Loss: 0.1451, Accuracy:0.945\nIteration: 12981, learning rate: 0.00536, Loss: 0.1476, Accuracy:0.945\nIteration: 12982, learning rate: 0.00536, Loss: 0.1725, Accuracy:0.945\nIteration: 12983, learning rate: 0.00536, Loss: 0.2129, Accuracy:0.914\nIteration: 12984, learning rate: 0.00536, Loss: 0.1375, Accuracy:0.938\nIteration: 12985, learning rate: 0.00536, Loss: 0.1031, Accuracy:0.969\nIteration: 12986, learning rate: 0.00536, Loss: 0.1570, Accuracy:0.938\nIteration: 12987, learning rate: 0.00536, Loss: 0.1618, Accuracy:0.930\nIteration: 12988, learning rate: 0.00536, Loss: 0.1081, Accuracy:0.953\nIteration: 12989, learning rate: 0.00536, Loss: 0.1443, Accuracy:0.925\nEpoch: 419, Loss: 0.1474, Accuracy:0.943, Val Loss: 0.3543, Val Accuracy: 0.859\nIteration: 12990, learning rate: 0.00536, Loss: 0.1252, Accuracy:0.945\nIteration: 12991, learning rate: 0.00536, Loss: 0.1963, Accuracy:0.930\nIteration: 12992, learning rate: 0.00536, Loss: 0.1663, Accuracy:0.914\nIteration: 12993, learning rate: 0.00536, Loss: 0.1298, Accuracy:0.945\nIteration: 12994, learning rate: 0.00536, Loss: 0.1596, Accuracy:0.930\nIteration: 12995, learning rate: 0.00536, Loss: 0.2213, Accuracy:0.891\nIteration: 12996, learning rate: 0.00536, Loss: 0.1553, Accuracy:0.938\nIteration: 12997, learning rate: 0.00536, Loss: 0.1536, Accuracy:0.930\nIteration: 12998, learning rate: 0.00535, Loss: 0.1994, Accuracy:0.922\nIteration: 12999, learning rate: 0.00535, Loss: 0.1690, Accuracy:0.953\nIteration: 13000, learning rate: 0.00535, Loss: 0.1361, Accuracy:0.938\nIteration: 13001, learning rate: 0.00535, Loss: 0.1216, Accuracy:0.961\nIteration: 13002, learning rate: 0.00535, Loss: 0.1599, Accuracy:0.945\nIteration: 13003, learning rate: 0.00535, Loss: 0.1333, Accuracy:0.961\nIteration: 13004, learning rate: 0.00535, Loss: 0.1396, Accuracy:0.945\nIteration: 13005, learning rate: 0.00535, Loss: 0.1697, Accuracy:0.961\nIteration: 13006, learning rate: 0.00535, Loss: 0.1347, Accuracy:0.969\nIteration: 13007, learning rate: 0.00535, Loss: 0.2317, Accuracy:0.922\nIteration: 13008, learning rate: 0.00535, Loss: 0.1653, Accuracy:0.930\nIteration: 13009, learning rate: 0.00535, Loss: 0.2122, Accuracy:0.898\nIteration: 13010, learning rate: 0.00535, Loss: 0.1604, Accuracy:0.938\nIteration: 13011, learning rate: 0.00535, Loss: 0.1969, Accuracy:0.938\nIteration: 13012, learning rate: 0.00535, Loss: 0.1469, Accuracy:0.945\nIteration: 13013, learning rate: 0.00535, Loss: 0.0940, Accuracy:0.961\nIteration: 13014, learning rate: 0.00535, Loss: 0.1445, Accuracy:0.961\nIteration: 13015, learning rate: 0.00535, Loss: 0.1606, Accuracy:0.938\nIteration: 13016, learning rate: 0.00535, Loss: 0.1740, Accuracy:0.938\nIteration: 13017, learning rate: 0.00535, Loss: 0.1532, Accuracy:0.945\nIteration: 13018, learning rate: 0.00535, Loss: 0.0932, Accuracy:0.969\nIteration: 13019, learning rate: 0.00535, Loss: 0.1655, Accuracy:0.938\nIteration: 13020, learning rate: 0.00535, Loss: 0.1087, Accuracy:0.957\nEpoch: 420, Loss: 0.1573, Accuracy:0.940, Val Loss: 0.3628, Val Accuracy: 0.860\nIteration: 13021, learning rate: 0.00535, Loss: 0.1614, Accuracy:0.930\nIteration: 13022, learning rate: 0.00535, Loss: 0.1014, Accuracy:0.961\nIteration: 13023, learning rate: 0.00535, Loss: 0.1511, Accuracy:0.953\nIteration: 13024, learning rate: 0.00535, Loss: 0.1644, Accuracy:0.938\nIteration: 13025, learning rate: 0.00535, Loss: 0.1664, Accuracy:0.906\nIteration: 13026, learning rate: 0.00535, Loss: 0.1830, Accuracy:0.922\nIteration: 13027, learning rate: 0.00535, Loss: 0.1314, Accuracy:0.930\nIteration: 13028, learning rate: 0.00535, Loss: 0.1533, Accuracy:0.945\nIteration: 13029, learning rate: 0.00535, Loss: 0.1582, Accuracy:0.953\nIteration: 13030, learning rate: 0.00535, Loss: 0.1329, Accuracy:0.953\nIteration: 13031, learning rate: 0.00535, Loss: 0.0583, Accuracy:0.992\nIteration: 13032, learning rate: 0.00535, Loss: 0.1514, Accuracy:0.930\nIteration: 13033, learning rate: 0.00535, Loss: 0.1001, Accuracy:0.961\nIteration: 13034, learning rate: 0.00535, Loss: 0.1126, Accuracy:0.961\nIteration: 13035, learning rate: 0.00535, Loss: 0.1572, Accuracy:0.914\nIteration: 13036, learning rate: 0.00535, Loss: 0.1774, Accuracy:0.938\nIteration: 13037, learning rate: 0.00535, Loss: 0.1712, Accuracy:0.922\nIteration: 13038, learning rate: 0.00535, Loss: 0.1358, Accuracy:0.953\nIteration: 13039, learning rate: 0.00535, Loss: 0.1840, Accuracy:0.906\nIteration: 13040, learning rate: 0.00535, Loss: 0.1005, Accuracy:0.969\nIteration: 13041, learning rate: 0.00535, Loss: 0.1069, Accuracy:0.961\nIteration: 13042, learning rate: 0.00535, Loss: 0.1034, Accuracy:0.969\nIteration: 13043, learning rate: 0.00535, Loss: 0.0840, Accuracy:0.953\nIteration: 13044, learning rate: 0.00535, Loss: 0.1404, Accuracy:0.938\nIteration: 13045, learning rate: 0.00535, Loss: 0.2049, Accuracy:0.930\nIteration: 13046, learning rate: 0.00535, Loss: 0.2116, Accuracy:0.922\nIteration: 13047, learning rate: 0.00535, Loss: 0.1171, Accuracy:0.953\nIteration: 13048, learning rate: 0.00535, Loss: 0.1190, Accuracy:0.953\nIteration: 13049, learning rate: 0.00535, Loss: 0.1722, Accuracy:0.930\nIteration: 13050, learning rate: 0.00535, Loss: 0.1365, Accuracy:0.945\nIteration: 13051, learning rate: 0.00535, Loss: 0.2032, Accuracy:0.925\nEpoch: 421, Loss: 0.1436, Accuracy:0.942, Val Loss: 0.3010, Val Accuracy: 0.878\nIteration: 13052, learning rate: 0.00535, Loss: 0.1771, Accuracy:0.930\nIteration: 13053, learning rate: 0.00535, Loss: 0.1029, Accuracy:0.961\nIteration: 13054, learning rate: 0.00535, Loss: 0.1278, Accuracy:0.953\nIteration: 13055, learning rate: 0.00534, Loss: 0.1226, Accuracy:0.961\nIteration: 13056, learning rate: 0.00534, Loss: 0.1336, Accuracy:0.953\nIteration: 13057, learning rate: 0.00534, Loss: 0.1823, Accuracy:0.922\nIteration: 13058, learning rate: 0.00534, Loss: 0.1423, Accuracy:0.953\nIteration: 13059, learning rate: 0.00534, Loss: 0.1688, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13060, learning rate: 0.00534, Loss: 0.2735, Accuracy:0.906\nIteration: 13061, learning rate: 0.00534, Loss: 0.1381, Accuracy:0.938\nIteration: 13062, learning rate: 0.00534, Loss: 0.1327, Accuracy:0.969\nIteration: 13063, learning rate: 0.00534, Loss: 0.1719, Accuracy:0.922\nIteration: 13064, learning rate: 0.00534, Loss: 0.0772, Accuracy:0.977\nIteration: 13065, learning rate: 0.00534, Loss: 0.2232, Accuracy:0.914\nIteration: 13066, learning rate: 0.00534, Loss: 0.1258, Accuracy:0.938\nIteration: 13067, learning rate: 0.00534, Loss: 0.1704, Accuracy:0.953\nIteration: 13068, learning rate: 0.00534, Loss: 0.1533, Accuracy:0.945\nIteration: 13069, learning rate: 0.00534, Loss: 0.1439, Accuracy:0.953\nIteration: 13070, learning rate: 0.00534, Loss: 0.1789, Accuracy:0.938\nIteration: 13071, learning rate: 0.00534, Loss: 0.0989, Accuracy:0.977\nIteration: 13072, learning rate: 0.00534, Loss: 0.1419, Accuracy:0.961\nIteration: 13073, learning rate: 0.00534, Loss: 0.1481, Accuracy:0.945\nIteration: 13074, learning rate: 0.00534, Loss: 0.2048, Accuracy:0.938\nIteration: 13075, learning rate: 0.00534, Loss: 0.1059, Accuracy:0.969\nIteration: 13076, learning rate: 0.00534, Loss: 0.1346, Accuracy:0.938\nIteration: 13077, learning rate: 0.00534, Loss: 0.1542, Accuracy:0.953\nIteration: 13078, learning rate: 0.00534, Loss: 0.1935, Accuracy:0.938\nIteration: 13079, learning rate: 0.00534, Loss: 0.1777, Accuracy:0.930\nIteration: 13080, learning rate: 0.00534, Loss: 0.1478, Accuracy:0.953\nIteration: 13081, learning rate: 0.00534, Loss: 0.1374, Accuracy:0.930\nIteration: 13082, learning rate: 0.00534, Loss: 0.1162, Accuracy:0.968\nEpoch: 422, Loss: 0.1519, Accuracy:0.946, Val Loss: 0.2604, Val Accuracy: 0.905\nIteration: 13083, learning rate: 0.00534, Loss: 0.2190, Accuracy:0.914\nIteration: 13084, learning rate: 0.00534, Loss: 0.1436, Accuracy:0.945\nIteration: 13085, learning rate: 0.00534, Loss: 0.1402, Accuracy:0.930\nIteration: 13086, learning rate: 0.00534, Loss: 0.1710, Accuracy:0.922\nIteration: 13087, learning rate: 0.00534, Loss: 0.1287, Accuracy:0.953\nIteration: 13088, learning rate: 0.00534, Loss: 0.1638, Accuracy:0.938\nIteration: 13089, learning rate: 0.00534, Loss: 0.1439, Accuracy:0.953\nIteration: 13090, learning rate: 0.00534, Loss: 0.2099, Accuracy:0.922\nIteration: 13091, learning rate: 0.00534, Loss: 0.1171, Accuracy:0.969\nIteration: 13092, learning rate: 0.00534, Loss: 0.1136, Accuracy:0.961\nIteration: 13093, learning rate: 0.00534, Loss: 0.1718, Accuracy:0.945\nIteration: 13094, learning rate: 0.00534, Loss: 0.1644, Accuracy:0.938\nIteration: 13095, learning rate: 0.00534, Loss: 0.1406, Accuracy:0.969\nIteration: 13096, learning rate: 0.00534, Loss: 0.1397, Accuracy:0.953\nIteration: 13097, learning rate: 0.00534, Loss: 0.1238, Accuracy:0.953\nIteration: 13098, learning rate: 0.00534, Loss: 0.1285, Accuracy:0.961\nIteration: 13099, learning rate: 0.00534, Loss: 0.0738, Accuracy:0.977\nIteration: 13100, learning rate: 0.00534, Loss: 0.1707, Accuracy:0.938\nIteration: 13101, learning rate: 0.00534, Loss: 0.1320, Accuracy:0.938\nIteration: 13102, learning rate: 0.00534, Loss: 0.1801, Accuracy:0.953\nIteration: 13103, learning rate: 0.00534, Loss: 0.1722, Accuracy:0.922\nIteration: 13104, learning rate: 0.00534, Loss: 0.1337, Accuracy:0.953\nIteration: 13105, learning rate: 0.00534, Loss: 0.1852, Accuracy:0.930\nIteration: 13106, learning rate: 0.00534, Loss: 0.1508, Accuracy:0.938\nIteration: 13107, learning rate: 0.00534, Loss: 0.1553, Accuracy:0.938\nIteration: 13108, learning rate: 0.00534, Loss: 0.1464, Accuracy:0.945\nIteration: 13109, learning rate: 0.00534, Loss: 0.1993, Accuracy:0.914\nIteration: 13110, learning rate: 0.00534, Loss: 0.3414, Accuracy:0.859\nIteration: 13111, learning rate: 0.00534, Loss: 0.1795, Accuracy:0.938\nIteration: 13112, learning rate: 0.00534, Loss: 0.1367, Accuracy:0.930\nIteration: 13113, learning rate: 0.00533, Loss: 0.1752, Accuracy:0.914\nEpoch: 423, Loss: 0.1597, Accuracy:0.939, Val Loss: 0.2828, Val Accuracy: 0.881\nIteration: 13114, learning rate: 0.00533, Loss: 0.0821, Accuracy:0.969\nIteration: 13115, learning rate: 0.00533, Loss: 0.1357, Accuracy:0.945\nIteration: 13116, learning rate: 0.00533, Loss: 0.1029, Accuracy:0.984\nIteration: 13117, learning rate: 0.00533, Loss: 0.1126, Accuracy:0.938\nIteration: 13118, learning rate: 0.00533, Loss: 0.1321, Accuracy:0.969\nIteration: 13119, learning rate: 0.00533, Loss: 0.1779, Accuracy:0.945\nIteration: 13120, learning rate: 0.00533, Loss: 0.1546, Accuracy:0.945\nIteration: 13121, learning rate: 0.00533, Loss: 0.1731, Accuracy:0.930\nIteration: 13122, learning rate: 0.00533, Loss: 0.1403, Accuracy:0.977\nIteration: 13123, learning rate: 0.00533, Loss: 0.1163, Accuracy:0.961\nIteration: 13124, learning rate: 0.00533, Loss: 0.1250, Accuracy:0.953\nIteration: 13125, learning rate: 0.00533, Loss: 0.1194, Accuracy:0.953\nIteration: 13126, learning rate: 0.00533, Loss: 0.1684, Accuracy:0.898\nIteration: 13127, learning rate: 0.00533, Loss: 0.1305, Accuracy:0.961\nIteration: 13128, learning rate: 0.00533, Loss: 0.0897, Accuracy:0.969\nIteration: 13129, learning rate: 0.00533, Loss: 0.2162, Accuracy:0.938\nIteration: 13130, learning rate: 0.00533, Loss: 0.1190, Accuracy:0.945\nIteration: 13131, learning rate: 0.00533, Loss: 0.0969, Accuracy:0.977\nIteration: 13132, learning rate: 0.00533, Loss: 0.1849, Accuracy:0.930\nIteration: 13133, learning rate: 0.00533, Loss: 0.1277, Accuracy:0.945\nIteration: 13134, learning rate: 0.00533, Loss: 0.1621, Accuracy:0.930\nIteration: 13135, learning rate: 0.00533, Loss: 0.1595, Accuracy:0.922\nIteration: 13136, learning rate: 0.00533, Loss: 0.1654, Accuracy:0.938\nIteration: 13137, learning rate: 0.00533, Loss: 0.1181, Accuracy:0.938\nIteration: 13138, learning rate: 0.00533, Loss: 0.1171, Accuracy:0.961\nIteration: 13139, learning rate: 0.00533, Loss: 0.1404, Accuracy:0.945\nIteration: 13140, learning rate: 0.00533, Loss: 0.1618, Accuracy:0.930\nIteration: 13141, learning rate: 0.00533, Loss: 0.1272, Accuracy:0.945\nIteration: 13142, learning rate: 0.00533, Loss: 0.1253, Accuracy:0.953\nIteration: 13143, learning rate: 0.00533, Loss: 0.1775, Accuracy:0.930\nIteration: 13144, learning rate: 0.00533, Loss: 0.1789, Accuracy:0.946\nEpoch: 424, Loss: 0.1400, Accuracy:0.947, Val Loss: 0.2524, Val Accuracy: 0.912\nIteration: 13145, learning rate: 0.00533, Loss: 0.0899, Accuracy:0.969\nIteration: 13146, learning rate: 0.00533, Loss: 0.1326, Accuracy:0.945\nIteration: 13147, learning rate: 0.00533, Loss: 0.1364, Accuracy:0.969\nIteration: 13148, learning rate: 0.00533, Loss: 0.1785, Accuracy:0.922\nIteration: 13149, learning rate: 0.00533, Loss: 0.1223, Accuracy:0.961\nIteration: 13150, learning rate: 0.00533, Loss: 0.1593, Accuracy:0.906\nIteration: 13151, learning rate: 0.00533, Loss: 0.1871, Accuracy:0.922\nIteration: 13152, learning rate: 0.00533, Loss: 0.1659, Accuracy:0.930\nIteration: 13153, learning rate: 0.00533, Loss: 0.1896, Accuracy:0.922\nIteration: 13154, learning rate: 0.00533, Loss: 0.1046, Accuracy:0.984\nIteration: 13155, learning rate: 0.00533, Loss: 0.1565, Accuracy:0.953\nIteration: 13156, learning rate: 0.00533, Loss: 0.1714, Accuracy:0.922\nIteration: 13157, learning rate: 0.00533, Loss: 0.1692, Accuracy:0.898\nIteration: 13158, learning rate: 0.00533, Loss: 0.0917, Accuracy:0.977\nIteration: 13159, learning rate: 0.00533, Loss: 0.1386, Accuracy:0.930\nIteration: 13160, learning rate: 0.00533, Loss: 0.1098, Accuracy:0.953\nIteration: 13161, learning rate: 0.00533, Loss: 0.1329, Accuracy:0.961\nIteration: 13162, learning rate: 0.00533, Loss: 0.1374, Accuracy:0.953\nIteration: 13163, learning rate: 0.00533, Loss: 0.1310, Accuracy:0.961\nIteration: 13164, learning rate: 0.00533, Loss: 0.1935, Accuracy:0.898\nIteration: 13165, learning rate: 0.00533, Loss: 0.2320, Accuracy:0.891\nIteration: 13166, learning rate: 0.00533, Loss: 0.1053, Accuracy:0.953\nIteration: 13167, learning rate: 0.00533, Loss: 0.1679, Accuracy:0.930\nIteration: 13168, learning rate: 0.00533, Loss: 0.2538, Accuracy:0.906\nIteration: 13169, learning rate: 0.00533, Loss: 0.1601, Accuracy:0.969\nIteration: 13170, learning rate: 0.00532, Loss: 0.1882, Accuracy:0.914\nIteration: 13171, learning rate: 0.00532, Loss: 0.1284, Accuracy:0.945\nIteration: 13172, learning rate: 0.00532, Loss: 0.1284, Accuracy:0.945\nIteration: 13173, learning rate: 0.00532, Loss: 0.0968, Accuracy:0.984\nIteration: 13174, learning rate: 0.00532, Loss: 0.1917, Accuracy:0.922\nIteration: 13175, learning rate: 0.00532, Loss: 0.2023, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 425, Loss: 0.1533, Accuracy:0.939, Val Loss: 0.2904, Val Accuracy: 0.878\nIteration: 13176, learning rate: 0.00532, Loss: 0.2320, Accuracy:0.922\nIteration: 13177, learning rate: 0.00532, Loss: 0.1455, Accuracy:0.930\nIteration: 13178, learning rate: 0.00532, Loss: 0.1485, Accuracy:0.930\nIteration: 13179, learning rate: 0.00532, Loss: 0.1594, Accuracy:0.945\nIteration: 13180, learning rate: 0.00532, Loss: 0.2274, Accuracy:0.922\nIteration: 13181, learning rate: 0.00532, Loss: 0.1111, Accuracy:0.953\nIteration: 13182, learning rate: 0.00532, Loss: 0.1526, Accuracy:0.945\nIteration: 13183, learning rate: 0.00532, Loss: 0.1280, Accuracy:0.969\nIteration: 13184, learning rate: 0.00532, Loss: 0.1085, Accuracy:0.961\nIteration: 13185, learning rate: 0.00532, Loss: 0.1372, Accuracy:0.945\nIteration: 13186, learning rate: 0.00532, Loss: 0.1983, Accuracy:0.938\nIteration: 13187, learning rate: 0.00532, Loss: 0.1991, Accuracy:0.930\nIteration: 13188, learning rate: 0.00532, Loss: 0.1752, Accuracy:0.922\nIteration: 13189, learning rate: 0.00532, Loss: 0.1520, Accuracy:0.930\nIteration: 13190, learning rate: 0.00532, Loss: 0.1658, Accuracy:0.938\nIteration: 13191, learning rate: 0.00532, Loss: 0.1471, Accuracy:0.930\nIteration: 13192, learning rate: 0.00532, Loss: 0.1698, Accuracy:0.906\nIteration: 13193, learning rate: 0.00532, Loss: 0.1713, Accuracy:0.938\nIteration: 13194, learning rate: 0.00532, Loss: 0.1857, Accuracy:0.945\nIteration: 13195, learning rate: 0.00532, Loss: 0.1310, Accuracy:0.938\nIteration: 13196, learning rate: 0.00532, Loss: 0.1783, Accuracy:0.914\nIteration: 13197, learning rate: 0.00532, Loss: 0.1329, Accuracy:0.930\nIteration: 13198, learning rate: 0.00532, Loss: 0.1125, Accuracy:0.961\nIteration: 13199, learning rate: 0.00532, Loss: 0.1826, Accuracy:0.891\nIteration: 13200, learning rate: 0.00532, Loss: 0.1304, Accuracy:0.945\nIteration: 13201, learning rate: 0.00532, Loss: 0.1438, Accuracy:0.938\nIteration: 13202, learning rate: 0.00532, Loss: 0.1755, Accuracy:0.930\nIteration: 13203, learning rate: 0.00532, Loss: 0.2188, Accuracy:0.906\nIteration: 13204, learning rate: 0.00532, Loss: 0.1447, Accuracy:0.938\nIteration: 13205, learning rate: 0.00532, Loss: 0.1377, Accuracy:0.945\nIteration: 13206, learning rate: 0.00532, Loss: 0.1775, Accuracy:0.935\nEpoch: 426, Loss: 0.1606, Accuracy:0.934, Val Loss: 0.2738, Val Accuracy: 0.883\nIteration: 13207, learning rate: 0.00532, Loss: 0.1927, Accuracy:0.906\nIteration: 13208, learning rate: 0.00532, Loss: 0.0985, Accuracy:0.969\nIteration: 13209, learning rate: 0.00532, Loss: 0.1700, Accuracy:0.922\nIteration: 13210, learning rate: 0.00532, Loss: 0.1161, Accuracy:0.961\nIteration: 13211, learning rate: 0.00532, Loss: 0.2557, Accuracy:0.875\nIteration: 13212, learning rate: 0.00532, Loss: 0.1301, Accuracy:0.953\nIteration: 13213, learning rate: 0.00532, Loss: 0.1100, Accuracy:0.961\nIteration: 13214, learning rate: 0.00532, Loss: 0.1937, Accuracy:0.930\nIteration: 13215, learning rate: 0.00532, Loss: 0.1720, Accuracy:0.938\nIteration: 13216, learning rate: 0.00532, Loss: 0.0930, Accuracy:0.969\nIteration: 13217, learning rate: 0.00532, Loss: 0.1525, Accuracy:0.953\nIteration: 13218, learning rate: 0.00532, Loss: 0.1681, Accuracy:0.914\nIteration: 13219, learning rate: 0.00532, Loss: 0.1489, Accuracy:0.945\nIteration: 13220, learning rate: 0.00532, Loss: 0.1557, Accuracy:0.953\nIteration: 13221, learning rate: 0.00532, Loss: 0.1019, Accuracy:0.961\nIteration: 13222, learning rate: 0.00532, Loss: 0.1527, Accuracy:0.938\nIteration: 13223, learning rate: 0.00532, Loss: 0.1433, Accuracy:0.930\nIteration: 13224, learning rate: 0.00532, Loss: 0.1246, Accuracy:0.961\nIteration: 13225, learning rate: 0.00532, Loss: 0.1519, Accuracy:0.938\nIteration: 13226, learning rate: 0.00532, Loss: 0.1602, Accuracy:0.945\nIteration: 13227, learning rate: 0.00532, Loss: 0.1776, Accuracy:0.938\nIteration: 13228, learning rate: 0.00532, Loss: 0.1604, Accuracy:0.945\nIteration: 13229, learning rate: 0.00531, Loss: 0.2293, Accuracy:0.906\nIteration: 13230, learning rate: 0.00531, Loss: 0.1468, Accuracy:0.938\nIteration: 13231, learning rate: 0.00531, Loss: 0.1411, Accuracy:0.953\nIteration: 13232, learning rate: 0.00531, Loss: 0.1165, Accuracy:0.953\nIteration: 13233, learning rate: 0.00531, Loss: 0.1439, Accuracy:0.961\nIteration: 13234, learning rate: 0.00531, Loss: 0.2041, Accuracy:0.930\nIteration: 13235, learning rate: 0.00531, Loss: 0.1910, Accuracy:0.930\nIteration: 13236, learning rate: 0.00531, Loss: 0.1463, Accuracy:0.961\nIteration: 13237, learning rate: 0.00531, Loss: 0.1055, Accuracy:0.968\nEpoch: 427, Loss: 0.1534, Accuracy:0.942, Val Loss: 0.2965, Val Accuracy: 0.873\nIteration: 13238, learning rate: 0.00531, Loss: 0.1569, Accuracy:0.938\nIteration: 13239, learning rate: 0.00531, Loss: 0.0873, Accuracy:0.977\nIteration: 13240, learning rate: 0.00531, Loss: 0.1084, Accuracy:0.961\nIteration: 13241, learning rate: 0.00531, Loss: 0.1162, Accuracy:0.977\nIteration: 13242, learning rate: 0.00531, Loss: 0.0956, Accuracy:0.969\nIteration: 13243, learning rate: 0.00531, Loss: 0.1726, Accuracy:0.930\nIteration: 13244, learning rate: 0.00531, Loss: 0.0809, Accuracy:0.977\nIteration: 13245, learning rate: 0.00531, Loss: 0.1432, Accuracy:0.945\nIteration: 13246, learning rate: 0.00531, Loss: 0.1143, Accuracy:0.961\nIteration: 13247, learning rate: 0.00531, Loss: 0.1596, Accuracy:0.938\nIteration: 13248, learning rate: 0.00531, Loss: 0.0880, Accuracy:0.969\nIteration: 13249, learning rate: 0.00531, Loss: 0.1201, Accuracy:0.961\nIteration: 13250, learning rate: 0.00531, Loss: 0.1600, Accuracy:0.922\nIteration: 13251, learning rate: 0.00531, Loss: 0.0920, Accuracy:0.961\nIteration: 13252, learning rate: 0.00531, Loss: 0.1711, Accuracy:0.945\nIteration: 13253, learning rate: 0.00531, Loss: 0.1503, Accuracy:0.969\nIteration: 13254, learning rate: 0.00531, Loss: 0.1515, Accuracy:0.930\nIteration: 13255, learning rate: 0.00531, Loss: 0.1514, Accuracy:0.953\nIteration: 13256, learning rate: 0.00531, Loss: 0.0981, Accuracy:0.961\nIteration: 13257, learning rate: 0.00531, Loss: 0.1478, Accuracy:0.953\nIteration: 13258, learning rate: 0.00531, Loss: 0.1725, Accuracy:0.938\nIteration: 13259, learning rate: 0.00531, Loss: 0.1930, Accuracy:0.938\nIteration: 13260, learning rate: 0.00531, Loss: 0.1853, Accuracy:0.930\nIteration: 13261, learning rate: 0.00531, Loss: 0.1880, Accuracy:0.938\nIteration: 13262, learning rate: 0.00531, Loss: 0.1540, Accuracy:0.938\nIteration: 13263, learning rate: 0.00531, Loss: 0.1492, Accuracy:0.945\nIteration: 13264, learning rate: 0.00531, Loss: 0.1123, Accuracy:0.938\nIteration: 13265, learning rate: 0.00531, Loss: 0.1334, Accuracy:0.953\nIteration: 13266, learning rate: 0.00531, Loss: 0.1737, Accuracy:0.922\nIteration: 13267, learning rate: 0.00531, Loss: 0.1099, Accuracy:0.953\nIteration: 13268, learning rate: 0.00531, Loss: 0.1962, Accuracy:0.914\nEpoch: 428, Loss: 0.1398, Accuracy:0.948, Val Loss: 0.3443, Val Accuracy: 0.877\nIteration: 13269, learning rate: 0.00531, Loss: 0.1683, Accuracy:0.938\nIteration: 13270, learning rate: 0.00531, Loss: 0.1295, Accuracy:0.938\nIteration: 13271, learning rate: 0.00531, Loss: 0.1658, Accuracy:0.945\nIteration: 13272, learning rate: 0.00531, Loss: 0.1634, Accuracy:0.938\nIteration: 13273, learning rate: 0.00531, Loss: 0.1012, Accuracy:0.969\nIteration: 13274, learning rate: 0.00531, Loss: 0.1453, Accuracy:0.930\nIteration: 13275, learning rate: 0.00531, Loss: 0.1743, Accuracy:0.930\nIteration: 13276, learning rate: 0.00531, Loss: 0.1545, Accuracy:0.945\nIteration: 13277, learning rate: 0.00531, Loss: 0.1555, Accuracy:0.922\nIteration: 13278, learning rate: 0.00531, Loss: 0.1108, Accuracy:0.969\nIteration: 13279, learning rate: 0.00531, Loss: 0.1571, Accuracy:0.938\nIteration: 13280, learning rate: 0.00531, Loss: 0.1054, Accuracy:0.969\nIteration: 13281, learning rate: 0.00531, Loss: 0.1825, Accuracy:0.930\nIteration: 13282, learning rate: 0.00531, Loss: 0.2074, Accuracy:0.906\nIteration: 13283, learning rate: 0.00531, Loss: 0.1150, Accuracy:0.953\nIteration: 13284, learning rate: 0.00531, Loss: 0.1308, Accuracy:0.945\nIteration: 13285, learning rate: 0.00531, Loss: 0.1649, Accuracy:0.938\nIteration: 13286, learning rate: 0.00531, Loss: 0.1860, Accuracy:0.922\nIteration: 13287, learning rate: 0.00530, Loss: 0.1554, Accuracy:0.953\nIteration: 13288, learning rate: 0.00530, Loss: 0.1605, Accuracy:0.914\nIteration: 13289, learning rate: 0.00530, Loss: 0.1831, Accuracy:0.945\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13290, learning rate: 0.00530, Loss: 0.1779, Accuracy:0.922\nIteration: 13291, learning rate: 0.00530, Loss: 0.1163, Accuracy:0.969\nIteration: 13292, learning rate: 0.00530, Loss: 0.1934, Accuracy:0.938\nIteration: 13293, learning rate: 0.00530, Loss: 0.2036, Accuracy:0.922\nIteration: 13294, learning rate: 0.00530, Loss: 0.1758, Accuracy:0.938\nIteration: 13295, learning rate: 0.00530, Loss: 0.1251, Accuracy:0.961\nIteration: 13296, learning rate: 0.00530, Loss: 0.2001, Accuracy:0.938\nIteration: 13297, learning rate: 0.00530, Loss: 0.1145, Accuracy:0.961\nIteration: 13298, learning rate: 0.00530, Loss: 0.1738, Accuracy:0.945\nIteration: 13299, learning rate: 0.00530, Loss: 0.1888, Accuracy:0.946\nEpoch: 429, Loss: 0.1576, Accuracy:0.941, Val Loss: 0.2664, Val Accuracy: 0.889\nIteration: 13300, learning rate: 0.00530, Loss: 0.1366, Accuracy:0.953\nIteration: 13301, learning rate: 0.00530, Loss: 0.1436, Accuracy:0.938\nIteration: 13302, learning rate: 0.00530, Loss: 0.1429, Accuracy:0.922\nIteration: 13303, learning rate: 0.00530, Loss: 0.1394, Accuracy:0.945\nIteration: 13304, learning rate: 0.00530, Loss: 0.1100, Accuracy:0.945\nIteration: 13305, learning rate: 0.00530, Loss: 0.1499, Accuracy:0.961\nIteration: 13306, learning rate: 0.00530, Loss: 0.1336, Accuracy:0.961\nIteration: 13307, learning rate: 0.00530, Loss: 0.1756, Accuracy:0.914\nIteration: 13308, learning rate: 0.00530, Loss: 0.1488, Accuracy:0.961\nIteration: 13309, learning rate: 0.00530, Loss: 0.2061, Accuracy:0.914\nIteration: 13310, learning rate: 0.00530, Loss: 0.0944, Accuracy:0.977\nIteration: 13311, learning rate: 0.00530, Loss: 0.1301, Accuracy:0.969\nIteration: 13312, learning rate: 0.00530, Loss: 0.1843, Accuracy:0.938\nIteration: 13313, learning rate: 0.00530, Loss: 0.1570, Accuracy:0.953\nIteration: 13314, learning rate: 0.00530, Loss: 0.1673, Accuracy:0.938\nIteration: 13315, learning rate: 0.00530, Loss: 0.1867, Accuracy:0.930\nIteration: 13316, learning rate: 0.00530, Loss: 0.2003, Accuracy:0.906\nIteration: 13317, learning rate: 0.00530, Loss: 0.0971, Accuracy:0.961\nIteration: 13318, learning rate: 0.00530, Loss: 0.1344, Accuracy:0.938\nIteration: 13319, learning rate: 0.00530, Loss: 0.1726, Accuracy:0.945\nIteration: 13320, learning rate: 0.00530, Loss: 0.1803, Accuracy:0.922\nIteration: 13321, learning rate: 0.00530, Loss: 0.2079, Accuracy:0.938\nIteration: 13322, learning rate: 0.00530, Loss: 0.1147, Accuracy:0.969\nIteration: 13323, learning rate: 0.00530, Loss: 0.1309, Accuracy:0.969\nIteration: 13324, learning rate: 0.00530, Loss: 0.1547, Accuracy:0.945\nIteration: 13325, learning rate: 0.00530, Loss: 0.1941, Accuracy:0.922\nIteration: 13326, learning rate: 0.00530, Loss: 0.1390, Accuracy:0.953\nIteration: 13327, learning rate: 0.00530, Loss: 0.1477, Accuracy:0.953\nIteration: 13328, learning rate: 0.00530, Loss: 0.1412, Accuracy:0.961\nIteration: 13329, learning rate: 0.00530, Loss: 0.1479, Accuracy:0.945\nIteration: 13330, learning rate: 0.00530, Loss: 0.1160, Accuracy:0.946\nEpoch: 430, Loss: 0.1511, Accuracy:0.945, Val Loss: 0.2834, Val Accuracy: 0.887\nIteration: 13331, learning rate: 0.00530, Loss: 0.1920, Accuracy:0.922\nIteration: 13332, learning rate: 0.00530, Loss: 0.2003, Accuracy:0.930\nIteration: 13333, learning rate: 0.00530, Loss: 0.1004, Accuracy:0.984\nIteration: 13334, learning rate: 0.00530, Loss: 0.1214, Accuracy:0.938\nIteration: 13335, learning rate: 0.00530, Loss: 0.0963, Accuracy:0.961\nIteration: 13336, learning rate: 0.00530, Loss: 0.1141, Accuracy:0.945\nIteration: 13337, learning rate: 0.00530, Loss: 0.1867, Accuracy:0.906\nIteration: 13338, learning rate: 0.00530, Loss: 0.1253, Accuracy:0.945\nIteration: 13339, learning rate: 0.00530, Loss: 0.1271, Accuracy:0.961\nIteration: 13340, learning rate: 0.00530, Loss: 0.1285, Accuracy:0.945\nIteration: 13341, learning rate: 0.00530, Loss: 0.1194, Accuracy:0.938\nIteration: 13342, learning rate: 0.00530, Loss: 0.1138, Accuracy:0.969\nIteration: 13343, learning rate: 0.00530, Loss: 0.1631, Accuracy:0.945\nIteration: 13344, learning rate: 0.00530, Loss: 0.1574, Accuracy:0.945\nIteration: 13345, learning rate: 0.00530, Loss: 0.1436, Accuracy:0.945\nIteration: 13346, learning rate: 0.00529, Loss: 0.0800, Accuracy:0.977\nIteration: 13347, learning rate: 0.00529, Loss: 0.0712, Accuracy:0.977\nIteration: 13348, learning rate: 0.00529, Loss: 0.0890, Accuracy:0.977\nIteration: 13349, learning rate: 0.00529, Loss: 0.2588, Accuracy:0.891\nIteration: 13350, learning rate: 0.00529, Loss: 0.1347, Accuracy:0.961\nIteration: 13351, learning rate: 0.00529, Loss: 0.2332, Accuracy:0.922\nIteration: 13352, learning rate: 0.00529, Loss: 0.1750, Accuracy:0.938\nIteration: 13353, learning rate: 0.00529, Loss: 0.1071, Accuracy:0.961\nIteration: 13354, learning rate: 0.00529, Loss: 0.1206, Accuracy:0.945\nIteration: 13355, learning rate: 0.00529, Loss: 0.1270, Accuracy:0.961\nIteration: 13356, learning rate: 0.00529, Loss: 0.1517, Accuracy:0.938\nIteration: 13357, learning rate: 0.00529, Loss: 0.1473, Accuracy:0.961\nIteration: 13358, learning rate: 0.00529, Loss: 0.1454, Accuracy:0.945\nIteration: 13359, learning rate: 0.00529, Loss: 0.0885, Accuracy:0.953\nIteration: 13360, learning rate: 0.00529, Loss: 0.1833, Accuracy:0.922\nIteration: 13361, learning rate: 0.00529, Loss: 0.1150, Accuracy:0.957\nEpoch: 431, Loss: 0.1393, Accuracy:0.947, Val Loss: 0.3212, Val Accuracy: 0.877\nIteration: 13362, learning rate: 0.00529, Loss: 0.1309, Accuracy:0.945\nIteration: 13363, learning rate: 0.00529, Loss: 0.1438, Accuracy:0.938\nIteration: 13364, learning rate: 0.00529, Loss: 0.1003, Accuracy:0.961\nIteration: 13365, learning rate: 0.00529, Loss: 0.1126, Accuracy:0.961\nIteration: 13366, learning rate: 0.00529, Loss: 0.1512, Accuracy:0.922\nIteration: 13367, learning rate: 0.00529, Loss: 0.0829, Accuracy:0.969\nIteration: 13368, learning rate: 0.00529, Loss: 0.1101, Accuracy:0.977\nIteration: 13369, learning rate: 0.00529, Loss: 0.1100, Accuracy:0.961\nIteration: 13370, learning rate: 0.00529, Loss: 0.2328, Accuracy:0.883\nIteration: 13371, learning rate: 0.00529, Loss: 0.1602, Accuracy:0.930\nIteration: 13372, learning rate: 0.00529, Loss: 0.1582, Accuracy:0.938\nIteration: 13373, learning rate: 0.00529, Loss: 0.1586, Accuracy:0.930\nIteration: 13374, learning rate: 0.00529, Loss: 0.1077, Accuracy:0.953\nIteration: 13375, learning rate: 0.00529, Loss: 0.1300, Accuracy:0.945\nIteration: 13376, learning rate: 0.00529, Loss: 0.1504, Accuracy:0.938\nIteration: 13377, learning rate: 0.00529, Loss: 0.1026, Accuracy:0.961\nIteration: 13378, learning rate: 0.00529, Loss: 0.1419, Accuracy:0.969\nIteration: 13379, learning rate: 0.00529, Loss: 0.1530, Accuracy:0.945\nIteration: 13380, learning rate: 0.00529, Loss: 0.1207, Accuracy:0.945\nIteration: 13381, learning rate: 0.00529, Loss: 0.2125, Accuracy:0.914\nIteration: 13382, learning rate: 0.00529, Loss: 0.1595, Accuracy:0.945\nIteration: 13383, learning rate: 0.00529, Loss: 0.1681, Accuracy:0.930\nIteration: 13384, learning rate: 0.00529, Loss: 0.1076, Accuracy:0.977\nIteration: 13385, learning rate: 0.00529, Loss: 0.0770, Accuracy:0.961\nIteration: 13386, learning rate: 0.00529, Loss: 0.1580, Accuracy:0.938\nIteration: 13387, learning rate: 0.00529, Loss: 0.1047, Accuracy:0.969\nIteration: 13388, learning rate: 0.00529, Loss: 0.1643, Accuracy:0.938\nIteration: 13389, learning rate: 0.00529, Loss: 0.1983, Accuracy:0.906\nIteration: 13390, learning rate: 0.00529, Loss: 0.0835, Accuracy:0.984\nIteration: 13391, learning rate: 0.00529, Loss: 0.0814, Accuracy:0.977\nIteration: 13392, learning rate: 0.00529, Loss: 0.1670, Accuracy:0.914\nEpoch: 432, Loss: 0.1368, Accuracy:0.946, Val Loss: 0.3103, Val Accuracy: 0.875\nIteration: 13393, learning rate: 0.00529, Loss: 0.1672, Accuracy:0.922\nIteration: 13394, learning rate: 0.00529, Loss: 0.2079, Accuracy:0.906\nIteration: 13395, learning rate: 0.00529, Loss: 0.0913, Accuracy:0.977\nIteration: 13396, learning rate: 0.00529, Loss: 0.1634, Accuracy:0.938\nIteration: 13397, learning rate: 0.00529, Loss: 0.1837, Accuracy:0.930\nIteration: 13398, learning rate: 0.00529, Loss: 0.1502, Accuracy:0.930\nIteration: 13399, learning rate: 0.00529, Loss: 0.2038, Accuracy:0.914\nIteration: 13400, learning rate: 0.00529, Loss: 0.1644, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13401, learning rate: 0.00529, Loss: 0.1968, Accuracy:0.906\nIteration: 13402, learning rate: 0.00529, Loss: 0.2295, Accuracy:0.906\nIteration: 13403, learning rate: 0.00529, Loss: 0.1573, Accuracy:0.930\nIteration: 13404, learning rate: 0.00529, Loss: 0.0988, Accuracy:0.969\nIteration: 13405, learning rate: 0.00528, Loss: 0.0979, Accuracy:0.961\nIteration: 13406, learning rate: 0.00528, Loss: 0.1316, Accuracy:0.961\nIteration: 13407, learning rate: 0.00528, Loss: 0.2094, Accuracy:0.914\nIteration: 13408, learning rate: 0.00528, Loss: 0.1839, Accuracy:0.930\nIteration: 13409, learning rate: 0.00528, Loss: 0.1140, Accuracy:0.961\nIteration: 13410, learning rate: 0.00528, Loss: 0.0929, Accuracy:0.977\nIteration: 13411, learning rate: 0.00528, Loss: 0.1620, Accuracy:0.930\nIteration: 13412, learning rate: 0.00528, Loss: 0.1357, Accuracy:0.930\nIteration: 13413, learning rate: 0.00528, Loss: 0.1581, Accuracy:0.922\nIteration: 13414, learning rate: 0.00528, Loss: 0.1282, Accuracy:0.953\nIteration: 13415, learning rate: 0.00528, Loss: 0.1053, Accuracy:0.969\nIteration: 13416, learning rate: 0.00528, Loss: 0.1064, Accuracy:0.953\nIteration: 13417, learning rate: 0.00528, Loss: 0.1341, Accuracy:0.953\nIteration: 13418, learning rate: 0.00528, Loss: 0.0970, Accuracy:0.961\nIteration: 13419, learning rate: 0.00528, Loss: 0.1637, Accuracy:0.922\nIteration: 13420, learning rate: 0.00528, Loss: 0.1342, Accuracy:0.945\nIteration: 13421, learning rate: 0.00528, Loss: 0.1409, Accuracy:0.938\nIteration: 13422, learning rate: 0.00528, Loss: 0.1259, Accuracy:0.961\nIteration: 13423, learning rate: 0.00528, Loss: 0.1312, Accuracy:0.957\nEpoch: 433, Loss: 0.1473, Accuracy:0.940, Val Loss: 0.2962, Val Accuracy: 0.890\nIteration: 13424, learning rate: 0.00528, Loss: 0.1900, Accuracy:0.938\nIteration: 13425, learning rate: 0.00528, Loss: 0.1508, Accuracy:0.930\nIteration: 13426, learning rate: 0.00528, Loss: 0.0909, Accuracy:0.977\nIteration: 13427, learning rate: 0.00528, Loss: 0.1103, Accuracy:0.984\nIteration: 13428, learning rate: 0.00528, Loss: 0.1089, Accuracy:0.969\nIteration: 13429, learning rate: 0.00528, Loss: 0.1584, Accuracy:0.922\nIteration: 13430, learning rate: 0.00528, Loss: 0.1179, Accuracy:0.953\nIteration: 13431, learning rate: 0.00528, Loss: 0.1370, Accuracy:0.930\nIteration: 13432, learning rate: 0.00528, Loss: 0.1597, Accuracy:0.938\nIteration: 13433, learning rate: 0.00528, Loss: 0.1351, Accuracy:0.930\nIteration: 13434, learning rate: 0.00528, Loss: 0.1089, Accuracy:0.953\nIteration: 13435, learning rate: 0.00528, Loss: 0.1441, Accuracy:0.945\nIteration: 13436, learning rate: 0.00528, Loss: 0.1662, Accuracy:0.953\nIteration: 13437, learning rate: 0.00528, Loss: 0.0756, Accuracy:0.984\nIteration: 13438, learning rate: 0.00528, Loss: 0.1618, Accuracy:0.930\nIteration: 13439, learning rate: 0.00528, Loss: 0.1415, Accuracy:0.922\nIteration: 13440, learning rate: 0.00528, Loss: 0.1203, Accuracy:0.953\nIteration: 13441, learning rate: 0.00528, Loss: 0.1367, Accuracy:0.938\nIteration: 13442, learning rate: 0.00528, Loss: 0.2043, Accuracy:0.930\nIteration: 13443, learning rate: 0.00528, Loss: 0.1607, Accuracy:0.961\nIteration: 13444, learning rate: 0.00528, Loss: 0.2065, Accuracy:0.914\nIteration: 13445, learning rate: 0.00528, Loss: 0.1224, Accuracy:0.953\nIteration: 13446, learning rate: 0.00528, Loss: 0.1002, Accuracy:0.953\nIteration: 13447, learning rate: 0.00528, Loss: 0.1197, Accuracy:0.961\nIteration: 13448, learning rate: 0.00528, Loss: 0.0943, Accuracy:0.969\nIteration: 13449, learning rate: 0.00528, Loss: 0.1674, Accuracy:0.906\nIteration: 13450, learning rate: 0.00528, Loss: 0.1408, Accuracy:0.922\nIteration: 13451, learning rate: 0.00528, Loss: 0.2165, Accuracy:0.922\nIteration: 13452, learning rate: 0.00528, Loss: 0.1056, Accuracy:0.977\nIteration: 13453, learning rate: 0.00528, Loss: 0.1658, Accuracy:0.922\nIteration: 13454, learning rate: 0.00528, Loss: 0.1250, Accuracy:0.935\nEpoch: 434, Loss: 0.1401, Accuracy:0.944, Val Loss: 0.2856, Val Accuracy: 0.871\nIteration: 13455, learning rate: 0.00528, Loss: 0.1661, Accuracy:0.891\nIteration: 13456, learning rate: 0.00528, Loss: 0.1899, Accuracy:0.922\nIteration: 13457, learning rate: 0.00528, Loss: 0.1086, Accuracy:0.969\nIteration: 13458, learning rate: 0.00528, Loss: 0.1877, Accuracy:0.938\nIteration: 13459, learning rate: 0.00528, Loss: 0.2107, Accuracy:0.914\nIteration: 13460, learning rate: 0.00528, Loss: 0.1561, Accuracy:0.953\nIteration: 13461, learning rate: 0.00528, Loss: 0.1021, Accuracy:0.969\nIteration: 13462, learning rate: 0.00528, Loss: 0.2271, Accuracy:0.914\nIteration: 13463, learning rate: 0.00528, Loss: 0.1327, Accuracy:0.945\nIteration: 13464, learning rate: 0.00527, Loss: 0.1932, Accuracy:0.938\nIteration: 13465, learning rate: 0.00527, Loss: 0.1879, Accuracy:0.938\nIteration: 13466, learning rate: 0.00527, Loss: 0.1849, Accuracy:0.945\nIteration: 13467, learning rate: 0.00527, Loss: 0.1646, Accuracy:0.914\nIteration: 13468, learning rate: 0.00527, Loss: 0.1308, Accuracy:0.945\nIteration: 13469, learning rate: 0.00527, Loss: 0.2047, Accuracy:0.930\nIteration: 13470, learning rate: 0.00527, Loss: 0.1560, Accuracy:0.922\nIteration: 13471, learning rate: 0.00527, Loss: 0.1180, Accuracy:0.969\nIteration: 13472, learning rate: 0.00527, Loss: 0.1802, Accuracy:0.945\nIteration: 13473, learning rate: 0.00527, Loss: 0.1856, Accuracy:0.906\nIteration: 13474, learning rate: 0.00527, Loss: 0.1852, Accuracy:0.930\nIteration: 13475, learning rate: 0.00527, Loss: 0.1064, Accuracy:0.953\nIteration: 13476, learning rate: 0.00527, Loss: 0.2089, Accuracy:0.953\nIteration: 13477, learning rate: 0.00527, Loss: 0.2743, Accuracy:0.906\nIteration: 13478, learning rate: 0.00527, Loss: 0.2314, Accuracy:0.898\nIteration: 13479, learning rate: 0.00527, Loss: 0.1516, Accuracy:0.953\nIteration: 13480, learning rate: 0.00527, Loss: 0.1617, Accuracy:0.938\nIteration: 13481, learning rate: 0.00527, Loss: 0.1937, Accuracy:0.945\nIteration: 13482, learning rate: 0.00527, Loss: 0.1892, Accuracy:0.930\nIteration: 13483, learning rate: 0.00527, Loss: 0.1435, Accuracy:0.945\nIteration: 13484, learning rate: 0.00527, Loss: 0.1249, Accuracy:0.930\nIteration: 13485, learning rate: 0.00527, Loss: 0.1086, Accuracy:0.957\nEpoch: 435, Loss: 0.1699, Accuracy:0.936, Val Loss: 0.2736, Val Accuracy: 0.892\nIteration: 13486, learning rate: 0.00527, Loss: 0.1454, Accuracy:0.953\nIteration: 13487, learning rate: 0.00527, Loss: 0.1419, Accuracy:0.938\nIteration: 13488, learning rate: 0.00527, Loss: 0.0966, Accuracy:0.961\nIteration: 13489, learning rate: 0.00527, Loss: 0.1900, Accuracy:0.922\nIteration: 13490, learning rate: 0.00527, Loss: 0.1353, Accuracy:0.953\nIteration: 13491, learning rate: 0.00527, Loss: 0.1128, Accuracy:0.953\nIteration: 13492, learning rate: 0.00527, Loss: 0.1180, Accuracy:0.953\nIteration: 13493, learning rate: 0.00527, Loss: 0.0956, Accuracy:0.969\nIteration: 13494, learning rate: 0.00527, Loss: 0.1761, Accuracy:0.938\nIteration: 13495, learning rate: 0.00527, Loss: 0.1432, Accuracy:0.953\nIteration: 13496, learning rate: 0.00527, Loss: 0.1604, Accuracy:0.922\nIteration: 13497, learning rate: 0.00527, Loss: 0.1205, Accuracy:0.945\nIteration: 13498, learning rate: 0.00527, Loss: 0.1108, Accuracy:0.969\nIteration: 13499, learning rate: 0.00527, Loss: 0.1026, Accuracy:0.969\nIteration: 13500, learning rate: 0.00527, Loss: 0.1127, Accuracy:0.977\nIteration: 13501, learning rate: 0.00527, Loss: 0.1656, Accuracy:0.914\nIteration: 13502, learning rate: 0.00527, Loss: 0.1512, Accuracy:0.938\nIteration: 13503, learning rate: 0.00527, Loss: 0.1956, Accuracy:0.914\nIteration: 13504, learning rate: 0.00527, Loss: 0.1393, Accuracy:0.945\nIteration: 13505, learning rate: 0.00527, Loss: 0.0966, Accuracy:0.961\nIteration: 13506, learning rate: 0.00527, Loss: 0.1923, Accuracy:0.922\nIteration: 13507, learning rate: 0.00527, Loss: 0.1411, Accuracy:0.938\nIteration: 13508, learning rate: 0.00527, Loss: 0.1375, Accuracy:0.922\nIteration: 13509, learning rate: 0.00527, Loss: 0.1598, Accuracy:0.938\nIteration: 13510, learning rate: 0.00527, Loss: 0.1645, Accuracy:0.945\nIteration: 13511, learning rate: 0.00527, Loss: 0.1781, Accuracy:0.930\nIteration: 13512, learning rate: 0.00527, Loss: 0.1920, Accuracy:0.906\nIteration: 13513, learning rate: 0.00527, Loss: 0.1250, Accuracy:0.961\nIteration: 13514, learning rate: 0.00527, Loss: 0.1238, Accuracy:0.945\nIteration: 13515, learning rate: 0.00527, Loss: 0.1373, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13516, learning rate: 0.00527, Loss: 0.1638, Accuracy:0.968\nEpoch: 436, Loss: 0.1428, Accuracy:0.944, Val Loss: 0.3499, Val Accuracy: 0.877\nIteration: 13517, learning rate: 0.00527, Loss: 0.1330, Accuracy:0.953\nIteration: 13518, learning rate: 0.00527, Loss: 0.1722, Accuracy:0.930\nIteration: 13519, learning rate: 0.00527, Loss: 0.1348, Accuracy:0.945\nIteration: 13520, learning rate: 0.00527, Loss: 0.2579, Accuracy:0.891\nIteration: 13521, learning rate: 0.00527, Loss: 0.1178, Accuracy:0.961\nIteration: 13522, learning rate: 0.00527, Loss: 0.1448, Accuracy:0.953\nIteration: 13523, learning rate: 0.00526, Loss: 0.1425, Accuracy:0.938\nIteration: 13524, learning rate: 0.00526, Loss: 0.1175, Accuracy:0.969\nIteration: 13525, learning rate: 0.00526, Loss: 0.1490, Accuracy:0.953\nIteration: 13526, learning rate: 0.00526, Loss: 0.1708, Accuracy:0.938\nIteration: 13527, learning rate: 0.00526, Loss: 0.1861, Accuracy:0.922\nIteration: 13528, learning rate: 0.00526, Loss: 0.1918, Accuracy:0.914\nIteration: 13529, learning rate: 0.00526, Loss: 0.1538, Accuracy:0.938\nIteration: 13530, learning rate: 0.00526, Loss: 0.1565, Accuracy:0.922\nIteration: 13531, learning rate: 0.00526, Loss: 0.1312, Accuracy:0.953\nIteration: 13532, learning rate: 0.00526, Loss: 0.1175, Accuracy:0.969\nIteration: 13533, learning rate: 0.00526, Loss: 0.1480, Accuracy:0.953\nIteration: 13534, learning rate: 0.00526, Loss: 0.1547, Accuracy:0.930\nIteration: 13535, learning rate: 0.00526, Loss: 0.1068, Accuracy:0.969\nIteration: 13536, learning rate: 0.00526, Loss: 0.1311, Accuracy:0.953\nIteration: 13537, learning rate: 0.00526, Loss: 0.1322, Accuracy:0.938\nIteration: 13538, learning rate: 0.00526, Loss: 0.1241, Accuracy:0.945\nIteration: 13539, learning rate: 0.00526, Loss: 0.1279, Accuracy:0.945\nIteration: 13540, learning rate: 0.00526, Loss: 0.1134, Accuracy:0.977\nIteration: 13541, learning rate: 0.00526, Loss: 0.2140, Accuracy:0.898\nIteration: 13542, learning rate: 0.00526, Loss: 0.1110, Accuracy:0.945\nIteration: 13543, learning rate: 0.00526, Loss: 0.1450, Accuracy:0.945\nIteration: 13544, learning rate: 0.00526, Loss: 0.2317, Accuracy:0.914\nIteration: 13545, learning rate: 0.00526, Loss: 0.1559, Accuracy:0.930\nIteration: 13546, learning rate: 0.00526, Loss: 0.1300, Accuracy:0.945\nIteration: 13547, learning rate: 0.00526, Loss: 0.1155, Accuracy:0.957\nEpoch: 437, Loss: 0.1490, Accuracy:0.942, Val Loss: 0.2879, Val Accuracy: 0.879\nIteration: 13548, learning rate: 0.00526, Loss: 0.1341, Accuracy:0.961\nIteration: 13549, learning rate: 0.00526, Loss: 0.1055, Accuracy:0.953\nIteration: 13550, learning rate: 0.00526, Loss: 0.1443, Accuracy:0.930\nIteration: 13551, learning rate: 0.00526, Loss: 0.1343, Accuracy:0.945\nIteration: 13552, learning rate: 0.00526, Loss: 0.0804, Accuracy:0.977\nIteration: 13553, learning rate: 0.00526, Loss: 0.1627, Accuracy:0.945\nIteration: 13554, learning rate: 0.00526, Loss: 0.1032, Accuracy:0.953\nIteration: 13555, learning rate: 0.00526, Loss: 0.1965, Accuracy:0.906\nIteration: 13556, learning rate: 0.00526, Loss: 0.1960, Accuracy:0.945\nIteration: 13557, learning rate: 0.00526, Loss: 0.1212, Accuracy:0.961\nIteration: 13558, learning rate: 0.00526, Loss: 0.1605, Accuracy:0.953\nIteration: 13559, learning rate: 0.00526, Loss: 0.1590, Accuracy:0.938\nIteration: 13560, learning rate: 0.00526, Loss: 0.2085, Accuracy:0.922\nIteration: 13561, learning rate: 0.00526, Loss: 0.1961, Accuracy:0.922\nIteration: 13562, learning rate: 0.00526, Loss: 0.1100, Accuracy:0.953\nIteration: 13563, learning rate: 0.00526, Loss: 0.1734, Accuracy:0.938\nIteration: 13564, learning rate: 0.00526, Loss: 0.2733, Accuracy:0.898\nIteration: 13565, learning rate: 0.00526, Loss: 0.2033, Accuracy:0.930\nIteration: 13566, learning rate: 0.00526, Loss: 0.1652, Accuracy:0.945\nIteration: 13567, learning rate: 0.00526, Loss: 0.1793, Accuracy:0.938\nIteration: 13568, learning rate: 0.00526, Loss: 0.1223, Accuracy:0.945\nIteration: 13569, learning rate: 0.00526, Loss: 0.1465, Accuracy:0.953\nIteration: 13570, learning rate: 0.00526, Loss: 0.0943, Accuracy:0.969\nIteration: 13571, learning rate: 0.00526, Loss: 0.1290, Accuracy:0.961\nIteration: 13572, learning rate: 0.00526, Loss: 0.1708, Accuracy:0.945\nIteration: 13573, learning rate: 0.00526, Loss: 0.1393, Accuracy:0.945\nIteration: 13574, learning rate: 0.00526, Loss: 0.1905, Accuracy:0.906\nIteration: 13575, learning rate: 0.00526, Loss: 0.1334, Accuracy:0.961\nIteration: 13576, learning rate: 0.00526, Loss: 0.2383, Accuracy:0.922\nIteration: 13577, learning rate: 0.00526, Loss: 0.1590, Accuracy:0.922\nIteration: 13578, learning rate: 0.00526, Loss: 0.2277, Accuracy:0.925\nEpoch: 438, Loss: 0.1599, Accuracy:0.941, Val Loss: 0.2600, Val Accuracy: 0.895\nIteration: 13579, learning rate: 0.00526, Loss: 0.2169, Accuracy:0.906\nIteration: 13580, learning rate: 0.00526, Loss: 0.1434, Accuracy:0.945\nIteration: 13581, learning rate: 0.00526, Loss: 0.1722, Accuracy:0.938\nIteration: 13582, learning rate: 0.00526, Loss: 0.2006, Accuracy:0.922\nIteration: 13583, learning rate: 0.00525, Loss: 0.1585, Accuracy:0.945\nIteration: 13584, learning rate: 0.00525, Loss: 0.1364, Accuracy:0.945\nIteration: 13585, learning rate: 0.00525, Loss: 0.1403, Accuracy:0.945\nIteration: 13586, learning rate: 0.00525, Loss: 0.1513, Accuracy:0.930\nIteration: 13587, learning rate: 0.00525, Loss: 0.1014, Accuracy:0.977\nIteration: 13588, learning rate: 0.00525, Loss: 0.0692, Accuracy:0.969\nIteration: 13589, learning rate: 0.00525, Loss: 0.1080, Accuracy:0.977\nIteration: 13590, learning rate: 0.00525, Loss: 0.1545, Accuracy:0.969\nIteration: 13591, learning rate: 0.00525, Loss: 0.1392, Accuracy:0.930\nIteration: 13592, learning rate: 0.00525, Loss: 0.1076, Accuracy:0.969\nIteration: 13593, learning rate: 0.00525, Loss: 0.0940, Accuracy:0.969\nIteration: 13594, learning rate: 0.00525, Loss: 0.1763, Accuracy:0.930\nIteration: 13595, learning rate: 0.00525, Loss: 0.2297, Accuracy:0.891\nIteration: 13596, learning rate: 0.00525, Loss: 0.1575, Accuracy:0.938\nIteration: 13597, learning rate: 0.00525, Loss: 0.2101, Accuracy:0.938\nIteration: 13598, learning rate: 0.00525, Loss: 0.0785, Accuracy:0.961\nIteration: 13599, learning rate: 0.00525, Loss: 0.2155, Accuracy:0.883\nIteration: 13600, learning rate: 0.00525, Loss: 0.0722, Accuracy:0.984\nIteration: 13601, learning rate: 0.00525, Loss: 0.1842, Accuracy:0.930\nIteration: 13602, learning rate: 0.00525, Loss: 0.1328, Accuracy:0.953\nIteration: 13603, learning rate: 0.00525, Loss: 0.1310, Accuracy:0.938\nIteration: 13604, learning rate: 0.00525, Loss: 0.1473, Accuracy:0.922\nIteration: 13605, learning rate: 0.00525, Loss: 0.1379, Accuracy:0.938\nIteration: 13606, learning rate: 0.00525, Loss: 0.0877, Accuracy:0.969\nIteration: 13607, learning rate: 0.00525, Loss: 0.1294, Accuracy:0.961\nIteration: 13608, learning rate: 0.00525, Loss: 0.2293, Accuracy:0.906\nIteration: 13609, learning rate: 0.00525, Loss: 0.1465, Accuracy:0.935\nEpoch: 439, Loss: 0.1471, Accuracy:0.942, Val Loss: 0.2863, Val Accuracy: 0.881\nIteration: 13610, learning rate: 0.00525, Loss: 0.1985, Accuracy:0.922\nIteration: 13611, learning rate: 0.00525, Loss: 0.1534, Accuracy:0.961\nIteration: 13612, learning rate: 0.00525, Loss: 0.1324, Accuracy:0.969\nIteration: 13613, learning rate: 0.00525, Loss: 0.1059, Accuracy:0.953\nIteration: 13614, learning rate: 0.00525, Loss: 0.1165, Accuracy:0.969\nIteration: 13615, learning rate: 0.00525, Loss: 0.1241, Accuracy:0.961\nIteration: 13616, learning rate: 0.00525, Loss: 0.1609, Accuracy:0.922\nIteration: 13617, learning rate: 0.00525, Loss: 0.1048, Accuracy:0.969\nIteration: 13618, learning rate: 0.00525, Loss: 0.1334, Accuracy:0.930\nIteration: 13619, learning rate: 0.00525, Loss: 0.1122, Accuracy:0.953\nIteration: 13620, learning rate: 0.00525, Loss: 0.1521, Accuracy:0.922\nIteration: 13621, learning rate: 0.00525, Loss: 0.1559, Accuracy:0.953\nIteration: 13622, learning rate: 0.00525, Loss: 0.2000, Accuracy:0.938\nIteration: 13623, learning rate: 0.00525, Loss: 0.1119, Accuracy:0.961\nIteration: 13624, learning rate: 0.00525, Loss: 0.1329, Accuracy:0.945\nIteration: 13625, learning rate: 0.00525, Loss: 0.1233, Accuracy:0.961\nIteration: 13626, learning rate: 0.00525, Loss: 0.1229, Accuracy:0.953\nIteration: 13627, learning rate: 0.00525, Loss: 0.2051, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13628, learning rate: 0.00525, Loss: 0.1547, Accuracy:0.938\nIteration: 13629, learning rate: 0.00525, Loss: 0.1179, Accuracy:0.969\nIteration: 13630, learning rate: 0.00525, Loss: 0.1240, Accuracy:0.961\nIteration: 13631, learning rate: 0.00525, Loss: 0.1841, Accuracy:0.930\nIteration: 13632, learning rate: 0.00525, Loss: 0.1747, Accuracy:0.938\nIteration: 13633, learning rate: 0.00525, Loss: 0.1052, Accuracy:0.961\nIteration: 13634, learning rate: 0.00525, Loss: 0.1679, Accuracy:0.945\nIteration: 13635, learning rate: 0.00525, Loss: 0.0801, Accuracy:0.969\nIteration: 13636, learning rate: 0.00525, Loss: 0.2151, Accuracy:0.922\nIteration: 13637, learning rate: 0.00525, Loss: 0.1687, Accuracy:0.938\nIteration: 13638, learning rate: 0.00525, Loss: 0.1825, Accuracy:0.938\nIteration: 13639, learning rate: 0.00525, Loss: 0.1418, Accuracy:0.953\nIteration: 13640, learning rate: 0.00525, Loss: 0.1260, Accuracy:0.914\nEpoch: 440, Loss: 0.1448, Accuracy:0.946, Val Loss: 0.2980, Val Accuracy: 0.878\nIteration: 13641, learning rate: 0.00525, Loss: 0.1019, Accuracy:0.984\nIteration: 13642, learning rate: 0.00525, Loss: 0.1350, Accuracy:0.945\nIteration: 13643, learning rate: 0.00524, Loss: 0.1596, Accuracy:0.930\nIteration: 13644, learning rate: 0.00524, Loss: 0.1170, Accuracy:0.969\nIteration: 13645, learning rate: 0.00524, Loss: 0.1205, Accuracy:0.961\nIteration: 13646, learning rate: 0.00524, Loss: 0.1364, Accuracy:0.945\nIteration: 13647, learning rate: 0.00524, Loss: 0.1220, Accuracy:0.961\nIteration: 13648, learning rate: 0.00524, Loss: 0.1571, Accuracy:0.969\nIteration: 13649, learning rate: 0.00524, Loss: 0.1762, Accuracy:0.945\nIteration: 13650, learning rate: 0.00524, Loss: 0.1580, Accuracy:0.961\nIteration: 13651, learning rate: 0.00524, Loss: 0.1067, Accuracy:0.961\nIteration: 13652, learning rate: 0.00524, Loss: 0.1253, Accuracy:0.938\nIteration: 13653, learning rate: 0.00524, Loss: 0.1489, Accuracy:0.969\nIteration: 13654, learning rate: 0.00524, Loss: 0.2089, Accuracy:0.898\nIteration: 13655, learning rate: 0.00524, Loss: 0.1556, Accuracy:0.945\nIteration: 13656, learning rate: 0.00524, Loss: 0.0531, Accuracy:0.984\nIteration: 13657, learning rate: 0.00524, Loss: 0.1774, Accuracy:0.922\nIteration: 13658, learning rate: 0.00524, Loss: 0.1991, Accuracy:0.891\nIteration: 13659, learning rate: 0.00524, Loss: 0.1941, Accuracy:0.914\nIteration: 13660, learning rate: 0.00524, Loss: 0.1666, Accuracy:0.953\nIteration: 13661, learning rate: 0.00524, Loss: 0.1701, Accuracy:0.945\nIteration: 13662, learning rate: 0.00524, Loss: 0.1492, Accuracy:0.945\nIteration: 13663, learning rate: 0.00524, Loss: 0.1099, Accuracy:0.969\nIteration: 13664, learning rate: 0.00524, Loss: 0.1332, Accuracy:0.938\nIteration: 13665, learning rate: 0.00524, Loss: 0.1525, Accuracy:0.938\nIteration: 13666, learning rate: 0.00524, Loss: 0.1757, Accuracy:0.914\nIteration: 13667, learning rate: 0.00524, Loss: 0.1800, Accuracy:0.945\nIteration: 13668, learning rate: 0.00524, Loss: 0.1875, Accuracy:0.953\nIteration: 13669, learning rate: 0.00524, Loss: 0.1342, Accuracy:0.938\nIteration: 13670, learning rate: 0.00524, Loss: 0.1516, Accuracy:0.945\nIteration: 13671, learning rate: 0.00524, Loss: 0.0732, Accuracy:0.978\nEpoch: 441, Loss: 0.1463, Accuracy:0.947, Val Loss: 0.2587, Val Accuracy: 0.899\nIteration: 13672, learning rate: 0.00524, Loss: 0.0896, Accuracy:0.977\nIteration: 13673, learning rate: 0.00524, Loss: 0.1252, Accuracy:0.953\nIteration: 13674, learning rate: 0.00524, Loss: 0.1545, Accuracy:0.938\nIteration: 13675, learning rate: 0.00524, Loss: 0.0952, Accuracy:0.961\nIteration: 13676, learning rate: 0.00524, Loss: 0.1890, Accuracy:0.930\nIteration: 13677, learning rate: 0.00524, Loss: 0.1893, Accuracy:0.930\nIteration: 13678, learning rate: 0.00524, Loss: 0.1196, Accuracy:0.953\nIteration: 13679, learning rate: 0.00524, Loss: 0.0950, Accuracy:0.969\nIteration: 13680, learning rate: 0.00524, Loss: 0.1568, Accuracy:0.945\nIteration: 13681, learning rate: 0.00524, Loss: 0.2129, Accuracy:0.930\nIteration: 13682, learning rate: 0.00524, Loss: 0.1111, Accuracy:0.961\nIteration: 13683, learning rate: 0.00524, Loss: 0.1845, Accuracy:0.945\nIteration: 13684, learning rate: 0.00524, Loss: 0.1179, Accuracy:0.945\nIteration: 13685, learning rate: 0.00524, Loss: 0.1015, Accuracy:0.961\nIteration: 13686, learning rate: 0.00524, Loss: 0.1245, Accuracy:0.961\nIteration: 13687, learning rate: 0.00524, Loss: 0.1207, Accuracy:0.953\nIteration: 13688, learning rate: 0.00524, Loss: 0.1630, Accuracy:0.938\nIteration: 13689, learning rate: 0.00524, Loss: 0.1326, Accuracy:0.922\nIteration: 13690, learning rate: 0.00524, Loss: 0.1108, Accuracy:0.961\nIteration: 13691, learning rate: 0.00524, Loss: 0.1650, Accuracy:0.938\nIteration: 13692, learning rate: 0.00524, Loss: 0.1807, Accuracy:0.906\nIteration: 13693, learning rate: 0.00524, Loss: 0.1056, Accuracy:0.953\nIteration: 13694, learning rate: 0.00524, Loss: 0.1023, Accuracy:0.984\nIteration: 13695, learning rate: 0.00524, Loss: 0.1289, Accuracy:0.953\nIteration: 13696, learning rate: 0.00524, Loss: 0.1768, Accuracy:0.930\nIteration: 13697, learning rate: 0.00524, Loss: 0.1368, Accuracy:0.961\nIteration: 13698, learning rate: 0.00524, Loss: 0.1426, Accuracy:0.930\nIteration: 13699, learning rate: 0.00524, Loss: 0.1447, Accuracy:0.938\nIteration: 13700, learning rate: 0.00524, Loss: 0.1440, Accuracy:0.938\nIteration: 13701, learning rate: 0.00524, Loss: 0.1034, Accuracy:0.969\nIteration: 13702, learning rate: 0.00524, Loss: 0.1066, Accuracy:0.968\nEpoch: 442, Loss: 0.1365, Accuracy:0.948, Val Loss: 0.3152, Val Accuracy: 0.876\nIteration: 13703, learning rate: 0.00523, Loss: 0.1177, Accuracy:0.953\nIteration: 13704, learning rate: 0.00523, Loss: 0.1067, Accuracy:0.977\nIteration: 13705, learning rate: 0.00523, Loss: 0.1946, Accuracy:0.922\nIteration: 13706, learning rate: 0.00523, Loss: 0.1128, Accuracy:0.953\nIteration: 13707, learning rate: 0.00523, Loss: 0.1067, Accuracy:0.953\nIteration: 13708, learning rate: 0.00523, Loss: 0.1075, Accuracy:0.961\nIteration: 13709, learning rate: 0.00523, Loss: 0.1424, Accuracy:0.938\nIteration: 13710, learning rate: 0.00523, Loss: 0.1157, Accuracy:0.961\nIteration: 13711, learning rate: 0.00523, Loss: 0.1141, Accuracy:0.977\nIteration: 13712, learning rate: 0.00523, Loss: 0.1772, Accuracy:0.922\nIteration: 13713, learning rate: 0.00523, Loss: 0.1706, Accuracy:0.922\nIteration: 13714, learning rate: 0.00523, Loss: 0.1792, Accuracy:0.922\nIteration: 13715, learning rate: 0.00523, Loss: 0.0845, Accuracy:0.984\nIteration: 13716, learning rate: 0.00523, Loss: 0.1721, Accuracy:0.938\nIteration: 13717, learning rate: 0.00523, Loss: 0.2043, Accuracy:0.938\nIteration: 13718, learning rate: 0.00523, Loss: 0.1269, Accuracy:0.969\nIteration: 13719, learning rate: 0.00523, Loss: 0.1555, Accuracy:0.945\nIteration: 13720, learning rate: 0.00523, Loss: 0.1777, Accuracy:0.938\nIteration: 13721, learning rate: 0.00523, Loss: 0.0794, Accuracy:0.984\nIteration: 13722, learning rate: 0.00523, Loss: 0.1373, Accuracy:0.945\nIteration: 13723, learning rate: 0.00523, Loss: 0.1853, Accuracy:0.938\nIteration: 13724, learning rate: 0.00523, Loss: 0.1586, Accuracy:0.938\nIteration: 13725, learning rate: 0.00523, Loss: 0.1571, Accuracy:0.953\nIteration: 13726, learning rate: 0.00523, Loss: 0.1443, Accuracy:0.953\nIteration: 13727, learning rate: 0.00523, Loss: 0.1622, Accuracy:0.945\nIteration: 13728, learning rate: 0.00523, Loss: 0.1988, Accuracy:0.922\nIteration: 13729, learning rate: 0.00523, Loss: 0.1630, Accuracy:0.938\nIteration: 13730, learning rate: 0.00523, Loss: 0.1549, Accuracy:0.961\nIteration: 13731, learning rate: 0.00523, Loss: 0.0768, Accuracy:0.984\nIteration: 13732, learning rate: 0.00523, Loss: 0.1501, Accuracy:0.930\nIteration: 13733, learning rate: 0.00523, Loss: 0.1902, Accuracy:0.914\nEpoch: 443, Loss: 0.1459, Accuracy:0.948, Val Loss: 0.2923, Val Accuracy: 0.890\nIteration: 13734, learning rate: 0.00523, Loss: 0.1241, Accuracy:0.938\nIteration: 13735, learning rate: 0.00523, Loss: 0.1461, Accuracy:0.938\nIteration: 13736, learning rate: 0.00523, Loss: 0.2163, Accuracy:0.914\nIteration: 13737, learning rate: 0.00523, Loss: 0.1781, Accuracy:0.914\nIteration: 13738, learning rate: 0.00523, Loss: 0.0913, Accuracy:0.961\nIteration: 13739, learning rate: 0.00523, Loss: 0.1268, Accuracy:0.969\nIteration: 13740, learning rate: 0.00523, Loss: 0.1547, Accuracy:0.961\nIteration: 13741, learning rate: 0.00523, Loss: 0.1014, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13742, learning rate: 0.00523, Loss: 0.0808, Accuracy:0.961\nIteration: 13743, learning rate: 0.00523, Loss: 0.1073, Accuracy:0.961\nIteration: 13744, learning rate: 0.00523, Loss: 0.1789, Accuracy:0.945\nIteration: 13745, learning rate: 0.00523, Loss: 0.1223, Accuracy:0.930\nIteration: 13746, learning rate: 0.00523, Loss: 0.1749, Accuracy:0.930\nIteration: 13747, learning rate: 0.00523, Loss: 0.1491, Accuracy:0.938\nIteration: 13748, learning rate: 0.00523, Loss: 0.1514, Accuracy:0.953\nIteration: 13749, learning rate: 0.00523, Loss: 0.1520, Accuracy:0.953\nIteration: 13750, learning rate: 0.00523, Loss: 0.2190, Accuracy:0.922\nIteration: 13751, learning rate: 0.00523, Loss: 0.0947, Accuracy:0.961\nIteration: 13752, learning rate: 0.00523, Loss: 0.1219, Accuracy:0.953\nIteration: 13753, learning rate: 0.00523, Loss: 0.1178, Accuracy:0.961\nIteration: 13754, learning rate: 0.00523, Loss: 0.1391, Accuracy:0.969\nIteration: 13755, learning rate: 0.00523, Loss: 0.1057, Accuracy:0.969\nIteration: 13756, learning rate: 0.00523, Loss: 0.1904, Accuracy:0.930\nIteration: 13757, learning rate: 0.00523, Loss: 0.1316, Accuracy:0.961\nIteration: 13758, learning rate: 0.00523, Loss: 0.1112, Accuracy:0.961\nIteration: 13759, learning rate: 0.00523, Loss: 0.1898, Accuracy:0.906\nIteration: 13760, learning rate: 0.00523, Loss: 0.1016, Accuracy:0.969\nIteration: 13761, learning rate: 0.00523, Loss: 0.1084, Accuracy:0.961\nIteration: 13762, learning rate: 0.00523, Loss: 0.0921, Accuracy:0.961\nIteration: 13763, learning rate: 0.00523, Loss: 0.1275, Accuracy:0.953\nIteration: 13764, learning rate: 0.00522, Loss: 0.1630, Accuracy:0.925\nEpoch: 444, Loss: 0.1377, Accuracy:0.947, Val Loss: 0.2720, Val Accuracy: 0.879\nIteration: 13765, learning rate: 0.00522, Loss: 0.1531, Accuracy:0.945\nIteration: 13766, learning rate: 0.00522, Loss: 0.1769, Accuracy:0.922\nIteration: 13767, learning rate: 0.00522, Loss: 0.1420, Accuracy:0.945\nIteration: 13768, learning rate: 0.00522, Loss: 0.1311, Accuracy:0.953\nIteration: 13769, learning rate: 0.00522, Loss: 0.1448, Accuracy:0.961\nIteration: 13770, learning rate: 0.00522, Loss: 0.0722, Accuracy:0.992\nIteration: 13771, learning rate: 0.00522, Loss: 0.1337, Accuracy:0.953\nIteration: 13772, learning rate: 0.00522, Loss: 0.1207, Accuracy:0.953\nIteration: 13773, learning rate: 0.00522, Loss: 0.1143, Accuracy:0.945\nIteration: 13774, learning rate: 0.00522, Loss: 0.3136, Accuracy:0.867\nIteration: 13775, learning rate: 0.00522, Loss: 0.1453, Accuracy:0.938\nIteration: 13776, learning rate: 0.00522, Loss: 0.0840, Accuracy:0.969\nIteration: 13777, learning rate: 0.00522, Loss: 0.1877, Accuracy:0.938\nIteration: 13778, learning rate: 0.00522, Loss: 0.2286, Accuracy:0.922\nIteration: 13779, learning rate: 0.00522, Loss: 0.0854, Accuracy:0.961\nIteration: 13780, learning rate: 0.00522, Loss: 0.1879, Accuracy:0.945\nIteration: 13781, learning rate: 0.00522, Loss: 0.1340, Accuracy:0.938\nIteration: 13782, learning rate: 0.00522, Loss: 0.1516, Accuracy:0.953\nIteration: 13783, learning rate: 0.00522, Loss: 0.2337, Accuracy:0.914\nIteration: 13784, learning rate: 0.00522, Loss: 0.1048, Accuracy:0.953\nIteration: 13785, learning rate: 0.00522, Loss: 0.1200, Accuracy:0.961\nIteration: 13786, learning rate: 0.00522, Loss: 0.1329, Accuracy:0.945\nIteration: 13787, learning rate: 0.00522, Loss: 0.1523, Accuracy:0.938\nIteration: 13788, learning rate: 0.00522, Loss: 0.2224, Accuracy:0.914\nIteration: 13789, learning rate: 0.00522, Loss: 0.1373, Accuracy:0.969\nIteration: 13790, learning rate: 0.00522, Loss: 0.1975, Accuracy:0.914\nIteration: 13791, learning rate: 0.00522, Loss: 0.1649, Accuracy:0.945\nIteration: 13792, learning rate: 0.00522, Loss: 0.0882, Accuracy:0.953\nIteration: 13793, learning rate: 0.00522, Loss: 0.2222, Accuracy:0.914\nIteration: 13794, learning rate: 0.00522, Loss: 0.1746, Accuracy:0.930\nIteration: 13795, learning rate: 0.00522, Loss: 0.1062, Accuracy:0.957\nEpoch: 445, Loss: 0.1537, Accuracy:0.942, Val Loss: 0.2885, Val Accuracy: 0.887\nIteration: 13796, learning rate: 0.00522, Loss: 0.0587, Accuracy:0.992\nIteration: 13797, learning rate: 0.00522, Loss: 0.1398, Accuracy:0.930\nIteration: 13798, learning rate: 0.00522, Loss: 0.1110, Accuracy:0.961\nIteration: 13799, learning rate: 0.00522, Loss: 0.1040, Accuracy:0.953\nIteration: 13800, learning rate: 0.00522, Loss: 0.1694, Accuracy:0.938\nIteration: 13801, learning rate: 0.00522, Loss: 0.1476, Accuracy:0.953\nIteration: 13802, learning rate: 0.00522, Loss: 0.1322, Accuracy:0.953\nIteration: 13803, learning rate: 0.00522, Loss: 0.1456, Accuracy:0.922\nIteration: 13804, learning rate: 0.00522, Loss: 0.1165, Accuracy:0.969\nIteration: 13805, learning rate: 0.00522, Loss: 0.1823, Accuracy:0.938\nIteration: 13806, learning rate: 0.00522, Loss: 0.1025, Accuracy:0.953\nIteration: 13807, learning rate: 0.00522, Loss: 0.1045, Accuracy:0.961\nIteration: 13808, learning rate: 0.00522, Loss: 0.1279, Accuracy:0.930\nIteration: 13809, learning rate: 0.00522, Loss: 0.1371, Accuracy:0.953\nIteration: 13810, learning rate: 0.00522, Loss: 0.1358, Accuracy:0.961\nIteration: 13811, learning rate: 0.00522, Loss: 0.0983, Accuracy:0.961\nIteration: 13812, learning rate: 0.00522, Loss: 0.1807, Accuracy:0.938\nIteration: 13813, learning rate: 0.00522, Loss: 0.1893, Accuracy:0.906\nIteration: 13814, learning rate: 0.00522, Loss: 0.0784, Accuracy:0.992\nIteration: 13815, learning rate: 0.00522, Loss: 0.1668, Accuracy:0.938\nIteration: 13816, learning rate: 0.00522, Loss: 0.1582, Accuracy:0.961\nIteration: 13817, learning rate: 0.00522, Loss: 0.1853, Accuracy:0.898\nIteration: 13818, learning rate: 0.00522, Loss: 0.1471, Accuracy:0.945\nIteration: 13819, learning rate: 0.00522, Loss: 0.1943, Accuracy:0.891\nIteration: 13820, learning rate: 0.00522, Loss: 0.1953, Accuracy:0.898\nIteration: 13821, learning rate: 0.00522, Loss: 0.0930, Accuracy:0.977\nIteration: 13822, learning rate: 0.00522, Loss: 0.2012, Accuracy:0.930\nIteration: 13823, learning rate: 0.00522, Loss: 0.1202, Accuracy:0.953\nIteration: 13824, learning rate: 0.00521, Loss: 0.0654, Accuracy:0.984\nIteration: 13825, learning rate: 0.00521, Loss: 0.1480, Accuracy:0.930\nIteration: 13826, learning rate: 0.00521, Loss: 0.1743, Accuracy:0.935\nEpoch: 446, Loss: 0.1391, Accuracy:0.945, Val Loss: 0.2808, Val Accuracy: 0.897\nIteration: 13827, learning rate: 0.00521, Loss: 0.1219, Accuracy:0.953\nIteration: 13828, learning rate: 0.00521, Loss: 0.1417, Accuracy:0.945\nIteration: 13829, learning rate: 0.00521, Loss: 0.1200, Accuracy:0.961\nIteration: 13830, learning rate: 0.00521, Loss: 0.1255, Accuracy:0.953\nIteration: 13831, learning rate: 0.00521, Loss: 0.0956, Accuracy:0.969\nIteration: 13832, learning rate: 0.00521, Loss: 0.1982, Accuracy:0.922\nIteration: 13833, learning rate: 0.00521, Loss: 0.1585, Accuracy:0.953\nIteration: 13834, learning rate: 0.00521, Loss: 0.2097, Accuracy:0.930\nIteration: 13835, learning rate: 0.00521, Loss: 0.1557, Accuracy:0.938\nIteration: 13836, learning rate: 0.00521, Loss: 0.1625, Accuracy:0.930\nIteration: 13837, learning rate: 0.00521, Loss: 0.1252, Accuracy:0.938\nIteration: 13838, learning rate: 0.00521, Loss: 0.1966, Accuracy:0.914\nIteration: 13839, learning rate: 0.00521, Loss: 0.2083, Accuracy:0.922\nIteration: 13840, learning rate: 0.00521, Loss: 0.1335, Accuracy:0.977\nIteration: 13841, learning rate: 0.00521, Loss: 0.1576, Accuracy:0.961\nIteration: 13842, learning rate: 0.00521, Loss: 0.2535, Accuracy:0.891\nIteration: 13843, learning rate: 0.00521, Loss: 0.1271, Accuracy:0.922\nIteration: 13844, learning rate: 0.00521, Loss: 0.1246, Accuracy:0.961\nIteration: 13845, learning rate: 0.00521, Loss: 0.0855, Accuracy:0.977\nIteration: 13846, learning rate: 0.00521, Loss: 0.1584, Accuracy:0.953\nIteration: 13847, learning rate: 0.00521, Loss: 0.1320, Accuracy:0.953\nIteration: 13848, learning rate: 0.00521, Loss: 0.1212, Accuracy:0.953\nIteration: 13849, learning rate: 0.00521, Loss: 0.1919, Accuracy:0.922\nIteration: 13850, learning rate: 0.00521, Loss: 0.1644, Accuracy:0.945\nIteration: 13851, learning rate: 0.00521, Loss: 0.1264, Accuracy:0.969\nIteration: 13852, learning rate: 0.00521, Loss: 0.1826, Accuracy:0.930\nIteration: 13853, learning rate: 0.00521, Loss: 0.1127, Accuracy:0.969\nIteration: 13854, learning rate: 0.00521, Loss: 0.2266, Accuracy:0.930\nIteration: 13855, learning rate: 0.00521, Loss: 0.1380, Accuracy:0.953\nIteration: 13856, learning rate: 0.00521, Loss: 0.1082, Accuracy:0.969\nIteration: 13857, learning rate: 0.00521, Loss: 0.1779, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 447, Loss: 0.1529, Accuracy:0.945, Val Loss: 0.2352, Val Accuracy: 0.900\nIteration: 13858, learning rate: 0.00521, Loss: 0.1409, Accuracy:0.922\nIteration: 13859, learning rate: 0.00521, Loss: 0.1280, Accuracy:0.938\nIteration: 13860, learning rate: 0.00521, Loss: 0.0751, Accuracy:0.984\nIteration: 13861, learning rate: 0.00521, Loss: 0.1585, Accuracy:0.945\nIteration: 13862, learning rate: 0.00521, Loss: 0.1621, Accuracy:0.914\nIteration: 13863, learning rate: 0.00521, Loss: 0.2011, Accuracy:0.914\nIteration: 13864, learning rate: 0.00521, Loss: 0.1254, Accuracy:0.945\nIteration: 13865, learning rate: 0.00521, Loss: 0.1430, Accuracy:0.938\nIteration: 13866, learning rate: 0.00521, Loss: 0.1153, Accuracy:0.953\nIteration: 13867, learning rate: 0.00521, Loss: 0.1326, Accuracy:0.945\nIteration: 13868, learning rate: 0.00521, Loss: 0.1847, Accuracy:0.938\nIteration: 13869, learning rate: 0.00521, Loss: 0.2360, Accuracy:0.906\nIteration: 13870, learning rate: 0.00521, Loss: 0.1371, Accuracy:0.961\nIteration: 13871, learning rate: 0.00521, Loss: 0.0847, Accuracy:0.984\nIteration: 13872, learning rate: 0.00521, Loss: 0.1523, Accuracy:0.938\nIteration: 13873, learning rate: 0.00521, Loss: 0.0702, Accuracy:0.977\nIteration: 13874, learning rate: 0.00521, Loss: 0.1658, Accuracy:0.922\nIteration: 13875, learning rate: 0.00521, Loss: 0.1512, Accuracy:0.953\nIteration: 13876, learning rate: 0.00521, Loss: 0.1895, Accuracy:0.938\nIteration: 13877, learning rate: 0.00521, Loss: 0.1387, Accuracy:0.922\nIteration: 13878, learning rate: 0.00521, Loss: 0.1099, Accuracy:0.953\nIteration: 13879, learning rate: 0.00521, Loss: 0.1161, Accuracy:0.961\nIteration: 13880, learning rate: 0.00521, Loss: 0.1987, Accuracy:0.938\nIteration: 13881, learning rate: 0.00521, Loss: 0.2051, Accuracy:0.914\nIteration: 13882, learning rate: 0.00521, Loss: 0.1982, Accuracy:0.922\nIteration: 13883, learning rate: 0.00521, Loss: 0.1704, Accuracy:0.930\nIteration: 13884, learning rate: 0.00521, Loss: 0.2289, Accuracy:0.906\nIteration: 13885, learning rate: 0.00520, Loss: 0.1710, Accuracy:0.945\nIteration: 13886, learning rate: 0.00520, Loss: 0.2404, Accuracy:0.898\nIteration: 13887, learning rate: 0.00520, Loss: 0.1170, Accuracy:0.953\nIteration: 13888, learning rate: 0.00520, Loss: 0.1813, Accuracy:0.925\nEpoch: 448, Loss: 0.1558, Accuracy:0.938, Val Loss: 0.2401, Val Accuracy: 0.898\nIteration: 13889, learning rate: 0.00520, Loss: 0.1135, Accuracy:0.953\nIteration: 13890, learning rate: 0.00520, Loss: 0.1337, Accuracy:0.938\nIteration: 13891, learning rate: 0.00520, Loss: 0.1393, Accuracy:0.930\nIteration: 13892, learning rate: 0.00520, Loss: 0.2201, Accuracy:0.914\nIteration: 13893, learning rate: 0.00520, Loss: 0.1210, Accuracy:0.953\nIteration: 13894, learning rate: 0.00520, Loss: 0.1084, Accuracy:0.969\nIteration: 13895, learning rate: 0.00520, Loss: 0.1015, Accuracy:0.953\nIteration: 13896, learning rate: 0.00520, Loss: 0.1932, Accuracy:0.938\nIteration: 13897, learning rate: 0.00520, Loss: 0.1752, Accuracy:0.922\nIteration: 13898, learning rate: 0.00520, Loss: 0.1445, Accuracy:0.953\nIteration: 13899, learning rate: 0.00520, Loss: 0.2128, Accuracy:0.914\nIteration: 13900, learning rate: 0.00520, Loss: 0.2079, Accuracy:0.922\nIteration: 13901, learning rate: 0.00520, Loss: 0.1532, Accuracy:0.938\nIteration: 13902, learning rate: 0.00520, Loss: 0.1482, Accuracy:0.938\nIteration: 13903, learning rate: 0.00520, Loss: 0.1130, Accuracy:0.953\nIteration: 13904, learning rate: 0.00520, Loss: 0.0824, Accuracy:0.977\nIteration: 13905, learning rate: 0.00520, Loss: 0.1404, Accuracy:0.945\nIteration: 13906, learning rate: 0.00520, Loss: 0.1527, Accuracy:0.930\nIteration: 13907, learning rate: 0.00520, Loss: 0.1551, Accuracy:0.945\nIteration: 13908, learning rate: 0.00520, Loss: 0.1047, Accuracy:0.969\nIteration: 13909, learning rate: 0.00520, Loss: 0.1306, Accuracy:0.953\nIteration: 13910, learning rate: 0.00520, Loss: 0.2170, Accuracy:0.906\nIteration: 13911, learning rate: 0.00520, Loss: 0.1073, Accuracy:0.945\nIteration: 13912, learning rate: 0.00520, Loss: 0.1638, Accuracy:0.922\nIteration: 13913, learning rate: 0.00520, Loss: 0.1576, Accuracy:0.930\nIteration: 13914, learning rate: 0.00520, Loss: 0.1767, Accuracy:0.930\nIteration: 13915, learning rate: 0.00520, Loss: 0.1832, Accuracy:0.930\nIteration: 13916, learning rate: 0.00520, Loss: 0.1509, Accuracy:0.945\nIteration: 13917, learning rate: 0.00520, Loss: 0.1064, Accuracy:0.969\nIteration: 13918, learning rate: 0.00520, Loss: 0.1956, Accuracy:0.922\nIteration: 13919, learning rate: 0.00520, Loss: 0.1619, Accuracy:0.946\nEpoch: 449, Loss: 0.1507, Accuracy:0.940, Val Loss: 0.2859, Val Accuracy: 0.883\nIteration: 13920, learning rate: 0.00520, Loss: 0.1038, Accuracy:0.969\nIteration: 13921, learning rate: 0.00520, Loss: 0.1589, Accuracy:0.938\nIteration: 13922, learning rate: 0.00520, Loss: 0.2060, Accuracy:0.922\nIteration: 13923, learning rate: 0.00520, Loss: 0.1716, Accuracy:0.938\nIteration: 13924, learning rate: 0.00520, Loss: 0.1354, Accuracy:0.930\nIteration: 13925, learning rate: 0.00520, Loss: 0.2359, Accuracy:0.906\nIteration: 13926, learning rate: 0.00520, Loss: 0.1653, Accuracy:0.930\nIteration: 13927, learning rate: 0.00520, Loss: 0.1381, Accuracy:0.953\nIteration: 13928, learning rate: 0.00520, Loss: 0.1996, Accuracy:0.898\nIteration: 13929, learning rate: 0.00520, Loss: 0.1408, Accuracy:0.953\nIteration: 13930, learning rate: 0.00520, Loss: 0.1120, Accuracy:0.945\nIteration: 13931, learning rate: 0.00520, Loss: 0.1160, Accuracy:0.953\nIteration: 13932, learning rate: 0.00520, Loss: 0.1864, Accuracy:0.930\nIteration: 13933, learning rate: 0.00520, Loss: 0.2125, Accuracy:0.922\nIteration: 13934, learning rate: 0.00520, Loss: 0.0978, Accuracy:0.977\nIteration: 13935, learning rate: 0.00520, Loss: 0.1132, Accuracy:0.969\nIteration: 13936, learning rate: 0.00520, Loss: 0.1598, Accuracy:0.938\nIteration: 13937, learning rate: 0.00520, Loss: 0.1196, Accuracy:0.945\nIteration: 13938, learning rate: 0.00520, Loss: 0.1469, Accuracy:0.930\nIteration: 13939, learning rate: 0.00520, Loss: 0.1077, Accuracy:0.961\nIteration: 13940, learning rate: 0.00520, Loss: 0.1764, Accuracy:0.922\nIteration: 13941, learning rate: 0.00520, Loss: 0.1182, Accuracy:0.961\nIteration: 13942, learning rate: 0.00520, Loss: 0.1428, Accuracy:0.930\nIteration: 13943, learning rate: 0.00520, Loss: 0.1571, Accuracy:0.922\nIteration: 13944, learning rate: 0.00520, Loss: 0.1585, Accuracy:0.938\nIteration: 13945, learning rate: 0.00520, Loss: 0.1511, Accuracy:0.938\nIteration: 13946, learning rate: 0.00520, Loss: 0.1575, Accuracy:0.938\nIteration: 13947, learning rate: 0.00519, Loss: 0.0966, Accuracy:0.961\nIteration: 13948, learning rate: 0.00519, Loss: 0.1583, Accuracy:0.938\nIteration: 13949, learning rate: 0.00519, Loss: 0.0995, Accuracy:0.977\nIteration: 13950, learning rate: 0.00519, Loss: 0.0822, Accuracy:0.989\nEpoch: 450, Loss: 0.1460, Accuracy:0.942, Val Loss: 0.2948, Val Accuracy: 0.884\nIteration: 13951, learning rate: 0.00519, Loss: 0.2215, Accuracy:0.930\nIteration: 13952, learning rate: 0.00519, Loss: 0.1251, Accuracy:0.945\nIteration: 13953, learning rate: 0.00519, Loss: 0.1721, Accuracy:0.938\nIteration: 13954, learning rate: 0.00519, Loss: 0.2353, Accuracy:0.906\nIteration: 13955, learning rate: 0.00519, Loss: 0.1698, Accuracy:0.914\nIteration: 13956, learning rate: 0.00519, Loss: 0.1768, Accuracy:0.922\nIteration: 13957, learning rate: 0.00519, Loss: 0.1532, Accuracy:0.953\nIteration: 13958, learning rate: 0.00519, Loss: 0.1839, Accuracy:0.922\nIteration: 13959, learning rate: 0.00519, Loss: 0.2191, Accuracy:0.922\nIteration: 13960, learning rate: 0.00519, Loss: 0.1149, Accuracy:0.969\nIteration: 13961, learning rate: 0.00519, Loss: 0.1534, Accuracy:0.938\nIteration: 13962, learning rate: 0.00519, Loss: 0.1359, Accuracy:0.961\nIteration: 13963, learning rate: 0.00519, Loss: 0.1372, Accuracy:0.969\nIteration: 13964, learning rate: 0.00519, Loss: 0.2098, Accuracy:0.898\nIteration: 13965, learning rate: 0.00519, Loss: 0.2154, Accuracy:0.930\nIteration: 13966, learning rate: 0.00519, Loss: 0.1568, Accuracy:0.938\nIteration: 13967, learning rate: 0.00519, Loss: 0.1078, Accuracy:0.961\nIteration: 13968, learning rate: 0.00519, Loss: 0.1441, Accuracy:0.945\nIteration: 13969, learning rate: 0.00519, Loss: 0.1427, Accuracy:0.922\nIteration: 13970, learning rate: 0.00519, Loss: 0.1462, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 13971, learning rate: 0.00519, Loss: 0.2319, Accuracy:0.906\nIteration: 13972, learning rate: 0.00519, Loss: 0.0842, Accuracy:0.969\nIteration: 13973, learning rate: 0.00519, Loss: 0.0962, Accuracy:0.977\nIteration: 13974, learning rate: 0.00519, Loss: 0.2088, Accuracy:0.930\nIteration: 13975, learning rate: 0.00519, Loss: 0.1897, Accuracy:0.914\nIteration: 13976, learning rate: 0.00519, Loss: 0.1198, Accuracy:0.969\nIteration: 13977, learning rate: 0.00519, Loss: 0.2574, Accuracy:0.898\nIteration: 13978, learning rate: 0.00519, Loss: 0.0899, Accuracy:0.969\nIteration: 13979, learning rate: 0.00519, Loss: 0.0978, Accuracy:0.961\nIteration: 13980, learning rate: 0.00519, Loss: 0.1538, Accuracy:0.930\nIteration: 13981, learning rate: 0.00519, Loss: 0.2197, Accuracy:0.903\nEpoch: 451, Loss: 0.1636, Accuracy:0.937, Val Loss: 0.2823, Val Accuracy: 0.891\nIteration: 13982, learning rate: 0.00519, Loss: 0.1528, Accuracy:0.938\nIteration: 13983, learning rate: 0.00519, Loss: 0.1619, Accuracy:0.953\nIteration: 13984, learning rate: 0.00519, Loss: 0.1609, Accuracy:0.914\nIteration: 13985, learning rate: 0.00519, Loss: 0.1008, Accuracy:0.969\nIteration: 13986, learning rate: 0.00519, Loss: 0.1560, Accuracy:0.938\nIteration: 13987, learning rate: 0.00519, Loss: 0.1425, Accuracy:0.938\nIteration: 13988, learning rate: 0.00519, Loss: 0.1850, Accuracy:0.930\nIteration: 13989, learning rate: 0.00519, Loss: 0.2126, Accuracy:0.938\nIteration: 13990, learning rate: 0.00519, Loss: 0.0982, Accuracy:0.977\nIteration: 13991, learning rate: 0.00519, Loss: 0.1321, Accuracy:0.961\nIteration: 13992, learning rate: 0.00519, Loss: 0.2227, Accuracy:0.922\nIteration: 13993, learning rate: 0.00519, Loss: 0.2197, Accuracy:0.914\nIteration: 13994, learning rate: 0.00519, Loss: 0.1107, Accuracy:0.961\nIteration: 13995, learning rate: 0.00519, Loss: 0.1591, Accuracy:0.945\nIteration: 13996, learning rate: 0.00519, Loss: 0.1787, Accuracy:0.930\nIteration: 13997, learning rate: 0.00519, Loss: 0.1738, Accuracy:0.945\nIteration: 13998, learning rate: 0.00519, Loss: 0.1489, Accuracy:0.914\nIteration: 13999, learning rate: 0.00519, Loss: 0.1547, Accuracy:0.977\nIteration: 14000, learning rate: 0.00519, Loss: 0.1721, Accuracy:0.953\nIteration: 14001, learning rate: 0.00519, Loss: 0.1703, Accuracy:0.930\nIteration: 14002, learning rate: 0.00519, Loss: 0.1869, Accuracy:0.914\nIteration: 14003, learning rate: 0.00519, Loss: 0.1542, Accuracy:0.938\nIteration: 14004, learning rate: 0.00519, Loss: 0.1131, Accuracy:0.961\nIteration: 14005, learning rate: 0.00519, Loss: 0.0899, Accuracy:0.961\nIteration: 14006, learning rate: 0.00519, Loss: 0.1652, Accuracy:0.922\nIteration: 14007, learning rate: 0.00519, Loss: 0.1858, Accuracy:0.914\nIteration: 14008, learning rate: 0.00518, Loss: 0.1316, Accuracy:0.930\nIteration: 14009, learning rate: 0.00518, Loss: 0.1354, Accuracy:0.938\nIteration: 14010, learning rate: 0.00518, Loss: 0.1077, Accuracy:0.977\nIteration: 14011, learning rate: 0.00518, Loss: 0.1029, Accuracy:0.961\nIteration: 14012, learning rate: 0.00518, Loss: 0.1799, Accuracy:0.925\nEpoch: 452, Loss: 0.1537, Accuracy:0.941, Val Loss: 0.3205, Val Accuracy: 0.878\nIteration: 14013, learning rate: 0.00518, Loss: 0.1063, Accuracy:0.969\nIteration: 14014, learning rate: 0.00518, Loss: 0.1734, Accuracy:0.938\nIteration: 14015, learning rate: 0.00518, Loss: 0.1372, Accuracy:0.922\nIteration: 14016, learning rate: 0.00518, Loss: 0.1299, Accuracy:0.953\nIteration: 14017, learning rate: 0.00518, Loss: 0.1113, Accuracy:0.969\nIteration: 14018, learning rate: 0.00518, Loss: 0.1732, Accuracy:0.930\nIteration: 14019, learning rate: 0.00518, Loss: 0.1195, Accuracy:0.945\nIteration: 14020, learning rate: 0.00518, Loss: 0.1278, Accuracy:0.961\nIteration: 14021, learning rate: 0.00518, Loss: 0.1615, Accuracy:0.938\nIteration: 14022, learning rate: 0.00518, Loss: 0.1228, Accuracy:0.961\nIteration: 14023, learning rate: 0.00518, Loss: 0.2490, Accuracy:0.906\nIteration: 14024, learning rate: 0.00518, Loss: 0.1442, Accuracy:0.922\nIteration: 14025, learning rate: 0.00518, Loss: 0.2347, Accuracy:0.914\nIteration: 14026, learning rate: 0.00518, Loss: 0.1747, Accuracy:0.938\nIteration: 14027, learning rate: 0.00518, Loss: 0.1765, Accuracy:0.906\nIteration: 14028, learning rate: 0.00518, Loss: 0.1120, Accuracy:0.953\nIteration: 14029, learning rate: 0.00518, Loss: 0.1271, Accuracy:0.945\nIteration: 14030, learning rate: 0.00518, Loss: 0.1793, Accuracy:0.930\nIteration: 14031, learning rate: 0.00518, Loss: 0.1511, Accuracy:0.953\nIteration: 14032, learning rate: 0.00518, Loss: 0.1405, Accuracy:0.953\nIteration: 14033, learning rate: 0.00518, Loss: 0.1745, Accuracy:0.930\nIteration: 14034, learning rate: 0.00518, Loss: 0.1657, Accuracy:0.922\nIteration: 14035, learning rate: 0.00518, Loss: 0.0946, Accuracy:0.969\nIteration: 14036, learning rate: 0.00518, Loss: 0.1177, Accuracy:0.953\nIteration: 14037, learning rate: 0.00518, Loss: 0.1012, Accuracy:0.961\nIteration: 14038, learning rate: 0.00518, Loss: 0.1458, Accuracy:0.938\nIteration: 14039, learning rate: 0.00518, Loss: 0.1418, Accuracy:0.938\nIteration: 14040, learning rate: 0.00518, Loss: 0.1067, Accuracy:0.961\nIteration: 14041, learning rate: 0.00518, Loss: 0.0844, Accuracy:0.961\nIteration: 14042, learning rate: 0.00518, Loss: 0.1770, Accuracy:0.906\nIteration: 14043, learning rate: 0.00518, Loss: 0.2140, Accuracy:0.903\nEpoch: 453, Loss: 0.1476, Accuracy:0.940, Val Loss: 0.2237, Val Accuracy: 0.914\nIteration: 14044, learning rate: 0.00518, Loss: 0.1535, Accuracy:0.930\nIteration: 14045, learning rate: 0.00518, Loss: 0.1364, Accuracy:0.945\nIteration: 14046, learning rate: 0.00518, Loss: 0.1593, Accuracy:0.930\nIteration: 14047, learning rate: 0.00518, Loss: 0.1449, Accuracy:0.922\nIteration: 14048, learning rate: 0.00518, Loss: 0.1838, Accuracy:0.938\nIteration: 14049, learning rate: 0.00518, Loss: 0.0957, Accuracy:0.977\nIteration: 14050, learning rate: 0.00518, Loss: 0.1535, Accuracy:0.938\nIteration: 14051, learning rate: 0.00518, Loss: 0.1621, Accuracy:0.930\nIteration: 14052, learning rate: 0.00518, Loss: 0.1205, Accuracy:0.961\nIteration: 14053, learning rate: 0.00518, Loss: 0.1670, Accuracy:0.938\nIteration: 14054, learning rate: 0.00518, Loss: 0.1709, Accuracy:0.930\nIteration: 14055, learning rate: 0.00518, Loss: 0.1486, Accuracy:0.938\nIteration: 14056, learning rate: 0.00518, Loss: 0.2517, Accuracy:0.898\nIteration: 14057, learning rate: 0.00518, Loss: 0.1997, Accuracy:0.938\nIteration: 14058, learning rate: 0.00518, Loss: 0.1344, Accuracy:0.953\nIteration: 14059, learning rate: 0.00518, Loss: 0.1794, Accuracy:0.914\nIteration: 14060, learning rate: 0.00518, Loss: 0.1548, Accuracy:0.945\nIteration: 14061, learning rate: 0.00518, Loss: 0.0837, Accuracy:0.984\nIteration: 14062, learning rate: 0.00518, Loss: 0.1378, Accuracy:0.953\nIteration: 14063, learning rate: 0.00518, Loss: 0.1457, Accuracy:0.969\nIteration: 14064, learning rate: 0.00518, Loss: 0.1009, Accuracy:0.961\nIteration: 14065, learning rate: 0.00518, Loss: 0.1162, Accuracy:0.961\nIteration: 14066, learning rate: 0.00518, Loss: 0.0979, Accuracy:0.961\nIteration: 14067, learning rate: 0.00518, Loss: 0.1914, Accuracy:0.930\nIteration: 14068, learning rate: 0.00518, Loss: 0.1048, Accuracy:0.969\nIteration: 14069, learning rate: 0.00518, Loss: 0.1037, Accuracy:0.969\nIteration: 14070, learning rate: 0.00517, Loss: 0.0723, Accuracy:0.984\nIteration: 14071, learning rate: 0.00517, Loss: 0.1222, Accuracy:0.961\nIteration: 14072, learning rate: 0.00517, Loss: 0.1859, Accuracy:0.922\nIteration: 14073, learning rate: 0.00517, Loss: 0.2094, Accuracy:0.930\nIteration: 14074, learning rate: 0.00517, Loss: 0.0761, Accuracy:0.968\nEpoch: 454, Loss: 0.1440, Accuracy:0.947, Val Loss: 0.2529, Val Accuracy: 0.900\nIteration: 14075, learning rate: 0.00517, Loss: 0.0985, Accuracy:0.969\nIteration: 14076, learning rate: 0.00517, Loss: 0.1703, Accuracy:0.922\nIteration: 14077, learning rate: 0.00517, Loss: 0.1177, Accuracy:0.961\nIteration: 14078, learning rate: 0.00517, Loss: 0.0996, Accuracy:0.953\nIteration: 14079, learning rate: 0.00517, Loss: 0.1382, Accuracy:0.969\nIteration: 14080, learning rate: 0.00517, Loss: 0.1085, Accuracy:0.953\nIteration: 14081, learning rate: 0.00517, Loss: 0.1423, Accuracy:0.938\nIteration: 14082, learning rate: 0.00517, Loss: 0.0688, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14083, learning rate: 0.00517, Loss: 0.1168, Accuracy:0.969\nIteration: 14084, learning rate: 0.00517, Loss: 0.1835, Accuracy:0.914\nIteration: 14085, learning rate: 0.00517, Loss: 0.0978, Accuracy:0.977\nIteration: 14086, learning rate: 0.00517, Loss: 0.0695, Accuracy:0.984\nIteration: 14087, learning rate: 0.00517, Loss: 0.1694, Accuracy:0.930\nIteration: 14088, learning rate: 0.00517, Loss: 0.1542, Accuracy:0.938\nIteration: 14089, learning rate: 0.00517, Loss: 0.1777, Accuracy:0.930\nIteration: 14090, learning rate: 0.00517, Loss: 0.1445, Accuracy:0.938\nIteration: 14091, learning rate: 0.00517, Loss: 0.1391, Accuracy:0.953\nIteration: 14092, learning rate: 0.00517, Loss: 0.1441, Accuracy:0.945\nIteration: 14093, learning rate: 0.00517, Loss: 0.1200, Accuracy:0.953\nIteration: 14094, learning rate: 0.00517, Loss: 0.1723, Accuracy:0.945\nIteration: 14095, learning rate: 0.00517, Loss: 0.1232, Accuracy:0.953\nIteration: 14096, learning rate: 0.00517, Loss: 0.1454, Accuracy:0.969\nIteration: 14097, learning rate: 0.00517, Loss: 0.1878, Accuracy:0.945\nIteration: 14098, learning rate: 0.00517, Loss: 0.1213, Accuracy:0.945\nIteration: 14099, learning rate: 0.00517, Loss: 0.1529, Accuracy:0.953\nIteration: 14100, learning rate: 0.00517, Loss: 0.1129, Accuracy:0.930\nIteration: 14101, learning rate: 0.00517, Loss: 0.1618, Accuracy:0.953\nIteration: 14102, learning rate: 0.00517, Loss: 0.1841, Accuracy:0.930\nIteration: 14103, learning rate: 0.00517, Loss: 0.1731, Accuracy:0.922\nIteration: 14104, learning rate: 0.00517, Loss: 0.2304, Accuracy:0.906\nIteration: 14105, learning rate: 0.00517, Loss: 0.1331, Accuracy:0.946\nEpoch: 455, Loss: 0.1406, Accuracy:0.947, Val Loss: 0.2798, Val Accuracy: 0.879\nIteration: 14106, learning rate: 0.00517, Loss: 0.2020, Accuracy:0.930\nIteration: 14107, learning rate: 0.00517, Loss: 0.1082, Accuracy:0.977\nIteration: 14108, learning rate: 0.00517, Loss: 0.1269, Accuracy:0.953\nIteration: 14109, learning rate: 0.00517, Loss: 0.1651, Accuracy:0.930\nIteration: 14110, learning rate: 0.00517, Loss: 0.1298, Accuracy:0.961\nIteration: 14111, learning rate: 0.00517, Loss: 0.1710, Accuracy:0.938\nIteration: 14112, learning rate: 0.00517, Loss: 0.1196, Accuracy:0.953\nIteration: 14113, learning rate: 0.00517, Loss: 0.1252, Accuracy:0.938\nIteration: 14114, learning rate: 0.00517, Loss: 0.0944, Accuracy:0.969\nIteration: 14115, learning rate: 0.00517, Loss: 0.1565, Accuracy:0.938\nIteration: 14116, learning rate: 0.00517, Loss: 0.1101, Accuracy:0.961\nIteration: 14117, learning rate: 0.00517, Loss: 0.1245, Accuracy:0.953\nIteration: 14118, learning rate: 0.00517, Loss: 0.1648, Accuracy:0.930\nIteration: 14119, learning rate: 0.00517, Loss: 0.1542, Accuracy:0.945\nIteration: 14120, learning rate: 0.00517, Loss: 0.1599, Accuracy:0.938\nIteration: 14121, learning rate: 0.00517, Loss: 0.1531, Accuracy:0.922\nIteration: 14122, learning rate: 0.00517, Loss: 0.1805, Accuracy:0.922\nIteration: 14123, learning rate: 0.00517, Loss: 0.2024, Accuracy:0.922\nIteration: 14124, learning rate: 0.00517, Loss: 0.1418, Accuracy:0.953\nIteration: 14125, learning rate: 0.00517, Loss: 0.1440, Accuracy:0.938\nIteration: 14126, learning rate: 0.00517, Loss: 0.1659, Accuracy:0.930\nIteration: 14127, learning rate: 0.00517, Loss: 0.1153, Accuracy:0.961\nIteration: 14128, learning rate: 0.00517, Loss: 0.1224, Accuracy:0.938\nIteration: 14129, learning rate: 0.00517, Loss: 0.0903, Accuracy:0.961\nIteration: 14130, learning rate: 0.00517, Loss: 0.1510, Accuracy:0.938\nIteration: 14131, learning rate: 0.00517, Loss: 0.1420, Accuracy:0.922\nIteration: 14132, learning rate: 0.00516, Loss: 0.2179, Accuracy:0.898\nIteration: 14133, learning rate: 0.00516, Loss: 0.1850, Accuracy:0.922\nIteration: 14134, learning rate: 0.00516, Loss: 0.1576, Accuracy:0.930\nIteration: 14135, learning rate: 0.00516, Loss: 0.1188, Accuracy:0.938\nIteration: 14136, learning rate: 0.00516, Loss: 0.2375, Accuracy:0.882\nEpoch: 456, Loss: 0.1496, Accuracy:0.938, Val Loss: 0.3357, Val Accuracy: 0.877\nIteration: 14137, learning rate: 0.00516, Loss: 0.1885, Accuracy:0.906\nIteration: 14138, learning rate: 0.00516, Loss: 0.1539, Accuracy:0.945\nIteration: 14139, learning rate: 0.00516, Loss: 0.1260, Accuracy:0.969\nIteration: 14140, learning rate: 0.00516, Loss: 0.1812, Accuracy:0.930\nIteration: 14141, learning rate: 0.00516, Loss: 0.0789, Accuracy:0.984\nIteration: 14142, learning rate: 0.00516, Loss: 0.1155, Accuracy:0.961\nIteration: 14143, learning rate: 0.00516, Loss: 0.1679, Accuracy:0.914\nIteration: 14144, learning rate: 0.00516, Loss: 0.2134, Accuracy:0.914\nIteration: 14145, learning rate: 0.00516, Loss: 0.1612, Accuracy:0.930\nIteration: 14146, learning rate: 0.00516, Loss: 0.1060, Accuracy:0.977\nIteration: 14147, learning rate: 0.00516, Loss: 0.1092, Accuracy:0.969\nIteration: 14148, learning rate: 0.00516, Loss: 0.0603, Accuracy:0.977\nIteration: 14149, learning rate: 0.00516, Loss: 0.1599, Accuracy:0.945\nIteration: 14150, learning rate: 0.00516, Loss: 0.1109, Accuracy:0.984\nIteration: 14151, learning rate: 0.00516, Loss: 0.1828, Accuracy:0.906\nIteration: 14152, learning rate: 0.00516, Loss: 0.1722, Accuracy:0.930\nIteration: 14153, learning rate: 0.00516, Loss: 0.0895, Accuracy:0.977\nIteration: 14154, learning rate: 0.00516, Loss: 0.1631, Accuracy:0.945\nIteration: 14155, learning rate: 0.00516, Loss: 0.1164, Accuracy:0.953\nIteration: 14156, learning rate: 0.00516, Loss: 0.1332, Accuracy:0.953\nIteration: 14157, learning rate: 0.00516, Loss: 0.1489, Accuracy:0.945\nIteration: 14158, learning rate: 0.00516, Loss: 0.1295, Accuracy:0.953\nIteration: 14159, learning rate: 0.00516, Loss: 0.0925, Accuracy:0.953\nIteration: 14160, learning rate: 0.00516, Loss: 0.1021, Accuracy:0.961\nIteration: 14161, learning rate: 0.00516, Loss: 0.1071, Accuracy:0.953\nIteration: 14162, learning rate: 0.00516, Loss: 0.1895, Accuracy:0.945\nIteration: 14163, learning rate: 0.00516, Loss: 0.1254, Accuracy:0.938\nIteration: 14164, learning rate: 0.00516, Loss: 0.1390, Accuracy:0.969\nIteration: 14165, learning rate: 0.00516, Loss: 0.2018, Accuracy:0.914\nIteration: 14166, learning rate: 0.00516, Loss: 0.1552, Accuracy:0.938\nIteration: 14167, learning rate: 0.00516, Loss: 0.1253, Accuracy:0.957\nEpoch: 457, Loss: 0.1389, Accuracy:0.948, Val Loss: 0.2574, Val Accuracy: 0.898\nIteration: 14168, learning rate: 0.00516, Loss: 0.1949, Accuracy:0.906\nIteration: 14169, learning rate: 0.00516, Loss: 0.1521, Accuracy:0.938\nIteration: 14170, learning rate: 0.00516, Loss: 0.1264, Accuracy:0.977\nIteration: 14171, learning rate: 0.00516, Loss: 0.1464, Accuracy:0.945\nIteration: 14172, learning rate: 0.00516, Loss: 0.1344, Accuracy:0.938\nIteration: 14173, learning rate: 0.00516, Loss: 0.1292, Accuracy:0.953\nIteration: 14174, learning rate: 0.00516, Loss: 0.1748, Accuracy:0.930\nIteration: 14175, learning rate: 0.00516, Loss: 0.1976, Accuracy:0.930\nIteration: 14176, learning rate: 0.00516, Loss: 0.2231, Accuracy:0.922\nIteration: 14177, learning rate: 0.00516, Loss: 0.1511, Accuracy:0.953\nIteration: 14178, learning rate: 0.00516, Loss: 0.1872, Accuracy:0.922\nIteration: 14179, learning rate: 0.00516, Loss: 0.1389, Accuracy:0.953\nIteration: 14180, learning rate: 0.00516, Loss: 0.1618, Accuracy:0.938\nIteration: 14181, learning rate: 0.00516, Loss: 0.1492, Accuracy:0.969\nIteration: 14182, learning rate: 0.00516, Loss: 0.0871, Accuracy:0.977\nIteration: 14183, learning rate: 0.00516, Loss: 0.0855, Accuracy:0.984\nIteration: 14184, learning rate: 0.00516, Loss: 0.1560, Accuracy:0.945\nIteration: 14185, learning rate: 0.00516, Loss: 0.1725, Accuracy:0.945\nIteration: 14186, learning rate: 0.00516, Loss: 0.1018, Accuracy:0.969\nIteration: 14187, learning rate: 0.00516, Loss: 0.2418, Accuracy:0.922\nIteration: 14188, learning rate: 0.00516, Loss: 0.1694, Accuracy:0.914\nIteration: 14189, learning rate: 0.00516, Loss: 0.0934, Accuracy:0.969\nIteration: 14190, learning rate: 0.00516, Loss: 0.1585, Accuracy:0.930\nIteration: 14191, learning rate: 0.00516, Loss: 0.1130, Accuracy:0.969\nIteration: 14192, learning rate: 0.00516, Loss: 0.1034, Accuracy:0.977\nIteration: 14193, learning rate: 0.00516, Loss: 0.2163, Accuracy:0.922\nIteration: 14194, learning rate: 0.00516, Loss: 0.2106, Accuracy:0.914\nIteration: 14195, learning rate: 0.00515, Loss: 0.1759, Accuracy:0.922\nIteration: 14196, learning rate: 0.00515, Loss: 0.1136, Accuracy:0.977\nIteration: 14197, learning rate: 0.00515, Loss: 0.2245, Accuracy:0.891\nIteration: 14198, learning rate: 0.00515, Loss: 0.1269, Accuracy:0.935\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 458, Loss: 0.1554, Accuracy:0.943, Val Loss: 0.3034, Val Accuracy: 0.897\nIteration: 14199, learning rate: 0.00515, Loss: 0.1093, Accuracy:0.961\nIteration: 14200, learning rate: 0.00515, Loss: 0.1957, Accuracy:0.938\nIteration: 14201, learning rate: 0.00515, Loss: 0.0949, Accuracy:0.961\nIteration: 14202, learning rate: 0.00515, Loss: 0.2091, Accuracy:0.930\nIteration: 14203, learning rate: 0.00515, Loss: 0.1407, Accuracy:0.930\nIteration: 14204, learning rate: 0.00515, Loss: 0.1094, Accuracy:0.969\nIteration: 14205, learning rate: 0.00515, Loss: 0.1585, Accuracy:0.938\nIteration: 14206, learning rate: 0.00515, Loss: 0.2139, Accuracy:0.922\nIteration: 14207, learning rate: 0.00515, Loss: 0.1897, Accuracy:0.922\nIteration: 14208, learning rate: 0.00515, Loss: 0.0738, Accuracy:0.969\nIteration: 14209, learning rate: 0.00515, Loss: 0.1713, Accuracy:0.922\nIteration: 14210, learning rate: 0.00515, Loss: 0.1603, Accuracy:0.953\nIteration: 14211, learning rate: 0.00515, Loss: 0.1502, Accuracy:0.938\nIteration: 14212, learning rate: 0.00515, Loss: 0.1395, Accuracy:0.930\nIteration: 14213, learning rate: 0.00515, Loss: 0.1656, Accuracy:0.938\nIteration: 14214, learning rate: 0.00515, Loss: 0.2228, Accuracy:0.930\nIteration: 14215, learning rate: 0.00515, Loss: 0.1678, Accuracy:0.914\nIteration: 14216, learning rate: 0.00515, Loss: 0.1534, Accuracy:0.945\nIteration: 14217, learning rate: 0.00515, Loss: 0.0473, Accuracy:1.000\nIteration: 14218, learning rate: 0.00515, Loss: 0.1307, Accuracy:0.961\nIteration: 14219, learning rate: 0.00515, Loss: 0.1914, Accuracy:0.930\nIteration: 14220, learning rate: 0.00515, Loss: 0.1079, Accuracy:0.961\nIteration: 14221, learning rate: 0.00515, Loss: 0.1649, Accuracy:0.945\nIteration: 14222, learning rate: 0.00515, Loss: 0.2481, Accuracy:0.906\nIteration: 14223, learning rate: 0.00515, Loss: 0.2182, Accuracy:0.922\nIteration: 14224, learning rate: 0.00515, Loss: 0.1681, Accuracy:0.914\nIteration: 14225, learning rate: 0.00515, Loss: 0.1366, Accuracy:0.953\nIteration: 14226, learning rate: 0.00515, Loss: 0.0887, Accuracy:0.961\nIteration: 14227, learning rate: 0.00515, Loss: 0.0798, Accuracy:0.984\nIteration: 14228, learning rate: 0.00515, Loss: 0.2139, Accuracy:0.930\nIteration: 14229, learning rate: 0.00515, Loss: 0.0721, Accuracy:0.978\nEpoch: 459, Loss: 0.1514, Accuracy:0.944, Val Loss: 0.2646, Val Accuracy: 0.895\nIteration: 14230, learning rate: 0.00515, Loss: 0.1251, Accuracy:0.945\nIteration: 14231, learning rate: 0.00515, Loss: 0.0949, Accuracy:0.977\nIteration: 14232, learning rate: 0.00515, Loss: 0.2587, Accuracy:0.891\nIteration: 14233, learning rate: 0.00515, Loss: 0.1284, Accuracy:0.961\nIteration: 14234, learning rate: 0.00515, Loss: 0.0815, Accuracy:0.977\nIteration: 14235, learning rate: 0.00515, Loss: 0.1388, Accuracy:0.953\nIteration: 14236, learning rate: 0.00515, Loss: 0.1495, Accuracy:0.953\nIteration: 14237, learning rate: 0.00515, Loss: 0.1656, Accuracy:0.953\nIteration: 14238, learning rate: 0.00515, Loss: 0.0975, Accuracy:0.977\nIteration: 14239, learning rate: 0.00515, Loss: 0.1167, Accuracy:0.945\nIteration: 14240, learning rate: 0.00515, Loss: 0.1492, Accuracy:0.945\nIteration: 14241, learning rate: 0.00515, Loss: 0.1964, Accuracy:0.945\nIteration: 14242, learning rate: 0.00515, Loss: 0.1211, Accuracy:0.945\nIteration: 14243, learning rate: 0.00515, Loss: 0.1099, Accuracy:0.969\nIteration: 14244, learning rate: 0.00515, Loss: 0.1438, Accuracy:0.945\nIteration: 14245, learning rate: 0.00515, Loss: 0.1384, Accuracy:0.938\nIteration: 14246, learning rate: 0.00515, Loss: 0.1018, Accuracy:0.969\nIteration: 14247, learning rate: 0.00515, Loss: 0.1226, Accuracy:0.961\nIteration: 14248, learning rate: 0.00515, Loss: 0.1283, Accuracy:0.953\nIteration: 14249, learning rate: 0.00515, Loss: 0.1293, Accuracy:0.930\nIteration: 14250, learning rate: 0.00515, Loss: 0.1676, Accuracy:0.930\nIteration: 14251, learning rate: 0.00515, Loss: 0.0654, Accuracy:0.984\nIteration: 14252, learning rate: 0.00515, Loss: 0.1749, Accuracy:0.930\nIteration: 14253, learning rate: 0.00515, Loss: 0.1137, Accuracy:0.969\nIteration: 14254, learning rate: 0.00515, Loss: 0.1969, Accuracy:0.914\nIteration: 14255, learning rate: 0.00515, Loss: 0.1541, Accuracy:0.938\nIteration: 14256, learning rate: 0.00515, Loss: 0.1496, Accuracy:0.930\nIteration: 14257, learning rate: 0.00515, Loss: 0.1667, Accuracy:0.945\nIteration: 14258, learning rate: 0.00514, Loss: 0.2141, Accuracy:0.922\nIteration: 14259, learning rate: 0.00514, Loss: 0.1445, Accuracy:0.953\nIteration: 14260, learning rate: 0.00514, Loss: 0.3448, Accuracy:0.882\nEpoch: 460, Loss: 0.1481, Accuracy:0.946, Val Loss: 0.2668, Val Accuracy: 0.900\nIteration: 14261, learning rate: 0.00514, Loss: 0.1289, Accuracy:0.961\nIteration: 14262, learning rate: 0.00514, Loss: 0.1183, Accuracy:0.969\nIteration: 14263, learning rate: 0.00514, Loss: 0.2047, Accuracy:0.938\nIteration: 14264, learning rate: 0.00514, Loss: 0.1415, Accuracy:0.945\nIteration: 14265, learning rate: 0.00514, Loss: 0.0993, Accuracy:0.953\nIteration: 14266, learning rate: 0.00514, Loss: 0.1746, Accuracy:0.945\nIteration: 14267, learning rate: 0.00514, Loss: 0.1823, Accuracy:0.922\nIteration: 14268, learning rate: 0.00514, Loss: 0.1137, Accuracy:0.961\nIteration: 14269, learning rate: 0.00514, Loss: 0.1479, Accuracy:0.930\nIteration: 14270, learning rate: 0.00514, Loss: 0.1628, Accuracy:0.953\nIteration: 14271, learning rate: 0.00514, Loss: 0.1362, Accuracy:0.938\nIteration: 14272, learning rate: 0.00514, Loss: 0.1039, Accuracy:0.945\nIteration: 14273, learning rate: 0.00514, Loss: 0.0946, Accuracy:0.977\nIteration: 14274, learning rate: 0.00514, Loss: 0.1421, Accuracy:0.953\nIteration: 14275, learning rate: 0.00514, Loss: 0.1751, Accuracy:0.922\nIteration: 14276, learning rate: 0.00514, Loss: 0.1941, Accuracy:0.914\nIteration: 14277, learning rate: 0.00514, Loss: 0.1053, Accuracy:0.961\nIteration: 14278, learning rate: 0.00514, Loss: 0.0755, Accuracy:0.961\nIteration: 14279, learning rate: 0.00514, Loss: 0.1347, Accuracy:0.953\nIteration: 14280, learning rate: 0.00514, Loss: 0.2033, Accuracy:0.930\nIteration: 14281, learning rate: 0.00514, Loss: 0.1572, Accuracy:0.930\nIteration: 14282, learning rate: 0.00514, Loss: 0.1671, Accuracy:0.930\nIteration: 14283, learning rate: 0.00514, Loss: 0.1036, Accuracy:0.969\nIteration: 14284, learning rate: 0.00514, Loss: 0.1087, Accuracy:0.938\nIteration: 14285, learning rate: 0.00514, Loss: 0.1149, Accuracy:0.961\nIteration: 14286, learning rate: 0.00514, Loss: 0.1084, Accuracy:0.961\nIteration: 14287, learning rate: 0.00514, Loss: 0.1527, Accuracy:0.938\nIteration: 14288, learning rate: 0.00514, Loss: 0.2295, Accuracy:0.906\nIteration: 14289, learning rate: 0.00514, Loss: 0.1309, Accuracy:0.953\nIteration: 14290, learning rate: 0.00514, Loss: 0.1912, Accuracy:0.938\nIteration: 14291, learning rate: 0.00514, Loss: 0.0979, Accuracy:0.978\nEpoch: 461, Loss: 0.1420, Accuracy:0.946, Val Loss: 0.2889, Val Accuracy: 0.887\nIteration: 14292, learning rate: 0.00514, Loss: 0.1735, Accuracy:0.938\nIteration: 14293, learning rate: 0.00514, Loss: 0.1687, Accuracy:0.945\nIteration: 14294, learning rate: 0.00514, Loss: 0.1893, Accuracy:0.953\nIteration: 14295, learning rate: 0.00514, Loss: 0.1101, Accuracy:0.945\nIteration: 14296, learning rate: 0.00514, Loss: 0.1963, Accuracy:0.930\nIteration: 14297, learning rate: 0.00514, Loss: 0.2039, Accuracy:0.922\nIteration: 14298, learning rate: 0.00514, Loss: 0.1919, Accuracy:0.922\nIteration: 14299, learning rate: 0.00514, Loss: 0.1688, Accuracy:0.953\nIteration: 14300, learning rate: 0.00514, Loss: 0.1490, Accuracy:0.961\nIteration: 14301, learning rate: 0.00514, Loss: 0.1217, Accuracy:0.953\nIteration: 14302, learning rate: 0.00514, Loss: 0.0954, Accuracy:0.961\nIteration: 14303, learning rate: 0.00514, Loss: 0.1640, Accuracy:0.945\nIteration: 14304, learning rate: 0.00514, Loss: 0.1391, Accuracy:0.938\nIteration: 14305, learning rate: 0.00514, Loss: 0.1129, Accuracy:0.961\nIteration: 14306, learning rate: 0.00514, Loss: 0.2028, Accuracy:0.914\nIteration: 14307, learning rate: 0.00514, Loss: 0.1557, Accuracy:0.945\nIteration: 14308, learning rate: 0.00514, Loss: 0.1262, Accuracy:0.945\nIteration: 14309, learning rate: 0.00514, Loss: 0.0826, Accuracy:0.969\nIteration: 14310, learning rate: 0.00514, Loss: 0.0703, Accuracy:0.984\nIteration: 14311, learning rate: 0.00514, Loss: 0.1540, Accuracy:0.945\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14312, learning rate: 0.00514, Loss: 0.1282, Accuracy:0.938\nIteration: 14313, learning rate: 0.00514, Loss: 0.1197, Accuracy:0.969\nIteration: 14314, learning rate: 0.00514, Loss: 0.1695, Accuracy:0.938\nIteration: 14315, learning rate: 0.00514, Loss: 0.1219, Accuracy:0.961\nIteration: 14316, learning rate: 0.00514, Loss: 0.1180, Accuracy:0.961\nIteration: 14317, learning rate: 0.00514, Loss: 0.2217, Accuracy:0.922\nIteration: 14318, learning rate: 0.00514, Loss: 0.1719, Accuracy:0.953\nIteration: 14319, learning rate: 0.00514, Loss: 0.1347, Accuracy:0.945\nIteration: 14320, learning rate: 0.00514, Loss: 0.2263, Accuracy:0.914\nIteration: 14321, learning rate: 0.00513, Loss: 0.1379, Accuracy:0.961\nIteration: 14322, learning rate: 0.00513, Loss: 0.0832, Accuracy:0.957\nEpoch: 462, Loss: 0.1487, Accuracy:0.947, Val Loss: 0.2663, Val Accuracy: 0.893\nIteration: 14323, learning rate: 0.00513, Loss: 0.1140, Accuracy:0.977\nIteration: 14324, learning rate: 0.00513, Loss: 0.1472, Accuracy:0.953\nIteration: 14325, learning rate: 0.00513, Loss: 0.1267, Accuracy:0.953\nIteration: 14326, learning rate: 0.00513, Loss: 0.1403, Accuracy:0.930\nIteration: 14327, learning rate: 0.00513, Loss: 0.2350, Accuracy:0.922\nIteration: 14328, learning rate: 0.00513, Loss: 0.1560, Accuracy:0.930\nIteration: 14329, learning rate: 0.00513, Loss: 0.1649, Accuracy:0.930\nIteration: 14330, learning rate: 0.00513, Loss: 0.1392, Accuracy:0.938\nIteration: 14331, learning rate: 0.00513, Loss: 0.2173, Accuracy:0.898\nIteration: 14332, learning rate: 0.00513, Loss: 0.2463, Accuracy:0.891\nIteration: 14333, learning rate: 0.00513, Loss: 0.2028, Accuracy:0.906\nIteration: 14334, learning rate: 0.00513, Loss: 0.1204, Accuracy:0.953\nIteration: 14335, learning rate: 0.00513, Loss: 0.1566, Accuracy:0.938\nIteration: 14336, learning rate: 0.00513, Loss: 0.1803, Accuracy:0.938\nIteration: 14337, learning rate: 0.00513, Loss: 0.1384, Accuracy:0.922\nIteration: 14338, learning rate: 0.00513, Loss: 0.1557, Accuracy:0.922\nIteration: 14339, learning rate: 0.00513, Loss: 0.0964, Accuracy:0.969\nIteration: 14340, learning rate: 0.00513, Loss: 0.1302, Accuracy:0.938\nIteration: 14341, learning rate: 0.00513, Loss: 0.2142, Accuracy:0.922\nIteration: 14342, learning rate: 0.00513, Loss: 0.1282, Accuracy:0.961\nIteration: 14343, learning rate: 0.00513, Loss: 0.1001, Accuracy:0.961\nIteration: 14344, learning rate: 0.00513, Loss: 0.1634, Accuracy:0.938\nIteration: 14345, learning rate: 0.00513, Loss: 0.0957, Accuracy:0.953\nIteration: 14346, learning rate: 0.00513, Loss: 0.1246, Accuracy:0.945\nIteration: 14347, learning rate: 0.00513, Loss: 0.2286, Accuracy:0.898\nIteration: 14348, learning rate: 0.00513, Loss: 0.1609, Accuracy:0.938\nIteration: 14349, learning rate: 0.00513, Loss: 0.1282, Accuracy:0.945\nIteration: 14350, learning rate: 0.00513, Loss: 0.0633, Accuracy:0.992\nIteration: 14351, learning rate: 0.00513, Loss: 0.1605, Accuracy:0.961\nIteration: 14352, learning rate: 0.00513, Loss: 0.1531, Accuracy:0.945\nIteration: 14353, learning rate: 0.00513, Loss: 0.1986, Accuracy:0.935\nEpoch: 463, Loss: 0.1544, Accuracy:0.939, Val Loss: 0.3562, Val Accuracy: 0.854\nIteration: 14354, learning rate: 0.00513, Loss: 0.1693, Accuracy:0.922\nIteration: 14355, learning rate: 0.00513, Loss: 0.1392, Accuracy:0.945\nIteration: 14356, learning rate: 0.00513, Loss: 0.1298, Accuracy:0.953\nIteration: 14357, learning rate: 0.00513, Loss: 0.1346, Accuracy:0.953\nIteration: 14358, learning rate: 0.00513, Loss: 0.1457, Accuracy:0.953\nIteration: 14359, learning rate: 0.00513, Loss: 0.1042, Accuracy:0.969\nIteration: 14360, learning rate: 0.00513, Loss: 0.1177, Accuracy:0.969\nIteration: 14361, learning rate: 0.00513, Loss: 0.1215, Accuracy:0.961\nIteration: 14362, learning rate: 0.00513, Loss: 0.1257, Accuracy:0.945\nIteration: 14363, learning rate: 0.00513, Loss: 0.1289, Accuracy:0.953\nIteration: 14364, learning rate: 0.00513, Loss: 0.1176, Accuracy:0.961\nIteration: 14365, learning rate: 0.00513, Loss: 0.1099, Accuracy:0.984\nIteration: 14366, learning rate: 0.00513, Loss: 0.1791, Accuracy:0.938\nIteration: 14367, learning rate: 0.00513, Loss: 0.1192, Accuracy:0.969\nIteration: 14368, learning rate: 0.00513, Loss: 0.1475, Accuracy:0.961\nIteration: 14369, learning rate: 0.00513, Loss: 0.1502, Accuracy:0.938\nIteration: 14370, learning rate: 0.00513, Loss: 0.1287, Accuracy:0.945\nIteration: 14371, learning rate: 0.00513, Loss: 0.1226, Accuracy:0.938\nIteration: 14372, learning rate: 0.00513, Loss: 0.1412, Accuracy:0.961\nIteration: 14373, learning rate: 0.00513, Loss: 0.1318, Accuracy:0.945\nIteration: 14374, learning rate: 0.00513, Loss: 0.1342, Accuracy:0.969\nIteration: 14375, learning rate: 0.00513, Loss: 0.2168, Accuracy:0.898\nIteration: 14376, learning rate: 0.00513, Loss: 0.1164, Accuracy:0.953\nIteration: 14377, learning rate: 0.00513, Loss: 0.1538, Accuracy:0.930\nIteration: 14378, learning rate: 0.00513, Loss: 0.1401, Accuracy:0.930\nIteration: 14379, learning rate: 0.00513, Loss: 0.1339, Accuracy:0.945\nIteration: 14380, learning rate: 0.00513, Loss: 0.1739, Accuracy:0.938\nIteration: 14381, learning rate: 0.00513, Loss: 0.0732, Accuracy:0.977\nIteration: 14382, learning rate: 0.00513, Loss: 0.1164, Accuracy:0.953\nIteration: 14383, learning rate: 0.00513, Loss: 0.1258, Accuracy:0.969\nIteration: 14384, learning rate: 0.00512, Loss: 0.1473, Accuracy:0.946\nEpoch: 464, Loss: 0.1354, Accuracy:0.951, Val Loss: 0.3227, Val Accuracy: 0.878\nIteration: 14385, learning rate: 0.00512, Loss: 0.1537, Accuracy:0.945\nIteration: 14386, learning rate: 0.00512, Loss: 0.1867, Accuracy:0.938\nIteration: 14387, learning rate: 0.00512, Loss: 0.1234, Accuracy:0.953\nIteration: 14388, learning rate: 0.00512, Loss: 0.0987, Accuracy:0.953\nIteration: 14389, learning rate: 0.00512, Loss: 0.0834, Accuracy:0.977\nIteration: 14390, learning rate: 0.00512, Loss: 0.1608, Accuracy:0.938\nIteration: 14391, learning rate: 0.00512, Loss: 0.1038, Accuracy:0.977\nIteration: 14392, learning rate: 0.00512, Loss: 0.1873, Accuracy:0.914\nIteration: 14393, learning rate: 0.00512, Loss: 0.1724, Accuracy:0.930\nIteration: 14394, learning rate: 0.00512, Loss: 0.1408, Accuracy:0.953\nIteration: 14395, learning rate: 0.00512, Loss: 0.1367, Accuracy:0.938\nIteration: 14396, learning rate: 0.00512, Loss: 0.1463, Accuracy:0.945\nIteration: 14397, learning rate: 0.00512, Loss: 0.1629, Accuracy:0.938\nIteration: 14398, learning rate: 0.00512, Loss: 0.1264, Accuracy:0.953\nIteration: 14399, learning rate: 0.00512, Loss: 0.0849, Accuracy:0.969\nIteration: 14400, learning rate: 0.00512, Loss: 0.1671, Accuracy:0.945\nIteration: 14401, learning rate: 0.00512, Loss: 0.1642, Accuracy:0.922\nIteration: 14402, learning rate: 0.00512, Loss: 0.1208, Accuracy:0.961\nIteration: 14403, learning rate: 0.00512, Loss: 0.1146, Accuracy:0.945\nIteration: 14404, learning rate: 0.00512, Loss: 0.1517, Accuracy:0.945\nIteration: 14405, learning rate: 0.00512, Loss: 0.0995, Accuracy:0.969\nIteration: 14406, learning rate: 0.00512, Loss: 0.1669, Accuracy:0.930\nIteration: 14407, learning rate: 0.00512, Loss: 0.0700, Accuracy:0.984\nIteration: 14408, learning rate: 0.00512, Loss: 0.1091, Accuracy:0.961\nIteration: 14409, learning rate: 0.00512, Loss: 0.1166, Accuracy:0.977\nIteration: 14410, learning rate: 0.00512, Loss: 0.1027, Accuracy:0.969\nIteration: 14411, learning rate: 0.00512, Loss: 0.0610, Accuracy:0.992\nIteration: 14412, learning rate: 0.00512, Loss: 0.0882, Accuracy:0.969\nIteration: 14413, learning rate: 0.00512, Loss: 0.1109, Accuracy:0.961\nIteration: 14414, learning rate: 0.00512, Loss: 0.1545, Accuracy:0.930\nIteration: 14415, learning rate: 0.00512, Loss: 0.1712, Accuracy:0.946\nEpoch: 465, Loss: 0.1302, Accuracy:0.952, Val Loss: 0.3033, Val Accuracy: 0.871\nIteration: 14416, learning rate: 0.00512, Loss: 0.1247, Accuracy:0.938\nIteration: 14417, learning rate: 0.00512, Loss: 0.1643, Accuracy:0.930\nIteration: 14418, learning rate: 0.00512, Loss: 0.1443, Accuracy:0.953\nIteration: 14419, learning rate: 0.00512, Loss: 0.1136, Accuracy:0.961\nIteration: 14420, learning rate: 0.00512, Loss: 0.1738, Accuracy:0.945\nIteration: 14421, learning rate: 0.00512, Loss: 0.1314, Accuracy:0.938\nIteration: 14422, learning rate: 0.00512, Loss: 0.1593, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14423, learning rate: 0.00512, Loss: 0.1036, Accuracy:0.953\nIteration: 14424, learning rate: 0.00512, Loss: 0.1731, Accuracy:0.945\nIteration: 14425, learning rate: 0.00512, Loss: 0.1710, Accuracy:0.953\nIteration: 14426, learning rate: 0.00512, Loss: 0.1120, Accuracy:0.953\nIteration: 14427, learning rate: 0.00512, Loss: 0.1293, Accuracy:0.953\nIteration: 14428, learning rate: 0.00512, Loss: 0.2142, Accuracy:0.898\nIteration: 14429, learning rate: 0.00512, Loss: 0.1843, Accuracy:0.922\nIteration: 14430, learning rate: 0.00512, Loss: 0.1962, Accuracy:0.906\nIteration: 14431, learning rate: 0.00512, Loss: 0.0884, Accuracy:0.984\nIteration: 14432, learning rate: 0.00512, Loss: 0.2416, Accuracy:0.938\nIteration: 14433, learning rate: 0.00512, Loss: 0.1167, Accuracy:0.961\nIteration: 14434, learning rate: 0.00512, Loss: 0.1395, Accuracy:0.938\nIteration: 14435, learning rate: 0.00512, Loss: 0.0746, Accuracy:0.977\nIteration: 14436, learning rate: 0.00512, Loss: 0.2126, Accuracy:0.898\nIteration: 14437, learning rate: 0.00512, Loss: 0.1266, Accuracy:0.945\nIteration: 14438, learning rate: 0.00512, Loss: 0.1265, Accuracy:0.961\nIteration: 14439, learning rate: 0.00512, Loss: 0.0925, Accuracy:0.969\nIteration: 14440, learning rate: 0.00512, Loss: 0.1180, Accuracy:0.938\nIteration: 14441, learning rate: 0.00512, Loss: 0.1075, Accuracy:0.938\nIteration: 14442, learning rate: 0.00512, Loss: 0.1677, Accuracy:0.930\nIteration: 14443, learning rate: 0.00512, Loss: 0.1159, Accuracy:0.953\nIteration: 14444, learning rate: 0.00512, Loss: 0.1574, Accuracy:0.961\nIteration: 14445, learning rate: 0.00512, Loss: 0.1572, Accuracy:0.938\nIteration: 14446, learning rate: 0.00512, Loss: 0.1123, Accuracy:0.957\nEpoch: 466, Loss: 0.1435, Accuracy:0.945, Val Loss: 0.2542, Val Accuracy: 0.889\nIteration: 14447, learning rate: 0.00511, Loss: 0.1116, Accuracy:0.953\nIteration: 14448, learning rate: 0.00511, Loss: 0.0789, Accuracy:0.977\nIteration: 14449, learning rate: 0.00511, Loss: 0.1673, Accuracy:0.945\nIteration: 14450, learning rate: 0.00511, Loss: 0.0655, Accuracy:0.984\nIteration: 14451, learning rate: 0.00511, Loss: 0.1742, Accuracy:0.938\nIteration: 14452, learning rate: 0.00511, Loss: 0.1139, Accuracy:0.969\nIteration: 14453, learning rate: 0.00511, Loss: 0.0905, Accuracy:0.969\nIteration: 14454, learning rate: 0.00511, Loss: 0.1110, Accuracy:0.977\nIteration: 14455, learning rate: 0.00511, Loss: 0.0899, Accuracy:0.977\nIteration: 14456, learning rate: 0.00511, Loss: 0.1421, Accuracy:0.945\nIteration: 14457, learning rate: 0.00511, Loss: 0.1020, Accuracy:0.969\nIteration: 14458, learning rate: 0.00511, Loss: 0.1107, Accuracy:0.961\nIteration: 14459, learning rate: 0.00511, Loss: 0.0883, Accuracy:0.969\nIteration: 14460, learning rate: 0.00511, Loss: 0.1646, Accuracy:0.930\nIteration: 14461, learning rate: 0.00511, Loss: 0.1053, Accuracy:0.969\nIteration: 14462, learning rate: 0.00511, Loss: 0.1722, Accuracy:0.898\nIteration: 14463, learning rate: 0.00511, Loss: 0.1525, Accuracy:0.930\nIteration: 14464, learning rate: 0.00511, Loss: 0.2655, Accuracy:0.883\nIteration: 14465, learning rate: 0.00511, Loss: 0.1431, Accuracy:0.953\nIteration: 14466, learning rate: 0.00511, Loss: 0.1631, Accuracy:0.922\nIteration: 14467, learning rate: 0.00511, Loss: 0.1027, Accuracy:0.961\nIteration: 14468, learning rate: 0.00511, Loss: 0.1921, Accuracy:0.922\nIteration: 14469, learning rate: 0.00511, Loss: 0.1349, Accuracy:0.945\nIteration: 14470, learning rate: 0.00511, Loss: 0.1317, Accuracy:0.938\nIteration: 14471, learning rate: 0.00511, Loss: 0.1663, Accuracy:0.945\nIteration: 14472, learning rate: 0.00511, Loss: 0.0878, Accuracy:0.977\nIteration: 14473, learning rate: 0.00511, Loss: 0.1225, Accuracy:0.953\nIteration: 14474, learning rate: 0.00511, Loss: 0.0787, Accuracy:0.984\nIteration: 14475, learning rate: 0.00511, Loss: 0.1578, Accuracy:0.938\nIteration: 14476, learning rate: 0.00511, Loss: 0.0712, Accuracy:0.977\nIteration: 14477, learning rate: 0.00511, Loss: 0.0865, Accuracy:0.978\nEpoch: 467, Loss: 0.1272, Accuracy:0.953, Val Loss: 0.2628, Val Accuracy: 0.887\nIteration: 14478, learning rate: 0.00511, Loss: 0.0405, Accuracy:0.992\nIteration: 14479, learning rate: 0.00511, Loss: 0.1439, Accuracy:0.961\nIteration: 14480, learning rate: 0.00511, Loss: 0.2636, Accuracy:0.898\nIteration: 14481, learning rate: 0.00511, Loss: 0.1494, Accuracy:0.938\nIteration: 14482, learning rate: 0.00511, Loss: 0.1057, Accuracy:0.977\nIteration: 14483, learning rate: 0.00511, Loss: 0.1265, Accuracy:0.961\nIteration: 14484, learning rate: 0.00511, Loss: 0.1104, Accuracy:0.969\nIteration: 14485, learning rate: 0.00511, Loss: 0.1189, Accuracy:0.953\nIteration: 14486, learning rate: 0.00511, Loss: 0.1078, Accuracy:0.961\nIteration: 14487, learning rate: 0.00511, Loss: 0.1299, Accuracy:0.945\nIteration: 14488, learning rate: 0.00511, Loss: 0.1118, Accuracy:0.953\nIteration: 14489, learning rate: 0.00511, Loss: 0.1857, Accuracy:0.914\nIteration: 14490, learning rate: 0.00511, Loss: 0.1348, Accuracy:0.938\nIteration: 14491, learning rate: 0.00511, Loss: 0.1221, Accuracy:0.961\nIteration: 14492, learning rate: 0.00511, Loss: 0.1505, Accuracy:0.938\nIteration: 14493, learning rate: 0.00511, Loss: 0.1801, Accuracy:0.938\nIteration: 14494, learning rate: 0.00511, Loss: 0.1752, Accuracy:0.938\nIteration: 14495, learning rate: 0.00511, Loss: 0.1257, Accuracy:0.945\nIteration: 14496, learning rate: 0.00511, Loss: 0.2442, Accuracy:0.898\nIteration: 14497, learning rate: 0.00511, Loss: 0.1292, Accuracy:0.953\nIteration: 14498, learning rate: 0.00511, Loss: 0.1740, Accuracy:0.938\nIteration: 14499, learning rate: 0.00511, Loss: 0.1091, Accuracy:0.953\nIteration: 14500, learning rate: 0.00511, Loss: 0.1247, Accuracy:0.945\nIteration: 14501, learning rate: 0.00511, Loss: 0.1796, Accuracy:0.938\nIteration: 14502, learning rate: 0.00511, Loss: 0.0991, Accuracy:0.961\nIteration: 14503, learning rate: 0.00511, Loss: 0.1027, Accuracy:0.961\nIteration: 14504, learning rate: 0.00511, Loss: 0.0678, Accuracy:0.977\nIteration: 14505, learning rate: 0.00511, Loss: 0.1484, Accuracy:0.938\nIteration: 14506, learning rate: 0.00511, Loss: 0.1089, Accuracy:0.961\nIteration: 14507, learning rate: 0.00511, Loss: 0.1400, Accuracy:0.922\nIteration: 14508, learning rate: 0.00511, Loss: 0.2288, Accuracy:0.882\nEpoch: 468, Loss: 0.1400, Accuracy:0.945, Val Loss: 0.3567, Val Accuracy: 0.869\nIteration: 14509, learning rate: 0.00511, Loss: 0.0926, Accuracy:0.977\nIteration: 14510, learning rate: 0.00511, Loss: 0.1586, Accuracy:0.945\nIteration: 14511, learning rate: 0.00510, Loss: 0.1093, Accuracy:0.961\nIteration: 14512, learning rate: 0.00510, Loss: 0.1227, Accuracy:0.969\nIteration: 14513, learning rate: 0.00510, Loss: 0.1536, Accuracy:0.945\nIteration: 14514, learning rate: 0.00510, Loss: 0.1936, Accuracy:0.922\nIteration: 14515, learning rate: 0.00510, Loss: 0.1604, Accuracy:0.938\nIteration: 14516, learning rate: 0.00510, Loss: 0.1703, Accuracy:0.914\nIteration: 14517, learning rate: 0.00510, Loss: 0.1361, Accuracy:0.953\nIteration: 14518, learning rate: 0.00510, Loss: 0.1239, Accuracy:0.969\nIteration: 14519, learning rate: 0.00510, Loss: 0.1459, Accuracy:0.938\nIteration: 14520, learning rate: 0.00510, Loss: 0.1364, Accuracy:0.938\nIteration: 14521, learning rate: 0.00510, Loss: 0.2051, Accuracy:0.930\nIteration: 14522, learning rate: 0.00510, Loss: 0.2047, Accuracy:0.906\nIteration: 14523, learning rate: 0.00510, Loss: 0.0727, Accuracy:0.984\nIteration: 14524, learning rate: 0.00510, Loss: 0.1390, Accuracy:0.922\nIteration: 14525, learning rate: 0.00510, Loss: 0.1286, Accuracy:0.953\nIteration: 14526, learning rate: 0.00510, Loss: 0.2252, Accuracy:0.922\nIteration: 14527, learning rate: 0.00510, Loss: 0.1516, Accuracy:0.945\nIteration: 14528, learning rate: 0.00510, Loss: 0.1852, Accuracy:0.938\nIteration: 14529, learning rate: 0.00510, Loss: 0.1555, Accuracy:0.914\nIteration: 14530, learning rate: 0.00510, Loss: 0.2409, Accuracy:0.906\nIteration: 14531, learning rate: 0.00510, Loss: 0.1441, Accuracy:0.938\nIteration: 14532, learning rate: 0.00510, Loss: 0.2054, Accuracy:0.922\nIteration: 14533, learning rate: 0.00510, Loss: 0.1548, Accuracy:0.945\nIteration: 14534, learning rate: 0.00510, Loss: 0.1175, Accuracy:0.945\nIteration: 14535, learning rate: 0.00510, Loss: 0.1405, Accuracy:0.945\nIteration: 14536, learning rate: 0.00510, Loss: 0.1505, Accuracy:0.938\nIteration: 14537, learning rate: 0.00510, Loss: 0.1436, Accuracy:0.961\nIteration: 14538, learning rate: 0.00510, Loss: 0.0649, Accuracy:0.992\nIteration: 14539, learning rate: 0.00510, Loss: 0.1682, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 469, Loss: 0.1517, Accuracy:0.942, Val Loss: 0.3921, Val Accuracy: 0.845\nIteration: 14540, learning rate: 0.00510, Loss: 0.1602, Accuracy:0.938\nIteration: 14541, learning rate: 0.00510, Loss: 0.1197, Accuracy:0.977\nIteration: 14542, learning rate: 0.00510, Loss: 0.1166, Accuracy:0.969\nIteration: 14543, learning rate: 0.00510, Loss: 0.1364, Accuracy:0.938\nIteration: 14544, learning rate: 0.00510, Loss: 0.2625, Accuracy:0.914\nIteration: 14545, learning rate: 0.00510, Loss: 0.1392, Accuracy:0.945\nIteration: 14546, learning rate: 0.00510, Loss: 0.0840, Accuracy:0.953\nIteration: 14547, learning rate: 0.00510, Loss: 0.1073, Accuracy:0.969\nIteration: 14548, learning rate: 0.00510, Loss: 0.1537, Accuracy:0.930\nIteration: 14549, learning rate: 0.00510, Loss: 0.0987, Accuracy:0.977\nIteration: 14550, learning rate: 0.00510, Loss: 0.0919, Accuracy:0.969\nIteration: 14551, learning rate: 0.00510, Loss: 0.2136, Accuracy:0.938\nIteration: 14552, learning rate: 0.00510, Loss: 0.1109, Accuracy:0.953\nIteration: 14553, learning rate: 0.00510, Loss: 0.1285, Accuracy:0.961\nIteration: 14554, learning rate: 0.00510, Loss: 0.1641, Accuracy:0.945\nIteration: 14555, learning rate: 0.00510, Loss: 0.1726, Accuracy:0.938\nIteration: 14556, learning rate: 0.00510, Loss: 0.1328, Accuracy:0.969\nIteration: 14557, learning rate: 0.00510, Loss: 0.1236, Accuracy:0.953\nIteration: 14558, learning rate: 0.00510, Loss: 0.1036, Accuracy:0.961\nIteration: 14559, learning rate: 0.00510, Loss: 0.0924, Accuracy:0.961\nIteration: 14560, learning rate: 0.00510, Loss: 0.1569, Accuracy:0.930\nIteration: 14561, learning rate: 0.00510, Loss: 0.1837, Accuracy:0.945\nIteration: 14562, learning rate: 0.00510, Loss: 0.1841, Accuracy:0.898\nIteration: 14563, learning rate: 0.00510, Loss: 0.0851, Accuracy:0.977\nIteration: 14564, learning rate: 0.00510, Loss: 0.1185, Accuracy:0.945\nIteration: 14565, learning rate: 0.00510, Loss: 0.1509, Accuracy:0.945\nIteration: 14566, learning rate: 0.00510, Loss: 0.1586, Accuracy:0.938\nIteration: 14567, learning rate: 0.00510, Loss: 0.1239, Accuracy:0.969\nIteration: 14568, learning rate: 0.00510, Loss: 0.1475, Accuracy:0.953\nIteration: 14569, learning rate: 0.00510, Loss: 0.1336, Accuracy:0.938\nIteration: 14570, learning rate: 0.00510, Loss: 0.1550, Accuracy:0.935\nEpoch: 470, Loss: 0.1390, Accuracy:0.949, Val Loss: 0.2403, Val Accuracy: 0.901\nIteration: 14571, learning rate: 0.00510, Loss: 0.1727, Accuracy:0.938\nIteration: 14572, learning rate: 0.00510, Loss: 0.1614, Accuracy:0.945\nIteration: 14573, learning rate: 0.00510, Loss: 0.1561, Accuracy:0.953\nIteration: 14574, learning rate: 0.00510, Loss: 0.2177, Accuracy:0.906\nIteration: 14575, learning rate: 0.00509, Loss: 0.1562, Accuracy:0.938\nIteration: 14576, learning rate: 0.00509, Loss: 0.1395, Accuracy:0.938\nIteration: 14577, learning rate: 0.00509, Loss: 0.1482, Accuracy:0.953\nIteration: 14578, learning rate: 0.00509, Loss: 0.1290, Accuracy:0.945\nIteration: 14579, learning rate: 0.00509, Loss: 0.1715, Accuracy:0.945\nIteration: 14580, learning rate: 0.00509, Loss: 0.1055, Accuracy:0.977\nIteration: 14581, learning rate: 0.00509, Loss: 0.1191, Accuracy:0.969\nIteration: 14582, learning rate: 0.00509, Loss: 0.1268, Accuracy:0.945\nIteration: 14583, learning rate: 0.00509, Loss: 0.1436, Accuracy:0.945\nIteration: 14584, learning rate: 0.00509, Loss: 0.1705, Accuracy:0.930\nIteration: 14585, learning rate: 0.00509, Loss: 0.1429, Accuracy:0.930\nIteration: 14586, learning rate: 0.00509, Loss: 0.1197, Accuracy:0.953\nIteration: 14587, learning rate: 0.00509, Loss: 0.0854, Accuracy:0.969\nIteration: 14588, learning rate: 0.00509, Loss: 0.1332, Accuracy:0.953\nIteration: 14589, learning rate: 0.00509, Loss: 0.2113, Accuracy:0.938\nIteration: 14590, learning rate: 0.00509, Loss: 0.1443, Accuracy:0.953\nIteration: 14591, learning rate: 0.00509, Loss: 0.2104, Accuracy:0.898\nIteration: 14592, learning rate: 0.00509, Loss: 0.1181, Accuracy:0.953\nIteration: 14593, learning rate: 0.00509, Loss: 0.1554, Accuracy:0.945\nIteration: 14594, learning rate: 0.00509, Loss: 0.1855, Accuracy:0.938\nIteration: 14595, learning rate: 0.00509, Loss: 0.1852, Accuracy:0.922\nIteration: 14596, learning rate: 0.00509, Loss: 0.1076, Accuracy:0.961\nIteration: 14597, learning rate: 0.00509, Loss: 0.1446, Accuracy:0.953\nIteration: 14598, learning rate: 0.00509, Loss: 0.1168, Accuracy:0.953\nIteration: 14599, learning rate: 0.00509, Loss: 0.0999, Accuracy:0.961\nIteration: 14600, learning rate: 0.00509, Loss: 0.1509, Accuracy:0.938\nIteration: 14601, learning rate: 0.00509, Loss: 0.1172, Accuracy:0.957\nEpoch: 471, Loss: 0.1466, Accuracy:0.945, Val Loss: 0.2680, Val Accuracy: 0.890\nIteration: 14602, learning rate: 0.00509, Loss: 0.1563, Accuracy:0.938\nIteration: 14603, learning rate: 0.00509, Loss: 0.0845, Accuracy:0.961\nIteration: 14604, learning rate: 0.00509, Loss: 0.1515, Accuracy:0.945\nIteration: 14605, learning rate: 0.00509, Loss: 0.1700, Accuracy:0.945\nIteration: 14606, learning rate: 0.00509, Loss: 0.1458, Accuracy:0.953\nIteration: 14607, learning rate: 0.00509, Loss: 0.1355, Accuracy:0.945\nIteration: 14608, learning rate: 0.00509, Loss: 0.1864, Accuracy:0.945\nIteration: 14609, learning rate: 0.00509, Loss: 0.1187, Accuracy:0.969\nIteration: 14610, learning rate: 0.00509, Loss: 0.1092, Accuracy:0.945\nIteration: 14611, learning rate: 0.00509, Loss: 0.2058, Accuracy:0.922\nIteration: 14612, learning rate: 0.00509, Loss: 0.2236, Accuracy:0.898\nIteration: 14613, learning rate: 0.00509, Loss: 0.1415, Accuracy:0.945\nIteration: 14614, learning rate: 0.00509, Loss: 0.1367, Accuracy:0.961\nIteration: 14615, learning rate: 0.00509, Loss: 0.1841, Accuracy:0.930\nIteration: 14616, learning rate: 0.00509, Loss: 0.0648, Accuracy:0.969\nIteration: 14617, learning rate: 0.00509, Loss: 0.0847, Accuracy:0.977\nIteration: 14618, learning rate: 0.00509, Loss: 0.1608, Accuracy:0.922\nIteration: 14619, learning rate: 0.00509, Loss: 0.1369, Accuracy:0.938\nIteration: 14620, learning rate: 0.00509, Loss: 0.0927, Accuracy:0.969\nIteration: 14621, learning rate: 0.00509, Loss: 0.0950, Accuracy:0.969\nIteration: 14622, learning rate: 0.00509, Loss: 0.1321, Accuracy:0.945\nIteration: 14623, learning rate: 0.00509, Loss: 0.2135, Accuracy:0.938\nIteration: 14624, learning rate: 0.00509, Loss: 0.1478, Accuracy:0.938\nIteration: 14625, learning rate: 0.00509, Loss: 0.1155, Accuracy:0.969\nIteration: 14626, learning rate: 0.00509, Loss: 0.1371, Accuracy:0.938\nIteration: 14627, learning rate: 0.00509, Loss: 0.2383, Accuracy:0.914\nIteration: 14628, learning rate: 0.00509, Loss: 0.1307, Accuracy:0.953\nIteration: 14629, learning rate: 0.00509, Loss: 0.1081, Accuracy:0.961\nIteration: 14630, learning rate: 0.00509, Loss: 0.0982, Accuracy:0.969\nIteration: 14631, learning rate: 0.00509, Loss: 0.1437, Accuracy:0.961\nIteration: 14632, learning rate: 0.00509, Loss: 0.1415, Accuracy:0.957\nEpoch: 472, Loss: 0.1416, Accuracy:0.948, Val Loss: 0.3146, Val Accuracy: 0.879\nIteration: 14633, learning rate: 0.00509, Loss: 0.1636, Accuracy:0.930\nIteration: 14634, learning rate: 0.00509, Loss: 0.1211, Accuracy:0.945\nIteration: 14635, learning rate: 0.00509, Loss: 0.1320, Accuracy:0.945\nIteration: 14636, learning rate: 0.00509, Loss: 0.1109, Accuracy:0.961\nIteration: 14637, learning rate: 0.00509, Loss: 0.1348, Accuracy:0.938\nIteration: 14638, learning rate: 0.00509, Loss: 0.1037, Accuracy:0.977\nIteration: 14639, learning rate: 0.00509, Loss: 0.1625, Accuracy:0.945\nIteration: 14640, learning rate: 0.00508, Loss: 0.2043, Accuracy:0.906\nIteration: 14641, learning rate: 0.00508, Loss: 0.0869, Accuracy:0.977\nIteration: 14642, learning rate: 0.00508, Loss: 0.1283, Accuracy:0.945\nIteration: 14643, learning rate: 0.00508, Loss: 0.2098, Accuracy:0.883\nIteration: 14644, learning rate: 0.00508, Loss: 0.0977, Accuracy:0.984\nIteration: 14645, learning rate: 0.00508, Loss: 0.1792, Accuracy:0.914\nIteration: 14646, learning rate: 0.00508, Loss: 0.1257, Accuracy:0.961\nIteration: 14647, learning rate: 0.00508, Loss: 0.1669, Accuracy:0.930\nIteration: 14648, learning rate: 0.00508, Loss: 0.1314, Accuracy:0.961\nIteration: 14649, learning rate: 0.00508, Loss: 0.1499, Accuracy:0.938\nIteration: 14650, learning rate: 0.00508, Loss: 0.1194, Accuracy:0.953\nIteration: 14651, learning rate: 0.00508, Loss: 0.1383, Accuracy:0.945\nIteration: 14652, learning rate: 0.00508, Loss: 0.1768, Accuracy:0.930\nIteration: 14653, learning rate: 0.00508, Loss: 0.1230, Accuracy:0.945\nIteration: 14654, learning rate: 0.00508, Loss: 0.0605, Accuracy:0.992\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14655, learning rate: 0.00508, Loss: 0.1326, Accuracy:0.961\nIteration: 14656, learning rate: 0.00508, Loss: 0.2348, Accuracy:0.922\nIteration: 14657, learning rate: 0.00508, Loss: 0.1879, Accuracy:0.930\nIteration: 14658, learning rate: 0.00508, Loss: 0.1034, Accuracy:0.977\nIteration: 14659, learning rate: 0.00508, Loss: 0.1746, Accuracy:0.922\nIteration: 14660, learning rate: 0.00508, Loss: 0.1228, Accuracy:0.945\nIteration: 14661, learning rate: 0.00508, Loss: 0.1291, Accuracy:0.945\nIteration: 14662, learning rate: 0.00508, Loss: 0.1927, Accuracy:0.922\nIteration: 14663, learning rate: 0.00508, Loss: 0.0794, Accuracy:0.978\nEpoch: 473, Loss: 0.1414, Accuracy:0.945, Val Loss: 0.3357, Val Accuracy: 0.861\nIteration: 14664, learning rate: 0.00508, Loss: 0.1714, Accuracy:0.945\nIteration: 14665, learning rate: 0.00508, Loss: 0.1515, Accuracy:0.938\nIteration: 14666, learning rate: 0.00508, Loss: 0.1219, Accuracy:0.953\nIteration: 14667, learning rate: 0.00508, Loss: 0.1490, Accuracy:0.938\nIteration: 14668, learning rate: 0.00508, Loss: 0.1988, Accuracy:0.906\nIteration: 14669, learning rate: 0.00508, Loss: 0.1455, Accuracy:0.938\nIteration: 14670, learning rate: 0.00508, Loss: 0.1238, Accuracy:0.961\nIteration: 14671, learning rate: 0.00508, Loss: 0.1909, Accuracy:0.922\nIteration: 14672, learning rate: 0.00508, Loss: 0.1186, Accuracy:0.945\nIteration: 14673, learning rate: 0.00508, Loss: 0.1630, Accuracy:0.945\nIteration: 14674, learning rate: 0.00508, Loss: 0.1279, Accuracy:0.961\nIteration: 14675, learning rate: 0.00508, Loss: 0.1674, Accuracy:0.953\nIteration: 14676, learning rate: 0.00508, Loss: 0.1731, Accuracy:0.945\nIteration: 14677, learning rate: 0.00508, Loss: 0.1276, Accuracy:0.969\nIteration: 14678, learning rate: 0.00508, Loss: 0.1473, Accuracy:0.961\nIteration: 14679, learning rate: 0.00508, Loss: 0.1899, Accuracy:0.898\nIteration: 14680, learning rate: 0.00508, Loss: 0.1050, Accuracy:0.969\nIteration: 14681, learning rate: 0.00508, Loss: 0.2046, Accuracy:0.922\nIteration: 14682, learning rate: 0.00508, Loss: 0.1271, Accuracy:0.961\nIteration: 14683, learning rate: 0.00508, Loss: 0.1069, Accuracy:0.953\nIteration: 14684, learning rate: 0.00508, Loss: 0.1755, Accuracy:0.945\nIteration: 14685, learning rate: 0.00508, Loss: 0.1983, Accuracy:0.914\nIteration: 14686, learning rate: 0.00508, Loss: 0.1742, Accuracy:0.938\nIteration: 14687, learning rate: 0.00508, Loss: 0.1072, Accuracy:0.945\nIteration: 14688, learning rate: 0.00508, Loss: 0.0782, Accuracy:0.977\nIteration: 14689, learning rate: 0.00508, Loss: 0.0980, Accuracy:0.953\nIteration: 14690, learning rate: 0.00508, Loss: 0.1660, Accuracy:0.938\nIteration: 14691, learning rate: 0.00508, Loss: 0.0856, Accuracy:0.977\nIteration: 14692, learning rate: 0.00508, Loss: 0.1656, Accuracy:0.938\nIteration: 14693, learning rate: 0.00508, Loss: 0.1389, Accuracy:0.961\nIteration: 14694, learning rate: 0.00508, Loss: 0.0759, Accuracy:0.968\nEpoch: 474, Loss: 0.1443, Accuracy:0.946, Val Loss: 0.3428, Val Accuracy: 0.855\nIteration: 14695, learning rate: 0.00508, Loss: 0.1021, Accuracy:0.961\nIteration: 14696, learning rate: 0.00508, Loss: 0.1654, Accuracy:0.922\nIteration: 14697, learning rate: 0.00508, Loss: 0.1467, Accuracy:0.930\nIteration: 14698, learning rate: 0.00508, Loss: 0.1514, Accuracy:0.938\nIteration: 14699, learning rate: 0.00508, Loss: 0.1918, Accuracy:0.945\nIteration: 14700, learning rate: 0.00508, Loss: 0.1436, Accuracy:0.945\nIteration: 14701, learning rate: 0.00508, Loss: 0.1134, Accuracy:0.945\nIteration: 14702, learning rate: 0.00508, Loss: 0.1631, Accuracy:0.914\nIteration: 14703, learning rate: 0.00508, Loss: 0.1478, Accuracy:0.930\nIteration: 14704, learning rate: 0.00508, Loss: 0.0725, Accuracy:0.977\nIteration: 14705, learning rate: 0.00507, Loss: 0.1434, Accuracy:0.945\nIteration: 14706, learning rate: 0.00507, Loss: 0.1738, Accuracy:0.938\nIteration: 14707, learning rate: 0.00507, Loss: 0.1267, Accuracy:0.953\nIteration: 14708, learning rate: 0.00507, Loss: 0.1930, Accuracy:0.930\nIteration: 14709, learning rate: 0.00507, Loss: 0.0972, Accuracy:0.969\nIteration: 14710, learning rate: 0.00507, Loss: 0.0998, Accuracy:0.977\nIteration: 14711, learning rate: 0.00507, Loss: 0.1069, Accuracy:0.961\nIteration: 14712, learning rate: 0.00507, Loss: 0.1048, Accuracy:0.977\nIteration: 14713, learning rate: 0.00507, Loss: 0.1455, Accuracy:0.945\nIteration: 14714, learning rate: 0.00507, Loss: 0.1016, Accuracy:0.953\nIteration: 14715, learning rate: 0.00507, Loss: 0.1687, Accuracy:0.930\nIteration: 14716, learning rate: 0.00507, Loss: 0.0922, Accuracy:0.977\nIteration: 14717, learning rate: 0.00507, Loss: 0.1557, Accuracy:0.930\nIteration: 14718, learning rate: 0.00507, Loss: 0.1505, Accuracy:0.922\nIteration: 14719, learning rate: 0.00507, Loss: 0.1139, Accuracy:0.961\nIteration: 14720, learning rate: 0.00507, Loss: 0.1345, Accuracy:0.945\nIteration: 14721, learning rate: 0.00507, Loss: 0.1337, Accuracy:0.953\nIteration: 14722, learning rate: 0.00507, Loss: 0.1911, Accuracy:0.945\nIteration: 14723, learning rate: 0.00507, Loss: 0.1104, Accuracy:0.969\nIteration: 14724, learning rate: 0.00507, Loss: 0.1143, Accuracy:0.953\nIteration: 14725, learning rate: 0.00507, Loss: 0.2268, Accuracy:0.925\nEpoch: 475, Loss: 0.1381, Accuracy:0.947, Val Loss: 0.3257, Val Accuracy: 0.873\nIteration: 14726, learning rate: 0.00507, Loss: 0.1372, Accuracy:0.930\nIteration: 14727, learning rate: 0.00507, Loss: 0.1491, Accuracy:0.930\nIteration: 14728, learning rate: 0.00507, Loss: 0.1126, Accuracy:0.961\nIteration: 14729, learning rate: 0.00507, Loss: 0.0935, Accuracy:0.977\nIteration: 14730, learning rate: 0.00507, Loss: 0.1563, Accuracy:0.961\nIteration: 14731, learning rate: 0.00507, Loss: 0.1731, Accuracy:0.938\nIteration: 14732, learning rate: 0.00507, Loss: 0.1610, Accuracy:0.930\nIteration: 14733, learning rate: 0.00507, Loss: 0.1597, Accuracy:0.953\nIteration: 14734, learning rate: 0.00507, Loss: 0.1647, Accuracy:0.914\nIteration: 14735, learning rate: 0.00507, Loss: 0.1794, Accuracy:0.938\nIteration: 14736, learning rate: 0.00507, Loss: 0.1440, Accuracy:0.938\nIteration: 14737, learning rate: 0.00507, Loss: 0.1067, Accuracy:0.961\nIteration: 14738, learning rate: 0.00507, Loss: 0.2028, Accuracy:0.914\nIteration: 14739, learning rate: 0.00507, Loss: 0.1029, Accuracy:0.945\nIteration: 14740, learning rate: 0.00507, Loss: 0.1679, Accuracy:0.930\nIteration: 14741, learning rate: 0.00507, Loss: 0.1028, Accuracy:0.961\nIteration: 14742, learning rate: 0.00507, Loss: 0.0873, Accuracy:0.969\nIteration: 14743, learning rate: 0.00507, Loss: 0.0935, Accuracy:0.969\nIteration: 14744, learning rate: 0.00507, Loss: 0.1106, Accuracy:0.961\nIteration: 14745, learning rate: 0.00507, Loss: 0.1570, Accuracy:0.953\nIteration: 14746, learning rate: 0.00507, Loss: 0.1886, Accuracy:0.914\nIteration: 14747, learning rate: 0.00507, Loss: 0.1541, Accuracy:0.930\nIteration: 14748, learning rate: 0.00507, Loss: 0.0740, Accuracy:0.977\nIteration: 14749, learning rate: 0.00507, Loss: 0.1491, Accuracy:0.945\nIteration: 14750, learning rate: 0.00507, Loss: 0.1257, Accuracy:0.938\nIteration: 14751, learning rate: 0.00507, Loss: 0.1116, Accuracy:0.969\nIteration: 14752, learning rate: 0.00507, Loss: 0.1671, Accuracy:0.938\nIteration: 14753, learning rate: 0.00507, Loss: 0.1145, Accuracy:0.961\nIteration: 14754, learning rate: 0.00507, Loss: 0.1757, Accuracy:0.930\nIteration: 14755, learning rate: 0.00507, Loss: 0.1239, Accuracy:0.961\nIteration: 14756, learning rate: 0.00507, Loss: 0.1373, Accuracy:0.925\nEpoch: 476, Loss: 0.1382, Accuracy:0.946, Val Loss: 0.3193, Val Accuracy: 0.857\nIteration: 14757, learning rate: 0.00507, Loss: 0.1478, Accuracy:0.969\nIteration: 14758, learning rate: 0.00507, Loss: 0.1553, Accuracy:0.930\nIteration: 14759, learning rate: 0.00507, Loss: 0.1345, Accuracy:0.945\nIteration: 14760, learning rate: 0.00507, Loss: 0.1551, Accuracy:0.922\nIteration: 14761, learning rate: 0.00507, Loss: 0.1598, Accuracy:0.922\nIteration: 14762, learning rate: 0.00507, Loss: 0.0918, Accuracy:0.977\nIteration: 14763, learning rate: 0.00507, Loss: 0.0775, Accuracy:0.984\nIteration: 14764, learning rate: 0.00507, Loss: 0.1563, Accuracy:0.945\nIteration: 14765, learning rate: 0.00507, Loss: 0.1436, Accuracy:0.938\nIteration: 14766, learning rate: 0.00507, Loss: 0.1977, Accuracy:0.906\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14767, learning rate: 0.00507, Loss: 0.1281, Accuracy:0.945\nIteration: 14768, learning rate: 0.00507, Loss: 0.1609, Accuracy:0.945\nIteration: 14769, learning rate: 0.00507, Loss: 0.2095, Accuracy:0.930\nIteration: 14770, learning rate: 0.00506, Loss: 0.1274, Accuracy:0.945\nIteration: 14771, learning rate: 0.00506, Loss: 0.0941, Accuracy:0.969\nIteration: 14772, learning rate: 0.00506, Loss: 0.1699, Accuracy:0.930\nIteration: 14773, learning rate: 0.00506, Loss: 0.1619, Accuracy:0.938\nIteration: 14774, learning rate: 0.00506, Loss: 0.1653, Accuracy:0.906\nIteration: 14775, learning rate: 0.00506, Loss: 0.1403, Accuracy:0.930\nIteration: 14776, learning rate: 0.00506, Loss: 0.1954, Accuracy:0.906\nIteration: 14777, learning rate: 0.00506, Loss: 0.0615, Accuracy:0.984\nIteration: 14778, learning rate: 0.00506, Loss: 0.1552, Accuracy:0.945\nIteration: 14779, learning rate: 0.00506, Loss: 0.1529, Accuracy:0.938\nIteration: 14780, learning rate: 0.00506, Loss: 0.1602, Accuracy:0.930\nIteration: 14781, learning rate: 0.00506, Loss: 0.0795, Accuracy:0.977\nIteration: 14782, learning rate: 0.00506, Loss: 0.1502, Accuracy:0.922\nIteration: 14783, learning rate: 0.00506, Loss: 0.0959, Accuracy:0.953\nIteration: 14784, learning rate: 0.00506, Loss: 0.1095, Accuracy:0.961\nIteration: 14785, learning rate: 0.00506, Loss: 0.2636, Accuracy:0.906\nIteration: 14786, learning rate: 0.00506, Loss: 0.1253, Accuracy:0.953\nIteration: 14787, learning rate: 0.00506, Loss: 0.1097, Accuracy:0.968\nEpoch: 477, Loss: 0.1431, Accuracy:0.943, Val Loss: 0.2522, Val Accuracy: 0.899\nIteration: 14788, learning rate: 0.00506, Loss: 0.1431, Accuracy:0.953\nIteration: 14789, learning rate: 0.00506, Loss: 0.1259, Accuracy:0.961\nIteration: 14790, learning rate: 0.00506, Loss: 0.1496, Accuracy:0.945\nIteration: 14791, learning rate: 0.00506, Loss: 0.1650, Accuracy:0.922\nIteration: 14792, learning rate: 0.00506, Loss: 0.0875, Accuracy:0.969\nIteration: 14793, learning rate: 0.00506, Loss: 0.1511, Accuracy:0.922\nIteration: 14794, learning rate: 0.00506, Loss: 0.1767, Accuracy:0.930\nIteration: 14795, learning rate: 0.00506, Loss: 0.0925, Accuracy:0.969\nIteration: 14796, learning rate: 0.00506, Loss: 0.1601, Accuracy:0.930\nIteration: 14797, learning rate: 0.00506, Loss: 0.1439, Accuracy:0.938\nIteration: 14798, learning rate: 0.00506, Loss: 0.0918, Accuracy:0.961\nIteration: 14799, learning rate: 0.00506, Loss: 0.1131, Accuracy:0.961\nIteration: 14800, learning rate: 0.00506, Loss: 0.1292, Accuracy:0.938\nIteration: 14801, learning rate: 0.00506, Loss: 0.1079, Accuracy:0.953\nIteration: 14802, learning rate: 0.00506, Loss: 0.1569, Accuracy:0.938\nIteration: 14803, learning rate: 0.00506, Loss: 0.1468, Accuracy:0.945\nIteration: 14804, learning rate: 0.00506, Loss: 0.1337, Accuracy:0.945\nIteration: 14805, learning rate: 0.00506, Loss: 0.1751, Accuracy:0.938\nIteration: 14806, learning rate: 0.00506, Loss: 0.1418, Accuracy:0.930\nIteration: 14807, learning rate: 0.00506, Loss: 0.1145, Accuracy:0.969\nIteration: 14808, learning rate: 0.00506, Loss: 0.0922, Accuracy:0.961\nIteration: 14809, learning rate: 0.00506, Loss: 0.2138, Accuracy:0.906\nIteration: 14810, learning rate: 0.00506, Loss: 0.1724, Accuracy:0.938\nIteration: 14811, learning rate: 0.00506, Loss: 0.2116, Accuracy:0.898\nIteration: 14812, learning rate: 0.00506, Loss: 0.1530, Accuracy:0.945\nIteration: 14813, learning rate: 0.00506, Loss: 0.0689, Accuracy:0.969\nIteration: 14814, learning rate: 0.00506, Loss: 0.1121, Accuracy:0.953\nIteration: 14815, learning rate: 0.00506, Loss: 0.1536, Accuracy:0.930\nIteration: 14816, learning rate: 0.00506, Loss: 0.2160, Accuracy:0.914\nIteration: 14817, learning rate: 0.00506, Loss: 0.1043, Accuracy:0.969\nIteration: 14818, learning rate: 0.00506, Loss: 0.1278, Accuracy:0.957\nEpoch: 478, Loss: 0.1397, Accuracy:0.944, Val Loss: 0.2934, Val Accuracy: 0.887\nIteration: 14819, learning rate: 0.00506, Loss: 0.1150, Accuracy:0.969\nIteration: 14820, learning rate: 0.00506, Loss: 0.0815, Accuracy:0.969\nIteration: 14821, learning rate: 0.00506, Loss: 0.1366, Accuracy:0.938\nIteration: 14822, learning rate: 0.00506, Loss: 0.1001, Accuracy:0.969\nIteration: 14823, learning rate: 0.00506, Loss: 0.0965, Accuracy:0.977\nIteration: 14824, learning rate: 0.00506, Loss: 0.1443, Accuracy:0.953\nIteration: 14825, learning rate: 0.00506, Loss: 0.1134, Accuracy:0.953\nIteration: 14826, learning rate: 0.00506, Loss: 0.1895, Accuracy:0.922\nIteration: 14827, learning rate: 0.00506, Loss: 0.1286, Accuracy:0.961\nIteration: 14828, learning rate: 0.00506, Loss: 0.1664, Accuracy:0.938\nIteration: 14829, learning rate: 0.00506, Loss: 0.0851, Accuracy:0.961\nIteration: 14830, learning rate: 0.00506, Loss: 0.1211, Accuracy:0.945\nIteration: 14831, learning rate: 0.00506, Loss: 0.1197, Accuracy:0.945\nIteration: 14832, learning rate: 0.00506, Loss: 0.0912, Accuracy:0.977\nIteration: 14833, learning rate: 0.00506, Loss: 0.1347, Accuracy:0.961\nIteration: 14834, learning rate: 0.00506, Loss: 0.1598, Accuracy:0.938\nIteration: 14835, learning rate: 0.00505, Loss: 0.2278, Accuracy:0.930\nIteration: 14836, learning rate: 0.00505, Loss: 0.1135, Accuracy:0.953\nIteration: 14837, learning rate: 0.00505, Loss: 0.1168, Accuracy:0.945\nIteration: 14838, learning rate: 0.00505, Loss: 0.1642, Accuracy:0.938\nIteration: 14839, learning rate: 0.00505, Loss: 0.0765, Accuracy:0.984\nIteration: 14840, learning rate: 0.00505, Loss: 0.1475, Accuracy:0.945\nIteration: 14841, learning rate: 0.00505, Loss: 0.0949, Accuracy:0.953\nIteration: 14842, learning rate: 0.00505, Loss: 0.1468, Accuracy:0.953\nIteration: 14843, learning rate: 0.00505, Loss: 0.2017, Accuracy:0.914\nIteration: 14844, learning rate: 0.00505, Loss: 0.1211, Accuracy:0.945\nIteration: 14845, learning rate: 0.00505, Loss: 0.1424, Accuracy:0.945\nIteration: 14846, learning rate: 0.00505, Loss: 0.1368, Accuracy:0.945\nIteration: 14847, learning rate: 0.00505, Loss: 0.1775, Accuracy:0.945\nIteration: 14848, learning rate: 0.00505, Loss: 0.1607, Accuracy:0.938\nIteration: 14849, learning rate: 0.00505, Loss: 0.1313, Accuracy:0.957\nEpoch: 479, Loss: 0.1336, Accuracy:0.950, Val Loss: 0.2918, Val Accuracy: 0.887\nIteration: 14850, learning rate: 0.00505, Loss: 0.1276, Accuracy:0.945\nIteration: 14851, learning rate: 0.00505, Loss: 0.1606, Accuracy:0.938\nIteration: 14852, learning rate: 0.00505, Loss: 0.1431, Accuracy:0.961\nIteration: 14853, learning rate: 0.00505, Loss: 0.1318, Accuracy:0.961\nIteration: 14854, learning rate: 0.00505, Loss: 0.1752, Accuracy:0.930\nIteration: 14855, learning rate: 0.00505, Loss: 0.2094, Accuracy:0.922\nIteration: 14856, learning rate: 0.00505, Loss: 0.1391, Accuracy:0.953\nIteration: 14857, learning rate: 0.00505, Loss: 0.0741, Accuracy:0.977\nIteration: 14858, learning rate: 0.00505, Loss: 0.1995, Accuracy:0.922\nIteration: 14859, learning rate: 0.00505, Loss: 0.0547, Accuracy:0.992\nIteration: 14860, learning rate: 0.00505, Loss: 0.1648, Accuracy:0.945\nIteration: 14861, learning rate: 0.00505, Loss: 0.1163, Accuracy:0.969\nIteration: 14862, learning rate: 0.00505, Loss: 0.1400, Accuracy:0.938\nIteration: 14863, learning rate: 0.00505, Loss: 0.1327, Accuracy:0.938\nIteration: 14864, learning rate: 0.00505, Loss: 0.1274, Accuracy:0.969\nIteration: 14865, learning rate: 0.00505, Loss: 0.1308, Accuracy:0.953\nIteration: 14866, learning rate: 0.00505, Loss: 0.0752, Accuracy:0.977\nIteration: 14867, learning rate: 0.00505, Loss: 0.1837, Accuracy:0.906\nIteration: 14868, learning rate: 0.00505, Loss: 0.0906, Accuracy:0.969\nIteration: 14869, learning rate: 0.00505, Loss: 0.1442, Accuracy:0.953\nIteration: 14870, learning rate: 0.00505, Loss: 0.1400, Accuracy:0.945\nIteration: 14871, learning rate: 0.00505, Loss: 0.0883, Accuracy:0.984\nIteration: 14872, learning rate: 0.00505, Loss: 0.2240, Accuracy:0.922\nIteration: 14873, learning rate: 0.00505, Loss: 0.1470, Accuracy:0.922\nIteration: 14874, learning rate: 0.00505, Loss: 0.0911, Accuracy:0.961\nIteration: 14875, learning rate: 0.00505, Loss: 0.1271, Accuracy:0.953\nIteration: 14876, learning rate: 0.00505, Loss: 0.1519, Accuracy:0.945\nIteration: 14877, learning rate: 0.00505, Loss: 0.1066, Accuracy:0.961\nIteration: 14878, learning rate: 0.00505, Loss: 0.1179, Accuracy:0.961\nIteration: 14879, learning rate: 0.00505, Loss: 0.1449, Accuracy:0.938\nIteration: 14880, learning rate: 0.00505, Loss: 0.2514, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 480, Loss: 0.1391, Accuracy:0.949, Val Loss: 0.3148, Val Accuracy: 0.877\nIteration: 14881, learning rate: 0.00505, Loss: 0.1381, Accuracy:0.953\nIteration: 14882, learning rate: 0.00505, Loss: 0.1157, Accuracy:0.953\nIteration: 14883, learning rate: 0.00505, Loss: 0.2058, Accuracy:0.922\nIteration: 14884, learning rate: 0.00505, Loss: 0.0995, Accuracy:0.961\nIteration: 14885, learning rate: 0.00505, Loss: 0.1540, Accuracy:0.938\nIteration: 14886, learning rate: 0.00505, Loss: 0.1915, Accuracy:0.922\nIteration: 14887, learning rate: 0.00505, Loss: 0.1152, Accuracy:0.945\nIteration: 14888, learning rate: 0.00505, Loss: 0.1942, Accuracy:0.891\nIteration: 14889, learning rate: 0.00505, Loss: 0.1408, Accuracy:0.969\nIteration: 14890, learning rate: 0.00505, Loss: 0.1393, Accuracy:0.930\nIteration: 14891, learning rate: 0.00505, Loss: 0.1429, Accuracy:0.945\nIteration: 14892, learning rate: 0.00505, Loss: 0.1838, Accuracy:0.922\nIteration: 14893, learning rate: 0.00505, Loss: 0.0809, Accuracy:0.969\nIteration: 14894, learning rate: 0.00505, Loss: 0.1354, Accuracy:0.961\nIteration: 14895, learning rate: 0.00505, Loss: 0.0798, Accuracy:0.969\nIteration: 14896, learning rate: 0.00505, Loss: 0.1039, Accuracy:0.953\nIteration: 14897, learning rate: 0.00505, Loss: 0.1590, Accuracy:0.945\nIteration: 14898, learning rate: 0.00505, Loss: 0.1362, Accuracy:0.930\nIteration: 14899, learning rate: 0.00505, Loss: 0.1521, Accuracy:0.961\nIteration: 14900, learning rate: 0.00505, Loss: 0.1556, Accuracy:0.961\nIteration: 14901, learning rate: 0.00504, Loss: 0.0946, Accuracy:0.969\nIteration: 14902, learning rate: 0.00504, Loss: 0.1243, Accuracy:0.938\nIteration: 14903, learning rate: 0.00504, Loss: 0.1548, Accuracy:0.906\nIteration: 14904, learning rate: 0.00504, Loss: 0.1025, Accuracy:0.961\nIteration: 14905, learning rate: 0.00504, Loss: 0.1516, Accuracy:0.938\nIteration: 14906, learning rate: 0.00504, Loss: 0.1432, Accuracy:0.945\nIteration: 14907, learning rate: 0.00504, Loss: 0.0973, Accuracy:0.969\nIteration: 14908, learning rate: 0.00504, Loss: 0.1091, Accuracy:0.961\nIteration: 14909, learning rate: 0.00504, Loss: 0.1189, Accuracy:0.945\nIteration: 14910, learning rate: 0.00504, Loss: 0.1791, Accuracy:0.922\nIteration: 14911, learning rate: 0.00504, Loss: 0.0853, Accuracy:0.978\nEpoch: 481, Loss: 0.1350, Accuracy:0.946, Val Loss: 0.2976, Val Accuracy: 0.884\nIteration: 14912, learning rate: 0.00504, Loss: 0.1128, Accuracy:0.945\nIteration: 14913, learning rate: 0.00504, Loss: 0.1395, Accuracy:0.961\nIteration: 14914, learning rate: 0.00504, Loss: 0.1265, Accuracy:0.953\nIteration: 14915, learning rate: 0.00504, Loss: 0.1376, Accuracy:0.945\nIteration: 14916, learning rate: 0.00504, Loss: 0.1163, Accuracy:0.961\nIteration: 14917, learning rate: 0.00504, Loss: 0.1141, Accuracy:0.930\nIteration: 14918, learning rate: 0.00504, Loss: 0.1793, Accuracy:0.922\nIteration: 14919, learning rate: 0.00504, Loss: 0.1418, Accuracy:0.945\nIteration: 14920, learning rate: 0.00504, Loss: 0.1383, Accuracy:0.953\nIteration: 14921, learning rate: 0.00504, Loss: 0.1552, Accuracy:0.961\nIteration: 14922, learning rate: 0.00504, Loss: 0.2185, Accuracy:0.914\nIteration: 14923, learning rate: 0.00504, Loss: 0.1567, Accuracy:0.930\nIteration: 14924, learning rate: 0.00504, Loss: 0.1696, Accuracy:0.922\nIteration: 14925, learning rate: 0.00504, Loss: 0.0677, Accuracy:0.992\nIteration: 14926, learning rate: 0.00504, Loss: 0.2135, Accuracy:0.906\nIteration: 14927, learning rate: 0.00504, Loss: 0.0896, Accuracy:0.977\nIteration: 14928, learning rate: 0.00504, Loss: 0.1496, Accuracy:0.945\nIteration: 14929, learning rate: 0.00504, Loss: 0.1886, Accuracy:0.938\nIteration: 14930, learning rate: 0.00504, Loss: 0.1028, Accuracy:0.969\nIteration: 14931, learning rate: 0.00504, Loss: 0.1123, Accuracy:0.953\nIteration: 14932, learning rate: 0.00504, Loss: 0.0963, Accuracy:0.969\nIteration: 14933, learning rate: 0.00504, Loss: 0.1583, Accuracy:0.945\nIteration: 14934, learning rate: 0.00504, Loss: 0.1821, Accuracy:0.930\nIteration: 14935, learning rate: 0.00504, Loss: 0.1542, Accuracy:0.953\nIteration: 14936, learning rate: 0.00504, Loss: 0.1460, Accuracy:0.969\nIteration: 14937, learning rate: 0.00504, Loss: 0.1807, Accuracy:0.938\nIteration: 14938, learning rate: 0.00504, Loss: 0.1263, Accuracy:0.938\nIteration: 14939, learning rate: 0.00504, Loss: 0.1819, Accuracy:0.922\nIteration: 14940, learning rate: 0.00504, Loss: 0.0918, Accuracy:0.977\nIteration: 14941, learning rate: 0.00504, Loss: 0.1642, Accuracy:0.914\nIteration: 14942, learning rate: 0.00504, Loss: 0.0675, Accuracy:1.000\nEpoch: 482, Loss: 0.1413, Accuracy:0.948, Val Loss: 0.2734, Val Accuracy: 0.881\nIteration: 14943, learning rate: 0.00504, Loss: 0.2423, Accuracy:0.898\nIteration: 14944, learning rate: 0.00504, Loss: 0.1774, Accuracy:0.938\nIteration: 14945, learning rate: 0.00504, Loss: 0.1714, Accuracy:0.953\nIteration: 14946, learning rate: 0.00504, Loss: 0.1010, Accuracy:0.961\nIteration: 14947, learning rate: 0.00504, Loss: 0.1346, Accuracy:0.938\nIteration: 14948, learning rate: 0.00504, Loss: 0.0971, Accuracy:0.977\nIteration: 14949, learning rate: 0.00504, Loss: 0.1761, Accuracy:0.953\nIteration: 14950, learning rate: 0.00504, Loss: 0.2104, Accuracy:0.930\nIteration: 14951, learning rate: 0.00504, Loss: 0.1530, Accuracy:0.953\nIteration: 14952, learning rate: 0.00504, Loss: 0.1559, Accuracy:0.938\nIteration: 14953, learning rate: 0.00504, Loss: 0.2324, Accuracy:0.906\nIteration: 14954, learning rate: 0.00504, Loss: 0.1552, Accuracy:0.938\nIteration: 14955, learning rate: 0.00504, Loss: 0.1808, Accuracy:0.922\nIteration: 14956, learning rate: 0.00504, Loss: 0.1736, Accuracy:0.930\nIteration: 14957, learning rate: 0.00504, Loss: 0.1471, Accuracy:0.938\nIteration: 14958, learning rate: 0.00504, Loss: 0.2090, Accuracy:0.930\nIteration: 14959, learning rate: 0.00504, Loss: 0.1489, Accuracy:0.953\nIteration: 14960, learning rate: 0.00504, Loss: 0.1611, Accuracy:0.938\nIteration: 14961, learning rate: 0.00504, Loss: 0.1473, Accuracy:0.930\nIteration: 14962, learning rate: 0.00504, Loss: 0.1155, Accuracy:0.930\nIteration: 14963, learning rate: 0.00504, Loss: 0.1656, Accuracy:0.938\nIteration: 14964, learning rate: 0.00504, Loss: 0.1233, Accuracy:0.945\nIteration: 14965, learning rate: 0.00504, Loss: 0.1773, Accuracy:0.938\nIteration: 14966, learning rate: 0.00504, Loss: 0.1700, Accuracy:0.930\nIteration: 14967, learning rate: 0.00503, Loss: 0.1169, Accuracy:0.969\nIteration: 14968, learning rate: 0.00503, Loss: 0.1717, Accuracy:0.945\nIteration: 14969, learning rate: 0.00503, Loss: 0.2282, Accuracy:0.922\nIteration: 14970, learning rate: 0.00503, Loss: 0.2387, Accuracy:0.906\nIteration: 14971, learning rate: 0.00503, Loss: 0.2024, Accuracy:0.898\nIteration: 14972, learning rate: 0.00503, Loss: 0.1170, Accuracy:0.945\nIteration: 14973, learning rate: 0.00503, Loss: 0.1729, Accuracy:0.903\nEpoch: 483, Loss: 0.1669, Accuracy:0.935, Val Loss: 0.2801, Val Accuracy: 0.890\nIteration: 14974, learning rate: 0.00503, Loss: 0.0852, Accuracy:0.953\nIteration: 14975, learning rate: 0.00503, Loss: 0.1594, Accuracy:0.938\nIteration: 14976, learning rate: 0.00503, Loss: 0.1714, Accuracy:0.945\nIteration: 14977, learning rate: 0.00503, Loss: 0.1468, Accuracy:0.930\nIteration: 14978, learning rate: 0.00503, Loss: 0.1764, Accuracy:0.922\nIteration: 14979, learning rate: 0.00503, Loss: 0.1121, Accuracy:0.953\nIteration: 14980, learning rate: 0.00503, Loss: 0.1707, Accuracy:0.930\nIteration: 14981, learning rate: 0.00503, Loss: 0.2215, Accuracy:0.922\nIteration: 14982, learning rate: 0.00503, Loss: 0.0993, Accuracy:0.977\nIteration: 14983, learning rate: 0.00503, Loss: 0.1001, Accuracy:0.945\nIteration: 14984, learning rate: 0.00503, Loss: 0.0758, Accuracy:0.977\nIteration: 14985, learning rate: 0.00503, Loss: 0.1532, Accuracy:0.930\nIteration: 14986, learning rate: 0.00503, Loss: 0.1362, Accuracy:0.945\nIteration: 14987, learning rate: 0.00503, Loss: 0.0656, Accuracy:0.992\nIteration: 14988, learning rate: 0.00503, Loss: 0.1408, Accuracy:0.953\nIteration: 14989, learning rate: 0.00503, Loss: 0.1196, Accuracy:0.953\nIteration: 14990, learning rate: 0.00503, Loss: 0.1311, Accuracy:0.953\nIteration: 14991, learning rate: 0.00503, Loss: 0.1451, Accuracy:0.930\nIteration: 14992, learning rate: 0.00503, Loss: 0.1495, Accuracy:0.945\nIteration: 14993, learning rate: 0.00503, Loss: 0.2065, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 14994, learning rate: 0.00503, Loss: 0.1413, Accuracy:0.953\nIteration: 14995, learning rate: 0.00503, Loss: 0.0895, Accuracy:0.977\nIteration: 14996, learning rate: 0.00503, Loss: 0.1532, Accuracy:0.961\nIteration: 14997, learning rate: 0.00503, Loss: 0.1182, Accuracy:0.961\nIteration: 14998, learning rate: 0.00503, Loss: 0.1305, Accuracy:0.930\nIteration: 14999, learning rate: 0.00503, Loss: 0.2082, Accuracy:0.914\nIteration: 15000, learning rate: 0.00503, Loss: 0.1917, Accuracy:0.930\nIteration: 15001, learning rate: 0.00503, Loss: 0.1341, Accuracy:0.938\nIteration: 15002, learning rate: 0.00503, Loss: 0.0925, Accuracy:0.961\nIteration: 15003, learning rate: 0.00503, Loss: 0.2439, Accuracy:0.906\nIteration: 15004, learning rate: 0.00503, Loss: 0.1090, Accuracy:0.978\nEpoch: 484, Loss: 0.1412, Accuracy:0.946, Val Loss: 0.3211, Val Accuracy: 0.878\nIteration: 15005, learning rate: 0.00503, Loss: 0.1164, Accuracy:0.969\nIteration: 15006, learning rate: 0.00503, Loss: 0.1243, Accuracy:0.953\nIteration: 15007, learning rate: 0.00503, Loss: 0.0921, Accuracy:0.953\nIteration: 15008, learning rate: 0.00503, Loss: 0.2080, Accuracy:0.938\nIteration: 15009, learning rate: 0.00503, Loss: 0.0754, Accuracy:0.977\nIteration: 15010, learning rate: 0.00503, Loss: 0.1197, Accuracy:0.969\nIteration: 15011, learning rate: 0.00503, Loss: 0.0981, Accuracy:0.984\nIteration: 15012, learning rate: 0.00503, Loss: 0.2021, Accuracy:0.914\nIteration: 15013, learning rate: 0.00503, Loss: 0.1303, Accuracy:0.938\nIteration: 15014, learning rate: 0.00503, Loss: 0.1193, Accuracy:0.953\nIteration: 15015, learning rate: 0.00503, Loss: 0.1555, Accuracy:0.914\nIteration: 15016, learning rate: 0.00503, Loss: 0.2101, Accuracy:0.914\nIteration: 15017, learning rate: 0.00503, Loss: 0.0952, Accuracy:0.961\nIteration: 15018, learning rate: 0.00503, Loss: 0.1199, Accuracy:0.961\nIteration: 15019, learning rate: 0.00503, Loss: 0.1988, Accuracy:0.906\nIteration: 15020, learning rate: 0.00503, Loss: 0.1606, Accuracy:0.938\nIteration: 15021, learning rate: 0.00503, Loss: 0.1282, Accuracy:0.969\nIteration: 15022, learning rate: 0.00503, Loss: 0.1420, Accuracy:0.953\nIteration: 15023, learning rate: 0.00503, Loss: 0.1695, Accuracy:0.945\nIteration: 15024, learning rate: 0.00503, Loss: 0.1357, Accuracy:0.953\nIteration: 15025, learning rate: 0.00503, Loss: 0.1419, Accuracy:0.914\nIteration: 15026, learning rate: 0.00503, Loss: 0.1535, Accuracy:0.945\nIteration: 15027, learning rate: 0.00503, Loss: 0.1015, Accuracy:0.969\nIteration: 15028, learning rate: 0.00503, Loss: 0.1614, Accuracy:0.938\nIteration: 15029, learning rate: 0.00503, Loss: 0.1746, Accuracy:0.945\nIteration: 15030, learning rate: 0.00503, Loss: 0.0993, Accuracy:0.969\nIteration: 15031, learning rate: 0.00503, Loss: 0.1230, Accuracy:0.953\nIteration: 15032, learning rate: 0.00503, Loss: 0.0928, Accuracy:0.977\nIteration: 15033, learning rate: 0.00502, Loss: 0.1144, Accuracy:0.953\nIteration: 15034, learning rate: 0.00502, Loss: 0.1788, Accuracy:0.930\nIteration: 15035, learning rate: 0.00502, Loss: 0.1050, Accuracy:0.946\nEpoch: 485, Loss: 0.1370, Accuracy:0.948, Val Loss: 0.3005, Val Accuracy: 0.890\nIteration: 15036, learning rate: 0.00502, Loss: 0.2324, Accuracy:0.891\nIteration: 15037, learning rate: 0.00502, Loss: 0.1011, Accuracy:0.961\nIteration: 15038, learning rate: 0.00502, Loss: 0.0953, Accuracy:0.961\nIteration: 15039, learning rate: 0.00502, Loss: 0.1004, Accuracy:0.961\nIteration: 15040, learning rate: 0.00502, Loss: 0.1533, Accuracy:0.938\nIteration: 15041, learning rate: 0.00502, Loss: 0.1181, Accuracy:0.945\nIteration: 15042, learning rate: 0.00502, Loss: 0.1312, Accuracy:0.961\nIteration: 15043, learning rate: 0.00502, Loss: 0.0881, Accuracy:0.977\nIteration: 15044, learning rate: 0.00502, Loss: 0.1295, Accuracy:0.938\nIteration: 15045, learning rate: 0.00502, Loss: 0.1073, Accuracy:0.953\nIteration: 15046, learning rate: 0.00502, Loss: 0.1266, Accuracy:0.961\nIteration: 15047, learning rate: 0.00502, Loss: 0.1809, Accuracy:0.914\nIteration: 15048, learning rate: 0.00502, Loss: 0.1853, Accuracy:0.961\nIteration: 15049, learning rate: 0.00502, Loss: 0.1309, Accuracy:0.953\nIteration: 15050, learning rate: 0.00502, Loss: 0.1649, Accuracy:0.930\nIteration: 15051, learning rate: 0.00502, Loss: 0.1231, Accuracy:0.961\nIteration: 15052, learning rate: 0.00502, Loss: 0.1398, Accuracy:0.945\nIteration: 15053, learning rate: 0.00502, Loss: 0.1552, Accuracy:0.930\nIteration: 15054, learning rate: 0.00502, Loss: 0.1315, Accuracy:0.945\nIteration: 15055, learning rate: 0.00502, Loss: 0.1144, Accuracy:0.961\nIteration: 15056, learning rate: 0.00502, Loss: 0.2045, Accuracy:0.930\nIteration: 15057, learning rate: 0.00502, Loss: 0.1044, Accuracy:0.969\nIteration: 15058, learning rate: 0.00502, Loss: 0.1177, Accuracy:0.961\nIteration: 15059, learning rate: 0.00502, Loss: 0.1049, Accuracy:0.953\nIteration: 15060, learning rate: 0.00502, Loss: 0.1136, Accuracy:0.969\nIteration: 15061, learning rate: 0.00502, Loss: 0.0757, Accuracy:0.984\nIteration: 15062, learning rate: 0.00502, Loss: 0.1118, Accuracy:0.961\nIteration: 15063, learning rate: 0.00502, Loss: 0.0732, Accuracy:0.977\nIteration: 15064, learning rate: 0.00502, Loss: 0.0779, Accuracy:0.977\nIteration: 15065, learning rate: 0.00502, Loss: 0.0960, Accuracy:0.977\nIteration: 15066, learning rate: 0.00502, Loss: 0.1725, Accuracy:0.925\nEpoch: 486, Loss: 0.1278, Accuracy:0.952, Val Loss: 0.2965, Val Accuracy: 0.884\nIteration: 15067, learning rate: 0.00502, Loss: 0.1077, Accuracy:0.953\nIteration: 15068, learning rate: 0.00502, Loss: 0.0850, Accuracy:0.961\nIteration: 15069, learning rate: 0.00502, Loss: 0.2314, Accuracy:0.898\nIteration: 15070, learning rate: 0.00502, Loss: 0.1206, Accuracy:0.961\nIteration: 15071, learning rate: 0.00502, Loss: 0.0572, Accuracy:0.992\nIteration: 15072, learning rate: 0.00502, Loss: 0.1488, Accuracy:0.953\nIteration: 15073, learning rate: 0.00502, Loss: 0.1181, Accuracy:0.945\nIteration: 15074, learning rate: 0.00502, Loss: 0.1782, Accuracy:0.930\nIteration: 15075, learning rate: 0.00502, Loss: 0.1239, Accuracy:0.969\nIteration: 15076, learning rate: 0.00502, Loss: 0.1554, Accuracy:0.945\nIteration: 15077, learning rate: 0.00502, Loss: 0.1142, Accuracy:0.961\nIteration: 15078, learning rate: 0.00502, Loss: 0.1143, Accuracy:0.953\nIteration: 15079, learning rate: 0.00502, Loss: 0.1772, Accuracy:0.914\nIteration: 15080, learning rate: 0.00502, Loss: 0.1755, Accuracy:0.922\nIteration: 15081, learning rate: 0.00502, Loss: 0.1351, Accuracy:0.938\nIteration: 15082, learning rate: 0.00502, Loss: 0.0948, Accuracy:0.961\nIteration: 15083, learning rate: 0.00502, Loss: 0.1179, Accuracy:0.969\nIteration: 15084, learning rate: 0.00502, Loss: 0.0929, Accuracy:0.969\nIteration: 15085, learning rate: 0.00502, Loss: 0.0958, Accuracy:0.953\nIteration: 15086, learning rate: 0.00502, Loss: 0.2259, Accuracy:0.906\nIteration: 15087, learning rate: 0.00502, Loss: 0.1860, Accuracy:0.930\nIteration: 15088, learning rate: 0.00502, Loss: 0.1224, Accuracy:0.945\nIteration: 15089, learning rate: 0.00502, Loss: 0.1075, Accuracy:0.953\nIteration: 15090, learning rate: 0.00502, Loss: 0.1495, Accuracy:0.945\nIteration: 15091, learning rate: 0.00502, Loss: 0.0976, Accuracy:0.969\nIteration: 15092, learning rate: 0.00502, Loss: 0.0990, Accuracy:0.961\nIteration: 15093, learning rate: 0.00502, Loss: 0.1021, Accuracy:0.969\nIteration: 15094, learning rate: 0.00502, Loss: 0.2266, Accuracy:0.938\nIteration: 15095, learning rate: 0.00502, Loss: 0.1055, Accuracy:0.961\nIteration: 15096, learning rate: 0.00502, Loss: 0.0990, Accuracy:0.969\nIteration: 15097, learning rate: 0.00502, Loss: 0.0756, Accuracy:0.968\nEpoch: 487, Loss: 0.1303, Accuracy:0.950, Val Loss: 0.3243, Val Accuracy: 0.886\nIteration: 15098, learning rate: 0.00502, Loss: 0.1357, Accuracy:0.953\nIteration: 15099, learning rate: 0.00501, Loss: 0.1065, Accuracy:0.969\nIteration: 15100, learning rate: 0.00501, Loss: 0.1242, Accuracy:0.945\nIteration: 15101, learning rate: 0.00501, Loss: 0.1501, Accuracy:0.930\nIteration: 15102, learning rate: 0.00501, Loss: 0.1433, Accuracy:0.938\nIteration: 15103, learning rate: 0.00501, Loss: 0.2287, Accuracy:0.914\nIteration: 15104, learning rate: 0.00501, Loss: 0.1591, Accuracy:0.922\nIteration: 15105, learning rate: 0.00501, Loss: 0.1039, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 15106, learning rate: 0.00501, Loss: 0.1255, Accuracy:0.953\nIteration: 15107, learning rate: 0.00501, Loss: 0.1398, Accuracy:0.938\nIteration: 15108, learning rate: 0.00501, Loss: 0.1808, Accuracy:0.945\nIteration: 15109, learning rate: 0.00501, Loss: 0.2719, Accuracy:0.891\nIteration: 15110, learning rate: 0.00501, Loss: 0.1817, Accuracy:0.922\nIteration: 15111, learning rate: 0.00501, Loss: 0.2184, Accuracy:0.922\nIteration: 15112, learning rate: 0.00501, Loss: 0.0868, Accuracy:0.977\nIteration: 15113, learning rate: 0.00501, Loss: 0.1176, Accuracy:0.938\nIteration: 15114, learning rate: 0.00501, Loss: 0.0914, Accuracy:0.977\nIteration: 15115, learning rate: 0.00501, Loss: 0.1493, Accuracy:0.961\nIteration: 15116, learning rate: 0.00501, Loss: 0.1580, Accuracy:0.922\nIteration: 15117, learning rate: 0.00501, Loss: 0.1518, Accuracy:0.953\nIteration: 15118, learning rate: 0.00501, Loss: 0.1636, Accuracy:0.945\nIteration: 15119, learning rate: 0.00501, Loss: 0.1135, Accuracy:0.945\nIteration: 15120, learning rate: 0.00501, Loss: 0.1670, Accuracy:0.938\nIteration: 15121, learning rate: 0.00501, Loss: 0.1303, Accuracy:0.953\nIteration: 15122, learning rate: 0.00501, Loss: 0.1214, Accuracy:0.938\nIteration: 15123, learning rate: 0.00501, Loss: 0.1471, Accuracy:0.938\nIteration: 15124, learning rate: 0.00501, Loss: 0.1062, Accuracy:0.961\nIteration: 15125, learning rate: 0.00501, Loss: 0.1229, Accuracy:0.945\nIteration: 15126, learning rate: 0.00501, Loss: 0.1145, Accuracy:0.945\nIteration: 15127, learning rate: 0.00501, Loss: 0.1973, Accuracy:0.914\nIteration: 15128, learning rate: 0.00501, Loss: 0.1157, Accuracy:0.957\nEpoch: 488, Loss: 0.1459, Accuracy:0.942, Val Loss: 0.3050, Val Accuracy: 0.891\nIteration: 15129, learning rate: 0.00501, Loss: 0.1616, Accuracy:0.945\nIteration: 15130, learning rate: 0.00501, Loss: 0.1535, Accuracy:0.930\nIteration: 15131, learning rate: 0.00501, Loss: 0.1135, Accuracy:0.969\nIteration: 15132, learning rate: 0.00501, Loss: 0.1440, Accuracy:0.922\nIteration: 15133, learning rate: 0.00501, Loss: 0.2064, Accuracy:0.922\nIteration: 15134, learning rate: 0.00501, Loss: 0.1719, Accuracy:0.914\nIteration: 15135, learning rate: 0.00501, Loss: 0.1680, Accuracy:0.945\nIteration: 15136, learning rate: 0.00501, Loss: 0.0896, Accuracy:0.977\nIteration: 15137, learning rate: 0.00501, Loss: 0.1332, Accuracy:0.938\nIteration: 15138, learning rate: 0.00501, Loss: 0.0922, Accuracy:0.977\nIteration: 15139, learning rate: 0.00501, Loss: 0.1390, Accuracy:0.953\nIteration: 15140, learning rate: 0.00501, Loss: 0.1247, Accuracy:0.938\nIteration: 15141, learning rate: 0.00501, Loss: 0.2128, Accuracy:0.938\nIteration: 15142, learning rate: 0.00501, Loss: 0.1006, Accuracy:0.945\nIteration: 15143, learning rate: 0.00501, Loss: 0.1025, Accuracy:0.953\nIteration: 15144, learning rate: 0.00501, Loss: 0.1417, Accuracy:0.953\nIteration: 15145, learning rate: 0.00501, Loss: 0.1833, Accuracy:0.930\nIteration: 15146, learning rate: 0.00501, Loss: 0.0921, Accuracy:0.961\nIteration: 15147, learning rate: 0.00501, Loss: 0.1317, Accuracy:0.953\nIteration: 15148, learning rate: 0.00501, Loss: 0.1465, Accuracy:0.930\nIteration: 15149, learning rate: 0.00501, Loss: 0.1566, Accuracy:0.938\nIteration: 15150, learning rate: 0.00501, Loss: 0.1234, Accuracy:0.953\nIteration: 15151, learning rate: 0.00501, Loss: 0.1657, Accuracy:0.938\nIteration: 15152, learning rate: 0.00501, Loss: 0.1289, Accuracy:0.961\nIteration: 15153, learning rate: 0.00501, Loss: 0.0920, Accuracy:0.961\nIteration: 15154, learning rate: 0.00501, Loss: 0.1741, Accuracy:0.922\nIteration: 15155, learning rate: 0.00501, Loss: 0.2104, Accuracy:0.922\nIteration: 15156, learning rate: 0.00501, Loss: 0.1381, Accuracy:0.953\nIteration: 15157, learning rate: 0.00501, Loss: 0.1162, Accuracy:0.953\nIteration: 15158, learning rate: 0.00501, Loss: 0.1035, Accuracy:0.953\nIteration: 15159, learning rate: 0.00501, Loss: 0.1859, Accuracy:0.914\nEpoch: 489, Loss: 0.1420, Accuracy:0.944, Val Loss: 0.2722, Val Accuracy: 0.892\nIteration: 15160, learning rate: 0.00501, Loss: 0.1160, Accuracy:0.953\nIteration: 15161, learning rate: 0.00501, Loss: 0.1247, Accuracy:0.961\nIteration: 15162, learning rate: 0.00501, Loss: 0.2349, Accuracy:0.914\nIteration: 15163, learning rate: 0.00501, Loss: 0.1796, Accuracy:0.930\nIteration: 15164, learning rate: 0.00501, Loss: 0.2309, Accuracy:0.891\nIteration: 15165, learning rate: 0.00501, Loss: 0.1397, Accuracy:0.938\nIteration: 15166, learning rate: 0.00500, Loss: 0.0995, Accuracy:0.961\nIteration: 15167, learning rate: 0.00500, Loss: 0.1389, Accuracy:0.953\nIteration: 15168, learning rate: 0.00500, Loss: 0.1502, Accuracy:0.938\nIteration: 15169, learning rate: 0.00500, Loss: 0.1249, Accuracy:0.961\nIteration: 15170, learning rate: 0.00500, Loss: 0.1827, Accuracy:0.930\nIteration: 15171, learning rate: 0.00500, Loss: 0.1356, Accuracy:0.945\nIteration: 15172, learning rate: 0.00500, Loss: 0.1300, Accuracy:0.945\nIteration: 15173, learning rate: 0.00500, Loss: 0.1403, Accuracy:0.945\nIteration: 15174, learning rate: 0.00500, Loss: 0.1324, Accuracy:0.945\nIteration: 15175, learning rate: 0.00500, Loss: 0.1549, Accuracy:0.938\nIteration: 15176, learning rate: 0.00500, Loss: 0.0902, Accuracy:0.953\nIteration: 15177, learning rate: 0.00500, Loss: 0.1183, Accuracy:0.953\nIteration: 15178, learning rate: 0.00500, Loss: 0.1266, Accuracy:0.945\nIteration: 15179, learning rate: 0.00500, Loss: 0.1403, Accuracy:0.953\nIteration: 15180, learning rate: 0.00500, Loss: 0.1548, Accuracy:0.945\nIteration: 15181, learning rate: 0.00500, Loss: 0.2690, Accuracy:0.883\nIteration: 15182, learning rate: 0.00500, Loss: 0.1419, Accuracy:0.961\nIteration: 15183, learning rate: 0.00500, Loss: 0.0923, Accuracy:0.969\nIteration: 15184, learning rate: 0.00500, Loss: 0.2326, Accuracy:0.914\nIteration: 15185, learning rate: 0.00500, Loss: 0.1698, Accuracy:0.930\nIteration: 15186, learning rate: 0.00500, Loss: 0.1584, Accuracy:0.953\nIteration: 15187, learning rate: 0.00500, Loss: 0.1741, Accuracy:0.930\nIteration: 15188, learning rate: 0.00500, Loss: 0.1172, Accuracy:0.969\nIteration: 15189, learning rate: 0.00500, Loss: 0.0953, Accuracy:0.977\nIteration: 15190, learning rate: 0.00500, Loss: 0.0992, Accuracy:0.978\nEpoch: 490, Loss: 0.1482, Accuracy:0.944, Val Loss: 0.2790, Val Accuracy: 0.891\nIteration: 15191, learning rate: 0.00500, Loss: 0.1546, Accuracy:0.945\nIteration: 15192, learning rate: 0.00500, Loss: 0.1196, Accuracy:0.945\nIteration: 15193, learning rate: 0.00500, Loss: 0.1338, Accuracy:0.969\nIteration: 15194, learning rate: 0.00500, Loss: 0.0901, Accuracy:0.977\nIteration: 15195, learning rate: 0.00500, Loss: 0.1099, Accuracy:0.953\nIteration: 15196, learning rate: 0.00500, Loss: 0.0970, Accuracy:0.969\nIteration: 15197, learning rate: 0.00500, Loss: 0.0665, Accuracy:0.961\nIteration: 15198, learning rate: 0.00500, Loss: 0.1280, Accuracy:0.945\nIteration: 15199, learning rate: 0.00500, Loss: 0.1443, Accuracy:0.953\nIteration: 15200, learning rate: 0.00500, Loss: 0.1205, Accuracy:0.938\nIteration: 15201, learning rate: 0.00500, Loss: 0.1229, Accuracy:0.953\nIteration: 15202, learning rate: 0.00500, Loss: 0.1967, Accuracy:0.938\nIteration: 15203, learning rate: 0.00500, Loss: 0.2213, Accuracy:0.922\nIteration: 15204, learning rate: 0.00500, Loss: 0.2033, Accuracy:0.930\nIteration: 15205, learning rate: 0.00500, Loss: 0.0713, Accuracy:0.992\nIteration: 15206, learning rate: 0.00500, Loss: 0.1344, Accuracy:0.953\nIteration: 15207, learning rate: 0.00500, Loss: 0.1629, Accuracy:0.938\nIteration: 15208, learning rate: 0.00500, Loss: 0.1008, Accuracy:0.945\nIteration: 15209, learning rate: 0.00500, Loss: 0.1545, Accuracy:0.922\nIteration: 15210, learning rate: 0.00500, Loss: 0.0910, Accuracy:0.984\nIteration: 15211, learning rate: 0.00500, Loss: 0.1856, Accuracy:0.930\nIteration: 15212, learning rate: 0.00500, Loss: 0.0909, Accuracy:0.977\nIteration: 15213, learning rate: 0.00500, Loss: 0.1143, Accuracy:0.969\nIteration: 15214, learning rate: 0.00500, Loss: 0.1698, Accuracy:0.945\nIteration: 15215, learning rate: 0.00500, Loss: 0.1411, Accuracy:0.938\nIteration: 15216, learning rate: 0.00500, Loss: 0.1792, Accuracy:0.945\nIteration: 15217, learning rate: 0.00500, Loss: 0.1459, Accuracy:0.938\nIteration: 15218, learning rate: 0.00500, Loss: 0.1467, Accuracy:0.922\nIteration: 15219, learning rate: 0.00500, Loss: 0.0750, Accuracy:0.969\nIteration: 15220, learning rate: 0.00500, Loss: 0.1139, Accuracy:0.945\nIteration: 15221, learning rate: 0.00500, Loss: 0.1075, Accuracy:0.968\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 491, Loss: 0.1320, Accuracy:0.951, Val Loss: 0.2718, Val Accuracy: 0.898\nIteration: 15222, learning rate: 0.00500, Loss: 0.1020, Accuracy:0.961\nIteration: 15223, learning rate: 0.00500, Loss: 0.1246, Accuracy:0.945\nIteration: 15224, learning rate: 0.00500, Loss: 0.1391, Accuracy:0.945\nIteration: 15225, learning rate: 0.00500, Loss: 0.1414, Accuracy:0.930\nIteration: 15226, learning rate: 0.00500, Loss: 0.1075, Accuracy:0.969\nIteration: 15227, learning rate: 0.00500, Loss: 0.1555, Accuracy:0.953\nIteration: 15228, learning rate: 0.00500, Loss: 0.1460, Accuracy:0.945\nIteration: 15229, learning rate: 0.00500, Loss: 0.0929, Accuracy:0.961\nIteration: 15230, learning rate: 0.00500, Loss: 0.1325, Accuracy:0.961\nIteration: 15231, learning rate: 0.00500, Loss: 0.0958, Accuracy:0.961\nIteration: 15232, learning rate: 0.00500, Loss: 0.0977, Accuracy:0.969\nIteration: 15233, learning rate: 0.00500, Loss: 0.1139, Accuracy:0.953\nIteration: 15234, learning rate: 0.00499, Loss: 0.0859, Accuracy:0.969\nIteration: 15235, learning rate: 0.00499, Loss: 0.0958, Accuracy:0.969\nIteration: 15236, learning rate: 0.00499, Loss: 0.1328, Accuracy:0.938\nIteration: 15237, learning rate: 0.00499, Loss: 0.1780, Accuracy:0.922\nIteration: 15238, learning rate: 0.00499, Loss: 0.1399, Accuracy:0.969\nIteration: 15239, learning rate: 0.00499, Loss: 0.1949, Accuracy:0.891\nIteration: 15240, learning rate: 0.00499, Loss: 0.1605, Accuracy:0.953\nIteration: 15241, learning rate: 0.00499, Loss: 0.1060, Accuracy:0.961\nIteration: 15242, learning rate: 0.00499, Loss: 0.1082, Accuracy:0.977\nIteration: 15243, learning rate: 0.00499, Loss: 0.1339, Accuracy:0.953\nIteration: 15244, learning rate: 0.00499, Loss: 0.1123, Accuracy:0.945\nIteration: 15245, learning rate: 0.00499, Loss: 0.1442, Accuracy:0.938\nIteration: 15246, learning rate: 0.00499, Loss: 0.0542, Accuracy:0.992\nIteration: 15247, learning rate: 0.00499, Loss: 0.1694, Accuracy:0.922\nIteration: 15248, learning rate: 0.00499, Loss: 0.1570, Accuracy:0.945\nIteration: 15249, learning rate: 0.00499, Loss: 0.1258, Accuracy:0.953\nIteration: 15250, learning rate: 0.00499, Loss: 0.1464, Accuracy:0.922\nIteration: 15251, learning rate: 0.00499, Loss: 0.1090, Accuracy:0.961\nIteration: 15252, learning rate: 0.00499, Loss: 0.1441, Accuracy:0.925\nEpoch: 492, Loss: 0.1273, Accuracy:0.950, Val Loss: 0.2448, Val Accuracy: 0.900\nIteration: 15253, learning rate: 0.00499, Loss: 0.1040, Accuracy:0.945\nIteration: 15254, learning rate: 0.00499, Loss: 0.1694, Accuracy:0.953\nIteration: 15255, learning rate: 0.00499, Loss: 0.1374, Accuracy:0.961\nIteration: 15256, learning rate: 0.00499, Loss: 0.1231, Accuracy:0.938\nIteration: 15257, learning rate: 0.00499, Loss: 0.1680, Accuracy:0.938\nIteration: 15258, learning rate: 0.00499, Loss: 0.1065, Accuracy:0.961\nIteration: 15259, learning rate: 0.00499, Loss: 0.1427, Accuracy:0.953\nIteration: 15260, learning rate: 0.00499, Loss: 0.1153, Accuracy:0.945\nIteration: 15261, learning rate: 0.00499, Loss: 0.0759, Accuracy:0.977\nIteration: 15262, learning rate: 0.00499, Loss: 0.2079, Accuracy:0.953\nIteration: 15263, learning rate: 0.00499, Loss: 0.1883, Accuracy:0.938\nIteration: 15264, learning rate: 0.00499, Loss: 0.1901, Accuracy:0.930\nIteration: 15265, learning rate: 0.00499, Loss: 0.0467, Accuracy:0.992\nIteration: 15266, learning rate: 0.00499, Loss: 0.2047, Accuracy:0.922\nIteration: 15267, learning rate: 0.00499, Loss: 0.1283, Accuracy:0.977\nIteration: 15268, learning rate: 0.00499, Loss: 0.1949, Accuracy:0.914\nIteration: 15269, learning rate: 0.00499, Loss: 0.1521, Accuracy:0.930\nIteration: 15270, learning rate: 0.00499, Loss: 0.1237, Accuracy:0.961\nIteration: 15271, learning rate: 0.00499, Loss: 0.0812, Accuracy:0.984\nIteration: 15272, learning rate: 0.00499, Loss: 0.1011, Accuracy:0.961\nIteration: 15273, learning rate: 0.00499, Loss: 0.1756, Accuracy:0.922\nIteration: 15274, learning rate: 0.00499, Loss: 0.1744, Accuracy:0.938\nIteration: 15275, learning rate: 0.00499, Loss: 0.0679, Accuracy:0.984\nIteration: 15276, learning rate: 0.00499, Loss: 0.1769, Accuracy:0.945\nIteration: 15277, learning rate: 0.00499, Loss: 0.1380, Accuracy:0.953\nIteration: 15278, learning rate: 0.00499, Loss: 0.1141, Accuracy:0.953\nIteration: 15279, learning rate: 0.00499, Loss: 0.1462, Accuracy:0.930\nIteration: 15280, learning rate: 0.00499, Loss: 0.1787, Accuracy:0.930\nIteration: 15281, learning rate: 0.00499, Loss: 0.0999, Accuracy:0.977\nIteration: 15282, learning rate: 0.00499, Loss: 0.1216, Accuracy:0.969\nIteration: 15283, learning rate: 0.00499, Loss: 0.1136, Accuracy:0.957\nEpoch: 493, Loss: 0.1377, Accuracy:0.951, Val Loss: 0.2830, Val Accuracy: 0.895\nIteration: 15284, learning rate: 0.00499, Loss: 0.1308, Accuracy:0.938\nIteration: 15285, learning rate: 0.00499, Loss: 0.1651, Accuracy:0.922\nIteration: 15286, learning rate: 0.00499, Loss: 0.0788, Accuracy:0.969\nIteration: 15287, learning rate: 0.00499, Loss: 0.1470, Accuracy:0.945\nIteration: 15288, learning rate: 0.00499, Loss: 0.0743, Accuracy:0.977\nIteration: 15289, learning rate: 0.00499, Loss: 0.1773, Accuracy:0.922\nIteration: 15290, learning rate: 0.00499, Loss: 0.1190, Accuracy:0.969\nIteration: 15291, learning rate: 0.00499, Loss: 0.1832, Accuracy:0.930\nIteration: 15292, learning rate: 0.00499, Loss: 0.1452, Accuracy:0.953\nIteration: 15293, learning rate: 0.00499, Loss: 0.2148, Accuracy:0.922\nIteration: 15294, learning rate: 0.00499, Loss: 0.1853, Accuracy:0.930\nIteration: 15295, learning rate: 0.00499, Loss: 0.1237, Accuracy:0.953\nIteration: 15296, learning rate: 0.00499, Loss: 0.1133, Accuracy:0.961\nIteration: 15297, learning rate: 0.00499, Loss: 0.0819, Accuracy:0.984\nIteration: 15298, learning rate: 0.00499, Loss: 0.1419, Accuracy:0.938\nIteration: 15299, learning rate: 0.00499, Loss: 0.1457, Accuracy:0.945\nIteration: 15300, learning rate: 0.00499, Loss: 0.1280, Accuracy:0.945\nIteration: 15301, learning rate: 0.00498, Loss: 0.1113, Accuracy:0.938\nIteration: 15302, learning rate: 0.00498, Loss: 0.1420, Accuracy:0.945\nIteration: 15303, learning rate: 0.00498, Loss: 0.1647, Accuracy:0.953\nIteration: 15304, learning rate: 0.00498, Loss: 0.0799, Accuracy:0.977\nIteration: 15305, learning rate: 0.00498, Loss: 0.1384, Accuracy:0.953\nIteration: 15306, learning rate: 0.00498, Loss: 0.0703, Accuracy:0.977\nIteration: 15307, learning rate: 0.00498, Loss: 0.1697, Accuracy:0.945\nIteration: 15308, learning rate: 0.00498, Loss: 0.1081, Accuracy:0.961\nIteration: 15309, learning rate: 0.00498, Loss: 0.1246, Accuracy:0.961\nIteration: 15310, learning rate: 0.00498, Loss: 0.1338, Accuracy:0.945\nIteration: 15311, learning rate: 0.00498, Loss: 0.1189, Accuracy:0.953\nIteration: 15312, learning rate: 0.00498, Loss: 0.1847, Accuracy:0.914\nIteration: 15313, learning rate: 0.00498, Loss: 0.0936, Accuracy:0.953\nIteration: 15314, learning rate: 0.00498, Loss: 0.0845, Accuracy:0.946\nEpoch: 494, Loss: 0.1316, Accuracy:0.949, Val Loss: 0.3004, Val Accuracy: 0.885\nIteration: 15315, learning rate: 0.00498, Loss: 0.1456, Accuracy:0.938\nIteration: 15316, learning rate: 0.00498, Loss: 0.0707, Accuracy:0.984\nIteration: 15317, learning rate: 0.00498, Loss: 0.1126, Accuracy:0.969\nIteration: 15318, learning rate: 0.00498, Loss: 0.1144, Accuracy:0.953\nIteration: 15319, learning rate: 0.00498, Loss: 0.1328, Accuracy:0.930\nIteration: 15320, learning rate: 0.00498, Loss: 0.1945, Accuracy:0.953\nIteration: 15321, learning rate: 0.00498, Loss: 0.1706, Accuracy:0.938\nIteration: 15322, learning rate: 0.00498, Loss: 0.1564, Accuracy:0.930\nIteration: 15323, learning rate: 0.00498, Loss: 0.2149, Accuracy:0.922\nIteration: 15324, learning rate: 0.00498, Loss: 0.0776, Accuracy:0.977\nIteration: 15325, learning rate: 0.00498, Loss: 0.1253, Accuracy:0.953\nIteration: 15326, learning rate: 0.00498, Loss: 0.0729, Accuracy:0.992\nIteration: 15327, learning rate: 0.00498, Loss: 0.1790, Accuracy:0.938\nIteration: 15328, learning rate: 0.00498, Loss: 0.1229, Accuracy:0.953\nIteration: 15329, learning rate: 0.00498, Loss: 0.1166, Accuracy:0.953\nIteration: 15330, learning rate: 0.00498, Loss: 0.1354, Accuracy:0.945\nIteration: 15331, learning rate: 0.00498, Loss: 0.1423, Accuracy:0.961\nIteration: 15332, learning rate: 0.00498, Loss: 0.1293, Accuracy:0.961\nIteration: 15333, learning rate: 0.00498, Loss: 0.1183, Accuracy:0.953\nIteration: 15334, learning rate: 0.00498, Loss: 0.1200, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 15335, learning rate: 0.00498, Loss: 0.1301, Accuracy:0.938\nIteration: 15336, learning rate: 0.00498, Loss: 0.1187, Accuracy:0.953\nIteration: 15337, learning rate: 0.00498, Loss: 0.0864, Accuracy:0.969\nIteration: 15338, learning rate: 0.00498, Loss: 0.2186, Accuracy:0.922\nIteration: 15339, learning rate: 0.00498, Loss: 0.1239, Accuracy:0.969\nIteration: 15340, learning rate: 0.00498, Loss: 0.1697, Accuracy:0.945\nIteration: 15341, learning rate: 0.00498, Loss: 0.0631, Accuracy:0.977\nIteration: 15342, learning rate: 0.00498, Loss: 0.0974, Accuracy:0.977\nIteration: 15343, learning rate: 0.00498, Loss: 0.0809, Accuracy:0.969\nIteration: 15344, learning rate: 0.00498, Loss: 0.1266, Accuracy:0.953\nIteration: 15345, learning rate: 0.00498, Loss: 0.2507, Accuracy:0.925\nEpoch: 495, Loss: 0.1328, Accuracy:0.953, Val Loss: 0.3853, Val Accuracy: 0.878\nIteration: 15346, learning rate: 0.00498, Loss: 0.1671, Accuracy:0.938\nIteration: 15347, learning rate: 0.00498, Loss: 0.1200, Accuracy:0.953\nIteration: 15348, learning rate: 0.00498, Loss: 0.3001, Accuracy:0.922\nIteration: 15349, learning rate: 0.00498, Loss: 0.1432, Accuracy:0.953\nIteration: 15350, learning rate: 0.00498, Loss: 0.1661, Accuracy:0.945\nIteration: 15351, learning rate: 0.00498, Loss: 0.2180, Accuracy:0.898\nIteration: 15352, learning rate: 0.00498, Loss: 0.1788, Accuracy:0.914\nIteration: 15353, learning rate: 0.00498, Loss: 0.1605, Accuracy:0.945\nIteration: 15354, learning rate: 0.00498, Loss: 0.1412, Accuracy:0.938\nIteration: 15355, learning rate: 0.00498, Loss: 0.1373, Accuracy:0.953\nIteration: 15356, learning rate: 0.00498, Loss: 0.1512, Accuracy:0.938\nIteration: 15357, learning rate: 0.00498, Loss: 0.0814, Accuracy:0.977\nIteration: 15358, learning rate: 0.00498, Loss: 0.1298, Accuracy:0.961\nIteration: 15359, learning rate: 0.00498, Loss: 0.1255, Accuracy:0.961\nIteration: 15360, learning rate: 0.00498, Loss: 0.1905, Accuracy:0.930\nIteration: 15361, learning rate: 0.00498, Loss: 0.1104, Accuracy:0.930\nIteration: 15362, learning rate: 0.00498, Loss: 0.1537, Accuracy:0.945\nIteration: 15363, learning rate: 0.00498, Loss: 0.1200, Accuracy:0.938\nIteration: 15364, learning rate: 0.00498, Loss: 0.0645, Accuracy:0.977\nIteration: 15365, learning rate: 0.00498, Loss: 0.1609, Accuracy:0.945\nIteration: 15366, learning rate: 0.00498, Loss: 0.0997, Accuracy:0.984\nIteration: 15367, learning rate: 0.00498, Loss: 0.1160, Accuracy:0.961\nIteration: 15368, learning rate: 0.00498, Loss: 0.1944, Accuracy:0.922\nIteration: 15369, learning rate: 0.00497, Loss: 0.1605, Accuracy:0.922\nIteration: 15370, learning rate: 0.00497, Loss: 0.2254, Accuracy:0.914\nIteration: 15371, learning rate: 0.00497, Loss: 0.0916, Accuracy:0.984\nIteration: 15372, learning rate: 0.00497, Loss: 0.1083, Accuracy:0.961\nIteration: 15373, learning rate: 0.00497, Loss: 0.1335, Accuracy:0.961\nIteration: 15374, learning rate: 0.00497, Loss: 0.1010, Accuracy:0.953\nIteration: 15375, learning rate: 0.00497, Loss: 0.1436, Accuracy:0.945\nIteration: 15376, learning rate: 0.00497, Loss: 0.2176, Accuracy:0.903\nEpoch: 496, Loss: 0.1488, Accuracy:0.944, Val Loss: 0.2983, Val Accuracy: 0.880\nIteration: 15377, learning rate: 0.00497, Loss: 0.1048, Accuracy:0.961\nIteration: 15378, learning rate: 0.00497, Loss: 0.1762, Accuracy:0.945\nIteration: 15379, learning rate: 0.00497, Loss: 0.1917, Accuracy:0.930\nIteration: 15380, learning rate: 0.00497, Loss: 0.1574, Accuracy:0.938\nIteration: 15381, learning rate: 0.00497, Loss: 0.1514, Accuracy:0.945\nIteration: 15382, learning rate: 0.00497, Loss: 0.1844, Accuracy:0.930\nIteration: 15383, learning rate: 0.00497, Loss: 0.0962, Accuracy:0.977\nIteration: 15384, learning rate: 0.00497, Loss: 0.1203, Accuracy:0.961\nIteration: 15385, learning rate: 0.00497, Loss: 0.1162, Accuracy:0.953\nIteration: 15386, learning rate: 0.00497, Loss: 0.0780, Accuracy:0.977\nIteration: 15387, learning rate: 0.00497, Loss: 0.1529, Accuracy:0.938\nIteration: 15388, learning rate: 0.00497, Loss: 0.1119, Accuracy:0.953\nIteration: 15389, learning rate: 0.00497, Loss: 0.2011, Accuracy:0.914\nIteration: 15390, learning rate: 0.00497, Loss: 0.1352, Accuracy:0.945\nIteration: 15391, learning rate: 0.00497, Loss: 0.1209, Accuracy:0.961\nIteration: 15392, learning rate: 0.00497, Loss: 0.0751, Accuracy:0.961\nIteration: 15393, learning rate: 0.00497, Loss: 0.1019, Accuracy:0.961\nIteration: 15394, learning rate: 0.00497, Loss: 0.1592, Accuracy:0.938\nIteration: 15395, learning rate: 0.00497, Loss: 0.1598, Accuracy:0.945\nIteration: 15396, learning rate: 0.00497, Loss: 0.1458, Accuracy:0.945\nIteration: 15397, learning rate: 0.00497, Loss: 0.0640, Accuracy:0.992\nIteration: 15398, learning rate: 0.00497, Loss: 0.1421, Accuracy:0.945\nIteration: 15399, learning rate: 0.00497, Loss: 0.0608, Accuracy:0.984\nIteration: 15400, learning rate: 0.00497, Loss: 0.1607, Accuracy:0.945\nIteration: 15401, learning rate: 0.00497, Loss: 0.1351, Accuracy:0.938\nIteration: 15402, learning rate: 0.00497, Loss: 0.1396, Accuracy:0.961\nIteration: 15403, learning rate: 0.00497, Loss: 0.0970, Accuracy:0.961\nIteration: 15404, learning rate: 0.00497, Loss: 0.1211, Accuracy:0.961\nIteration: 15405, learning rate: 0.00497, Loss: 0.1071, Accuracy:0.961\nIteration: 15406, learning rate: 0.00497, Loss: 0.1935, Accuracy:0.930\nIteration: 15407, learning rate: 0.00497, Loss: 0.1767, Accuracy:0.946\nEpoch: 497, Loss: 0.1335, Accuracy:0.952, Val Loss: 0.3184, Val Accuracy: 0.871\nIteration: 15408, learning rate: 0.00497, Loss: 0.1070, Accuracy:0.977\nIteration: 15409, learning rate: 0.00497, Loss: 0.1370, Accuracy:0.953\nIteration: 15410, learning rate: 0.00497, Loss: 0.1509, Accuracy:0.930\nIteration: 15411, learning rate: 0.00497, Loss: 0.1589, Accuracy:0.906\nIteration: 15412, learning rate: 0.00497, Loss: 0.1795, Accuracy:0.953\nIteration: 15413, learning rate: 0.00497, Loss: 0.1377, Accuracy:0.953\nIteration: 15414, learning rate: 0.00497, Loss: 0.1168, Accuracy:0.977\nIteration: 15415, learning rate: 0.00497, Loss: 0.1373, Accuracy:0.945\nIteration: 15416, learning rate: 0.00497, Loss: 0.1569, Accuracy:0.953\nIteration: 15417, learning rate: 0.00497, Loss: 0.2372, Accuracy:0.930\nIteration: 15418, learning rate: 0.00497, Loss: 0.1438, Accuracy:0.953\nIteration: 15419, learning rate: 0.00497, Loss: 0.1216, Accuracy:0.945\nIteration: 15420, learning rate: 0.00497, Loss: 0.1980, Accuracy:0.898\nIteration: 15421, learning rate: 0.00497, Loss: 0.1986, Accuracy:0.922\nIteration: 15422, learning rate: 0.00497, Loss: 0.1350, Accuracy:0.961\nIteration: 15423, learning rate: 0.00497, Loss: 0.1190, Accuracy:0.945\nIteration: 15424, learning rate: 0.00497, Loss: 0.0807, Accuracy:0.977\nIteration: 15425, learning rate: 0.00497, Loss: 0.1034, Accuracy:0.969\nIteration: 15426, learning rate: 0.00497, Loss: 0.1560, Accuracy:0.938\nIteration: 15427, learning rate: 0.00497, Loss: 0.1445, Accuracy:0.930\nIteration: 15428, learning rate: 0.00497, Loss: 0.1430, Accuracy:0.945\nIteration: 15429, learning rate: 0.00497, Loss: 0.2064, Accuracy:0.930\nIteration: 15430, learning rate: 0.00497, Loss: 0.2113, Accuracy:0.906\nIteration: 15431, learning rate: 0.00497, Loss: 0.1737, Accuracy:0.930\nIteration: 15432, learning rate: 0.00497, Loss: 0.1347, Accuracy:0.969\nIteration: 15433, learning rate: 0.00497, Loss: 0.2163, Accuracy:0.914\nIteration: 15434, learning rate: 0.00497, Loss: 0.1589, Accuracy:0.945\nIteration: 15435, learning rate: 0.00497, Loss: 0.1278, Accuracy:0.945\nIteration: 15436, learning rate: 0.00497, Loss: 0.1424, Accuracy:0.930\nIteration: 15437, learning rate: 0.00496, Loss: 0.1974, Accuracy:0.922\nIteration: 15438, learning rate: 0.00496, Loss: 0.0891, Accuracy:0.968\nEpoch: 498, Loss: 0.1523, Accuracy:0.943, Val Loss: 0.2577, Val Accuracy: 0.903\nIteration: 15439, learning rate: 0.00496, Loss: 0.1078, Accuracy:0.984\nIteration: 15440, learning rate: 0.00496, Loss: 0.0740, Accuracy:0.992\nIteration: 15441, learning rate: 0.00496, Loss: 0.1232, Accuracy:0.945\nIteration: 15442, learning rate: 0.00496, Loss: 0.1373, Accuracy:0.953\nIteration: 15443, learning rate: 0.00496, Loss: 0.1948, Accuracy:0.938\nIteration: 15444, learning rate: 0.00496, Loss: 0.0848, Accuracy:0.969\nIteration: 15445, learning rate: 0.00496, Loss: 0.0787, Accuracy:0.984\nIteration: 15446, learning rate: 0.00496, Loss: 0.1239, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 15447, learning rate: 0.00496, Loss: 0.0803, Accuracy:0.969\nIteration: 15448, learning rate: 0.00496, Loss: 0.1172, Accuracy:0.953\nIteration: 15449, learning rate: 0.00496, Loss: 0.1800, Accuracy:0.922\nIteration: 15450, learning rate: 0.00496, Loss: 0.1168, Accuracy:0.945\nIteration: 15451, learning rate: 0.00496, Loss: 0.1611, Accuracy:0.938\nIteration: 15452, learning rate: 0.00496, Loss: 0.1584, Accuracy:0.930\nIteration: 15453, learning rate: 0.00496, Loss: 0.1546, Accuracy:0.930\nIteration: 15454, learning rate: 0.00496, Loss: 0.1394, Accuracy:0.969\nIteration: 15455, learning rate: 0.00496, Loss: 0.0974, Accuracy:0.953\nIteration: 15456, learning rate: 0.00496, Loss: 0.1442, Accuracy:0.961\nIteration: 15457, learning rate: 0.00496, Loss: 0.1268, Accuracy:0.938\nIteration: 15458, learning rate: 0.00496, Loss: 0.1063, Accuracy:0.961\nIteration: 15459, learning rate: 0.00496, Loss: 0.1594, Accuracy:0.945\nIteration: 15460, learning rate: 0.00496, Loss: 0.1001, Accuracy:0.953\nIteration: 15461, learning rate: 0.00496, Loss: 0.1337, Accuracy:0.945\nIteration: 15462, learning rate: 0.00496, Loss: 0.0360, Accuracy:1.000\nIteration: 15463, learning rate: 0.00496, Loss: 0.1581, Accuracy:0.945\nIteration: 15464, learning rate: 0.00496, Loss: 0.0803, Accuracy:0.977\nIteration: 15465, learning rate: 0.00496, Loss: 0.2304, Accuracy:0.898\nIteration: 15466, learning rate: 0.00496, Loss: 0.1772, Accuracy:0.930\nIteration: 15467, learning rate: 0.00496, Loss: 0.2510, Accuracy:0.914\nIteration: 15468, learning rate: 0.00496, Loss: 0.1854, Accuracy:0.938\nIteration: 15469, learning rate: 0.00496, Loss: 0.1212, Accuracy:0.957\nEpoch: 499, Loss: 0.1335, Accuracy:0.952, Val Loss: 0.3536, Val Accuracy: 0.857\nIteration: 15470, learning rate: 0.00496, Loss: 0.1263, Accuracy:0.945\nIteration: 15471, learning rate: 0.00496, Loss: 0.0808, Accuracy:0.953\nIteration: 15472, learning rate: 0.00496, Loss: 0.0941, Accuracy:0.969\nIteration: 15473, learning rate: 0.00496, Loss: 0.0969, Accuracy:0.961\nIteration: 15474, learning rate: 0.00496, Loss: 0.1254, Accuracy:0.961\nIteration: 15475, learning rate: 0.00496, Loss: 0.2117, Accuracy:0.930\nIteration: 15476, learning rate: 0.00496, Loss: 0.1405, Accuracy:0.945\nIteration: 15477, learning rate: 0.00496, Loss: 0.0973, Accuracy:0.977\nIteration: 15478, learning rate: 0.00496, Loss: 0.1342, Accuracy:0.938\nIteration: 15479, learning rate: 0.00496, Loss: 0.1718, Accuracy:0.961\nIteration: 15480, learning rate: 0.00496, Loss: 0.1551, Accuracy:0.922\nIteration: 15481, learning rate: 0.00496, Loss: 0.2626, Accuracy:0.867\nIteration: 15482, learning rate: 0.00496, Loss: 0.1984, Accuracy:0.938\nIteration: 15483, learning rate: 0.00496, Loss: 0.1628, Accuracy:0.945\nIteration: 15484, learning rate: 0.00496, Loss: 0.0737, Accuracy:0.969\nIteration: 15485, learning rate: 0.00496, Loss: 0.1353, Accuracy:0.961\nIteration: 15486, learning rate: 0.00496, Loss: 0.2184, Accuracy:0.914\nIteration: 15487, learning rate: 0.00496, Loss: 0.1143, Accuracy:0.961\nIteration: 15488, learning rate: 0.00496, Loss: 0.1396, Accuracy:0.953\nIteration: 15489, learning rate: 0.00496, Loss: 0.1891, Accuracy:0.938\nIteration: 15490, learning rate: 0.00496, Loss: 0.0848, Accuracy:0.977\nIteration: 15491, learning rate: 0.00496, Loss: 0.1450, Accuracy:0.938\nIteration: 15492, learning rate: 0.00496, Loss: 0.2062, Accuracy:0.938\nIteration: 15493, learning rate: 0.00496, Loss: 0.1067, Accuracy:0.969\nIteration: 15494, learning rate: 0.00496, Loss: 0.1480, Accuracy:0.930\nIteration: 15495, learning rate: 0.00496, Loss: 0.1673, Accuracy:0.914\nIteration: 15496, learning rate: 0.00496, Loss: 0.1898, Accuracy:0.922\nIteration: 15497, learning rate: 0.00496, Loss: 0.1269, Accuracy:0.945\nIteration: 15498, learning rate: 0.00496, Loss: 0.2226, Accuracy:0.898\nIteration: 15499, learning rate: 0.00496, Loss: 0.0750, Accuracy:0.984\nIteration: 15500, learning rate: 0.00496, Loss: 0.1177, Accuracy:0.978\nEpoch: 500, Loss: 0.1458, Accuracy:0.945, Val Loss: 0.2896, Val Accuracy: 0.888\nIteration: 15501, learning rate: 0.00496, Loss: 0.1983, Accuracy:0.938\nIteration: 15502, learning rate: 0.00496, Loss: 0.1018, Accuracy:0.969\nIteration: 15503, learning rate: 0.00496, Loss: 0.1053, Accuracy:0.961\nIteration: 15504, learning rate: 0.00496, Loss: 0.1003, Accuracy:0.945\nIteration: 15505, learning rate: 0.00496, Loss: 0.1252, Accuracy:0.969\nIteration: 15506, learning rate: 0.00495, Loss: 0.1113, Accuracy:0.969\nIteration: 15507, learning rate: 0.00495, Loss: 0.1386, Accuracy:0.938\nIteration: 15508, learning rate: 0.00495, Loss: 0.1595, Accuracy:0.914\nIteration: 15509, learning rate: 0.00495, Loss: 0.0793, Accuracy:0.961\nIteration: 15510, learning rate: 0.00495, Loss: 0.1229, Accuracy:0.953\nIteration: 15511, learning rate: 0.00495, Loss: 0.1642, Accuracy:0.906\nIteration: 15512, learning rate: 0.00495, Loss: 0.1895, Accuracy:0.922\nIteration: 15513, learning rate: 0.00495, Loss: 0.1095, Accuracy:0.953\nIteration: 15514, learning rate: 0.00495, Loss: 0.0537, Accuracy:0.992\nIteration: 15515, learning rate: 0.00495, Loss: 0.1069, Accuracy:0.953\nIteration: 15516, learning rate: 0.00495, Loss: 0.1613, Accuracy:0.945\nIteration: 15517, learning rate: 0.00495, Loss: 0.1201, Accuracy:0.953\nIteration: 15518, learning rate: 0.00495, Loss: 0.0849, Accuracy:0.969\nIteration: 15519, learning rate: 0.00495, Loss: 0.0964, Accuracy:0.961\nIteration: 15520, learning rate: 0.00495, Loss: 0.1692, Accuracy:0.953\nIteration: 15521, learning rate: 0.00495, Loss: 0.1040, Accuracy:0.945\nIteration: 15522, learning rate: 0.00495, Loss: 0.1684, Accuracy:0.922\nIteration: 15523, learning rate: 0.00495, Loss: 0.1242, Accuracy:0.945\nIteration: 15524, learning rate: 0.00495, Loss: 0.1730, Accuracy:0.914\nIteration: 15525, learning rate: 0.00495, Loss: 0.0899, Accuracy:0.969\nIteration: 15526, learning rate: 0.00495, Loss: 0.0599, Accuracy:0.977\nIteration: 15527, learning rate: 0.00495, Loss: 0.1307, Accuracy:0.930\nIteration: 15528, learning rate: 0.00495, Loss: 0.1003, Accuracy:0.984\nIteration: 15529, learning rate: 0.00495, Loss: 0.1298, Accuracy:0.938\nIteration: 15530, learning rate: 0.00495, Loss: 0.1019, Accuracy:0.953\nIteration: 15531, learning rate: 0.00495, Loss: 0.1605, Accuracy:0.935\nEpoch: 501, Loss: 0.1239, Accuracy:0.950, Val Loss: 0.3377, Val Accuracy: 0.856\nIteration: 15532, learning rate: 0.00495, Loss: 0.1277, Accuracy:0.969\nIteration: 15533, learning rate: 0.00495, Loss: 0.1605, Accuracy:0.938\nIteration: 15534, learning rate: 0.00495, Loss: 0.0818, Accuracy:0.977\nIteration: 15535, learning rate: 0.00495, Loss: 0.1916, Accuracy:0.922\nIteration: 15536, learning rate: 0.00495, Loss: 0.0850, Accuracy:0.977\nIteration: 15537, learning rate: 0.00495, Loss: 0.2318, Accuracy:0.922\nIteration: 15538, learning rate: 0.00495, Loss: 0.1186, Accuracy:0.953\nIteration: 15539, learning rate: 0.00495, Loss: 0.1308, Accuracy:0.938\nIteration: 15540, learning rate: 0.00495, Loss: 0.1425, Accuracy:0.945\nIteration: 15541, learning rate: 0.00495, Loss: 0.1736, Accuracy:0.945\nIteration: 15542, learning rate: 0.00495, Loss: 0.1067, Accuracy:0.984\nIteration: 15543, learning rate: 0.00495, Loss: 0.1320, Accuracy:0.938\nIteration: 15544, learning rate: 0.00495, Loss: 0.1251, Accuracy:0.969\nIteration: 15545, learning rate: 0.00495, Loss: 0.1198, Accuracy:0.953\nIteration: 15546, learning rate: 0.00495, Loss: 0.1523, Accuracy:0.938\nIteration: 15547, learning rate: 0.00495, Loss: 0.1467, Accuracy:0.953\nIteration: 15548, learning rate: 0.00495, Loss: 0.2311, Accuracy:0.906\nIteration: 15549, learning rate: 0.00495, Loss: 0.1045, Accuracy:0.977\nIteration: 15550, learning rate: 0.00495, Loss: 0.0750, Accuracy:0.992\nIteration: 15551, learning rate: 0.00495, Loss: 0.1229, Accuracy:0.938\nIteration: 15552, learning rate: 0.00495, Loss: 0.1279, Accuracy:0.961\nIteration: 15553, learning rate: 0.00495, Loss: 0.1756, Accuracy:0.938\nIteration: 15554, learning rate: 0.00495, Loss: 0.0984, Accuracy:0.953\nIteration: 15555, learning rate: 0.00495, Loss: 0.2219, Accuracy:0.906\nIteration: 15556, learning rate: 0.00495, Loss: 0.1132, Accuracy:0.961\nIteration: 15557, learning rate: 0.00495, Loss: 0.1239, Accuracy:0.938\nIteration: 15558, learning rate: 0.00495, Loss: 0.1009, Accuracy:0.984\nIteration: 15559, learning rate: 0.00495, Loss: 0.1095, Accuracy:0.969\nIteration: 15560, learning rate: 0.00495, Loss: 0.1334, Accuracy:0.953\nIteration: 15561, learning rate: 0.00495, Loss: 0.1265, Accuracy:0.961\nIteration: 15562, learning rate: 0.00495, Loss: 0.2091, Accuracy:0.925\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 502, Loss: 0.1387, Accuracy:0.951, Val Loss: 0.2897, Val Accuracy: 0.878\nIteration: 15563, learning rate: 0.00495, Loss: 0.2351, Accuracy:0.922\nIteration: 15564, learning rate: 0.00495, Loss: 0.0882, Accuracy:0.961\nIteration: 15565, learning rate: 0.00495, Loss: 0.0784, Accuracy:0.969\nIteration: 15566, learning rate: 0.00495, Loss: 0.1132, Accuracy:0.953\nIteration: 15567, learning rate: 0.00495, Loss: 0.1034, Accuracy:0.953\nIteration: 15568, learning rate: 0.00495, Loss: 0.1353, Accuracy:0.945\nIteration: 15569, learning rate: 0.00495, Loss: 0.1397, Accuracy:0.938\nIteration: 15570, learning rate: 0.00495, Loss: 0.1038, Accuracy:0.953\nIteration: 15571, learning rate: 0.00495, Loss: 0.1184, Accuracy:0.953\nIteration: 15572, learning rate: 0.00495, Loss: 0.1265, Accuracy:0.953\nIteration: 15573, learning rate: 0.00495, Loss: 0.1254, Accuracy:0.938\nIteration: 15574, learning rate: 0.00494, Loss: 0.1349, Accuracy:0.945\nIteration: 15575, learning rate: 0.00494, Loss: 0.0466, Accuracy:0.992\nIteration: 15576, learning rate: 0.00494, Loss: 0.2228, Accuracy:0.922\nIteration: 15577, learning rate: 0.00494, Loss: 0.1734, Accuracy:0.945\nIteration: 15578, learning rate: 0.00494, Loss: 0.1001, Accuracy:0.977\nIteration: 15579, learning rate: 0.00494, Loss: 0.1320, Accuracy:0.953\nIteration: 15580, learning rate: 0.00494, Loss: 0.1212, Accuracy:0.953\nIteration: 15581, learning rate: 0.00494, Loss: 0.1741, Accuracy:0.914\nIteration: 15582, learning rate: 0.00494, Loss: 0.1128, Accuracy:0.961\nIteration: 15583, learning rate: 0.00494, Loss: 0.1695, Accuracy:0.938\nIteration: 15584, learning rate: 0.00494, Loss: 0.0949, Accuracy:0.961\nIteration: 15585, learning rate: 0.00494, Loss: 0.0987, Accuracy:0.961\nIteration: 15586, learning rate: 0.00494, Loss: 0.1781, Accuracy:0.945\nIteration: 15587, learning rate: 0.00494, Loss: 0.2203, Accuracy:0.914\nIteration: 15588, learning rate: 0.00494, Loss: 0.1805, Accuracy:0.938\nIteration: 15589, learning rate: 0.00494, Loss: 0.1416, Accuracy:0.945\nIteration: 15590, learning rate: 0.00494, Loss: 0.0600, Accuracy:0.984\nIteration: 15591, learning rate: 0.00494, Loss: 0.1325, Accuracy:0.945\nIteration: 15592, learning rate: 0.00494, Loss: 0.1119, Accuracy:0.961\nIteration: 15593, learning rate: 0.00494, Loss: 0.1524, Accuracy:0.935\nEpoch: 503, Loss: 0.1331, Accuracy:0.949, Val Loss: 0.3155, Val Accuracy: 0.863\nIteration: 15594, learning rate: 0.00494, Loss: 0.1521, Accuracy:0.945\nIteration: 15595, learning rate: 0.00494, Loss: 0.1406, Accuracy:0.953\nIteration: 15596, learning rate: 0.00494, Loss: 0.0842, Accuracy:0.977\nIteration: 15597, learning rate: 0.00494, Loss: 0.1088, Accuracy:0.969\nIteration: 15598, learning rate: 0.00494, Loss: 0.1525, Accuracy:0.953\nIteration: 15599, learning rate: 0.00494, Loss: 0.2020, Accuracy:0.938\nIteration: 15600, learning rate: 0.00494, Loss: 0.0853, Accuracy:0.961\nIteration: 15601, learning rate: 0.00494, Loss: 0.0933, Accuracy:0.969\nIteration: 15602, learning rate: 0.00494, Loss: 0.1807, Accuracy:0.922\nIteration: 15603, learning rate: 0.00494, Loss: 0.1261, Accuracy:0.945\nIteration: 15604, learning rate: 0.00494, Loss: 0.1379, Accuracy:0.930\nIteration: 15605, learning rate: 0.00494, Loss: 0.0978, Accuracy:0.969\nIteration: 15606, learning rate: 0.00494, Loss: 0.1708, Accuracy:0.914\nIteration: 15607, learning rate: 0.00494, Loss: 0.1418, Accuracy:0.953\nIteration: 15608, learning rate: 0.00494, Loss: 0.1559, Accuracy:0.945\nIteration: 15609, learning rate: 0.00494, Loss: 0.0898, Accuracy:0.977\nIteration: 15610, learning rate: 0.00494, Loss: 0.1635, Accuracy:0.945\nIteration: 15611, learning rate: 0.00494, Loss: 0.1224, Accuracy:0.969\nIteration: 15612, learning rate: 0.00494, Loss: 0.1266, Accuracy:0.953\nIteration: 15613, learning rate: 0.00494, Loss: 0.1440, Accuracy:0.953\nIteration: 15614, learning rate: 0.00494, Loss: 0.1079, Accuracy:0.961\nIteration: 15615, learning rate: 0.00494, Loss: 0.1589, Accuracy:0.953\nIteration: 15616, learning rate: 0.00494, Loss: 0.1469, Accuracy:0.945\nIteration: 15617, learning rate: 0.00494, Loss: 0.1240, Accuracy:0.977\nIteration: 15618, learning rate: 0.00494, Loss: 0.1886, Accuracy:0.930\nIteration: 15619, learning rate: 0.00494, Loss: 0.1002, Accuracy:0.953\nIteration: 15620, learning rate: 0.00494, Loss: 0.0863, Accuracy:0.992\nIteration: 15621, learning rate: 0.00494, Loss: 0.1526, Accuracy:0.953\nIteration: 15622, learning rate: 0.00494, Loss: 0.0809, Accuracy:0.977\nIteration: 15623, learning rate: 0.00494, Loss: 0.2422, Accuracy:0.906\nIteration: 15624, learning rate: 0.00494, Loss: 0.1411, Accuracy:0.935\nEpoch: 504, Loss: 0.1357, Accuracy:0.952, Val Loss: 0.3598, Val Accuracy: 0.851\nIteration: 15625, learning rate: 0.00494, Loss: 0.0709, Accuracy:0.984\nIteration: 15626, learning rate: 0.00494, Loss: 0.1549, Accuracy:0.930\nIteration: 15627, learning rate: 0.00494, Loss: 0.1428, Accuracy:0.953\nIteration: 15628, learning rate: 0.00494, Loss: 0.1941, Accuracy:0.930\nIteration: 15629, learning rate: 0.00494, Loss: 0.1576, Accuracy:0.938\nIteration: 15630, learning rate: 0.00494, Loss: 0.1741, Accuracy:0.922\nIteration: 15631, learning rate: 0.00494, Loss: 0.1554, Accuracy:0.953\nIteration: 15632, learning rate: 0.00494, Loss: 0.1129, Accuracy:0.953\nIteration: 15633, learning rate: 0.00494, Loss: 0.1604, Accuracy:0.938\nIteration: 15634, learning rate: 0.00494, Loss: 0.1608, Accuracy:0.938\nIteration: 15635, learning rate: 0.00494, Loss: 0.0924, Accuracy:0.969\nIteration: 15636, learning rate: 0.00494, Loss: 0.1464, Accuracy:0.938\nIteration: 15637, learning rate: 0.00494, Loss: 0.1586, Accuracy:0.930\nIteration: 15638, learning rate: 0.00494, Loss: 0.1387, Accuracy:0.930\nIteration: 15639, learning rate: 0.00494, Loss: 0.1410, Accuracy:0.938\nIteration: 15640, learning rate: 0.00494, Loss: 0.1115, Accuracy:0.945\nIteration: 15641, learning rate: 0.00494, Loss: 0.1309, Accuracy:0.961\nIteration: 15642, learning rate: 0.00494, Loss: 0.1286, Accuracy:0.953\nIteration: 15643, learning rate: 0.00493, Loss: 0.1863, Accuracy:0.914\nIteration: 15644, learning rate: 0.00493, Loss: 0.1006, Accuracy:0.977\nIteration: 15645, learning rate: 0.00493, Loss: 0.1045, Accuracy:0.961\nIteration: 15646, learning rate: 0.00493, Loss: 0.2326, Accuracy:0.930\nIteration: 15647, learning rate: 0.00493, Loss: 0.1581, Accuracy:0.945\nIteration: 15648, learning rate: 0.00493, Loss: 0.0868, Accuracy:0.961\nIteration: 15649, learning rate: 0.00493, Loss: 0.1497, Accuracy:0.930\nIteration: 15650, learning rate: 0.00493, Loss: 0.1071, Accuracy:0.961\nIteration: 15651, learning rate: 0.00493, Loss: 0.1956, Accuracy:0.938\nIteration: 15652, learning rate: 0.00493, Loss: 0.1737, Accuracy:0.938\nIteration: 15653, learning rate: 0.00493, Loss: 0.1022, Accuracy:0.953\nIteration: 15654, learning rate: 0.00493, Loss: 0.1796, Accuracy:0.953\nIteration: 15655, learning rate: 0.00493, Loss: 0.1584, Accuracy:0.957\nEpoch: 505, Loss: 0.1441, Accuracy:0.946, Val Loss: 0.2661, Val Accuracy: 0.895\nIteration: 15656, learning rate: 0.00493, Loss: 0.2252, Accuracy:0.898\nIteration: 15657, learning rate: 0.00493, Loss: 0.1016, Accuracy:0.953\nIteration: 15658, learning rate: 0.00493, Loss: 0.1198, Accuracy:0.953\nIteration: 15659, learning rate: 0.00493, Loss: 0.1272, Accuracy:0.961\nIteration: 15660, learning rate: 0.00493, Loss: 0.1667, Accuracy:0.938\nIteration: 15661, learning rate: 0.00493, Loss: 0.1825, Accuracy:0.945\nIteration: 15662, learning rate: 0.00493, Loss: 0.1108, Accuracy:0.930\nIteration: 15663, learning rate: 0.00493, Loss: 0.1266, Accuracy:0.984\nIteration: 15664, learning rate: 0.00493, Loss: 0.1292, Accuracy:0.945\nIteration: 15665, learning rate: 0.00493, Loss: 0.1017, Accuracy:0.984\nIteration: 15666, learning rate: 0.00493, Loss: 0.0796, Accuracy:0.977\nIteration: 15667, learning rate: 0.00493, Loss: 0.1584, Accuracy:0.945\nIteration: 15668, learning rate: 0.00493, Loss: 0.1921, Accuracy:0.914\nIteration: 15669, learning rate: 0.00493, Loss: 0.1070, Accuracy:0.953\nIteration: 15670, learning rate: 0.00493, Loss: 0.1056, Accuracy:0.953\nIteration: 15671, learning rate: 0.00493, Loss: 0.1497, Accuracy:0.953\nIteration: 15672, learning rate: 0.00493, Loss: 0.1349, Accuracy:0.953\nIteration: 15673, learning rate: 0.00493, Loss: 0.1542, Accuracy:0.953\nIteration: 15674, learning rate: 0.00493, Loss: 0.1238, Accuracy:0.953\nIteration: 15675, learning rate: 0.00493, Loss: 0.1318, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 15676, learning rate: 0.00493, Loss: 0.0849, Accuracy:0.961\nIteration: 15677, learning rate: 0.00493, Loss: 0.1428, Accuracy:0.953\nIteration: 15678, learning rate: 0.00493, Loss: 0.1367, Accuracy:0.953\nIteration: 15679, learning rate: 0.00493, Loss: 0.1011, Accuracy:0.953\nIteration: 15680, learning rate: 0.00493, Loss: 0.1365, Accuracy:0.938\nIteration: 15681, learning rate: 0.00493, Loss: 0.1968, Accuracy:0.914\nIteration: 15682, learning rate: 0.00493, Loss: 0.1169, Accuracy:0.945\nIteration: 15683, learning rate: 0.00493, Loss: 0.2360, Accuracy:0.891\nIteration: 15684, learning rate: 0.00493, Loss: 0.1477, Accuracy:0.953\nIteration: 15685, learning rate: 0.00493, Loss: 0.1214, Accuracy:0.953\nIteration: 15686, learning rate: 0.00493, Loss: 0.1842, Accuracy:0.914\nEpoch: 506, Loss: 0.1398, Accuracy:0.946, Val Loss: 0.3145, Val Accuracy: 0.876\nIteration: 15687, learning rate: 0.00493, Loss: 0.0972, Accuracy:0.977\nIteration: 15688, learning rate: 0.00493, Loss: 0.1219, Accuracy:0.945\nIteration: 15689, learning rate: 0.00493, Loss: 0.1516, Accuracy:0.945\nIteration: 15690, learning rate: 0.00493, Loss: 0.1560, Accuracy:0.938\nIteration: 15691, learning rate: 0.00493, Loss: 0.0974, Accuracy:0.969\nIteration: 15692, learning rate: 0.00493, Loss: 0.1500, Accuracy:0.930\nIteration: 15693, learning rate: 0.00493, Loss: 0.1418, Accuracy:0.953\nIteration: 15694, learning rate: 0.00493, Loss: 0.1536, Accuracy:0.938\nIteration: 15695, learning rate: 0.00493, Loss: 0.1570, Accuracy:0.945\nIteration: 15696, learning rate: 0.00493, Loss: 0.1550, Accuracy:0.938\nIteration: 15697, learning rate: 0.00493, Loss: 0.1366, Accuracy:0.961\nIteration: 15698, learning rate: 0.00493, Loss: 0.1013, Accuracy:0.969\nIteration: 15699, learning rate: 0.00493, Loss: 0.1704, Accuracy:0.938\nIteration: 15700, learning rate: 0.00493, Loss: 0.0920, Accuracy:0.953\nIteration: 15701, learning rate: 0.00493, Loss: 0.1229, Accuracy:0.945\nIteration: 15702, learning rate: 0.00493, Loss: 0.1054, Accuracy:0.961\nIteration: 15703, learning rate: 0.00493, Loss: 0.1624, Accuracy:0.945\nIteration: 15704, learning rate: 0.00493, Loss: 0.1277, Accuracy:0.953\nIteration: 15705, learning rate: 0.00493, Loss: 0.0774, Accuracy:0.984\nIteration: 15706, learning rate: 0.00493, Loss: 0.2083, Accuracy:0.938\nIteration: 15707, learning rate: 0.00493, Loss: 0.1003, Accuracy:0.945\nIteration: 15708, learning rate: 0.00493, Loss: 0.1458, Accuracy:0.961\nIteration: 15709, learning rate: 0.00493, Loss: 0.1195, Accuracy:0.953\nIteration: 15710, learning rate: 0.00493, Loss: 0.1348, Accuracy:0.953\nIteration: 15711, learning rate: 0.00493, Loss: 0.0859, Accuracy:0.977\nIteration: 15712, learning rate: 0.00493, Loss: 0.1895, Accuracy:0.906\nIteration: 15713, learning rate: 0.00492, Loss: 0.2029, Accuracy:0.922\nIteration: 15714, learning rate: 0.00492, Loss: 0.1531, Accuracy:0.914\nIteration: 15715, learning rate: 0.00492, Loss: 0.1565, Accuracy:0.945\nIteration: 15716, learning rate: 0.00492, Loss: 0.1406, Accuracy:0.930\nIteration: 15717, learning rate: 0.00492, Loss: 0.1168, Accuracy:0.946\nEpoch: 507, Loss: 0.1365, Accuracy:0.948, Val Loss: 0.2686, Val Accuracy: 0.895\nIteration: 15718, learning rate: 0.00492, Loss: 0.0820, Accuracy:0.977\nIteration: 15719, learning rate: 0.00492, Loss: 0.1563, Accuracy:0.938\nIteration: 15720, learning rate: 0.00492, Loss: 0.1264, Accuracy:0.953\nIteration: 15721, learning rate: 0.00492, Loss: 0.1627, Accuracy:0.922\nIteration: 15722, learning rate: 0.00492, Loss: 0.1345, Accuracy:0.930\nIteration: 15723, learning rate: 0.00492, Loss: 0.1322, Accuracy:0.953\nIteration: 15724, learning rate: 0.00492, Loss: 0.1063, Accuracy:0.945\nIteration: 15725, learning rate: 0.00492, Loss: 0.1420, Accuracy:0.969\nIteration: 15726, learning rate: 0.00492, Loss: 0.1802, Accuracy:0.945\nIteration: 15727, learning rate: 0.00492, Loss: 0.1191, Accuracy:0.961\nIteration: 15728, learning rate: 0.00492, Loss: 0.1312, Accuracy:0.945\nIteration: 15729, learning rate: 0.00492, Loss: 0.1511, Accuracy:0.953\nIteration: 15730, learning rate: 0.00492, Loss: 0.1057, Accuracy:0.969\nIteration: 15731, learning rate: 0.00492, Loss: 0.1116, Accuracy:0.961\nIteration: 15732, learning rate: 0.00492, Loss: 0.1075, Accuracy:0.969\nIteration: 15733, learning rate: 0.00492, Loss: 0.1230, Accuracy:0.961\nIteration: 15734, learning rate: 0.00492, Loss: 0.0845, Accuracy:0.961\nIteration: 15735, learning rate: 0.00492, Loss: 0.1515, Accuracy:0.953\nIteration: 15736, learning rate: 0.00492, Loss: 0.1055, Accuracy:0.945\nIteration: 15737, learning rate: 0.00492, Loss: 0.1803, Accuracy:0.945\nIteration: 15738, learning rate: 0.00492, Loss: 0.2605, Accuracy:0.898\nIteration: 15739, learning rate: 0.00492, Loss: 0.0989, Accuracy:0.961\nIteration: 15740, learning rate: 0.00492, Loss: 0.1479, Accuracy:0.953\nIteration: 15741, learning rate: 0.00492, Loss: 0.0909, Accuracy:0.977\nIteration: 15742, learning rate: 0.00492, Loss: 0.1604, Accuracy:0.938\nIteration: 15743, learning rate: 0.00492, Loss: 0.1995, Accuracy:0.906\nIteration: 15744, learning rate: 0.00492, Loss: 0.1191, Accuracy:0.969\nIteration: 15745, learning rate: 0.00492, Loss: 0.1130, Accuracy:0.961\nIteration: 15746, learning rate: 0.00492, Loss: 0.1389, Accuracy:0.961\nIteration: 15747, learning rate: 0.00492, Loss: 0.1051, Accuracy:0.969\nIteration: 15748, learning rate: 0.00492, Loss: 0.1033, Accuracy:0.957\nEpoch: 508, Loss: 0.1333, Accuracy:0.952, Val Loss: 0.2847, Val Accuracy: 0.879\nIteration: 15749, learning rate: 0.00492, Loss: 0.1391, Accuracy:0.930\nIteration: 15750, learning rate: 0.00492, Loss: 0.1840, Accuracy:0.922\nIteration: 15751, learning rate: 0.00492, Loss: 0.1130, Accuracy:0.969\nIteration: 15752, learning rate: 0.00492, Loss: 0.1377, Accuracy:0.930\nIteration: 15753, learning rate: 0.00492, Loss: 0.1711, Accuracy:0.930\nIteration: 15754, learning rate: 0.00492, Loss: 0.1357, Accuracy:0.938\nIteration: 15755, learning rate: 0.00492, Loss: 0.1483, Accuracy:0.922\nIteration: 15756, learning rate: 0.00492, Loss: 0.1144, Accuracy:0.938\nIteration: 15757, learning rate: 0.00492, Loss: 0.1173, Accuracy:0.945\nIteration: 15758, learning rate: 0.00492, Loss: 0.1480, Accuracy:0.961\nIteration: 15759, learning rate: 0.00492, Loss: 0.1734, Accuracy:0.945\nIteration: 15760, learning rate: 0.00492, Loss: 0.1544, Accuracy:0.930\nIteration: 15761, learning rate: 0.00492, Loss: 0.2122, Accuracy:0.922\nIteration: 15762, learning rate: 0.00492, Loss: 0.1702, Accuracy:0.945\nIteration: 15763, learning rate: 0.00492, Loss: 0.0968, Accuracy:0.953\nIteration: 15764, learning rate: 0.00492, Loss: 0.1434, Accuracy:0.938\nIteration: 15765, learning rate: 0.00492, Loss: 0.1492, Accuracy:0.938\nIteration: 15766, learning rate: 0.00492, Loss: 0.1213, Accuracy:0.945\nIteration: 15767, learning rate: 0.00492, Loss: 0.1664, Accuracy:0.945\nIteration: 15768, learning rate: 0.00492, Loss: 0.1598, Accuracy:0.922\nIteration: 15769, learning rate: 0.00492, Loss: 0.1011, Accuracy:0.977\nIteration: 15770, learning rate: 0.00492, Loss: 0.1333, Accuracy:0.922\nIteration: 15771, learning rate: 0.00492, Loss: 0.1543, Accuracy:0.961\nIteration: 15772, learning rate: 0.00492, Loss: 0.1712, Accuracy:0.914\nIteration: 15773, learning rate: 0.00492, Loss: 0.1913, Accuracy:0.930\nIteration: 15774, learning rate: 0.00492, Loss: 0.0605, Accuracy:0.969\nIteration: 15775, learning rate: 0.00492, Loss: 0.1337, Accuracy:0.938\nIteration: 15776, learning rate: 0.00492, Loss: 0.1424, Accuracy:0.938\nIteration: 15777, learning rate: 0.00492, Loss: 0.1684, Accuracy:0.938\nIteration: 15778, learning rate: 0.00492, Loss: 0.2128, Accuracy:0.930\nIteration: 15779, learning rate: 0.00492, Loss: 0.2210, Accuracy:0.871\nEpoch: 509, Loss: 0.1499, Accuracy:0.937, Val Loss: 0.2872, Val Accuracy: 0.884\nIteration: 15780, learning rate: 0.00492, Loss: 0.1691, Accuracy:0.938\nIteration: 15781, learning rate: 0.00492, Loss: 0.1083, Accuracy:0.969\nIteration: 15782, learning rate: 0.00492, Loss: 0.1341, Accuracy:0.953\nIteration: 15783, learning rate: 0.00491, Loss: 0.1487, Accuracy:0.938\nIteration: 15784, learning rate: 0.00491, Loss: 0.1415, Accuracy:0.969\nIteration: 15785, learning rate: 0.00491, Loss: 0.1651, Accuracy:0.969\nIteration: 15786, learning rate: 0.00491, Loss: 0.3405, Accuracy:0.875\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 15787, learning rate: 0.00491, Loss: 0.0653, Accuracy:0.977\nIteration: 15788, learning rate: 0.00491, Loss: 0.0862, Accuracy:0.984\nIteration: 15789, learning rate: 0.00491, Loss: 0.1328, Accuracy:0.945\nIteration: 15790, learning rate: 0.00491, Loss: 0.1194, Accuracy:0.969\nIteration: 15791, learning rate: 0.00491, Loss: 0.1227, Accuracy:0.953\nIteration: 15792, learning rate: 0.00491, Loss: 0.1386, Accuracy:0.930\nIteration: 15793, learning rate: 0.00491, Loss: 0.1219, Accuracy:0.961\nIteration: 15794, learning rate: 0.00491, Loss: 0.0641, Accuracy:0.984\nIteration: 15795, learning rate: 0.00491, Loss: 0.1511, Accuracy:0.938\nIteration: 15796, learning rate: 0.00491, Loss: 0.1163, Accuracy:0.969\nIteration: 15797, learning rate: 0.00491, Loss: 0.1278, Accuracy:0.961\nIteration: 15798, learning rate: 0.00491, Loss: 0.2204, Accuracy:0.906\nIteration: 15799, learning rate: 0.00491, Loss: 0.1289, Accuracy:0.953\nIteration: 15800, learning rate: 0.00491, Loss: 0.1386, Accuracy:0.945\nIteration: 15801, learning rate: 0.00491, Loss: 0.1113, Accuracy:0.953\nIteration: 15802, learning rate: 0.00491, Loss: 0.0940, Accuracy:0.961\nIteration: 15803, learning rate: 0.00491, Loss: 0.1674, Accuracy:0.938\nIteration: 15804, learning rate: 0.00491, Loss: 0.1521, Accuracy:0.953\nIteration: 15805, learning rate: 0.00491, Loss: 0.1344, Accuracy:0.961\nIteration: 15806, learning rate: 0.00491, Loss: 0.2029, Accuracy:0.906\nIteration: 15807, learning rate: 0.00491, Loss: 0.1620, Accuracy:0.938\nIteration: 15808, learning rate: 0.00491, Loss: 0.1050, Accuracy:0.977\nIteration: 15809, learning rate: 0.00491, Loss: 0.0711, Accuracy:0.961\nIteration: 15810, learning rate: 0.00491, Loss: 0.1601, Accuracy:0.946\nEpoch: 510, Loss: 0.1388, Accuracy:0.951, Val Loss: 0.2741, Val Accuracy: 0.885\nIteration: 15811, learning rate: 0.00491, Loss: 0.1860, Accuracy:0.914\nIteration: 15812, learning rate: 0.00491, Loss: 0.1278, Accuracy:0.938\nIteration: 15813, learning rate: 0.00491, Loss: 0.1474, Accuracy:0.961\nIteration: 15814, learning rate: 0.00491, Loss: 0.0972, Accuracy:0.961\nIteration: 15815, learning rate: 0.00491, Loss: 0.1630, Accuracy:0.914\nIteration: 15816, learning rate: 0.00491, Loss: 0.1440, Accuracy:0.938\nIteration: 15817, learning rate: 0.00491, Loss: 0.1398, Accuracy:0.953\nIteration: 15818, learning rate: 0.00491, Loss: 0.1985, Accuracy:0.898\nIteration: 15819, learning rate: 0.00491, Loss: 0.1325, Accuracy:0.945\nIteration: 15820, learning rate: 0.00491, Loss: 0.1688, Accuracy:0.945\nIteration: 15821, learning rate: 0.00491, Loss: 0.1766, Accuracy:0.938\nIteration: 15822, learning rate: 0.00491, Loss: 0.1386, Accuracy:0.938\nIteration: 15823, learning rate: 0.00491, Loss: 0.0890, Accuracy:0.961\nIteration: 15824, learning rate: 0.00491, Loss: 0.1030, Accuracy:0.969\nIteration: 15825, learning rate: 0.00491, Loss: 0.1502, Accuracy:0.961\nIteration: 15826, learning rate: 0.00491, Loss: 0.1361, Accuracy:0.945\nIteration: 15827, learning rate: 0.00491, Loss: 0.1917, Accuracy:0.922\nIteration: 15828, learning rate: 0.00491, Loss: 0.1162, Accuracy:0.977\nIteration: 15829, learning rate: 0.00491, Loss: 0.1232, Accuracy:0.953\nIteration: 15830, learning rate: 0.00491, Loss: 0.1812, Accuracy:0.914\nIteration: 15831, learning rate: 0.00491, Loss: 0.1811, Accuracy:0.922\nIteration: 15832, learning rate: 0.00491, Loss: 0.1743, Accuracy:0.930\nIteration: 15833, learning rate: 0.00491, Loss: 0.1458, Accuracy:0.945\nIteration: 15834, learning rate: 0.00491, Loss: 0.0999, Accuracy:0.969\nIteration: 15835, learning rate: 0.00491, Loss: 0.1402, Accuracy:0.969\nIteration: 15836, learning rate: 0.00491, Loss: 0.1395, Accuracy:0.953\nIteration: 15837, learning rate: 0.00491, Loss: 0.0855, Accuracy:0.961\nIteration: 15838, learning rate: 0.00491, Loss: 0.2009, Accuracy:0.953\nIteration: 15839, learning rate: 0.00491, Loss: 0.1549, Accuracy:0.930\nIteration: 15840, learning rate: 0.00491, Loss: 0.0914, Accuracy:0.977\nIteration: 15841, learning rate: 0.00491, Loss: 0.0856, Accuracy:0.978\nEpoch: 511, Loss: 0.1423, Accuracy:0.946, Val Loss: 0.2918, Val Accuracy: 0.883\nIteration: 15842, learning rate: 0.00491, Loss: 0.1001, Accuracy:0.961\nIteration: 15843, learning rate: 0.00491, Loss: 0.1755, Accuracy:0.945\nIteration: 15844, learning rate: 0.00491, Loss: 0.1713, Accuracy:0.930\nIteration: 15845, learning rate: 0.00491, Loss: 0.1569, Accuracy:0.930\nIteration: 15846, learning rate: 0.00491, Loss: 0.1183, Accuracy:0.953\nIteration: 15847, learning rate: 0.00491, Loss: 0.1718, Accuracy:0.938\nIteration: 15848, learning rate: 0.00491, Loss: 0.1671, Accuracy:0.953\nIteration: 15849, learning rate: 0.00491, Loss: 0.1029, Accuracy:0.969\nIteration: 15850, learning rate: 0.00491, Loss: 0.1115, Accuracy:0.938\nIteration: 15851, learning rate: 0.00491, Loss: 0.1532, Accuracy:0.938\nIteration: 15852, learning rate: 0.00491, Loss: 0.1227, Accuracy:0.953\nIteration: 15853, learning rate: 0.00490, Loss: 0.0867, Accuracy:0.977\nIteration: 15854, learning rate: 0.00490, Loss: 0.0700, Accuracy:0.969\nIteration: 15855, learning rate: 0.00490, Loss: 0.1491, Accuracy:0.945\nIteration: 15856, learning rate: 0.00490, Loss: 0.1202, Accuracy:0.984\nIteration: 15857, learning rate: 0.00490, Loss: 0.1718, Accuracy:0.961\nIteration: 15858, learning rate: 0.00490, Loss: 0.1545, Accuracy:0.945\nIteration: 15859, learning rate: 0.00490, Loss: 0.2108, Accuracy:0.938\nIteration: 15860, learning rate: 0.00490, Loss: 0.0987, Accuracy:0.961\nIteration: 15861, learning rate: 0.00490, Loss: 0.2023, Accuracy:0.914\nIteration: 15862, learning rate: 0.00490, Loss: 0.1028, Accuracy:0.977\nIteration: 15863, learning rate: 0.00490, Loss: 0.1891, Accuracy:0.938\nIteration: 15864, learning rate: 0.00490, Loss: 0.0937, Accuracy:0.969\nIteration: 15865, learning rate: 0.00490, Loss: 0.1397, Accuracy:0.938\nIteration: 15866, learning rate: 0.00490, Loss: 0.1646, Accuracy:0.922\nIteration: 15867, learning rate: 0.00490, Loss: 0.1941, Accuracy:0.930\nIteration: 15868, learning rate: 0.00490, Loss: 0.0930, Accuracy:0.969\nIteration: 15869, learning rate: 0.00490, Loss: 0.1797, Accuracy:0.922\nIteration: 15870, learning rate: 0.00490, Loss: 0.1315, Accuracy:0.969\nIteration: 15871, learning rate: 0.00490, Loss: 0.1107, Accuracy:0.953\nIteration: 15872, learning rate: 0.00490, Loss: 0.1402, Accuracy:0.957\nEpoch: 512, Loss: 0.1405, Accuracy:0.950, Val Loss: 0.3041, Val Accuracy: 0.888\nIteration: 15873, learning rate: 0.00490, Loss: 0.1070, Accuracy:0.961\nIteration: 15874, learning rate: 0.00490, Loss: 0.1077, Accuracy:0.961\nIteration: 15875, learning rate: 0.00490, Loss: 0.1125, Accuracy:0.961\nIteration: 15876, learning rate: 0.00490, Loss: 0.1318, Accuracy:0.953\nIteration: 15877, learning rate: 0.00490, Loss: 0.1212, Accuracy:0.961\nIteration: 15878, learning rate: 0.00490, Loss: 0.1879, Accuracy:0.945\nIteration: 15879, learning rate: 0.00490, Loss: 0.1371, Accuracy:0.945\nIteration: 15880, learning rate: 0.00490, Loss: 0.0892, Accuracy:0.961\nIteration: 15881, learning rate: 0.00490, Loss: 0.1977, Accuracy:0.953\nIteration: 15882, learning rate: 0.00490, Loss: 0.0580, Accuracy:0.984\nIteration: 15883, learning rate: 0.00490, Loss: 0.1626, Accuracy:0.938\nIteration: 15884, learning rate: 0.00490, Loss: 0.1376, Accuracy:0.930\nIteration: 15885, learning rate: 0.00490, Loss: 0.1327, Accuracy:0.953\nIteration: 15886, learning rate: 0.00490, Loss: 0.1628, Accuracy:0.945\nIteration: 15887, learning rate: 0.00490, Loss: 0.2095, Accuracy:0.922\nIteration: 15888, learning rate: 0.00490, Loss: 0.0907, Accuracy:0.992\nIteration: 15889, learning rate: 0.00490, Loss: 0.0888, Accuracy:0.969\nIteration: 15890, learning rate: 0.00490, Loss: 0.0893, Accuracy:0.961\nIteration: 15891, learning rate: 0.00490, Loss: 0.1148, Accuracy:0.961\nIteration: 15892, learning rate: 0.00490, Loss: 0.1256, Accuracy:0.945\nIteration: 15893, learning rate: 0.00490, Loss: 0.1723, Accuracy:0.945\nIteration: 15894, learning rate: 0.00490, Loss: 0.1124, Accuracy:0.969\nIteration: 15895, learning rate: 0.00490, Loss: 0.1377, Accuracy:0.961\nIteration: 15896, learning rate: 0.00490, Loss: 0.1269, Accuracy:0.953\nIteration: 15897, learning rate: 0.00490, Loss: 0.1010, Accuracy:0.961\nIteration: 15898, learning rate: 0.00490, Loss: 0.0850, Accuracy:0.984\nIteration: 15899, learning rate: 0.00490, Loss: 0.1085, Accuracy:0.953\nIteration: 15900, learning rate: 0.00490, Loss: 0.1357, Accuracy:0.938\nIteration: 15901, learning rate: 0.00490, Loss: 0.1936, Accuracy:0.906\nIteration: 15902, learning rate: 0.00490, Loss: 0.1055, Accuracy:0.969\nIteration: 15903, learning rate: 0.00490, Loss: 0.1087, Accuracy:0.968\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 513, Loss: 0.1275, Accuracy:0.955, Val Loss: 0.2958, Val Accuracy: 0.891\nIteration: 15904, learning rate: 0.00490, Loss: 0.1578, Accuracy:0.945\nIteration: 15905, learning rate: 0.00490, Loss: 0.2321, Accuracy:0.906\nIteration: 15906, learning rate: 0.00490, Loss: 0.1631, Accuracy:0.930\nIteration: 15907, learning rate: 0.00490, Loss: 0.1073, Accuracy:0.961\nIteration: 15908, learning rate: 0.00490, Loss: 0.1327, Accuracy:0.945\nIteration: 15909, learning rate: 0.00490, Loss: 0.1214, Accuracy:0.945\nIteration: 15910, learning rate: 0.00490, Loss: 0.1013, Accuracy:0.961\nIteration: 15911, learning rate: 0.00490, Loss: 0.2158, Accuracy:0.922\nIteration: 15912, learning rate: 0.00490, Loss: 0.1575, Accuracy:0.930\nIteration: 15913, learning rate: 0.00490, Loss: 0.0876, Accuracy:0.969\nIteration: 15914, learning rate: 0.00490, Loss: 0.1529, Accuracy:0.938\nIteration: 15915, learning rate: 0.00490, Loss: 0.1216, Accuracy:0.930\nIteration: 15916, learning rate: 0.00490, Loss: 0.0508, Accuracy:1.000\nIteration: 15917, learning rate: 0.00490, Loss: 0.1295, Accuracy:0.961\nIteration: 15918, learning rate: 0.00490, Loss: 0.0899, Accuracy:0.961\nIteration: 15919, learning rate: 0.00490, Loss: 0.2106, Accuracy:0.914\nIteration: 15920, learning rate: 0.00490, Loss: 0.1246, Accuracy:0.953\nIteration: 15921, learning rate: 0.00490, Loss: 0.1692, Accuracy:0.961\nIteration: 15922, learning rate: 0.00490, Loss: 0.1440, Accuracy:0.969\nIteration: 15923, learning rate: 0.00489, Loss: 0.2429, Accuracy:0.906\nIteration: 15924, learning rate: 0.00489, Loss: 0.1370, Accuracy:0.945\nIteration: 15925, learning rate: 0.00489, Loss: 0.1019, Accuracy:0.961\nIteration: 15926, learning rate: 0.00489, Loss: 0.0962, Accuracy:0.969\nIteration: 15927, learning rate: 0.00489, Loss: 0.1644, Accuracy:0.953\nIteration: 15928, learning rate: 0.00489, Loss: 0.1155, Accuracy:0.961\nIteration: 15929, learning rate: 0.00489, Loss: 0.1303, Accuracy:0.969\nIteration: 15930, learning rate: 0.00489, Loss: 0.1527, Accuracy:0.969\nIteration: 15931, learning rate: 0.00489, Loss: 0.1964, Accuracy:0.898\nIteration: 15932, learning rate: 0.00489, Loss: 0.1595, Accuracy:0.953\nIteration: 15933, learning rate: 0.00489, Loss: 0.1765, Accuracy:0.914\nIteration: 15934, learning rate: 0.00489, Loss: 0.1462, Accuracy:0.957\nEpoch: 514, Loss: 0.1448, Accuracy:0.947, Val Loss: 0.2812, Val Accuracy: 0.896\nIteration: 15935, learning rate: 0.00489, Loss: 0.1029, Accuracy:0.961\nIteration: 15936, learning rate: 0.00489, Loss: 0.1737, Accuracy:0.930\nIteration: 15937, learning rate: 0.00489, Loss: 0.1376, Accuracy:0.961\nIteration: 15938, learning rate: 0.00489, Loss: 0.1028, Accuracy:0.977\nIteration: 15939, learning rate: 0.00489, Loss: 0.1433, Accuracy:0.922\nIteration: 15940, learning rate: 0.00489, Loss: 0.1394, Accuracy:0.953\nIteration: 15941, learning rate: 0.00489, Loss: 0.1044, Accuracy:0.961\nIteration: 15942, learning rate: 0.00489, Loss: 0.1073, Accuracy:0.953\nIteration: 15943, learning rate: 0.00489, Loss: 0.0846, Accuracy:0.969\nIteration: 15944, learning rate: 0.00489, Loss: 0.2034, Accuracy:0.914\nIteration: 15945, learning rate: 0.00489, Loss: 0.1650, Accuracy:0.953\nIteration: 15946, learning rate: 0.00489, Loss: 0.1146, Accuracy:0.953\nIteration: 15947, learning rate: 0.00489, Loss: 0.0941, Accuracy:0.969\nIteration: 15948, learning rate: 0.00489, Loss: 0.1615, Accuracy:0.906\nIteration: 15949, learning rate: 0.00489, Loss: 0.1772, Accuracy:0.938\nIteration: 15950, learning rate: 0.00489, Loss: 0.1037, Accuracy:0.953\nIteration: 15951, learning rate: 0.00489, Loss: 0.1072, Accuracy:0.961\nIteration: 15952, learning rate: 0.00489, Loss: 0.1069, Accuracy:0.961\nIteration: 15953, learning rate: 0.00489, Loss: 0.1368, Accuracy:0.953\nIteration: 15954, learning rate: 0.00489, Loss: 0.1263, Accuracy:0.945\nIteration: 15955, learning rate: 0.00489, Loss: 0.1345, Accuracy:0.953\nIteration: 15956, learning rate: 0.00489, Loss: 0.1386, Accuracy:0.953\nIteration: 15957, learning rate: 0.00489, Loss: 0.1098, Accuracy:0.953\nIteration: 15958, learning rate: 0.00489, Loss: 0.1219, Accuracy:0.938\nIteration: 15959, learning rate: 0.00489, Loss: 0.1281, Accuracy:0.938\nIteration: 15960, learning rate: 0.00489, Loss: 0.2848, Accuracy:0.898\nIteration: 15961, learning rate: 0.00489, Loss: 0.1316, Accuracy:0.945\nIteration: 15962, learning rate: 0.00489, Loss: 0.1441, Accuracy:0.938\nIteration: 15963, learning rate: 0.00489, Loss: 0.1496, Accuracy:0.945\nIteration: 15964, learning rate: 0.00489, Loss: 0.1568, Accuracy:0.953\nIteration: 15965, learning rate: 0.00489, Loss: 0.0602, Accuracy:0.968\nEpoch: 515, Loss: 0.1340, Accuracy:0.948, Val Loss: 0.2445, Val Accuracy: 0.902\nIteration: 15966, learning rate: 0.00489, Loss: 0.1442, Accuracy:0.938\nIteration: 15967, learning rate: 0.00489, Loss: 0.1416, Accuracy:0.945\nIteration: 15968, learning rate: 0.00489, Loss: 0.1246, Accuracy:0.945\nIteration: 15969, learning rate: 0.00489, Loss: 0.1385, Accuracy:0.938\nIteration: 15970, learning rate: 0.00489, Loss: 0.1292, Accuracy:0.953\nIteration: 15971, learning rate: 0.00489, Loss: 0.1309, Accuracy:0.953\nIteration: 15972, learning rate: 0.00489, Loss: 0.0958, Accuracy:0.977\nIteration: 15973, learning rate: 0.00489, Loss: 0.1152, Accuracy:0.953\nIteration: 15974, learning rate: 0.00489, Loss: 0.0577, Accuracy:0.984\nIteration: 15975, learning rate: 0.00489, Loss: 0.1638, Accuracy:0.945\nIteration: 15976, learning rate: 0.00489, Loss: 0.1211, Accuracy:0.945\nIteration: 15977, learning rate: 0.00489, Loss: 0.1498, Accuracy:0.938\nIteration: 15978, learning rate: 0.00489, Loss: 0.1285, Accuracy:0.938\nIteration: 15979, learning rate: 0.00489, Loss: 0.1165, Accuracy:0.961\nIteration: 15980, learning rate: 0.00489, Loss: 0.1903, Accuracy:0.945\nIteration: 15981, learning rate: 0.00489, Loss: 0.1733, Accuracy:0.930\nIteration: 15982, learning rate: 0.00489, Loss: 0.0872, Accuracy:0.961\nIteration: 15983, learning rate: 0.00489, Loss: 0.1049, Accuracy:0.953\nIteration: 15984, learning rate: 0.00489, Loss: 0.1168, Accuracy:0.961\nIteration: 15985, learning rate: 0.00489, Loss: 0.1854, Accuracy:0.906\nIteration: 15986, learning rate: 0.00489, Loss: 0.1519, Accuracy:0.938\nIteration: 15987, learning rate: 0.00489, Loss: 0.1045, Accuracy:0.969\nIteration: 15988, learning rate: 0.00489, Loss: 0.1871, Accuracy:0.922\nIteration: 15989, learning rate: 0.00489, Loss: 0.1025, Accuracy:0.953\nIteration: 15990, learning rate: 0.00489, Loss: 0.1662, Accuracy:0.938\nIteration: 15991, learning rate: 0.00489, Loss: 0.1714, Accuracy:0.938\nIteration: 15992, learning rate: 0.00489, Loss: 0.1361, Accuracy:0.961\nIteration: 15993, learning rate: 0.00489, Loss: 0.1092, Accuracy:0.961\nIteration: 15994, learning rate: 0.00488, Loss: 0.1623, Accuracy:0.953\nIteration: 15995, learning rate: 0.00488, Loss: 0.0960, Accuracy:0.961\nIteration: 15996, learning rate: 0.00488, Loss: 0.1010, Accuracy:0.978\nEpoch: 516, Loss: 0.1324, Accuracy:0.950, Val Loss: 0.2976, Val Accuracy: 0.892\nIteration: 15997, learning rate: 0.00488, Loss: 0.0909, Accuracy:0.977\nIteration: 15998, learning rate: 0.00488, Loss: 0.1552, Accuracy:0.969\nIteration: 15999, learning rate: 0.00488, Loss: 0.1302, Accuracy:0.969\nIteration: 16000, learning rate: 0.00488, Loss: 0.0928, Accuracy:0.977\nIteration: 16001, learning rate: 0.00488, Loss: 0.1985, Accuracy:0.930\nIteration: 16002, learning rate: 0.00488, Loss: 0.1699, Accuracy:0.938\nIteration: 16003, learning rate: 0.00488, Loss: 0.1726, Accuracy:0.922\nIteration: 16004, learning rate: 0.00488, Loss: 0.1117, Accuracy:0.977\nIteration: 16005, learning rate: 0.00488, Loss: 0.1249, Accuracy:0.945\nIteration: 16006, learning rate: 0.00488, Loss: 0.0956, Accuracy:0.969\nIteration: 16007, learning rate: 0.00488, Loss: 0.0887, Accuracy:0.961\nIteration: 16008, learning rate: 0.00488, Loss: 0.1390, Accuracy:0.938\nIteration: 16009, learning rate: 0.00488, Loss: 0.1330, Accuracy:0.961\nIteration: 16010, learning rate: 0.00488, Loss: 0.1049, Accuracy:0.969\nIteration: 16011, learning rate: 0.00488, Loss: 0.1162, Accuracy:0.953\nIteration: 16012, learning rate: 0.00488, Loss: 0.1396, Accuracy:0.953\nIteration: 16013, learning rate: 0.00488, Loss: 0.1632, Accuracy:0.914\nIteration: 16014, learning rate: 0.00488, Loss: 0.1789, Accuracy:0.945\nIteration: 16015, learning rate: 0.00488, Loss: 0.1587, Accuracy:0.922\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16016, learning rate: 0.00488, Loss: 0.1679, Accuracy:0.945\nIteration: 16017, learning rate: 0.00488, Loss: 0.1481, Accuracy:0.945\nIteration: 16018, learning rate: 0.00488, Loss: 0.1937, Accuracy:0.914\nIteration: 16019, learning rate: 0.00488, Loss: 0.1161, Accuracy:0.953\nIteration: 16020, learning rate: 0.00488, Loss: 0.1210, Accuracy:0.938\nIteration: 16021, learning rate: 0.00488, Loss: 0.1734, Accuracy:0.930\nIteration: 16022, learning rate: 0.00488, Loss: 0.2021, Accuracy:0.906\nIteration: 16023, learning rate: 0.00488, Loss: 0.1243, Accuracy:0.953\nIteration: 16024, learning rate: 0.00488, Loss: 0.1432, Accuracy:0.961\nIteration: 16025, learning rate: 0.00488, Loss: 0.0554, Accuracy:0.977\nIteration: 16026, learning rate: 0.00488, Loss: 0.1432, Accuracy:0.938\nIteration: 16027, learning rate: 0.00488, Loss: 0.1275, Accuracy:0.957\nEpoch: 517, Loss: 0.1381, Accuracy:0.948, Val Loss: 0.2835, Val Accuracy: 0.891\nIteration: 16028, learning rate: 0.00488, Loss: 0.0898, Accuracy:0.977\nIteration: 16029, learning rate: 0.00488, Loss: 0.1570, Accuracy:0.945\nIteration: 16030, learning rate: 0.00488, Loss: 0.1117, Accuracy:0.945\nIteration: 16031, learning rate: 0.00488, Loss: 0.0930, Accuracy:0.977\nIteration: 16032, learning rate: 0.00488, Loss: 0.1480, Accuracy:0.922\nIteration: 16033, learning rate: 0.00488, Loss: 0.2123, Accuracy:0.914\nIteration: 16034, learning rate: 0.00488, Loss: 0.0963, Accuracy:0.977\nIteration: 16035, learning rate: 0.00488, Loss: 0.1402, Accuracy:0.961\nIteration: 16036, learning rate: 0.00488, Loss: 0.0973, Accuracy:0.969\nIteration: 16037, learning rate: 0.00488, Loss: 0.1251, Accuracy:0.930\nIteration: 16038, learning rate: 0.00488, Loss: 0.1446, Accuracy:0.945\nIteration: 16039, learning rate: 0.00488, Loss: 0.1968, Accuracy:0.938\nIteration: 16040, learning rate: 0.00488, Loss: 0.1403, Accuracy:0.953\nIteration: 16041, learning rate: 0.00488, Loss: 0.1284, Accuracy:0.938\nIteration: 16042, learning rate: 0.00488, Loss: 0.0825, Accuracy:0.984\nIteration: 16043, learning rate: 0.00488, Loss: 0.0914, Accuracy:0.961\nIteration: 16044, learning rate: 0.00488, Loss: 0.1882, Accuracy:0.945\nIteration: 16045, learning rate: 0.00488, Loss: 0.1303, Accuracy:0.945\nIteration: 16046, learning rate: 0.00488, Loss: 0.1263, Accuracy:0.945\nIteration: 16047, learning rate: 0.00488, Loss: 0.1113, Accuracy:0.953\nIteration: 16048, learning rate: 0.00488, Loss: 0.1644, Accuracy:0.938\nIteration: 16049, learning rate: 0.00488, Loss: 0.0772, Accuracy:0.961\nIteration: 16050, learning rate: 0.00488, Loss: 0.1253, Accuracy:0.953\nIteration: 16051, learning rate: 0.00488, Loss: 0.1572, Accuracy:0.945\nIteration: 16052, learning rate: 0.00488, Loss: 0.0946, Accuracy:0.984\nIteration: 16053, learning rate: 0.00488, Loss: 0.1586, Accuracy:0.953\nIteration: 16054, learning rate: 0.00488, Loss: 0.1165, Accuracy:0.961\nIteration: 16055, learning rate: 0.00488, Loss: 0.1232, Accuracy:0.953\nIteration: 16056, learning rate: 0.00488, Loss: 0.1052, Accuracy:0.984\nIteration: 16057, learning rate: 0.00488, Loss: 0.1434, Accuracy:0.953\nIteration: 16058, learning rate: 0.00488, Loss: 0.2215, Accuracy:0.925\nEpoch: 518, Loss: 0.1322, Accuracy:0.953, Val Loss: 0.2815, Val Accuracy: 0.892\nIteration: 16059, learning rate: 0.00488, Loss: 0.1798, Accuracy:0.938\nIteration: 16060, learning rate: 0.00488, Loss: 0.1764, Accuracy:0.945\nIteration: 16061, learning rate: 0.00488, Loss: 0.0919, Accuracy:0.961\nIteration: 16062, learning rate: 0.00488, Loss: 0.1095, Accuracy:0.977\nIteration: 16063, learning rate: 0.00488, Loss: 0.0865, Accuracy:0.977\nIteration: 16064, learning rate: 0.00488, Loss: 0.2391, Accuracy:0.875\nIteration: 16065, learning rate: 0.00487, Loss: 0.0967, Accuracy:0.953\nIteration: 16066, learning rate: 0.00487, Loss: 0.1382, Accuracy:0.953\nIteration: 16067, learning rate: 0.00487, Loss: 0.1070, Accuracy:0.961\nIteration: 16068, learning rate: 0.00487, Loss: 0.1022, Accuracy:0.953\nIteration: 16069, learning rate: 0.00487, Loss: 0.2307, Accuracy:0.906\nIteration: 16070, learning rate: 0.00487, Loss: 0.1472, Accuracy:0.930\nIteration: 16071, learning rate: 0.00487, Loss: 0.1196, Accuracy:0.961\nIteration: 16072, learning rate: 0.00487, Loss: 0.1263, Accuracy:0.969\nIteration: 16073, learning rate: 0.00487, Loss: 0.1650, Accuracy:0.938\nIteration: 16074, learning rate: 0.00487, Loss: 0.1171, Accuracy:0.945\nIteration: 16075, learning rate: 0.00487, Loss: 0.1481, Accuracy:0.945\nIteration: 16076, learning rate: 0.00487, Loss: 0.1236, Accuracy:0.953\nIteration: 16077, learning rate: 0.00487, Loss: 0.1020, Accuracy:0.953\nIteration: 16078, learning rate: 0.00487, Loss: 0.1128, Accuracy:0.961\nIteration: 16079, learning rate: 0.00487, Loss: 0.1614, Accuracy:0.930\nIteration: 16080, learning rate: 0.00487, Loss: 0.1092, Accuracy:0.977\nIteration: 16081, learning rate: 0.00487, Loss: 0.1409, Accuracy:0.930\nIteration: 16082, learning rate: 0.00487, Loss: 0.1552, Accuracy:0.945\nIteration: 16083, learning rate: 0.00487, Loss: 0.1523, Accuracy:0.945\nIteration: 16084, learning rate: 0.00487, Loss: 0.1961, Accuracy:0.945\nIteration: 16085, learning rate: 0.00487, Loss: 0.2305, Accuracy:0.953\nIteration: 16086, learning rate: 0.00487, Loss: 0.0898, Accuracy:0.953\nIteration: 16087, learning rate: 0.00487, Loss: 0.1685, Accuracy:0.938\nIteration: 16088, learning rate: 0.00487, Loss: 0.1500, Accuracy:0.938\nIteration: 16089, learning rate: 0.00487, Loss: 0.1261, Accuracy:0.946\nEpoch: 519, Loss: 0.1419, Accuracy:0.947, Val Loss: 0.2609, Val Accuracy: 0.905\nIteration: 16090, learning rate: 0.00487, Loss: 0.1110, Accuracy:0.953\nIteration: 16091, learning rate: 0.00487, Loss: 0.1370, Accuracy:0.953\nIteration: 16092, learning rate: 0.00487, Loss: 0.1011, Accuracy:0.961\nIteration: 16093, learning rate: 0.00487, Loss: 0.1212, Accuracy:0.953\nIteration: 16094, learning rate: 0.00487, Loss: 0.1878, Accuracy:0.922\nIteration: 16095, learning rate: 0.00487, Loss: 0.1175, Accuracy:0.961\nIteration: 16096, learning rate: 0.00487, Loss: 0.1214, Accuracy:0.945\nIteration: 16097, learning rate: 0.00487, Loss: 0.1956, Accuracy:0.938\nIteration: 16098, learning rate: 0.00487, Loss: 0.0664, Accuracy:0.992\nIteration: 16099, learning rate: 0.00487, Loss: 0.0709, Accuracy:0.977\nIteration: 16100, learning rate: 0.00487, Loss: 0.1210, Accuracy:0.953\nIteration: 16101, learning rate: 0.00487, Loss: 0.1377, Accuracy:0.953\nIteration: 16102, learning rate: 0.00487, Loss: 0.0988, Accuracy:0.961\nIteration: 16103, learning rate: 0.00487, Loss: 0.1545, Accuracy:0.930\nIteration: 16104, learning rate: 0.00487, Loss: 0.1021, Accuracy:0.961\nIteration: 16105, learning rate: 0.00487, Loss: 0.1073, Accuracy:0.977\nIteration: 16106, learning rate: 0.00487, Loss: 0.1372, Accuracy:0.938\nIteration: 16107, learning rate: 0.00487, Loss: 0.1785, Accuracy:0.945\nIteration: 16108, learning rate: 0.00487, Loss: 0.0800, Accuracy:0.961\nIteration: 16109, learning rate: 0.00487, Loss: 0.1369, Accuracy:0.953\nIteration: 16110, learning rate: 0.00487, Loss: 0.1334, Accuracy:0.930\nIteration: 16111, learning rate: 0.00487, Loss: 0.0820, Accuracy:0.977\nIteration: 16112, learning rate: 0.00487, Loss: 0.1340, Accuracy:0.969\nIteration: 16113, learning rate: 0.00487, Loss: 0.1124, Accuracy:0.961\nIteration: 16114, learning rate: 0.00487, Loss: 0.1477, Accuracy:0.930\nIteration: 16115, learning rate: 0.00487, Loss: 0.1712, Accuracy:0.930\nIteration: 16116, learning rate: 0.00487, Loss: 0.0852, Accuracy:0.969\nIteration: 16117, learning rate: 0.00487, Loss: 0.0922, Accuracy:0.977\nIteration: 16118, learning rate: 0.00487, Loss: 0.1046, Accuracy:0.953\nIteration: 16119, learning rate: 0.00487, Loss: 0.1283, Accuracy:0.938\nIteration: 16120, learning rate: 0.00487, Loss: 0.1278, Accuracy:0.957\nEpoch: 520, Loss: 0.1227, Accuracy:0.954, Val Loss: 0.2641, Val Accuracy: 0.894\nIteration: 16121, learning rate: 0.00487, Loss: 0.1388, Accuracy:0.945\nIteration: 16122, learning rate: 0.00487, Loss: 0.1307, Accuracy:0.945\nIteration: 16123, learning rate: 0.00487, Loss: 0.1289, Accuracy:0.953\nIteration: 16124, learning rate: 0.00487, Loss: 0.1262, Accuracy:0.969\nIteration: 16125, learning rate: 0.00487, Loss: 0.0979, Accuracy:0.961\nIteration: 16126, learning rate: 0.00487, Loss: 0.1625, Accuracy:0.922\nIteration: 16127, learning rate: 0.00487, Loss: 0.1797, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16128, learning rate: 0.00487, Loss: 0.1431, Accuracy:0.945\nIteration: 16129, learning rate: 0.00487, Loss: 0.1434, Accuracy:0.953\nIteration: 16130, learning rate: 0.00487, Loss: 0.1473, Accuracy:0.945\nIteration: 16131, learning rate: 0.00487, Loss: 0.1407, Accuracy:0.922\nIteration: 16132, learning rate: 0.00487, Loss: 0.0894, Accuracy:0.977\nIteration: 16133, learning rate: 0.00487, Loss: 0.1652, Accuracy:0.953\nIteration: 16134, learning rate: 0.00487, Loss: 0.1413, Accuracy:0.938\nIteration: 16135, learning rate: 0.00487, Loss: 0.0981, Accuracy:0.969\nIteration: 16136, learning rate: 0.00487, Loss: 0.1313, Accuracy:0.945\nIteration: 16137, learning rate: 0.00486, Loss: 0.0893, Accuracy:0.984\nIteration: 16138, learning rate: 0.00486, Loss: 0.2534, Accuracy:0.891\nIteration: 16139, learning rate: 0.00486, Loss: 0.1079, Accuracy:0.961\nIteration: 16140, learning rate: 0.00486, Loss: 0.1127, Accuracy:0.961\nIteration: 16141, learning rate: 0.00486, Loss: 0.0902, Accuracy:0.992\nIteration: 16142, learning rate: 0.00486, Loss: 0.0994, Accuracy:0.953\nIteration: 16143, learning rate: 0.00486, Loss: 0.1201, Accuracy:0.953\nIteration: 16144, learning rate: 0.00486, Loss: 0.1481, Accuracy:0.945\nIteration: 16145, learning rate: 0.00486, Loss: 0.2105, Accuracy:0.883\nIteration: 16146, learning rate: 0.00486, Loss: 0.1052, Accuracy:0.953\nIteration: 16147, learning rate: 0.00486, Loss: 0.1417, Accuracy:0.930\nIteration: 16148, learning rate: 0.00486, Loss: 0.0730, Accuracy:0.977\nIteration: 16149, learning rate: 0.00486, Loss: 0.0778, Accuracy:0.969\nIteration: 16150, learning rate: 0.00486, Loss: 0.0947, Accuracy:0.984\nIteration: 16151, learning rate: 0.00486, Loss: 0.0941, Accuracy:0.978\nEpoch: 521, Loss: 0.1285, Accuracy:0.951, Val Loss: 0.2955, Val Accuracy: 0.875\nIteration: 16152, learning rate: 0.00486, Loss: 0.1056, Accuracy:0.969\nIteration: 16153, learning rate: 0.00486, Loss: 0.1660, Accuracy:0.922\nIteration: 16154, learning rate: 0.00486, Loss: 0.0916, Accuracy:0.969\nIteration: 16155, learning rate: 0.00486, Loss: 0.1853, Accuracy:0.930\nIteration: 16156, learning rate: 0.00486, Loss: 0.1071, Accuracy:0.961\nIteration: 16157, learning rate: 0.00486, Loss: 0.1162, Accuracy:0.938\nIteration: 16158, learning rate: 0.00486, Loss: 0.1910, Accuracy:0.922\nIteration: 16159, learning rate: 0.00486, Loss: 0.0809, Accuracy:0.977\nIteration: 16160, learning rate: 0.00486, Loss: 0.1523, Accuracy:0.938\nIteration: 16161, learning rate: 0.00486, Loss: 0.0806, Accuracy:0.984\nIteration: 16162, learning rate: 0.00486, Loss: 0.1175, Accuracy:0.961\nIteration: 16163, learning rate: 0.00486, Loss: 0.0976, Accuracy:0.977\nIteration: 16164, learning rate: 0.00486, Loss: 0.1138, Accuracy:0.969\nIteration: 16165, learning rate: 0.00486, Loss: 0.1895, Accuracy:0.930\nIteration: 16166, learning rate: 0.00486, Loss: 0.1140, Accuracy:0.953\nIteration: 16167, learning rate: 0.00486, Loss: 0.1871, Accuracy:0.922\nIteration: 16168, learning rate: 0.00486, Loss: 0.0961, Accuracy:0.953\nIteration: 16169, learning rate: 0.00486, Loss: 0.1232, Accuracy:0.961\nIteration: 16170, learning rate: 0.00486, Loss: 0.1173, Accuracy:0.961\nIteration: 16171, learning rate: 0.00486, Loss: 0.1675, Accuracy:0.898\nIteration: 16172, learning rate: 0.00486, Loss: 0.0668, Accuracy:0.977\nIteration: 16173, learning rate: 0.00486, Loss: 0.1460, Accuracy:0.945\nIteration: 16174, learning rate: 0.00486, Loss: 0.0566, Accuracy:0.984\nIteration: 16175, learning rate: 0.00486, Loss: 0.1270, Accuracy:0.961\nIteration: 16176, learning rate: 0.00486, Loss: 0.1056, Accuracy:0.969\nIteration: 16177, learning rate: 0.00486, Loss: 0.1357, Accuracy:0.938\nIteration: 16178, learning rate: 0.00486, Loss: 0.0832, Accuracy:0.977\nIteration: 16179, learning rate: 0.00486, Loss: 0.0595, Accuracy:0.977\nIteration: 16180, learning rate: 0.00486, Loss: 0.1073, Accuracy:0.961\nIteration: 16181, learning rate: 0.00486, Loss: 0.2342, Accuracy:0.922\nIteration: 16182, learning rate: 0.00486, Loss: 0.1357, Accuracy:0.925\nEpoch: 522, Loss: 0.1244, Accuracy:0.952, Val Loss: 0.3140, Val Accuracy: 0.885\nIteration: 16183, learning rate: 0.00486, Loss: 0.1377, Accuracy:0.938\nIteration: 16184, learning rate: 0.00486, Loss: 0.0789, Accuracy:0.961\nIteration: 16185, learning rate: 0.00486, Loss: 0.2057, Accuracy:0.938\nIteration: 16186, learning rate: 0.00486, Loss: 0.1029, Accuracy:0.969\nIteration: 16187, learning rate: 0.00486, Loss: 0.1591, Accuracy:0.930\nIteration: 16188, learning rate: 0.00486, Loss: 0.1044, Accuracy:0.961\nIteration: 16189, learning rate: 0.00486, Loss: 0.1385, Accuracy:0.938\nIteration: 16190, learning rate: 0.00486, Loss: 0.0909, Accuracy:0.969\nIteration: 16191, learning rate: 0.00486, Loss: 0.1423, Accuracy:0.969\nIteration: 16192, learning rate: 0.00486, Loss: 0.1279, Accuracy:0.945\nIteration: 16193, learning rate: 0.00486, Loss: 0.1455, Accuracy:0.953\nIteration: 16194, learning rate: 0.00486, Loss: 0.1849, Accuracy:0.945\nIteration: 16195, learning rate: 0.00486, Loss: 0.1596, Accuracy:0.945\nIteration: 16196, learning rate: 0.00486, Loss: 0.1545, Accuracy:0.953\nIteration: 16197, learning rate: 0.00486, Loss: 0.1076, Accuracy:0.953\nIteration: 16198, learning rate: 0.00486, Loss: 0.1201, Accuracy:0.938\nIteration: 16199, learning rate: 0.00486, Loss: 0.1486, Accuracy:0.945\nIteration: 16200, learning rate: 0.00486, Loss: 0.0973, Accuracy:0.953\nIteration: 16201, learning rate: 0.00486, Loss: 0.1317, Accuracy:0.961\nIteration: 16202, learning rate: 0.00486, Loss: 0.0867, Accuracy:0.969\nIteration: 16203, learning rate: 0.00486, Loss: 0.0635, Accuracy:0.977\nIteration: 16204, learning rate: 0.00486, Loss: 0.1640, Accuracy:0.938\nIteration: 16205, learning rate: 0.00486, Loss: 0.1556, Accuracy:0.953\nIteration: 16206, learning rate: 0.00486, Loss: 0.1523, Accuracy:0.945\nIteration: 16207, learning rate: 0.00486, Loss: 0.1492, Accuracy:0.953\nIteration: 16208, learning rate: 0.00485, Loss: 0.1451, Accuracy:0.938\nIteration: 16209, learning rate: 0.00485, Loss: 0.1078, Accuracy:0.969\nIteration: 16210, learning rate: 0.00485, Loss: 0.1107, Accuracy:0.977\nIteration: 16211, learning rate: 0.00485, Loss: 0.0828, Accuracy:0.969\nIteration: 16212, learning rate: 0.00485, Loss: 0.1725, Accuracy:0.930\nIteration: 16213, learning rate: 0.00485, Loss: 0.1654, Accuracy:0.925\nEpoch: 523, Loss: 0.1321, Accuracy:0.952, Val Loss: 0.2651, Val Accuracy: 0.886\nIteration: 16214, learning rate: 0.00485, Loss: 0.1029, Accuracy:0.961\nIteration: 16215, learning rate: 0.00485, Loss: 0.1005, Accuracy:0.953\nIteration: 16216, learning rate: 0.00485, Loss: 0.1189, Accuracy:0.977\nIteration: 16217, learning rate: 0.00485, Loss: 0.1515, Accuracy:0.953\nIteration: 16218, learning rate: 0.00485, Loss: 0.0727, Accuracy:0.977\nIteration: 16219, learning rate: 0.00485, Loss: 0.1503, Accuracy:0.922\nIteration: 16220, learning rate: 0.00485, Loss: 0.1984, Accuracy:0.922\nIteration: 16221, learning rate: 0.00485, Loss: 0.1806, Accuracy:0.914\nIteration: 16222, learning rate: 0.00485, Loss: 0.0920, Accuracy:0.977\nIteration: 16223, learning rate: 0.00485, Loss: 0.1385, Accuracy:0.961\nIteration: 16224, learning rate: 0.00485, Loss: 0.1457, Accuracy:0.930\nIteration: 16225, learning rate: 0.00485, Loss: 0.1616, Accuracy:0.938\nIteration: 16226, learning rate: 0.00485, Loss: 0.1212, Accuracy:0.945\nIteration: 16227, learning rate: 0.00485, Loss: 0.0977, Accuracy:0.969\nIteration: 16228, learning rate: 0.00485, Loss: 0.1240, Accuracy:0.961\nIteration: 16229, learning rate: 0.00485, Loss: 0.1000, Accuracy:0.969\nIteration: 16230, learning rate: 0.00485, Loss: 0.1643, Accuracy:0.938\nIteration: 16231, learning rate: 0.00485, Loss: 0.0948, Accuracy:0.945\nIteration: 16232, learning rate: 0.00485, Loss: 0.1386, Accuracy:0.945\nIteration: 16233, learning rate: 0.00485, Loss: 0.0775, Accuracy:0.961\nIteration: 16234, learning rate: 0.00485, Loss: 0.1325, Accuracy:0.945\nIteration: 16235, learning rate: 0.00485, Loss: 0.1744, Accuracy:0.930\nIteration: 16236, learning rate: 0.00485, Loss: 0.1338, Accuracy:0.953\nIteration: 16237, learning rate: 0.00485, Loss: 0.1627, Accuracy:0.914\nIteration: 16238, learning rate: 0.00485, Loss: 0.1380, Accuracy:0.953\nIteration: 16239, learning rate: 0.00485, Loss: 0.1289, Accuracy:0.953\nIteration: 16240, learning rate: 0.00485, Loss: 0.2430, Accuracy:0.898\nIteration: 16241, learning rate: 0.00485, Loss: 0.1920, Accuracy:0.930\nIteration: 16242, learning rate: 0.00485, Loss: 0.1229, Accuracy:0.961\nIteration: 16243, learning rate: 0.00485, Loss: 0.1579, Accuracy:0.953\nIteration: 16244, learning rate: 0.00485, Loss: 0.0875, Accuracy:0.968\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 524, Loss: 0.1357, Accuracy:0.948, Val Loss: 0.4087, Val Accuracy: 0.871\nIteration: 16245, learning rate: 0.00485, Loss: 0.1112, Accuracy:0.945\nIteration: 16246, learning rate: 0.00485, Loss: 0.0585, Accuracy:0.984\nIteration: 16247, learning rate: 0.00485, Loss: 0.1272, Accuracy:0.938\nIteration: 16248, learning rate: 0.00485, Loss: 0.1899, Accuracy:0.930\nIteration: 16249, learning rate: 0.00485, Loss: 0.1598, Accuracy:0.961\nIteration: 16250, learning rate: 0.00485, Loss: 0.1130, Accuracy:0.961\nIteration: 16251, learning rate: 0.00485, Loss: 0.1154, Accuracy:0.969\nIteration: 16252, learning rate: 0.00485, Loss: 0.1750, Accuracy:0.930\nIteration: 16253, learning rate: 0.00485, Loss: 0.1405, Accuracy:0.953\nIteration: 16254, learning rate: 0.00485, Loss: 0.1560, Accuracy:0.922\nIteration: 16255, learning rate: 0.00485, Loss: 0.1338, Accuracy:0.953\nIteration: 16256, learning rate: 0.00485, Loss: 0.1173, Accuracy:0.945\nIteration: 16257, learning rate: 0.00485, Loss: 0.2056, Accuracy:0.938\nIteration: 16258, learning rate: 0.00485, Loss: 0.0853, Accuracy:0.969\nIteration: 16259, learning rate: 0.00485, Loss: 0.1121, Accuracy:0.953\nIteration: 16260, learning rate: 0.00485, Loss: 0.1404, Accuracy:0.961\nIteration: 16261, learning rate: 0.00485, Loss: 0.1488, Accuracy:0.938\nIteration: 16262, learning rate: 0.00485, Loss: 0.2119, Accuracy:0.930\nIteration: 16263, learning rate: 0.00485, Loss: 0.0986, Accuracy:0.953\nIteration: 16264, learning rate: 0.00485, Loss: 0.1640, Accuracy:0.938\nIteration: 16265, learning rate: 0.00485, Loss: 0.1427, Accuracy:0.938\nIteration: 16266, learning rate: 0.00485, Loss: 0.0780, Accuracy:0.977\nIteration: 16267, learning rate: 0.00485, Loss: 0.0924, Accuracy:0.969\nIteration: 16268, learning rate: 0.00485, Loss: 0.1793, Accuracy:0.945\nIteration: 16269, learning rate: 0.00485, Loss: 0.1083, Accuracy:0.961\nIteration: 16270, learning rate: 0.00485, Loss: 0.1848, Accuracy:0.938\nIteration: 16271, learning rate: 0.00485, Loss: 0.1567, Accuracy:0.961\nIteration: 16272, learning rate: 0.00485, Loss: 0.1024, Accuracy:0.953\nIteration: 16273, learning rate: 0.00485, Loss: 0.1512, Accuracy:0.945\nIteration: 16274, learning rate: 0.00485, Loss: 0.0778, Accuracy:0.984\nIteration: 16275, learning rate: 0.00485, Loss: 0.1296, Accuracy:0.978\nEpoch: 525, Loss: 0.1344, Accuracy:0.952, Val Loss: 0.3487, Val Accuracy: 0.850\nIteration: 16276, learning rate: 0.00485, Loss: 0.1715, Accuracy:0.906\nIteration: 16277, learning rate: 0.00485, Loss: 0.0747, Accuracy:0.969\nIteration: 16278, learning rate: 0.00485, Loss: 0.1566, Accuracy:0.938\nIteration: 16279, learning rate: 0.00485, Loss: 0.0800, Accuracy:0.969\nIteration: 16280, learning rate: 0.00484, Loss: 0.1478, Accuracy:0.961\nIteration: 16281, learning rate: 0.00484, Loss: 0.1326, Accuracy:0.930\nIteration: 16282, learning rate: 0.00484, Loss: 0.1378, Accuracy:0.945\nIteration: 16283, learning rate: 0.00484, Loss: 0.1723, Accuracy:0.945\nIteration: 16284, learning rate: 0.00484, Loss: 0.1043, Accuracy:0.961\nIteration: 16285, learning rate: 0.00484, Loss: 0.0884, Accuracy:0.961\nIteration: 16286, learning rate: 0.00484, Loss: 0.0836, Accuracy:0.961\nIteration: 16287, learning rate: 0.00484, Loss: 0.1594, Accuracy:0.953\nIteration: 16288, learning rate: 0.00484, Loss: 0.1892, Accuracy:0.930\nIteration: 16289, learning rate: 0.00484, Loss: 0.1408, Accuracy:0.945\nIteration: 16290, learning rate: 0.00484, Loss: 0.1201, Accuracy:0.945\nIteration: 16291, learning rate: 0.00484, Loss: 0.1320, Accuracy:0.945\nIteration: 16292, learning rate: 0.00484, Loss: 0.1326, Accuracy:0.938\nIteration: 16293, learning rate: 0.00484, Loss: 0.0961, Accuracy:0.961\nIteration: 16294, learning rate: 0.00484, Loss: 0.1459, Accuracy:0.930\nIteration: 16295, learning rate: 0.00484, Loss: 0.1213, Accuracy:0.945\nIteration: 16296, learning rate: 0.00484, Loss: 0.1441, Accuracy:0.945\nIteration: 16297, learning rate: 0.00484, Loss: 0.0555, Accuracy:0.992\nIteration: 16298, learning rate: 0.00484, Loss: 0.1108, Accuracy:0.961\nIteration: 16299, learning rate: 0.00484, Loss: 0.1386, Accuracy:0.953\nIteration: 16300, learning rate: 0.00484, Loss: 0.1182, Accuracy:0.961\nIteration: 16301, learning rate: 0.00484, Loss: 0.1197, Accuracy:0.969\nIteration: 16302, learning rate: 0.00484, Loss: 0.1068, Accuracy:0.945\nIteration: 16303, learning rate: 0.00484, Loss: 0.1811, Accuracy:0.906\nIteration: 16304, learning rate: 0.00484, Loss: 0.1118, Accuracy:0.945\nIteration: 16305, learning rate: 0.00484, Loss: 0.1241, Accuracy:0.961\nIteration: 16306, learning rate: 0.00484, Loss: 0.0916, Accuracy:0.957\nEpoch: 526, Loss: 0.1255, Accuracy:0.949, Val Loss: 0.3045, Val Accuracy: 0.891\nIteration: 16307, learning rate: 0.00484, Loss: 0.1376, Accuracy:0.938\nIteration: 16308, learning rate: 0.00484, Loss: 0.1923, Accuracy:0.945\nIteration: 16309, learning rate: 0.00484, Loss: 0.0863, Accuracy:0.984\nIteration: 16310, learning rate: 0.00484, Loss: 0.1048, Accuracy:0.977\nIteration: 16311, learning rate: 0.00484, Loss: 0.1404, Accuracy:0.938\nIteration: 16312, learning rate: 0.00484, Loss: 0.1269, Accuracy:0.961\nIteration: 16313, learning rate: 0.00484, Loss: 0.0980, Accuracy:0.969\nIteration: 16314, learning rate: 0.00484, Loss: 0.2007, Accuracy:0.930\nIteration: 16315, learning rate: 0.00484, Loss: 0.1571, Accuracy:0.953\nIteration: 16316, learning rate: 0.00484, Loss: 0.1333, Accuracy:0.930\nIteration: 16317, learning rate: 0.00484, Loss: 0.2111, Accuracy:0.898\nIteration: 16318, learning rate: 0.00484, Loss: 0.1288, Accuracy:0.961\nIteration: 16319, learning rate: 0.00484, Loss: 0.1030, Accuracy:0.969\nIteration: 16320, learning rate: 0.00484, Loss: 0.1051, Accuracy:0.953\nIteration: 16321, learning rate: 0.00484, Loss: 0.1180, Accuracy:0.953\nIteration: 16322, learning rate: 0.00484, Loss: 0.1068, Accuracy:0.969\nIteration: 16323, learning rate: 0.00484, Loss: 0.1154, Accuracy:0.953\nIteration: 16324, learning rate: 0.00484, Loss: 0.1716, Accuracy:0.953\nIteration: 16325, learning rate: 0.00484, Loss: 0.0900, Accuracy:0.977\nIteration: 16326, learning rate: 0.00484, Loss: 0.1105, Accuracy:0.953\nIteration: 16327, learning rate: 0.00484, Loss: 0.1461, Accuracy:0.953\nIteration: 16328, learning rate: 0.00484, Loss: 0.1950, Accuracy:0.914\nIteration: 16329, learning rate: 0.00484, Loss: 0.0906, Accuracy:0.961\nIteration: 16330, learning rate: 0.00484, Loss: 0.0834, Accuracy:0.969\nIteration: 16331, learning rate: 0.00484, Loss: 0.0950, Accuracy:0.969\nIteration: 16332, learning rate: 0.00484, Loss: 0.1268, Accuracy:0.953\nIteration: 16333, learning rate: 0.00484, Loss: 0.1249, Accuracy:0.961\nIteration: 16334, learning rate: 0.00484, Loss: 0.2114, Accuracy:0.922\nIteration: 16335, learning rate: 0.00484, Loss: 0.1146, Accuracy:0.945\nIteration: 16336, learning rate: 0.00484, Loss: 0.1029, Accuracy:0.961\nIteration: 16337, learning rate: 0.00484, Loss: 0.0638, Accuracy:0.989\nEpoch: 527, Loss: 0.1288, Accuracy:0.954, Val Loss: 0.2582, Val Accuracy: 0.905\nIteration: 16338, learning rate: 0.00484, Loss: 0.1414, Accuracy:0.938\nIteration: 16339, learning rate: 0.00484, Loss: 0.1211, Accuracy:0.945\nIteration: 16340, learning rate: 0.00484, Loss: 0.1354, Accuracy:0.961\nIteration: 16341, learning rate: 0.00484, Loss: 0.0793, Accuracy:0.977\nIteration: 16342, learning rate: 0.00484, Loss: 0.1311, Accuracy:0.953\nIteration: 16343, learning rate: 0.00484, Loss: 0.1177, Accuracy:0.945\nIteration: 16344, learning rate: 0.00484, Loss: 0.1146, Accuracy:0.945\nIteration: 16345, learning rate: 0.00484, Loss: 0.1374, Accuracy:0.945\nIteration: 16346, learning rate: 0.00484, Loss: 0.1247, Accuracy:0.969\nIteration: 16347, learning rate: 0.00484, Loss: 0.0861, Accuracy:0.977\nIteration: 16348, learning rate: 0.00484, Loss: 0.0992, Accuracy:0.945\nIteration: 16349, learning rate: 0.00484, Loss: 0.0981, Accuracy:0.953\nIteration: 16350, learning rate: 0.00484, Loss: 0.1118, Accuracy:0.969\nIteration: 16351, learning rate: 0.00484, Loss: 0.1241, Accuracy:0.961\nIteration: 16352, learning rate: 0.00484, Loss: 0.1419, Accuracy:0.969\nIteration: 16353, learning rate: 0.00483, Loss: 0.1085, Accuracy:0.953\nIteration: 16354, learning rate: 0.00483, Loss: 0.1748, Accuracy:0.945\nIteration: 16355, learning rate: 0.00483, Loss: 0.1631, Accuracy:0.945\nIteration: 16356, learning rate: 0.00483, Loss: 0.1059, Accuracy:0.961\nIteration: 16357, learning rate: 0.00483, Loss: 0.0894, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16358, learning rate: 0.00483, Loss: 0.1099, Accuracy:0.969\nIteration: 16359, learning rate: 0.00483, Loss: 0.1750, Accuracy:0.930\nIteration: 16360, learning rate: 0.00483, Loss: 0.1354, Accuracy:0.945\nIteration: 16361, learning rate: 0.00483, Loss: 0.1134, Accuracy:0.953\nIteration: 16362, learning rate: 0.00483, Loss: 0.1473, Accuracy:0.930\nIteration: 16363, learning rate: 0.00483, Loss: 0.0878, Accuracy:0.969\nIteration: 16364, learning rate: 0.00483, Loss: 0.0793, Accuracy:0.969\nIteration: 16365, learning rate: 0.00483, Loss: 0.0930, Accuracy:0.977\nIteration: 16366, learning rate: 0.00483, Loss: 0.0964, Accuracy:0.953\nIteration: 16367, learning rate: 0.00483, Loss: 0.1539, Accuracy:0.938\nIteration: 16368, learning rate: 0.00483, Loss: 0.1454, Accuracy:0.978\nEpoch: 528, Loss: 0.1207, Accuracy:0.956, Val Loss: 0.2970, Val Accuracy: 0.888\nIteration: 16369, learning rate: 0.00483, Loss: 0.1125, Accuracy:0.953\nIteration: 16370, learning rate: 0.00483, Loss: 0.1240, Accuracy:0.953\nIteration: 16371, learning rate: 0.00483, Loss: 0.0753, Accuracy:0.984\nIteration: 16372, learning rate: 0.00483, Loss: 0.1833, Accuracy:0.938\nIteration: 16373, learning rate: 0.00483, Loss: 0.1145, Accuracy:0.953\nIteration: 16374, learning rate: 0.00483, Loss: 0.1097, Accuracy:0.953\nIteration: 16375, learning rate: 0.00483, Loss: 0.1299, Accuracy:0.945\nIteration: 16376, learning rate: 0.00483, Loss: 0.1655, Accuracy:0.945\nIteration: 16377, learning rate: 0.00483, Loss: 0.0842, Accuracy:0.969\nIteration: 16378, learning rate: 0.00483, Loss: 0.1637, Accuracy:0.930\nIteration: 16379, learning rate: 0.00483, Loss: 0.1037, Accuracy:0.977\nIteration: 16380, learning rate: 0.00483, Loss: 0.1061, Accuracy:0.977\nIteration: 16381, learning rate: 0.00483, Loss: 0.1109, Accuracy:0.961\nIteration: 16382, learning rate: 0.00483, Loss: 0.1284, Accuracy:0.945\nIteration: 16383, learning rate: 0.00483, Loss: 0.1948, Accuracy:0.906\nIteration: 16384, learning rate: 0.00483, Loss: 0.1043, Accuracy:0.969\nIteration: 16385, learning rate: 0.00483, Loss: 0.0825, Accuracy:0.969\nIteration: 16386, learning rate: 0.00483, Loss: 0.1848, Accuracy:0.914\nIteration: 16387, learning rate: 0.00483, Loss: 0.0566, Accuracy:0.984\nIteration: 16388, learning rate: 0.00483, Loss: 0.1507, Accuracy:0.945\nIteration: 16389, learning rate: 0.00483, Loss: 0.1352, Accuracy:0.945\nIteration: 16390, learning rate: 0.00483, Loss: 0.0677, Accuracy:0.984\nIteration: 16391, learning rate: 0.00483, Loss: 0.1142, Accuracy:0.969\nIteration: 16392, learning rate: 0.00483, Loss: 0.0918, Accuracy:0.969\nIteration: 16393, learning rate: 0.00483, Loss: 0.1543, Accuracy:0.938\nIteration: 16394, learning rate: 0.00483, Loss: 0.0870, Accuracy:0.977\nIteration: 16395, learning rate: 0.00483, Loss: 0.1328, Accuracy:0.945\nIteration: 16396, learning rate: 0.00483, Loss: 0.1196, Accuracy:0.945\nIteration: 16397, learning rate: 0.00483, Loss: 0.0632, Accuracy:0.977\nIteration: 16398, learning rate: 0.00483, Loss: 0.1768, Accuracy:0.922\nIteration: 16399, learning rate: 0.00483, Loss: 0.1707, Accuracy:0.946\nEpoch: 529, Loss: 0.1225, Accuracy:0.954, Val Loss: 0.3352, Val Accuracy: 0.882\nIteration: 16400, learning rate: 0.00483, Loss: 0.1384, Accuracy:0.938\nIteration: 16401, learning rate: 0.00483, Loss: 0.1690, Accuracy:0.938\nIteration: 16402, learning rate: 0.00483, Loss: 0.1724, Accuracy:0.922\nIteration: 16403, learning rate: 0.00483, Loss: 0.1448, Accuracy:0.938\nIteration: 16404, learning rate: 0.00483, Loss: 0.1916, Accuracy:0.930\nIteration: 16405, learning rate: 0.00483, Loss: 0.1401, Accuracy:0.945\nIteration: 16406, learning rate: 0.00483, Loss: 0.1857, Accuracy:0.938\nIteration: 16407, learning rate: 0.00483, Loss: 0.1619, Accuracy:0.930\nIteration: 16408, learning rate: 0.00483, Loss: 0.1586, Accuracy:0.938\nIteration: 16409, learning rate: 0.00483, Loss: 0.1721, Accuracy:0.938\nIteration: 16410, learning rate: 0.00483, Loss: 0.0969, Accuracy:0.961\nIteration: 16411, learning rate: 0.00483, Loss: 0.1381, Accuracy:0.961\nIteration: 16412, learning rate: 0.00483, Loss: 0.1180, Accuracy:0.953\nIteration: 16413, learning rate: 0.00483, Loss: 0.1073, Accuracy:0.945\nIteration: 16414, learning rate: 0.00483, Loss: 0.0863, Accuracy:0.961\nIteration: 16415, learning rate: 0.00483, Loss: 0.1527, Accuracy:0.930\nIteration: 16416, learning rate: 0.00483, Loss: 0.2323, Accuracy:0.906\nIteration: 16417, learning rate: 0.00483, Loss: 0.1162, Accuracy:0.945\nIteration: 16418, learning rate: 0.00483, Loss: 0.1051, Accuracy:0.977\nIteration: 16419, learning rate: 0.00483, Loss: 0.1224, Accuracy:0.938\nIteration: 16420, learning rate: 0.00483, Loss: 0.1150, Accuracy:0.961\nIteration: 16421, learning rate: 0.00483, Loss: 0.1181, Accuracy:0.961\nIteration: 16422, learning rate: 0.00483, Loss: 0.1045, Accuracy:0.961\nIteration: 16423, learning rate: 0.00483, Loss: 0.0673, Accuracy:0.969\nIteration: 16424, learning rate: 0.00483, Loss: 0.1362, Accuracy:0.953\nIteration: 16425, learning rate: 0.00483, Loss: 0.1816, Accuracy:0.930\nIteration: 16426, learning rate: 0.00482, Loss: 0.1939, Accuracy:0.922\nIteration: 16427, learning rate: 0.00482, Loss: 0.1159, Accuracy:0.945\nIteration: 16428, learning rate: 0.00482, Loss: 0.1195, Accuracy:0.945\nIteration: 16429, learning rate: 0.00482, Loss: 0.1564, Accuracy:0.938\nIteration: 16430, learning rate: 0.00482, Loss: 0.1317, Accuracy:0.935\nEpoch: 530, Loss: 0.1403, Accuracy:0.943, Val Loss: 0.3195, Val Accuracy: 0.871\nIteration: 16431, learning rate: 0.00482, Loss: 0.2284, Accuracy:0.930\nIteration: 16432, learning rate: 0.00482, Loss: 0.1144, Accuracy:0.969\nIteration: 16433, learning rate: 0.00482, Loss: 0.0987, Accuracy:0.977\nIteration: 16434, learning rate: 0.00482, Loss: 0.1047, Accuracy:0.953\nIteration: 16435, learning rate: 0.00482, Loss: 0.1671, Accuracy:0.922\nIteration: 16436, learning rate: 0.00482, Loss: 0.1605, Accuracy:0.914\nIteration: 16437, learning rate: 0.00482, Loss: 0.1465, Accuracy:0.953\nIteration: 16438, learning rate: 0.00482, Loss: 0.1733, Accuracy:0.914\nIteration: 16439, learning rate: 0.00482, Loss: 0.1017, Accuracy:0.961\nIteration: 16440, learning rate: 0.00482, Loss: 0.0781, Accuracy:0.969\nIteration: 16441, learning rate: 0.00482, Loss: 0.1479, Accuracy:0.953\nIteration: 16442, learning rate: 0.00482, Loss: 0.2122, Accuracy:0.922\nIteration: 16443, learning rate: 0.00482, Loss: 0.0967, Accuracy:0.961\nIteration: 16444, learning rate: 0.00482, Loss: 0.1068, Accuracy:0.953\nIteration: 16445, learning rate: 0.00482, Loss: 0.1165, Accuracy:0.969\nIteration: 16446, learning rate: 0.00482, Loss: 0.1150, Accuracy:0.961\nIteration: 16447, learning rate: 0.00482, Loss: 0.0589, Accuracy:0.984\nIteration: 16448, learning rate: 0.00482, Loss: 0.1831, Accuracy:0.945\nIteration: 16449, learning rate: 0.00482, Loss: 0.1372, Accuracy:0.961\nIteration: 16450, learning rate: 0.00482, Loss: 0.0995, Accuracy:0.977\nIteration: 16451, learning rate: 0.00482, Loss: 0.2006, Accuracy:0.891\nIteration: 16452, learning rate: 0.00482, Loss: 0.1127, Accuracy:0.953\nIteration: 16453, learning rate: 0.00482, Loss: 0.1913, Accuracy:0.922\nIteration: 16454, learning rate: 0.00482, Loss: 0.1641, Accuracy:0.922\nIteration: 16455, learning rate: 0.00482, Loss: 0.1794, Accuracy:0.906\nIteration: 16456, learning rate: 0.00482, Loss: 0.1211, Accuracy:0.961\nIteration: 16457, learning rate: 0.00482, Loss: 0.0905, Accuracy:0.953\nIteration: 16458, learning rate: 0.00482, Loss: 0.1575, Accuracy:0.945\nIteration: 16459, learning rate: 0.00482, Loss: 0.1076, Accuracy:0.953\nIteration: 16460, learning rate: 0.00482, Loss: 0.0900, Accuracy:0.977\nIteration: 16461, learning rate: 0.00482, Loss: 0.0800, Accuracy:0.978\nEpoch: 531, Loss: 0.1336, Accuracy:0.949, Val Loss: 0.2505, Val Accuracy: 0.909\nIteration: 16462, learning rate: 0.00482, Loss: 0.1760, Accuracy:0.914\nIteration: 16463, learning rate: 0.00482, Loss: 0.0790, Accuracy:0.984\nIteration: 16464, learning rate: 0.00482, Loss: 0.1751, Accuracy:0.930\nIteration: 16465, learning rate: 0.00482, Loss: 0.1110, Accuracy:0.961\nIteration: 16466, learning rate: 0.00482, Loss: 0.0945, Accuracy:0.961\nIteration: 16467, learning rate: 0.00482, Loss: 0.1610, Accuracy:0.938\nIteration: 16468, learning rate: 0.00482, Loss: 0.1211, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16469, learning rate: 0.00482, Loss: 0.0932, Accuracy:0.969\nIteration: 16470, learning rate: 0.00482, Loss: 0.1518, Accuracy:0.930\nIteration: 16471, learning rate: 0.00482, Loss: 0.1570, Accuracy:0.953\nIteration: 16472, learning rate: 0.00482, Loss: 0.1503, Accuracy:0.938\nIteration: 16473, learning rate: 0.00482, Loss: 0.0874, Accuracy:0.969\nIteration: 16474, learning rate: 0.00482, Loss: 0.1144, Accuracy:0.961\nIteration: 16475, learning rate: 0.00482, Loss: 0.1122, Accuracy:0.984\nIteration: 16476, learning rate: 0.00482, Loss: 0.0875, Accuracy:0.984\nIteration: 16477, learning rate: 0.00482, Loss: 0.1443, Accuracy:0.945\nIteration: 16478, learning rate: 0.00482, Loss: 0.2139, Accuracy:0.922\nIteration: 16479, learning rate: 0.00482, Loss: 0.1231, Accuracy:0.953\nIteration: 16480, learning rate: 0.00482, Loss: 0.1712, Accuracy:0.930\nIteration: 16481, learning rate: 0.00482, Loss: 0.1297, Accuracy:0.945\nIteration: 16482, learning rate: 0.00482, Loss: 0.1160, Accuracy:0.969\nIteration: 16483, learning rate: 0.00482, Loss: 0.1218, Accuracy:0.953\nIteration: 16484, learning rate: 0.00482, Loss: 0.1269, Accuracy:0.961\nIteration: 16485, learning rate: 0.00482, Loss: 0.1290, Accuracy:0.969\nIteration: 16486, learning rate: 0.00482, Loss: 0.0721, Accuracy:0.977\nIteration: 16487, learning rate: 0.00482, Loss: 0.1427, Accuracy:0.953\nIteration: 16488, learning rate: 0.00482, Loss: 0.1274, Accuracy:0.953\nIteration: 16489, learning rate: 0.00482, Loss: 0.0688, Accuracy:0.984\nIteration: 16490, learning rate: 0.00482, Loss: 0.1909, Accuracy:0.930\nIteration: 16491, learning rate: 0.00482, Loss: 0.1390, Accuracy:0.938\nIteration: 16492, learning rate: 0.00482, Loss: 0.1007, Accuracy:0.957\nEpoch: 532, Loss: 0.1287, Accuracy:0.954, Val Loss: 0.3374, Val Accuracy: 0.861\nIteration: 16493, learning rate: 0.00482, Loss: 0.1049, Accuracy:0.953\nIteration: 16494, learning rate: 0.00482, Loss: 0.1928, Accuracy:0.938\nIteration: 16495, learning rate: 0.00482, Loss: 0.1141, Accuracy:0.953\nIteration: 16496, learning rate: 0.00482, Loss: 0.1366, Accuracy:0.953\nIteration: 16497, learning rate: 0.00482, Loss: 0.1843, Accuracy:0.945\nIteration: 16498, learning rate: 0.00482, Loss: 0.1268, Accuracy:0.953\nIteration: 16499, learning rate: 0.00481, Loss: 0.1689, Accuracy:0.930\nIteration: 16500, learning rate: 0.00481, Loss: 0.0686, Accuracy:0.977\nIteration: 16501, learning rate: 0.00481, Loss: 0.0676, Accuracy:0.969\nIteration: 16502, learning rate: 0.00481, Loss: 0.1472, Accuracy:0.953\nIteration: 16503, learning rate: 0.00481, Loss: 0.0933, Accuracy:0.969\nIteration: 16504, learning rate: 0.00481, Loss: 0.1936, Accuracy:0.922\nIteration: 16505, learning rate: 0.00481, Loss: 0.1870, Accuracy:0.938\nIteration: 16506, learning rate: 0.00481, Loss: 0.1096, Accuracy:0.953\nIteration: 16507, learning rate: 0.00481, Loss: 0.1688, Accuracy:0.938\nIteration: 16508, learning rate: 0.00481, Loss: 0.0776, Accuracy:0.992\nIteration: 16509, learning rate: 0.00481, Loss: 0.1132, Accuracy:0.969\nIteration: 16510, learning rate: 0.00481, Loss: 0.1324, Accuracy:0.961\nIteration: 16511, learning rate: 0.00481, Loss: 0.1340, Accuracy:0.945\nIteration: 16512, learning rate: 0.00481, Loss: 0.1112, Accuracy:0.953\nIteration: 16513, learning rate: 0.00481, Loss: 0.0833, Accuracy:0.969\nIteration: 16514, learning rate: 0.00481, Loss: 0.1558, Accuracy:0.938\nIteration: 16515, learning rate: 0.00481, Loss: 0.1460, Accuracy:0.945\nIteration: 16516, learning rate: 0.00481, Loss: 0.1115, Accuracy:0.953\nIteration: 16517, learning rate: 0.00481, Loss: 0.1947, Accuracy:0.930\nIteration: 16518, learning rate: 0.00481, Loss: 0.1237, Accuracy:0.961\nIteration: 16519, learning rate: 0.00481, Loss: 0.1075, Accuracy:0.961\nIteration: 16520, learning rate: 0.00481, Loss: 0.1454, Accuracy:0.938\nIteration: 16521, learning rate: 0.00481, Loss: 0.1845, Accuracy:0.945\nIteration: 16522, learning rate: 0.00481, Loss: 0.1338, Accuracy:0.953\nIteration: 16523, learning rate: 0.00481, Loss: 0.1060, Accuracy:0.957\nEpoch: 533, Loss: 0.1331, Accuracy:0.952, Val Loss: 0.3084, Val Accuracy: 0.869\nIteration: 16524, learning rate: 0.00481, Loss: 0.1809, Accuracy:0.922\nIteration: 16525, learning rate: 0.00481, Loss: 0.1473, Accuracy:0.945\nIteration: 16526, learning rate: 0.00481, Loss: 0.0936, Accuracy:0.961\nIteration: 16527, learning rate: 0.00481, Loss: 0.1289, Accuracy:0.938\nIteration: 16528, learning rate: 0.00481, Loss: 0.1536, Accuracy:0.945\nIteration: 16529, learning rate: 0.00481, Loss: 0.1842, Accuracy:0.953\nIteration: 16530, learning rate: 0.00481, Loss: 0.1186, Accuracy:0.953\nIteration: 16531, learning rate: 0.00481, Loss: 0.1462, Accuracy:0.945\nIteration: 16532, learning rate: 0.00481, Loss: 0.1272, Accuracy:0.961\nIteration: 16533, learning rate: 0.00481, Loss: 0.1740, Accuracy:0.914\nIteration: 16534, learning rate: 0.00481, Loss: 0.1578, Accuracy:0.945\nIteration: 16535, learning rate: 0.00481, Loss: 0.1324, Accuracy:0.945\nIteration: 16536, learning rate: 0.00481, Loss: 0.0952, Accuracy:0.969\nIteration: 16537, learning rate: 0.00481, Loss: 0.1534, Accuracy:0.953\nIteration: 16538, learning rate: 0.00481, Loss: 0.0598, Accuracy:0.984\nIteration: 16539, learning rate: 0.00481, Loss: 0.1858, Accuracy:0.938\nIteration: 16540, learning rate: 0.00481, Loss: 0.1073, Accuracy:0.953\nIteration: 16541, learning rate: 0.00481, Loss: 0.0880, Accuracy:0.969\nIteration: 16542, learning rate: 0.00481, Loss: 0.1855, Accuracy:0.922\nIteration: 16543, learning rate: 0.00481, Loss: 0.0522, Accuracy:0.984\nIteration: 16544, learning rate: 0.00481, Loss: 0.1121, Accuracy:0.961\nIteration: 16545, learning rate: 0.00481, Loss: 0.0816, Accuracy:0.977\nIteration: 16546, learning rate: 0.00481, Loss: 0.0999, Accuracy:0.977\nIteration: 16547, learning rate: 0.00481, Loss: 0.1028, Accuracy:0.953\nIteration: 16548, learning rate: 0.00481, Loss: 0.1332, Accuracy:0.961\nIteration: 16549, learning rate: 0.00481, Loss: 0.1718, Accuracy:0.930\nIteration: 16550, learning rate: 0.00481, Loss: 0.0582, Accuracy:0.984\nIteration: 16551, learning rate: 0.00481, Loss: 0.1332, Accuracy:0.953\nIteration: 16552, learning rate: 0.00481, Loss: 0.2243, Accuracy:0.906\nIteration: 16553, learning rate: 0.00481, Loss: 0.1679, Accuracy:0.953\nIteration: 16554, learning rate: 0.00481, Loss: 0.1378, Accuracy:0.957\nEpoch: 534, Loss: 0.1321, Accuracy:0.952, Val Loss: 0.3157, Val Accuracy: 0.877\nIteration: 16555, learning rate: 0.00481, Loss: 0.1158, Accuracy:0.930\nIteration: 16556, learning rate: 0.00481, Loss: 0.2255, Accuracy:0.891\nIteration: 16557, learning rate: 0.00481, Loss: 0.1048, Accuracy:0.961\nIteration: 16558, learning rate: 0.00481, Loss: 0.1457, Accuracy:0.930\nIteration: 16559, learning rate: 0.00481, Loss: 0.0845, Accuracy:0.984\nIteration: 16560, learning rate: 0.00481, Loss: 0.1178, Accuracy:0.938\nIteration: 16561, learning rate: 0.00481, Loss: 0.1195, Accuracy:0.945\nIteration: 16562, learning rate: 0.00481, Loss: 0.0940, Accuracy:0.961\nIteration: 16563, learning rate: 0.00481, Loss: 0.1706, Accuracy:0.922\nIteration: 16564, learning rate: 0.00481, Loss: 0.1571, Accuracy:0.930\nIteration: 16565, learning rate: 0.00481, Loss: 0.2010, Accuracy:0.930\nIteration: 16566, learning rate: 0.00481, Loss: 0.1608, Accuracy:0.930\nIteration: 16567, learning rate: 0.00481, Loss: 0.1524, Accuracy:0.930\nIteration: 16568, learning rate: 0.00481, Loss: 0.1148, Accuracy:0.977\nIteration: 16569, learning rate: 0.00481, Loss: 0.1535, Accuracy:0.938\nIteration: 16570, learning rate: 0.00481, Loss: 0.0995, Accuracy:0.961\nIteration: 16571, learning rate: 0.00481, Loss: 0.1330, Accuracy:0.945\nIteration: 16572, learning rate: 0.00481, Loss: 0.1378, Accuracy:0.953\nIteration: 16573, learning rate: 0.00480, Loss: 0.1333, Accuracy:0.961\nIteration: 16574, learning rate: 0.00480, Loss: 0.0717, Accuracy:0.977\nIteration: 16575, learning rate: 0.00480, Loss: 0.1568, Accuracy:0.930\nIteration: 16576, learning rate: 0.00480, Loss: 0.1030, Accuracy:0.969\nIteration: 16577, learning rate: 0.00480, Loss: 0.1686, Accuracy:0.945\nIteration: 16578, learning rate: 0.00480, Loss: 0.1103, Accuracy:0.969\nIteration: 16579, learning rate: 0.00480, Loss: 0.0611, Accuracy:0.977\nIteration: 16580, learning rate: 0.00480, Loss: 0.1524, Accuracy:0.922\nIteration: 16581, learning rate: 0.00480, Loss: 0.1016, Accuracy:0.969\nIteration: 16582, learning rate: 0.00480, Loss: 0.1154, Accuracy:0.945\nIteration: 16583, learning rate: 0.00480, Loss: 0.1389, Accuracy:0.945\nIteration: 16584, learning rate: 0.00480, Loss: 0.1049, Accuracy:0.969\nIteration: 16585, learning rate: 0.00480, Loss: 0.1670, Accuracy:0.914\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 535, Loss: 0.1314, Accuracy:0.947, Val Loss: 0.3118, Val Accuracy: 0.878\nIteration: 16586, learning rate: 0.00480, Loss: 0.1061, Accuracy:0.969\nIteration: 16587, learning rate: 0.00480, Loss: 0.1078, Accuracy:0.969\nIteration: 16588, learning rate: 0.00480, Loss: 0.1427, Accuracy:0.953\nIteration: 16589, learning rate: 0.00480, Loss: 0.1250, Accuracy:0.938\nIteration: 16590, learning rate: 0.00480, Loss: 0.1654, Accuracy:0.930\nIteration: 16591, learning rate: 0.00480, Loss: 0.1538, Accuracy:0.945\nIteration: 16592, learning rate: 0.00480, Loss: 0.1297, Accuracy:0.938\nIteration: 16593, learning rate: 0.00480, Loss: 0.2162, Accuracy:0.930\nIteration: 16594, learning rate: 0.00480, Loss: 0.1424, Accuracy:0.953\nIteration: 16595, learning rate: 0.00480, Loss: 0.1145, Accuracy:0.953\nIteration: 16596, learning rate: 0.00480, Loss: 0.1383, Accuracy:0.953\nIteration: 16597, learning rate: 0.00480, Loss: 0.1698, Accuracy:0.922\nIteration: 16598, learning rate: 0.00480, Loss: 0.1497, Accuracy:0.938\nIteration: 16599, learning rate: 0.00480, Loss: 0.2197, Accuracy:0.938\nIteration: 16600, learning rate: 0.00480, Loss: 0.1339, Accuracy:0.953\nIteration: 16601, learning rate: 0.00480, Loss: 0.1849, Accuracy:0.914\nIteration: 16602, learning rate: 0.00480, Loss: 0.1330, Accuracy:0.953\nIteration: 16603, learning rate: 0.00480, Loss: 0.1414, Accuracy:0.930\nIteration: 16604, learning rate: 0.00480, Loss: 0.1396, Accuracy:0.930\nIteration: 16605, learning rate: 0.00480, Loss: 0.0890, Accuracy:0.953\nIteration: 16606, learning rate: 0.00480, Loss: 0.1805, Accuracy:0.938\nIteration: 16607, learning rate: 0.00480, Loss: 0.0780, Accuracy:0.977\nIteration: 16608, learning rate: 0.00480, Loss: 0.1066, Accuracy:0.961\nIteration: 16609, learning rate: 0.00480, Loss: 0.1693, Accuracy:0.938\nIteration: 16610, learning rate: 0.00480, Loss: 0.1426, Accuracy:0.922\nIteration: 16611, learning rate: 0.00480, Loss: 0.1116, Accuracy:0.961\nIteration: 16612, learning rate: 0.00480, Loss: 0.0862, Accuracy:0.977\nIteration: 16613, learning rate: 0.00480, Loss: 0.1623, Accuracy:0.922\nIteration: 16614, learning rate: 0.00480, Loss: 0.1287, Accuracy:0.945\nIteration: 16615, learning rate: 0.00480, Loss: 0.1806, Accuracy:0.945\nIteration: 16616, learning rate: 0.00480, Loss: 0.2175, Accuracy:0.903\nEpoch: 536, Loss: 0.1441, Accuracy:0.943, Val Loss: 0.2634, Val Accuracy: 0.892\nIteration: 16617, learning rate: 0.00480, Loss: 0.1461, Accuracy:0.945\nIteration: 16618, learning rate: 0.00480, Loss: 0.1365, Accuracy:0.969\nIteration: 16619, learning rate: 0.00480, Loss: 0.1208, Accuracy:0.953\nIteration: 16620, learning rate: 0.00480, Loss: 0.1166, Accuracy:0.953\nIteration: 16621, learning rate: 0.00480, Loss: 0.1438, Accuracy:0.953\nIteration: 16622, learning rate: 0.00480, Loss: 0.1334, Accuracy:0.953\nIteration: 16623, learning rate: 0.00480, Loss: 0.1013, Accuracy:0.961\nIteration: 16624, learning rate: 0.00480, Loss: 0.0972, Accuracy:0.969\nIteration: 16625, learning rate: 0.00480, Loss: 0.1427, Accuracy:0.922\nIteration: 16626, learning rate: 0.00480, Loss: 0.1002, Accuracy:0.969\nIteration: 16627, learning rate: 0.00480, Loss: 0.1073, Accuracy:0.961\nIteration: 16628, learning rate: 0.00480, Loss: 0.1559, Accuracy:0.938\nIteration: 16629, learning rate: 0.00480, Loss: 0.2044, Accuracy:0.906\nIteration: 16630, learning rate: 0.00480, Loss: 0.1639, Accuracy:0.938\nIteration: 16631, learning rate: 0.00480, Loss: 0.0730, Accuracy:0.961\nIteration: 16632, learning rate: 0.00480, Loss: 0.1987, Accuracy:0.914\nIteration: 16633, learning rate: 0.00480, Loss: 0.1056, Accuracy:0.953\nIteration: 16634, learning rate: 0.00480, Loss: 0.0998, Accuracy:0.969\nIteration: 16635, learning rate: 0.00480, Loss: 0.1064, Accuracy:0.945\nIteration: 16636, learning rate: 0.00480, Loss: 0.1991, Accuracy:0.906\nIteration: 16637, learning rate: 0.00480, Loss: 0.1408, Accuracy:0.953\nIteration: 16638, learning rate: 0.00480, Loss: 0.0967, Accuracy:0.961\nIteration: 16639, learning rate: 0.00480, Loss: 0.1966, Accuracy:0.922\nIteration: 16640, learning rate: 0.00480, Loss: 0.2146, Accuracy:0.906\nIteration: 16641, learning rate: 0.00480, Loss: 0.1365, Accuracy:0.945\nIteration: 16642, learning rate: 0.00480, Loss: 0.1704, Accuracy:0.945\nIteration: 16643, learning rate: 0.00480, Loss: 0.0688, Accuracy:0.977\nIteration: 16644, learning rate: 0.00480, Loss: 0.1228, Accuracy:0.945\nIteration: 16645, learning rate: 0.00480, Loss: 0.0661, Accuracy:0.977\nIteration: 16646, learning rate: 0.00479, Loss: 0.1331, Accuracy:0.953\nIteration: 16647, learning rate: 0.00479, Loss: 0.1625, Accuracy:0.925\nEpoch: 537, Loss: 0.1342, Accuracy:0.947, Val Loss: 0.2878, Val Accuracy: 0.881\nIteration: 16648, learning rate: 0.00479, Loss: 0.0954, Accuracy:0.969\nIteration: 16649, learning rate: 0.00479, Loss: 0.1118, Accuracy:0.961\nIteration: 16650, learning rate: 0.00479, Loss: 0.1203, Accuracy:0.969\nIteration: 16651, learning rate: 0.00479, Loss: 0.1530, Accuracy:0.953\nIteration: 16652, learning rate: 0.00479, Loss: 0.1653, Accuracy:0.914\nIteration: 16653, learning rate: 0.00479, Loss: 0.1458, Accuracy:0.961\nIteration: 16654, learning rate: 0.00479, Loss: 0.1497, Accuracy:0.930\nIteration: 16655, learning rate: 0.00479, Loss: 0.2255, Accuracy:0.914\nIteration: 16656, learning rate: 0.00479, Loss: 0.1630, Accuracy:0.938\nIteration: 16657, learning rate: 0.00479, Loss: 0.1582, Accuracy:0.922\nIteration: 16658, learning rate: 0.00479, Loss: 0.1174, Accuracy:0.945\nIteration: 16659, learning rate: 0.00479, Loss: 0.1334, Accuracy:0.930\nIteration: 16660, learning rate: 0.00479, Loss: 0.1460, Accuracy:0.930\nIteration: 16661, learning rate: 0.00479, Loss: 0.0802, Accuracy:0.961\nIteration: 16662, learning rate: 0.00479, Loss: 0.1587, Accuracy:0.945\nIteration: 16663, learning rate: 0.00479, Loss: 0.1635, Accuracy:0.945\nIteration: 16664, learning rate: 0.00479, Loss: 0.1170, Accuracy:0.945\nIteration: 16665, learning rate: 0.00479, Loss: 0.0894, Accuracy:0.961\nIteration: 16666, learning rate: 0.00479, Loss: 0.2404, Accuracy:0.914\nIteration: 16667, learning rate: 0.00479, Loss: 0.1013, Accuracy:0.953\nIteration: 16668, learning rate: 0.00479, Loss: 0.0959, Accuracy:0.977\nIteration: 16669, learning rate: 0.00479, Loss: 0.0676, Accuracy:0.977\nIteration: 16670, learning rate: 0.00479, Loss: 0.0808, Accuracy:0.977\nIteration: 16671, learning rate: 0.00479, Loss: 0.2467, Accuracy:0.914\nIteration: 16672, learning rate: 0.00479, Loss: 0.1165, Accuracy:0.961\nIteration: 16673, learning rate: 0.00479, Loss: 0.0842, Accuracy:0.961\nIteration: 16674, learning rate: 0.00479, Loss: 0.1678, Accuracy:0.945\nIteration: 16675, learning rate: 0.00479, Loss: 0.1600, Accuracy:0.938\nIteration: 16676, learning rate: 0.00479, Loss: 0.1195, Accuracy:0.961\nIteration: 16677, learning rate: 0.00479, Loss: 0.0664, Accuracy:0.984\nIteration: 16678, learning rate: 0.00479, Loss: 0.1632, Accuracy:0.946\nEpoch: 538, Loss: 0.1356, Accuracy:0.948, Val Loss: 0.3540, Val Accuracy: 0.847\nIteration: 16679, learning rate: 0.00479, Loss: 0.1761, Accuracy:0.945\nIteration: 16680, learning rate: 0.00479, Loss: 0.1150, Accuracy:0.961\nIteration: 16681, learning rate: 0.00479, Loss: 0.1200, Accuracy:0.961\nIteration: 16682, learning rate: 0.00479, Loss: 0.1219, Accuracy:0.953\nIteration: 16683, learning rate: 0.00479, Loss: 0.1839, Accuracy:0.914\nIteration: 16684, learning rate: 0.00479, Loss: 0.1562, Accuracy:0.930\nIteration: 16685, learning rate: 0.00479, Loss: 0.1387, Accuracy:0.953\nIteration: 16686, learning rate: 0.00479, Loss: 0.1162, Accuracy:0.953\nIteration: 16687, learning rate: 0.00479, Loss: 0.0728, Accuracy:0.977\nIteration: 16688, learning rate: 0.00479, Loss: 0.0918, Accuracy:0.953\nIteration: 16689, learning rate: 0.00479, Loss: 0.1650, Accuracy:0.914\nIteration: 16690, learning rate: 0.00479, Loss: 0.1014, Accuracy:0.969\nIteration: 16691, learning rate: 0.00479, Loss: 0.1235, Accuracy:0.953\nIteration: 16692, learning rate: 0.00479, Loss: 0.0890, Accuracy:0.969\nIteration: 16693, learning rate: 0.00479, Loss: 0.1965, Accuracy:0.953\nIteration: 16694, learning rate: 0.00479, Loss: 0.1787, Accuracy:0.938\nIteration: 16695, learning rate: 0.00479, Loss: 0.0872, Accuracy:0.969\nIteration: 16696, learning rate: 0.00479, Loss: 0.1204, Accuracy:0.961\nIteration: 16697, learning rate: 0.00479, Loss: 0.2254, Accuracy:0.891\nIteration: 16698, learning rate: 0.00479, Loss: 0.1144, Accuracy:0.969\nIteration: 16699, learning rate: 0.00479, Loss: 0.0705, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16700, learning rate: 0.00479, Loss: 0.2063, Accuracy:0.906\nIteration: 16701, learning rate: 0.00479, Loss: 0.0936, Accuracy:0.969\nIteration: 16702, learning rate: 0.00479, Loss: 0.1470, Accuracy:0.953\nIteration: 16703, learning rate: 0.00479, Loss: 0.0971, Accuracy:0.961\nIteration: 16704, learning rate: 0.00479, Loss: 0.1177, Accuracy:0.938\nIteration: 16705, learning rate: 0.00479, Loss: 0.1088, Accuracy:0.945\nIteration: 16706, learning rate: 0.00479, Loss: 0.1920, Accuracy:0.914\nIteration: 16707, learning rate: 0.00479, Loss: 0.1152, Accuracy:0.961\nIteration: 16708, learning rate: 0.00479, Loss: 0.1069, Accuracy:0.961\nIteration: 16709, learning rate: 0.00479, Loss: 0.0949, Accuracy:0.957\nEpoch: 539, Loss: 0.1305, Accuracy:0.949, Val Loss: 0.2795, Val Accuracy: 0.898\nIteration: 16710, learning rate: 0.00479, Loss: 0.1164, Accuracy:0.961\nIteration: 16711, learning rate: 0.00479, Loss: 0.1196, Accuracy:0.969\nIteration: 16712, learning rate: 0.00479, Loss: 0.0798, Accuracy:0.969\nIteration: 16713, learning rate: 0.00479, Loss: 0.1892, Accuracy:0.938\nIteration: 16714, learning rate: 0.00479, Loss: 0.0747, Accuracy:0.953\nIteration: 16715, learning rate: 0.00479, Loss: 0.0994, Accuracy:0.961\nIteration: 16716, learning rate: 0.00479, Loss: 0.0888, Accuracy:0.977\nIteration: 16717, learning rate: 0.00479, Loss: 0.1634, Accuracy:0.961\nIteration: 16718, learning rate: 0.00479, Loss: 0.0877, Accuracy:0.961\nIteration: 16719, learning rate: 0.00479, Loss: 0.1000, Accuracy:0.953\nIteration: 16720, learning rate: 0.00479, Loss: 0.1340, Accuracy:0.938\nIteration: 16721, learning rate: 0.00478, Loss: 0.1056, Accuracy:0.953\nIteration: 16722, learning rate: 0.00478, Loss: 0.1001, Accuracy:0.969\nIteration: 16723, learning rate: 0.00478, Loss: 0.1319, Accuracy:0.945\nIteration: 16724, learning rate: 0.00478, Loss: 0.1126, Accuracy:0.938\nIteration: 16725, learning rate: 0.00478, Loss: 0.1059, Accuracy:0.969\nIteration: 16726, learning rate: 0.00478, Loss: 0.1800, Accuracy:0.930\nIteration: 16727, learning rate: 0.00478, Loss: 0.1664, Accuracy:0.922\nIteration: 16728, learning rate: 0.00478, Loss: 0.1473, Accuracy:0.930\nIteration: 16729, learning rate: 0.00478, Loss: 0.1562, Accuracy:0.953\nIteration: 16730, learning rate: 0.00478, Loss: 0.1609, Accuracy:0.945\nIteration: 16731, learning rate: 0.00478, Loss: 0.1452, Accuracy:0.945\nIteration: 16732, learning rate: 0.00478, Loss: 0.1979, Accuracy:0.938\nIteration: 16733, learning rate: 0.00478, Loss: 0.1233, Accuracy:0.953\nIteration: 16734, learning rate: 0.00478, Loss: 0.1169, Accuracy:0.977\nIteration: 16735, learning rate: 0.00478, Loss: 0.1657, Accuracy:0.922\nIteration: 16736, learning rate: 0.00478, Loss: 0.1314, Accuracy:0.953\nIteration: 16737, learning rate: 0.00478, Loss: 0.1033, Accuracy:0.961\nIteration: 16738, learning rate: 0.00478, Loss: 0.1025, Accuracy:0.977\nIteration: 16739, learning rate: 0.00478, Loss: 0.1036, Accuracy:0.938\nIteration: 16740, learning rate: 0.00478, Loss: 0.1128, Accuracy:0.978\nEpoch: 540, Loss: 0.1265, Accuracy:0.953, Val Loss: 0.2898, Val Accuracy: 0.887\nIteration: 16741, learning rate: 0.00478, Loss: 0.1762, Accuracy:0.922\nIteration: 16742, learning rate: 0.00478, Loss: 0.0897, Accuracy:0.969\nIteration: 16743, learning rate: 0.00478, Loss: 0.0784, Accuracy:0.969\nIteration: 16744, learning rate: 0.00478, Loss: 0.2744, Accuracy:0.891\nIteration: 16745, learning rate: 0.00478, Loss: 0.1622, Accuracy:0.953\nIteration: 16746, learning rate: 0.00478, Loss: 0.1391, Accuracy:0.938\nIteration: 16747, learning rate: 0.00478, Loss: 0.1457, Accuracy:0.914\nIteration: 16748, learning rate: 0.00478, Loss: 0.1258, Accuracy:0.953\nIteration: 16749, learning rate: 0.00478, Loss: 0.1071, Accuracy:0.969\nIteration: 16750, learning rate: 0.00478, Loss: 0.1046, Accuracy:0.961\nIteration: 16751, learning rate: 0.00478, Loss: 0.0946, Accuracy:0.969\nIteration: 16752, learning rate: 0.00478, Loss: 0.0923, Accuracy:0.961\nIteration: 16753, learning rate: 0.00478, Loss: 0.0965, Accuracy:0.961\nIteration: 16754, learning rate: 0.00478, Loss: 0.0918, Accuracy:0.969\nIteration: 16755, learning rate: 0.00478, Loss: 0.1149, Accuracy:0.969\nIteration: 16756, learning rate: 0.00478, Loss: 0.0964, Accuracy:0.945\nIteration: 16757, learning rate: 0.00478, Loss: 0.1440, Accuracy:0.922\nIteration: 16758, learning rate: 0.00478, Loss: 0.1566, Accuracy:0.930\nIteration: 16759, learning rate: 0.00478, Loss: 0.1163, Accuracy:0.961\nIteration: 16760, learning rate: 0.00478, Loss: 0.1155, Accuracy:0.961\nIteration: 16761, learning rate: 0.00478, Loss: 0.2020, Accuracy:0.938\nIteration: 16762, learning rate: 0.00478, Loss: 0.1635, Accuracy:0.953\nIteration: 16763, learning rate: 0.00478, Loss: 0.0974, Accuracy:0.953\nIteration: 16764, learning rate: 0.00478, Loss: 0.1650, Accuracy:0.945\nIteration: 16765, learning rate: 0.00478, Loss: 0.1530, Accuracy:0.938\nIteration: 16766, learning rate: 0.00478, Loss: 0.1485, Accuracy:0.938\nIteration: 16767, learning rate: 0.00478, Loss: 0.1832, Accuracy:0.938\nIteration: 16768, learning rate: 0.00478, Loss: 0.1251, Accuracy:0.945\nIteration: 16769, learning rate: 0.00478, Loss: 0.1239, Accuracy:0.938\nIteration: 16770, learning rate: 0.00478, Loss: 0.1850, Accuracy:0.922\nIteration: 16771, learning rate: 0.00478, Loss: 0.1588, Accuracy:0.946\nEpoch: 541, Loss: 0.1364, Accuracy:0.946, Val Loss: 0.2827, Val Accuracy: 0.898\nIteration: 16772, learning rate: 0.00478, Loss: 0.2038, Accuracy:0.906\nIteration: 16773, learning rate: 0.00478, Loss: 0.1306, Accuracy:0.945\nIteration: 16774, learning rate: 0.00478, Loss: 0.1533, Accuracy:0.922\nIteration: 16775, learning rate: 0.00478, Loss: 0.1640, Accuracy:0.945\nIteration: 16776, learning rate: 0.00478, Loss: 0.1412, Accuracy:0.930\nIteration: 16777, learning rate: 0.00478, Loss: 0.1385, Accuracy:0.969\nIteration: 16778, learning rate: 0.00478, Loss: 0.1041, Accuracy:0.953\nIteration: 16779, learning rate: 0.00478, Loss: 0.0963, Accuracy:0.969\nIteration: 16780, learning rate: 0.00478, Loss: 0.0896, Accuracy:0.984\nIteration: 16781, learning rate: 0.00478, Loss: 0.1081, Accuracy:0.961\nIteration: 16782, learning rate: 0.00478, Loss: 0.2279, Accuracy:0.930\nIteration: 16783, learning rate: 0.00478, Loss: 0.1436, Accuracy:0.945\nIteration: 16784, learning rate: 0.00478, Loss: 0.1489, Accuracy:0.930\nIteration: 16785, learning rate: 0.00478, Loss: 0.1728, Accuracy:0.922\nIteration: 16786, learning rate: 0.00478, Loss: 0.1297, Accuracy:0.953\nIteration: 16787, learning rate: 0.00478, Loss: 0.1487, Accuracy:0.930\nIteration: 16788, learning rate: 0.00478, Loss: 0.0745, Accuracy:0.984\nIteration: 16789, learning rate: 0.00478, Loss: 0.1144, Accuracy:0.961\nIteration: 16790, learning rate: 0.00478, Loss: 0.1359, Accuracy:0.953\nIteration: 16791, learning rate: 0.00478, Loss: 0.1259, Accuracy:0.953\nIteration: 16792, learning rate: 0.00478, Loss: 0.0522, Accuracy:0.977\nIteration: 16793, learning rate: 0.00478, Loss: 0.1208, Accuracy:0.969\nIteration: 16794, learning rate: 0.00478, Loss: 0.1374, Accuracy:0.953\nIteration: 16795, learning rate: 0.00477, Loss: 0.0759, Accuracy:0.984\nIteration: 16796, learning rate: 0.00477, Loss: 0.1115, Accuracy:0.953\nIteration: 16797, learning rate: 0.00477, Loss: 0.1334, Accuracy:0.945\nIteration: 16798, learning rate: 0.00477, Loss: 0.0771, Accuracy:0.977\nIteration: 16799, learning rate: 0.00477, Loss: 0.1147, Accuracy:0.969\nIteration: 16800, learning rate: 0.00477, Loss: 0.1917, Accuracy:0.906\nIteration: 16801, learning rate: 0.00477, Loss: 0.1652, Accuracy:0.945\nIteration: 16802, learning rate: 0.00477, Loss: 0.1285, Accuracy:0.957\nEpoch: 542, Loss: 0.1310, Accuracy:0.951, Val Loss: 0.2900, Val Accuracy: 0.891\nIteration: 16803, learning rate: 0.00477, Loss: 0.1321, Accuracy:0.953\nIteration: 16804, learning rate: 0.00477, Loss: 0.0883, Accuracy:0.961\nIteration: 16805, learning rate: 0.00477, Loss: 0.2046, Accuracy:0.938\nIteration: 16806, learning rate: 0.00477, Loss: 0.1424, Accuracy:0.961\nIteration: 16807, learning rate: 0.00477, Loss: 0.0716, Accuracy:0.984\nIteration: 16808, learning rate: 0.00477, Loss: 0.1057, Accuracy:0.969\nIteration: 16809, learning rate: 0.00477, Loss: 0.1454, Accuracy:0.938\nIteration: 16810, learning rate: 0.00477, Loss: 0.1318, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16811, learning rate: 0.00477, Loss: 0.1636, Accuracy:0.906\nIteration: 16812, learning rate: 0.00477, Loss: 0.1310, Accuracy:0.938\nIteration: 16813, learning rate: 0.00477, Loss: 0.0982, Accuracy:0.953\nIteration: 16814, learning rate: 0.00477, Loss: 0.1878, Accuracy:0.938\nIteration: 16815, learning rate: 0.00477, Loss: 0.1427, Accuracy:0.945\nIteration: 16816, learning rate: 0.00477, Loss: 0.1242, Accuracy:0.945\nIteration: 16817, learning rate: 0.00477, Loss: 0.1202, Accuracy:0.977\nIteration: 16818, learning rate: 0.00477, Loss: 0.0832, Accuracy:0.969\nIteration: 16819, learning rate: 0.00477, Loss: 0.1142, Accuracy:0.961\nIteration: 16820, learning rate: 0.00477, Loss: 0.1725, Accuracy:0.945\nIteration: 16821, learning rate: 0.00477, Loss: 0.1833, Accuracy:0.938\nIteration: 16822, learning rate: 0.00477, Loss: 0.1497, Accuracy:0.945\nIteration: 16823, learning rate: 0.00477, Loss: 0.1575, Accuracy:0.906\nIteration: 16824, learning rate: 0.00477, Loss: 0.1090, Accuracy:0.961\nIteration: 16825, learning rate: 0.00477, Loss: 0.1250, Accuracy:0.953\nIteration: 16826, learning rate: 0.00477, Loss: 0.1305, Accuracy:0.953\nIteration: 16827, learning rate: 0.00477, Loss: 0.1433, Accuracy:0.945\nIteration: 16828, learning rate: 0.00477, Loss: 0.1659, Accuracy:0.953\nIteration: 16829, learning rate: 0.00477, Loss: 0.1131, Accuracy:0.969\nIteration: 16830, learning rate: 0.00477, Loss: 0.1429, Accuracy:0.938\nIteration: 16831, learning rate: 0.00477, Loss: 0.1554, Accuracy:0.938\nIteration: 16832, learning rate: 0.00477, Loss: 0.1030, Accuracy:0.945\nIteration: 16833, learning rate: 0.00477, Loss: 0.0950, Accuracy:0.978\nEpoch: 543, Loss: 0.1333, Accuracy:0.950, Val Loss: 0.3245, Val Accuracy: 0.875\nIteration: 16834, learning rate: 0.00477, Loss: 0.0735, Accuracy:0.977\nIteration: 16835, learning rate: 0.00477, Loss: 0.0997, Accuracy:0.961\nIteration: 16836, learning rate: 0.00477, Loss: 0.0982, Accuracy:0.961\nIteration: 16837, learning rate: 0.00477, Loss: 0.0840, Accuracy:0.969\nIteration: 16838, learning rate: 0.00477, Loss: 0.0940, Accuracy:0.969\nIteration: 16839, learning rate: 0.00477, Loss: 0.0647, Accuracy:0.977\nIteration: 16840, learning rate: 0.00477, Loss: 0.1524, Accuracy:0.945\nIteration: 16841, learning rate: 0.00477, Loss: 0.0871, Accuracy:0.984\nIteration: 16842, learning rate: 0.00477, Loss: 0.1482, Accuracy:0.938\nIteration: 16843, learning rate: 0.00477, Loss: 0.1182, Accuracy:0.961\nIteration: 16844, learning rate: 0.00477, Loss: 0.0961, Accuracy:0.969\nIteration: 16845, learning rate: 0.00477, Loss: 0.1859, Accuracy:0.922\nIteration: 16846, learning rate: 0.00477, Loss: 0.1203, Accuracy:0.961\nIteration: 16847, learning rate: 0.00477, Loss: 0.1932, Accuracy:0.938\nIteration: 16848, learning rate: 0.00477, Loss: 0.1068, Accuracy:0.977\nIteration: 16849, learning rate: 0.00477, Loss: 0.1153, Accuracy:0.961\nIteration: 16850, learning rate: 0.00477, Loss: 0.1564, Accuracy:0.961\nIteration: 16851, learning rate: 0.00477, Loss: 0.0579, Accuracy:0.984\nIteration: 16852, learning rate: 0.00477, Loss: 0.1080, Accuracy:0.953\nIteration: 16853, learning rate: 0.00477, Loss: 0.1508, Accuracy:0.938\nIteration: 16854, learning rate: 0.00477, Loss: 0.1473, Accuracy:0.945\nIteration: 16855, learning rate: 0.00477, Loss: 0.1173, Accuracy:0.945\nIteration: 16856, learning rate: 0.00477, Loss: 0.1649, Accuracy:0.969\nIteration: 16857, learning rate: 0.00477, Loss: 0.1447, Accuracy:0.945\nIteration: 16858, learning rate: 0.00477, Loss: 0.1881, Accuracy:0.938\nIteration: 16859, learning rate: 0.00477, Loss: 0.1281, Accuracy:0.945\nIteration: 16860, learning rate: 0.00477, Loss: 0.1855, Accuracy:0.938\nIteration: 16861, learning rate: 0.00477, Loss: 0.0663, Accuracy:0.992\nIteration: 16862, learning rate: 0.00477, Loss: 0.1236, Accuracy:0.945\nIteration: 16863, learning rate: 0.00477, Loss: 0.1453, Accuracy:0.930\nIteration: 16864, learning rate: 0.00477, Loss: 0.1296, Accuracy:0.946\nEpoch: 544, Loss: 0.1242, Accuracy:0.956, Val Loss: 0.3292, Val Accuracy: 0.865\nIteration: 16865, learning rate: 0.00477, Loss: 0.0945, Accuracy:0.969\nIteration: 16866, learning rate: 0.00477, Loss: 0.0997, Accuracy:0.961\nIteration: 16867, learning rate: 0.00477, Loss: 0.0844, Accuracy:0.992\nIteration: 16868, learning rate: 0.00477, Loss: 0.1077, Accuracy:0.945\nIteration: 16869, learning rate: 0.00477, Loss: 0.1269, Accuracy:0.953\nIteration: 16870, learning rate: 0.00476, Loss: 0.0616, Accuracy:0.984\nIteration: 16871, learning rate: 0.00476, Loss: 0.0728, Accuracy:0.969\nIteration: 16872, learning rate: 0.00476, Loss: 0.1402, Accuracy:0.953\nIteration: 16873, learning rate: 0.00476, Loss: 0.1112, Accuracy:0.953\nIteration: 16874, learning rate: 0.00476, Loss: 0.1332, Accuracy:0.945\nIteration: 16875, learning rate: 0.00476, Loss: 0.1624, Accuracy:0.945\nIteration: 16876, learning rate: 0.00476, Loss: 0.0574, Accuracy:0.992\nIteration: 16877, learning rate: 0.00476, Loss: 0.1169, Accuracy:0.953\nIteration: 16878, learning rate: 0.00476, Loss: 0.0910, Accuracy:0.977\nIteration: 16879, learning rate: 0.00476, Loss: 0.0758, Accuracy:0.977\nIteration: 16880, learning rate: 0.00476, Loss: 0.1329, Accuracy:0.953\nIteration: 16881, learning rate: 0.00476, Loss: 0.0975, Accuracy:0.953\nIteration: 16882, learning rate: 0.00476, Loss: 0.1629, Accuracy:0.938\nIteration: 16883, learning rate: 0.00476, Loss: 0.1166, Accuracy:0.961\nIteration: 16884, learning rate: 0.00476, Loss: 0.1188, Accuracy:0.961\nIteration: 16885, learning rate: 0.00476, Loss: 0.1174, Accuracy:0.961\nIteration: 16886, learning rate: 0.00476, Loss: 0.0760, Accuracy:0.984\nIteration: 16887, learning rate: 0.00476, Loss: 0.1152, Accuracy:0.961\nIteration: 16888, learning rate: 0.00476, Loss: 0.1347, Accuracy:0.930\nIteration: 16889, learning rate: 0.00476, Loss: 0.1688, Accuracy:0.953\nIteration: 16890, learning rate: 0.00476, Loss: 0.1046, Accuracy:0.953\nIteration: 16891, learning rate: 0.00476, Loss: 0.1959, Accuracy:0.922\nIteration: 16892, learning rate: 0.00476, Loss: 0.0984, Accuracy:0.953\nIteration: 16893, learning rate: 0.00476, Loss: 0.1000, Accuracy:0.984\nIteration: 16894, learning rate: 0.00476, Loss: 0.1793, Accuracy:0.938\nIteration: 16895, learning rate: 0.00476, Loss: 0.1057, Accuracy:0.957\nEpoch: 545, Loss: 0.1149, Accuracy:0.959, Val Loss: 0.3007, Val Accuracy: 0.886\nIteration: 16896, learning rate: 0.00476, Loss: 0.1792, Accuracy:0.938\nIteration: 16897, learning rate: 0.00476, Loss: 0.0773, Accuracy:0.977\nIteration: 16898, learning rate: 0.00476, Loss: 0.2672, Accuracy:0.898\nIteration: 16899, learning rate: 0.00476, Loss: 0.1694, Accuracy:0.961\nIteration: 16900, learning rate: 0.00476, Loss: 0.0816, Accuracy:0.961\nIteration: 16901, learning rate: 0.00476, Loss: 0.0912, Accuracy:0.961\nIteration: 16902, learning rate: 0.00476, Loss: 0.1509, Accuracy:0.938\nIteration: 16903, learning rate: 0.00476, Loss: 0.1616, Accuracy:0.945\nIteration: 16904, learning rate: 0.00476, Loss: 0.1181, Accuracy:0.953\nIteration: 16905, learning rate: 0.00476, Loss: 0.1027, Accuracy:0.953\nIteration: 16906, learning rate: 0.00476, Loss: 0.0915, Accuracy:0.977\nIteration: 16907, learning rate: 0.00476, Loss: 0.0682, Accuracy:0.984\nIteration: 16908, learning rate: 0.00476, Loss: 0.0789, Accuracy:0.977\nIteration: 16909, learning rate: 0.00476, Loss: 0.1436, Accuracy:0.953\nIteration: 16910, learning rate: 0.00476, Loss: 0.0798, Accuracy:0.992\nIteration: 16911, learning rate: 0.00476, Loss: 0.1245, Accuracy:0.961\nIteration: 16912, learning rate: 0.00476, Loss: 0.2079, Accuracy:0.906\nIteration: 16913, learning rate: 0.00476, Loss: 0.1581, Accuracy:0.938\nIteration: 16914, learning rate: 0.00476, Loss: 0.1625, Accuracy:0.938\nIteration: 16915, learning rate: 0.00476, Loss: 0.1088, Accuracy:0.969\nIteration: 16916, learning rate: 0.00476, Loss: 0.1012, Accuracy:0.961\nIteration: 16917, learning rate: 0.00476, Loss: 0.1257, Accuracy:0.961\nIteration: 16918, learning rate: 0.00476, Loss: 0.1069, Accuracy:0.953\nIteration: 16919, learning rate: 0.00476, Loss: 0.1009, Accuracy:0.953\nIteration: 16920, learning rate: 0.00476, Loss: 0.1117, Accuracy:0.953\nIteration: 16921, learning rate: 0.00476, Loss: 0.1335, Accuracy:0.945\nIteration: 16922, learning rate: 0.00476, Loss: 0.1252, Accuracy:0.961\nIteration: 16923, learning rate: 0.00476, Loss: 0.1286, Accuracy:0.945\nIteration: 16924, learning rate: 0.00476, Loss: 0.0946, Accuracy:0.969\nIteration: 16925, learning rate: 0.00476, Loss: 0.1554, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 16926, learning rate: 0.00476, Loss: 0.1064, Accuracy:0.946\nEpoch: 546, Loss: 0.1262, Accuracy:0.954, Val Loss: 0.2741, Val Accuracy: 0.897\nIteration: 16927, learning rate: 0.00476, Loss: 0.1625, Accuracy:0.930\nIteration: 16928, learning rate: 0.00476, Loss: 0.1132, Accuracy:0.953\nIteration: 16929, learning rate: 0.00476, Loss: 0.2269, Accuracy:0.930\nIteration: 16930, learning rate: 0.00476, Loss: 0.1902, Accuracy:0.922\nIteration: 16931, learning rate: 0.00476, Loss: 0.0858, Accuracy:0.984\nIteration: 16932, learning rate: 0.00476, Loss: 0.0662, Accuracy:0.969\nIteration: 16933, learning rate: 0.00476, Loss: 0.1771, Accuracy:0.922\nIteration: 16934, learning rate: 0.00476, Loss: 0.1541, Accuracy:0.969\nIteration: 16935, learning rate: 0.00476, Loss: 0.1317, Accuracy:0.945\nIteration: 16936, learning rate: 0.00476, Loss: 0.1283, Accuracy:0.945\nIteration: 16937, learning rate: 0.00476, Loss: 0.0836, Accuracy:0.953\nIteration: 16938, learning rate: 0.00476, Loss: 0.0678, Accuracy:0.992\nIteration: 16939, learning rate: 0.00476, Loss: 0.2087, Accuracy:0.898\nIteration: 16940, learning rate: 0.00476, Loss: 0.0986, Accuracy:0.969\nIteration: 16941, learning rate: 0.00476, Loss: 0.1063, Accuracy:0.953\nIteration: 16942, learning rate: 0.00476, Loss: 0.1161, Accuracy:0.953\nIteration: 16943, learning rate: 0.00476, Loss: 0.1657, Accuracy:0.930\nIteration: 16944, learning rate: 0.00476, Loss: 0.1452, Accuracy:0.953\nIteration: 16945, learning rate: 0.00476, Loss: 0.1079, Accuracy:0.961\nIteration: 16946, learning rate: 0.00475, Loss: 0.1074, Accuracy:0.969\nIteration: 16947, learning rate: 0.00475, Loss: 0.1381, Accuracy:0.945\nIteration: 16948, learning rate: 0.00475, Loss: 0.2036, Accuracy:0.945\nIteration: 16949, learning rate: 0.00475, Loss: 0.1431, Accuracy:0.953\nIteration: 16950, learning rate: 0.00475, Loss: 0.1447, Accuracy:0.953\nIteration: 16951, learning rate: 0.00475, Loss: 0.1058, Accuracy:0.969\nIteration: 16952, learning rate: 0.00475, Loss: 0.1721, Accuracy:0.930\nIteration: 16953, learning rate: 0.00475, Loss: 0.1055, Accuracy:0.945\nIteration: 16954, learning rate: 0.00475, Loss: 0.1186, Accuracy:0.961\nIteration: 16955, learning rate: 0.00475, Loss: 0.1922, Accuracy:0.914\nIteration: 16956, learning rate: 0.00475, Loss: 0.0728, Accuracy:0.977\nIteration: 16957, learning rate: 0.00475, Loss: 0.1718, Accuracy:0.935\nEpoch: 547, Loss: 0.1359, Accuracy:0.949, Val Loss: 0.3432, Val Accuracy: 0.857\nIteration: 16958, learning rate: 0.00475, Loss: 0.1691, Accuracy:0.938\nIteration: 16959, learning rate: 0.00475, Loss: 0.1546, Accuracy:0.938\nIteration: 16960, learning rate: 0.00475, Loss: 0.1285, Accuracy:0.953\nIteration: 16961, learning rate: 0.00475, Loss: 0.0871, Accuracy:0.969\nIteration: 16962, learning rate: 0.00475, Loss: 0.1074, Accuracy:0.953\nIteration: 16963, learning rate: 0.00475, Loss: 0.1251, Accuracy:0.961\nIteration: 16964, learning rate: 0.00475, Loss: 0.1785, Accuracy:0.930\nIteration: 16965, learning rate: 0.00475, Loss: 0.1035, Accuracy:0.977\nIteration: 16966, learning rate: 0.00475, Loss: 0.1245, Accuracy:0.961\nIteration: 16967, learning rate: 0.00475, Loss: 0.1492, Accuracy:0.945\nIteration: 16968, learning rate: 0.00475, Loss: 0.0937, Accuracy:0.969\nIteration: 16969, learning rate: 0.00475, Loss: 0.0974, Accuracy:0.969\nIteration: 16970, learning rate: 0.00475, Loss: 0.1235, Accuracy:0.961\nIteration: 16971, learning rate: 0.00475, Loss: 0.2133, Accuracy:0.906\nIteration: 16972, learning rate: 0.00475, Loss: 0.1535, Accuracy:0.922\nIteration: 16973, learning rate: 0.00475, Loss: 0.1210, Accuracy:0.961\nIteration: 16974, learning rate: 0.00475, Loss: 0.0697, Accuracy:0.984\nIteration: 16975, learning rate: 0.00475, Loss: 0.1110, Accuracy:0.945\nIteration: 16976, learning rate: 0.00475, Loss: 0.1117, Accuracy:0.953\nIteration: 16977, learning rate: 0.00475, Loss: 0.1068, Accuracy:0.961\nIteration: 16978, learning rate: 0.00475, Loss: 0.1239, Accuracy:0.953\nIteration: 16979, learning rate: 0.00475, Loss: 0.1124, Accuracy:0.969\nIteration: 16980, learning rate: 0.00475, Loss: 0.1371, Accuracy:0.922\nIteration: 16981, learning rate: 0.00475, Loss: 0.1159, Accuracy:0.953\nIteration: 16982, learning rate: 0.00475, Loss: 0.1438, Accuracy:0.961\nIteration: 16983, learning rate: 0.00475, Loss: 0.1180, Accuracy:0.961\nIteration: 16984, learning rate: 0.00475, Loss: 0.2107, Accuracy:0.914\nIteration: 16985, learning rate: 0.00475, Loss: 0.1905, Accuracy:0.906\nIteration: 16986, learning rate: 0.00475, Loss: 0.1574, Accuracy:0.930\nIteration: 16987, learning rate: 0.00475, Loss: 0.1325, Accuracy:0.930\nIteration: 16988, learning rate: 0.00475, Loss: 0.1098, Accuracy:0.946\nEpoch: 548, Loss: 0.1316, Accuracy:0.948, Val Loss: 0.3550, Val Accuracy: 0.868\nIteration: 16989, learning rate: 0.00475, Loss: 0.1811, Accuracy:0.930\nIteration: 16990, learning rate: 0.00475, Loss: 0.1859, Accuracy:0.922\nIteration: 16991, learning rate: 0.00475, Loss: 0.0859, Accuracy:0.984\nIteration: 16992, learning rate: 0.00475, Loss: 0.1508, Accuracy:0.953\nIteration: 16993, learning rate: 0.00475, Loss: 0.1240, Accuracy:0.945\nIteration: 16994, learning rate: 0.00475, Loss: 0.1045, Accuracy:0.969\nIteration: 16995, learning rate: 0.00475, Loss: 0.1084, Accuracy:0.953\nIteration: 16996, learning rate: 0.00475, Loss: 0.1322, Accuracy:0.938\nIteration: 16997, learning rate: 0.00475, Loss: 0.1735, Accuracy:0.914\nIteration: 16998, learning rate: 0.00475, Loss: 0.1328, Accuracy:0.945\nIteration: 16999, learning rate: 0.00475, Loss: 0.0849, Accuracy:0.977\nIteration: 17000, learning rate: 0.00475, Loss: 0.0997, Accuracy:0.961\nIteration: 17001, learning rate: 0.00475, Loss: 0.0879, Accuracy:0.961\nIteration: 17002, learning rate: 0.00475, Loss: 0.0827, Accuracy:0.969\nIteration: 17003, learning rate: 0.00475, Loss: 0.1212, Accuracy:0.945\nIteration: 17004, learning rate: 0.00475, Loss: 0.0810, Accuracy:0.977\nIteration: 17005, learning rate: 0.00475, Loss: 0.2023, Accuracy:0.914\nIteration: 17006, learning rate: 0.00475, Loss: 0.1871, Accuracy:0.938\nIteration: 17007, learning rate: 0.00475, Loss: 0.0758, Accuracy:0.977\nIteration: 17008, learning rate: 0.00475, Loss: 0.1052, Accuracy:0.961\nIteration: 17009, learning rate: 0.00475, Loss: 0.1248, Accuracy:0.930\nIteration: 17010, learning rate: 0.00475, Loss: 0.1147, Accuracy:0.961\nIteration: 17011, learning rate: 0.00475, Loss: 0.1186, Accuracy:0.953\nIteration: 17012, learning rate: 0.00475, Loss: 0.1529, Accuracy:0.930\nIteration: 17013, learning rate: 0.00475, Loss: 0.0822, Accuracy:0.961\nIteration: 17014, learning rate: 0.00475, Loss: 0.1893, Accuracy:0.938\nIteration: 17015, learning rate: 0.00475, Loss: 0.0852, Accuracy:0.969\nIteration: 17016, learning rate: 0.00475, Loss: 0.2262, Accuracy:0.930\nIteration: 17017, learning rate: 0.00475, Loss: 0.1111, Accuracy:0.969\nIteration: 17018, learning rate: 0.00475, Loss: 0.1035, Accuracy:0.961\nIteration: 17019, learning rate: 0.00475, Loss: 0.1047, Accuracy:0.957\nEpoch: 549, Loss: 0.1265, Accuracy:0.951, Val Loss: 0.2935, Val Accuracy: 0.882\nIteration: 17020, learning rate: 0.00475, Loss: 0.1526, Accuracy:0.953\nIteration: 17021, learning rate: 0.00474, Loss: 0.0762, Accuracy:0.992\nIteration: 17022, learning rate: 0.00474, Loss: 0.0341, Accuracy:1.000\nIteration: 17023, learning rate: 0.00474, Loss: 0.0986, Accuracy:0.961\nIteration: 17024, learning rate: 0.00474, Loss: 0.1027, Accuracy:0.953\nIteration: 17025, learning rate: 0.00474, Loss: 0.1195, Accuracy:0.961\nIteration: 17026, learning rate: 0.00474, Loss: 0.1042, Accuracy:0.961\nIteration: 17027, learning rate: 0.00474, Loss: 0.1800, Accuracy:0.914\nIteration: 17028, learning rate: 0.00474, Loss: 0.0936, Accuracy:0.984\nIteration: 17029, learning rate: 0.00474, Loss: 0.1060, Accuracy:0.930\nIteration: 17030, learning rate: 0.00474, Loss: 0.0717, Accuracy:0.977\nIteration: 17031, learning rate: 0.00474, Loss: 0.1773, Accuracy:0.914\nIteration: 17032, learning rate: 0.00474, Loss: 0.0617, Accuracy:0.969\nIteration: 17033, learning rate: 0.00474, Loss: 0.0875, Accuracy:0.977\nIteration: 17034, learning rate: 0.00474, Loss: 0.1350, Accuracy:0.945\nIteration: 17035, learning rate: 0.00474, Loss: 0.1705, Accuracy:0.914\nIteration: 17036, learning rate: 0.00474, Loss: 0.1506, Accuracy:0.961\nIteration: 17037, learning rate: 0.00474, Loss: 0.1043, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17038, learning rate: 0.00474, Loss: 0.1122, Accuracy:0.961\nIteration: 17039, learning rate: 0.00474, Loss: 0.1286, Accuracy:0.969\nIteration: 17040, learning rate: 0.00474, Loss: 0.1531, Accuracy:0.938\nIteration: 17041, learning rate: 0.00474, Loss: 0.1162, Accuracy:0.953\nIteration: 17042, learning rate: 0.00474, Loss: 0.0780, Accuracy:0.984\nIteration: 17043, learning rate: 0.00474, Loss: 0.1010, Accuracy:0.969\nIteration: 17044, learning rate: 0.00474, Loss: 0.1478, Accuracy:0.953\nIteration: 17045, learning rate: 0.00474, Loss: 0.2538, Accuracy:0.914\nIteration: 17046, learning rate: 0.00474, Loss: 0.2124, Accuracy:0.930\nIteration: 17047, learning rate: 0.00474, Loss: 0.2100, Accuracy:0.914\nIteration: 17048, learning rate: 0.00474, Loss: 0.1368, Accuracy:0.938\nIteration: 17049, learning rate: 0.00474, Loss: 0.1031, Accuracy:0.953\nIteration: 17050, learning rate: 0.00474, Loss: 0.1493, Accuracy:0.946\nEpoch: 550, Loss: 0.1267, Accuracy:0.953, Val Loss: 0.3029, Val Accuracy: 0.889\nIteration: 17051, learning rate: 0.00474, Loss: 0.0634, Accuracy:0.984\nIteration: 17052, learning rate: 0.00474, Loss: 0.1257, Accuracy:0.945\nIteration: 17053, learning rate: 0.00474, Loss: 0.0947, Accuracy:0.961\nIteration: 17054, learning rate: 0.00474, Loss: 0.1053, Accuracy:0.953\nIteration: 17055, learning rate: 0.00474, Loss: 0.0911, Accuracy:0.977\nIteration: 17056, learning rate: 0.00474, Loss: 0.1393, Accuracy:0.953\nIteration: 17057, learning rate: 0.00474, Loss: 0.0704, Accuracy:0.977\nIteration: 17058, learning rate: 0.00474, Loss: 0.1418, Accuracy:0.945\nIteration: 17059, learning rate: 0.00474, Loss: 0.1806, Accuracy:0.938\nIteration: 17060, learning rate: 0.00474, Loss: 0.0920, Accuracy:0.977\nIteration: 17061, learning rate: 0.00474, Loss: 0.1833, Accuracy:0.914\nIteration: 17062, learning rate: 0.00474, Loss: 0.1738, Accuracy:0.945\nIteration: 17063, learning rate: 0.00474, Loss: 0.1627, Accuracy:0.930\nIteration: 17064, learning rate: 0.00474, Loss: 0.1101, Accuracy:0.961\nIteration: 17065, learning rate: 0.00474, Loss: 0.2210, Accuracy:0.914\nIteration: 17066, learning rate: 0.00474, Loss: 0.1655, Accuracy:0.953\nIteration: 17067, learning rate: 0.00474, Loss: 0.1452, Accuracy:0.945\nIteration: 17068, learning rate: 0.00474, Loss: 0.1589, Accuracy:0.945\nIteration: 17069, learning rate: 0.00474, Loss: 0.1650, Accuracy:0.938\nIteration: 17070, learning rate: 0.00474, Loss: 0.0883, Accuracy:0.961\nIteration: 17071, learning rate: 0.00474, Loss: 0.1215, Accuracy:0.953\nIteration: 17072, learning rate: 0.00474, Loss: 0.1193, Accuracy:0.969\nIteration: 17073, learning rate: 0.00474, Loss: 0.1157, Accuracy:0.969\nIteration: 17074, learning rate: 0.00474, Loss: 0.1444, Accuracy:0.930\nIteration: 17075, learning rate: 0.00474, Loss: 0.1032, Accuracy:0.953\nIteration: 17076, learning rate: 0.00474, Loss: 0.1343, Accuracy:0.953\nIteration: 17077, learning rate: 0.00474, Loss: 0.1983, Accuracy:0.938\nIteration: 17078, learning rate: 0.00474, Loss: 0.0969, Accuracy:0.953\nIteration: 17079, learning rate: 0.00474, Loss: 0.1618, Accuracy:0.922\nIteration: 17080, learning rate: 0.00474, Loss: 0.0546, Accuracy:0.992\nIteration: 17081, learning rate: 0.00474, Loss: 0.1283, Accuracy:0.968\nEpoch: 551, Loss: 0.1309, Accuracy:0.952, Val Loss: 0.2876, Val Accuracy: 0.887\nIteration: 17082, learning rate: 0.00474, Loss: 0.1578, Accuracy:0.922\nIteration: 17083, learning rate: 0.00474, Loss: 0.1418, Accuracy:0.945\nIteration: 17084, learning rate: 0.00474, Loss: 0.0989, Accuracy:0.961\nIteration: 17085, learning rate: 0.00474, Loss: 0.1535, Accuracy:0.953\nIteration: 17086, learning rate: 0.00474, Loss: 0.0772, Accuracy:0.984\nIteration: 17087, learning rate: 0.00474, Loss: 0.2160, Accuracy:0.922\nIteration: 17088, learning rate: 0.00474, Loss: 0.1451, Accuracy:0.953\nIteration: 17089, learning rate: 0.00474, Loss: 0.2168, Accuracy:0.930\nIteration: 17090, learning rate: 0.00474, Loss: 0.0919, Accuracy:0.977\nIteration: 17091, learning rate: 0.00474, Loss: 0.0980, Accuracy:0.977\nIteration: 17092, learning rate: 0.00474, Loss: 0.1843, Accuracy:0.930\nIteration: 17093, learning rate: 0.00474, Loss: 0.1081, Accuracy:0.953\nIteration: 17094, learning rate: 0.00474, Loss: 0.2141, Accuracy:0.930\nIteration: 17095, learning rate: 0.00474, Loss: 0.1133, Accuracy:0.945\nIteration: 17096, learning rate: 0.00474, Loss: 0.0968, Accuracy:0.977\nIteration: 17097, learning rate: 0.00474, Loss: 0.1013, Accuracy:0.953\nIteration: 17098, learning rate: 0.00473, Loss: 0.1173, Accuracy:0.953\nIteration: 17099, learning rate: 0.00473, Loss: 0.0685, Accuracy:0.977\nIteration: 17100, learning rate: 0.00473, Loss: 0.1178, Accuracy:0.969\nIteration: 17101, learning rate: 0.00473, Loss: 0.1019, Accuracy:0.961\nIteration: 17102, learning rate: 0.00473, Loss: 0.2258, Accuracy:0.914\nIteration: 17103, learning rate: 0.00473, Loss: 0.1095, Accuracy:0.969\nIteration: 17104, learning rate: 0.00473, Loss: 0.1306, Accuracy:0.938\nIteration: 17105, learning rate: 0.00473, Loss: 0.2062, Accuracy:0.898\nIteration: 17106, learning rate: 0.00473, Loss: 0.1385, Accuracy:0.945\nIteration: 17107, learning rate: 0.00473, Loss: 0.1860, Accuracy:0.938\nIteration: 17108, learning rate: 0.00473, Loss: 0.2126, Accuracy:0.945\nIteration: 17109, learning rate: 0.00473, Loss: 0.1818, Accuracy:0.938\nIteration: 17110, learning rate: 0.00473, Loss: 0.1167, Accuracy:0.961\nIteration: 17111, learning rate: 0.00473, Loss: 0.2391, Accuracy:0.922\nIteration: 17112, learning rate: 0.00473, Loss: 0.1025, Accuracy:0.957\nEpoch: 552, Loss: 0.1442, Accuracy:0.948, Val Loss: 0.3073, Val Accuracy: 0.880\nIteration: 17113, learning rate: 0.00473, Loss: 0.1589, Accuracy:0.938\nIteration: 17114, learning rate: 0.00473, Loss: 0.0740, Accuracy:0.969\nIteration: 17115, learning rate: 0.00473, Loss: 0.1211, Accuracy:0.953\nIteration: 17116, learning rate: 0.00473, Loss: 0.1280, Accuracy:0.953\nIteration: 17117, learning rate: 0.00473, Loss: 0.0797, Accuracy:0.977\nIteration: 17118, learning rate: 0.00473, Loss: 0.1000, Accuracy:0.961\nIteration: 17119, learning rate: 0.00473, Loss: 0.1139, Accuracy:0.961\nIteration: 17120, learning rate: 0.00473, Loss: 0.1162, Accuracy:0.969\nIteration: 17121, learning rate: 0.00473, Loss: 0.1243, Accuracy:0.945\nIteration: 17122, learning rate: 0.00473, Loss: 0.1453, Accuracy:0.930\nIteration: 17123, learning rate: 0.00473, Loss: 0.0801, Accuracy:0.977\nIteration: 17124, learning rate: 0.00473, Loss: 0.1635, Accuracy:0.922\nIteration: 17125, learning rate: 0.00473, Loss: 0.0770, Accuracy:0.984\nIteration: 17126, learning rate: 0.00473, Loss: 0.1535, Accuracy:0.938\nIteration: 17127, learning rate: 0.00473, Loss: 0.1319, Accuracy:0.945\nIteration: 17128, learning rate: 0.00473, Loss: 0.1134, Accuracy:0.961\nIteration: 17129, learning rate: 0.00473, Loss: 0.1839, Accuracy:0.938\nIteration: 17130, learning rate: 0.00473, Loss: 0.1228, Accuracy:0.961\nIteration: 17131, learning rate: 0.00473, Loss: 0.1810, Accuracy:0.938\nIteration: 17132, learning rate: 0.00473, Loss: 0.0542, Accuracy:0.984\nIteration: 17133, learning rate: 0.00473, Loss: 0.1575, Accuracy:0.961\nIteration: 17134, learning rate: 0.00473, Loss: 0.1559, Accuracy:0.930\nIteration: 17135, learning rate: 0.00473, Loss: 0.0484, Accuracy:1.000\nIteration: 17136, learning rate: 0.00473, Loss: 0.0868, Accuracy:0.969\nIteration: 17137, learning rate: 0.00473, Loss: 0.1409, Accuracy:0.961\nIteration: 17138, learning rate: 0.00473, Loss: 0.1110, Accuracy:0.969\nIteration: 17139, learning rate: 0.00473, Loss: 0.1300, Accuracy:0.953\nIteration: 17140, learning rate: 0.00473, Loss: 0.0602, Accuracy:1.000\nIteration: 17141, learning rate: 0.00473, Loss: 0.0944, Accuracy:0.953\nIteration: 17142, learning rate: 0.00473, Loss: 0.0832, Accuracy:0.969\nIteration: 17143, learning rate: 0.00473, Loss: 0.0827, Accuracy:0.968\nEpoch: 553, Loss: 0.1153, Accuracy:0.959, Val Loss: 0.2793, Val Accuracy: 0.887\nIteration: 17144, learning rate: 0.00473, Loss: 0.1140, Accuracy:0.945\nIteration: 17145, learning rate: 0.00473, Loss: 0.1015, Accuracy:0.969\nIteration: 17146, learning rate: 0.00473, Loss: 0.1322, Accuracy:0.945\nIteration: 17147, learning rate: 0.00473, Loss: 0.1216, Accuracy:0.953\nIteration: 17148, learning rate: 0.00473, Loss: 0.1508, Accuracy:0.922\nIteration: 17149, learning rate: 0.00473, Loss: 0.1182, Accuracy:0.945\nIteration: 17150, learning rate: 0.00473, Loss: 0.1234, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17151, learning rate: 0.00473, Loss: 0.1164, Accuracy:0.961\nIteration: 17152, learning rate: 0.00473, Loss: 0.1197, Accuracy:0.953\nIteration: 17153, learning rate: 0.00473, Loss: 0.1321, Accuracy:0.938\nIteration: 17154, learning rate: 0.00473, Loss: 0.1205, Accuracy:0.953\nIteration: 17155, learning rate: 0.00473, Loss: 0.0829, Accuracy:0.977\nIteration: 17156, learning rate: 0.00473, Loss: 0.1031, Accuracy:0.969\nIteration: 17157, learning rate: 0.00473, Loss: 0.0988, Accuracy:0.977\nIteration: 17158, learning rate: 0.00473, Loss: 0.1464, Accuracy:0.945\nIteration: 17159, learning rate: 0.00473, Loss: 0.1231, Accuracy:0.953\nIteration: 17160, learning rate: 0.00473, Loss: 0.0923, Accuracy:0.977\nIteration: 17161, learning rate: 0.00473, Loss: 0.1027, Accuracy:0.961\nIteration: 17162, learning rate: 0.00473, Loss: 0.1554, Accuracy:0.938\nIteration: 17163, learning rate: 0.00473, Loss: 0.0894, Accuracy:0.969\nIteration: 17164, learning rate: 0.00473, Loss: 0.1587, Accuracy:0.945\nIteration: 17165, learning rate: 0.00473, Loss: 0.1332, Accuracy:0.938\nIteration: 17166, learning rate: 0.00473, Loss: 0.1675, Accuracy:0.906\nIteration: 17167, learning rate: 0.00473, Loss: 0.0910, Accuracy:0.969\nIteration: 17168, learning rate: 0.00473, Loss: 0.1316, Accuracy:0.945\nIteration: 17169, learning rate: 0.00473, Loss: 0.0955, Accuracy:0.969\nIteration: 17170, learning rate: 0.00473, Loss: 0.0831, Accuracy:0.984\nIteration: 17171, learning rate: 0.00473, Loss: 0.0878, Accuracy:0.961\nIteration: 17172, learning rate: 0.00473, Loss: 0.1078, Accuracy:0.969\nIteration: 17173, learning rate: 0.00473, Loss: 0.0663, Accuracy:0.984\nIteration: 17174, learning rate: 0.00472, Loss: 0.1676, Accuracy:0.946\nEpoch: 554, Loss: 0.1172, Accuracy:0.956, Val Loss: 0.2862, Val Accuracy: 0.893\nIteration: 17175, learning rate: 0.00472, Loss: 0.1160, Accuracy:0.961\nIteration: 17176, learning rate: 0.00472, Loss: 0.2075, Accuracy:0.906\nIteration: 17177, learning rate: 0.00472, Loss: 0.1344, Accuracy:0.961\nIteration: 17178, learning rate: 0.00472, Loss: 0.0674, Accuracy:0.977\nIteration: 17179, learning rate: 0.00472, Loss: 0.1774, Accuracy:0.930\nIteration: 17180, learning rate: 0.00472, Loss: 0.0894, Accuracy:0.961\nIteration: 17181, learning rate: 0.00472, Loss: 0.0510, Accuracy:0.992\nIteration: 17182, learning rate: 0.00472, Loss: 0.1651, Accuracy:0.961\nIteration: 17183, learning rate: 0.00472, Loss: 0.1183, Accuracy:0.961\nIteration: 17184, learning rate: 0.00472, Loss: 0.0994, Accuracy:0.953\nIteration: 17185, learning rate: 0.00472, Loss: 0.1737, Accuracy:0.938\nIteration: 17186, learning rate: 0.00472, Loss: 0.1693, Accuracy:0.953\nIteration: 17187, learning rate: 0.00472, Loss: 0.1144, Accuracy:0.953\nIteration: 17188, learning rate: 0.00472, Loss: 0.1319, Accuracy:0.953\nIteration: 17189, learning rate: 0.00472, Loss: 0.1074, Accuracy:0.938\nIteration: 17190, learning rate: 0.00472, Loss: 0.1488, Accuracy:0.961\nIteration: 17191, learning rate: 0.00472, Loss: 0.1340, Accuracy:0.922\nIteration: 17192, learning rate: 0.00472, Loss: 0.0677, Accuracy:0.977\nIteration: 17193, learning rate: 0.00472, Loss: 0.2036, Accuracy:0.922\nIteration: 17194, learning rate: 0.00472, Loss: 0.1476, Accuracy:0.961\nIteration: 17195, learning rate: 0.00472, Loss: 0.1668, Accuracy:0.961\nIteration: 17196, learning rate: 0.00472, Loss: 0.1562, Accuracy:0.945\nIteration: 17197, learning rate: 0.00472, Loss: 0.1144, Accuracy:0.938\nIteration: 17198, learning rate: 0.00472, Loss: 0.1557, Accuracy:0.914\nIteration: 17199, learning rate: 0.00472, Loss: 0.1015, Accuracy:0.969\nIteration: 17200, learning rate: 0.00472, Loss: 0.1731, Accuracy:0.945\nIteration: 17201, learning rate: 0.00472, Loss: 0.1766, Accuracy:0.930\nIteration: 17202, learning rate: 0.00472, Loss: 0.1419, Accuracy:0.938\nIteration: 17203, learning rate: 0.00472, Loss: 0.1421, Accuracy:0.945\nIteration: 17204, learning rate: 0.00472, Loss: 0.1435, Accuracy:0.930\nIteration: 17205, learning rate: 0.00472, Loss: 0.1473, Accuracy:0.968\nEpoch: 555, Loss: 0.1369, Accuracy:0.949, Val Loss: 0.3479, Val Accuracy: 0.862\nIteration: 17206, learning rate: 0.00472, Loss: 0.1426, Accuracy:0.945\nIteration: 17207, learning rate: 0.00472, Loss: 0.1301, Accuracy:0.945\nIteration: 17208, learning rate: 0.00472, Loss: 0.1195, Accuracy:0.953\nIteration: 17209, learning rate: 0.00472, Loss: 0.1475, Accuracy:0.945\nIteration: 17210, learning rate: 0.00472, Loss: 0.0860, Accuracy:0.961\nIteration: 17211, learning rate: 0.00472, Loss: 0.1278, Accuracy:0.961\nIteration: 17212, learning rate: 0.00472, Loss: 0.1157, Accuracy:0.945\nIteration: 17213, learning rate: 0.00472, Loss: 0.1628, Accuracy:0.930\nIteration: 17214, learning rate: 0.00472, Loss: 0.2169, Accuracy:0.930\nIteration: 17215, learning rate: 0.00472, Loss: 0.1893, Accuracy:0.922\nIteration: 17216, learning rate: 0.00472, Loss: 0.1531, Accuracy:0.961\nIteration: 17217, learning rate: 0.00472, Loss: 0.1991, Accuracy:0.930\nIteration: 17218, learning rate: 0.00472, Loss: 0.0859, Accuracy:0.969\nIteration: 17219, learning rate: 0.00472, Loss: 0.1118, Accuracy:0.969\nIteration: 17220, learning rate: 0.00472, Loss: 0.2019, Accuracy:0.930\nIteration: 17221, learning rate: 0.00472, Loss: 0.0988, Accuracy:0.953\nIteration: 17222, learning rate: 0.00472, Loss: 0.1482, Accuracy:0.945\nIteration: 17223, learning rate: 0.00472, Loss: 0.1863, Accuracy:0.922\nIteration: 17224, learning rate: 0.00472, Loss: 0.1295, Accuracy:0.953\nIteration: 17225, learning rate: 0.00472, Loss: 0.0928, Accuracy:0.961\nIteration: 17226, learning rate: 0.00472, Loss: 0.1491, Accuracy:0.953\nIteration: 17227, learning rate: 0.00472, Loss: 0.1776, Accuracy:0.906\nIteration: 17228, learning rate: 0.00472, Loss: 0.0676, Accuracy:0.977\nIteration: 17229, learning rate: 0.00472, Loss: 0.1262, Accuracy:0.953\nIteration: 17230, learning rate: 0.00472, Loss: 0.1169, Accuracy:0.961\nIteration: 17231, learning rate: 0.00472, Loss: 0.1896, Accuracy:0.938\nIteration: 17232, learning rate: 0.00472, Loss: 0.1186, Accuracy:0.969\nIteration: 17233, learning rate: 0.00472, Loss: 0.1128, Accuracy:0.961\nIteration: 17234, learning rate: 0.00472, Loss: 0.2118, Accuracy:0.906\nIteration: 17235, learning rate: 0.00472, Loss: 0.1170, Accuracy:0.969\nIteration: 17236, learning rate: 0.00472, Loss: 0.3074, Accuracy:0.903\nEpoch: 556, Loss: 0.1465, Accuracy:0.946, Val Loss: 0.3008, Val Accuracy: 0.885\nIteration: 17237, learning rate: 0.00472, Loss: 0.1830, Accuracy:0.930\nIteration: 17238, learning rate: 0.00472, Loss: 0.1092, Accuracy:0.938\nIteration: 17239, learning rate: 0.00472, Loss: 0.1594, Accuracy:0.930\nIteration: 17240, learning rate: 0.00472, Loss: 0.2645, Accuracy:0.906\nIteration: 17241, learning rate: 0.00472, Loss: 0.1638, Accuracy:0.930\nIteration: 17242, learning rate: 0.00472, Loss: 0.1238, Accuracy:0.969\nIteration: 17243, learning rate: 0.00472, Loss: 0.2125, Accuracy:0.938\nIteration: 17244, learning rate: 0.00472, Loss: 0.1485, Accuracy:0.945\nIteration: 17245, learning rate: 0.00472, Loss: 0.0828, Accuracy:0.969\nIteration: 17246, learning rate: 0.00472, Loss: 0.0902, Accuracy:0.969\nIteration: 17247, learning rate: 0.00472, Loss: 0.1146, Accuracy:0.969\nIteration: 17248, learning rate: 0.00472, Loss: 0.1027, Accuracy:0.961\nIteration: 17249, learning rate: 0.00472, Loss: 0.1295, Accuracy:0.961\nIteration: 17250, learning rate: 0.00472, Loss: 0.1674, Accuracy:0.953\nIteration: 17251, learning rate: 0.00471, Loss: 0.1728, Accuracy:0.945\nIteration: 17252, learning rate: 0.00471, Loss: 0.1747, Accuracy:0.953\nIteration: 17253, learning rate: 0.00471, Loss: 0.2622, Accuracy:0.914\nIteration: 17254, learning rate: 0.00471, Loss: 0.1160, Accuracy:0.945\nIteration: 17255, learning rate: 0.00471, Loss: 0.2120, Accuracy:0.891\nIteration: 17256, learning rate: 0.00471, Loss: 0.1694, Accuracy:0.930\nIteration: 17257, learning rate: 0.00471, Loss: 0.0833, Accuracy:0.961\nIteration: 17258, learning rate: 0.00471, Loss: 0.1663, Accuracy:0.938\nIteration: 17259, learning rate: 0.00471, Loss: 0.1975, Accuracy:0.945\nIteration: 17260, learning rate: 0.00471, Loss: 0.1629, Accuracy:0.922\nIteration: 17261, learning rate: 0.00471, Loss: 0.1178, Accuracy:0.945\nIteration: 17262, learning rate: 0.00471, Loss: 0.1409, Accuracy:0.938\nIteration: 17263, learning rate: 0.00471, Loss: 0.1277, Accuracy:0.938\nIteration: 17264, learning rate: 0.00471, Loss: 0.1371, Accuracy:0.953\nIteration: 17265, learning rate: 0.00471, Loss: 0.1028, Accuracy:0.969\nIteration: 17266, learning rate: 0.00471, Loss: 0.1252, Accuracy:0.961\nIteration: 17267, learning rate: 0.00471, Loss: 0.1526, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 557, Loss: 0.1507, Accuracy:0.944, Val Loss: 0.2998, Val Accuracy: 0.874\nIteration: 17268, learning rate: 0.00471, Loss: 0.0824, Accuracy:0.977\nIteration: 17269, learning rate: 0.00471, Loss: 0.1946, Accuracy:0.930\nIteration: 17270, learning rate: 0.00471, Loss: 0.1263, Accuracy:0.953\nIteration: 17271, learning rate: 0.00471, Loss: 0.1430, Accuracy:0.930\nIteration: 17272, learning rate: 0.00471, Loss: 0.1717, Accuracy:0.938\nIteration: 17273, learning rate: 0.00471, Loss: 0.1190, Accuracy:0.938\nIteration: 17274, learning rate: 0.00471, Loss: 0.1673, Accuracy:0.922\nIteration: 17275, learning rate: 0.00471, Loss: 0.1679, Accuracy:0.930\nIteration: 17276, learning rate: 0.00471, Loss: 0.1460, Accuracy:0.938\nIteration: 17277, learning rate: 0.00471, Loss: 0.1942, Accuracy:0.938\nIteration: 17278, learning rate: 0.00471, Loss: 0.1516, Accuracy:0.945\nIteration: 17279, learning rate: 0.00471, Loss: 0.2042, Accuracy:0.922\nIteration: 17280, learning rate: 0.00471, Loss: 0.0915, Accuracy:0.969\nIteration: 17281, learning rate: 0.00471, Loss: 0.1504, Accuracy:0.961\nIteration: 17282, learning rate: 0.00471, Loss: 0.1412, Accuracy:0.953\nIteration: 17283, learning rate: 0.00471, Loss: 0.0944, Accuracy:0.961\nIteration: 17284, learning rate: 0.00471, Loss: 0.1588, Accuracy:0.930\nIteration: 17285, learning rate: 0.00471, Loss: 0.1182, Accuracy:0.953\nIteration: 17286, learning rate: 0.00471, Loss: 0.0740, Accuracy:0.977\nIteration: 17287, learning rate: 0.00471, Loss: 0.2073, Accuracy:0.914\nIteration: 17288, learning rate: 0.00471, Loss: 0.1561, Accuracy:0.953\nIteration: 17289, learning rate: 0.00471, Loss: 0.1179, Accuracy:0.953\nIteration: 17290, learning rate: 0.00471, Loss: 0.1370, Accuracy:0.938\nIteration: 17291, learning rate: 0.00471, Loss: 0.1218, Accuracy:0.945\nIteration: 17292, learning rate: 0.00471, Loss: 0.1477, Accuracy:0.938\nIteration: 17293, learning rate: 0.00471, Loss: 0.1480, Accuracy:0.945\nIteration: 17294, learning rate: 0.00471, Loss: 0.1687, Accuracy:0.906\nIteration: 17295, learning rate: 0.00471, Loss: 0.1232, Accuracy:0.961\nIteration: 17296, learning rate: 0.00471, Loss: 0.2080, Accuracy:0.922\nIteration: 17297, learning rate: 0.00471, Loss: 0.1283, Accuracy:0.945\nIteration: 17298, learning rate: 0.00471, Loss: 0.1721, Accuracy:0.946\nEpoch: 558, Loss: 0.1462, Accuracy:0.943, Val Loss: 0.2512, Val Accuracy: 0.891\nIteration: 17299, learning rate: 0.00471, Loss: 0.1053, Accuracy:0.945\nIteration: 17300, learning rate: 0.00471, Loss: 0.1232, Accuracy:0.953\nIteration: 17301, learning rate: 0.00471, Loss: 0.1519, Accuracy:0.945\nIteration: 17302, learning rate: 0.00471, Loss: 0.1384, Accuracy:0.938\nIteration: 17303, learning rate: 0.00471, Loss: 0.1493, Accuracy:0.953\nIteration: 17304, learning rate: 0.00471, Loss: 0.1779, Accuracy:0.945\nIteration: 17305, learning rate: 0.00471, Loss: 0.1052, Accuracy:0.961\nIteration: 17306, learning rate: 0.00471, Loss: 0.1553, Accuracy:0.953\nIteration: 17307, learning rate: 0.00471, Loss: 0.0604, Accuracy:0.984\nIteration: 17308, learning rate: 0.00471, Loss: 0.1401, Accuracy:0.930\nIteration: 17309, learning rate: 0.00471, Loss: 0.1307, Accuracy:0.938\nIteration: 17310, learning rate: 0.00471, Loss: 0.1700, Accuracy:0.938\nIteration: 17311, learning rate: 0.00471, Loss: 0.1245, Accuracy:0.953\nIteration: 17312, learning rate: 0.00471, Loss: 0.1367, Accuracy:0.938\nIteration: 17313, learning rate: 0.00471, Loss: 0.1133, Accuracy:0.953\nIteration: 17314, learning rate: 0.00471, Loss: 0.0793, Accuracy:0.961\nIteration: 17315, learning rate: 0.00471, Loss: 0.1552, Accuracy:0.938\nIteration: 17316, learning rate: 0.00471, Loss: 0.0976, Accuracy:0.969\nIteration: 17317, learning rate: 0.00471, Loss: 0.1284, Accuracy:0.922\nIteration: 17318, learning rate: 0.00471, Loss: 0.1370, Accuracy:0.930\nIteration: 17319, learning rate: 0.00471, Loss: 0.1624, Accuracy:0.938\nIteration: 17320, learning rate: 0.00471, Loss: 0.2064, Accuracy:0.930\nIteration: 17321, learning rate: 0.00471, Loss: 0.1399, Accuracy:0.953\nIteration: 17322, learning rate: 0.00471, Loss: 0.1132, Accuracy:0.953\nIteration: 17323, learning rate: 0.00471, Loss: 0.1160, Accuracy:0.961\nIteration: 17324, learning rate: 0.00471, Loss: 0.1234, Accuracy:0.938\nIteration: 17325, learning rate: 0.00471, Loss: 0.1043, Accuracy:0.961\nIteration: 17326, learning rate: 0.00471, Loss: 0.0797, Accuracy:0.977\nIteration: 17327, learning rate: 0.00471, Loss: 0.1688, Accuracy:0.945\nIteration: 17328, learning rate: 0.00470, Loss: 0.1166, Accuracy:0.953\nIteration: 17329, learning rate: 0.00470, Loss: 0.2368, Accuracy:0.903\nEpoch: 559, Loss: 0.1338, Accuracy:0.947, Val Loss: 0.2514, Val Accuracy: 0.896\nIteration: 17330, learning rate: 0.00470, Loss: 0.2527, Accuracy:0.914\nIteration: 17331, learning rate: 0.00470, Loss: 0.1305, Accuracy:0.930\nIteration: 17332, learning rate: 0.00470, Loss: 0.1463, Accuracy:0.953\nIteration: 17333, learning rate: 0.00470, Loss: 0.1900, Accuracy:0.945\nIteration: 17334, learning rate: 0.00470, Loss: 0.1173, Accuracy:0.961\nIteration: 17335, learning rate: 0.00470, Loss: 0.1415, Accuracy:0.945\nIteration: 17336, learning rate: 0.00470, Loss: 0.1030, Accuracy:0.953\nIteration: 17337, learning rate: 0.00470, Loss: 0.1524, Accuracy:0.961\nIteration: 17338, learning rate: 0.00470, Loss: 0.0953, Accuracy:0.969\nIteration: 17339, learning rate: 0.00470, Loss: 0.1783, Accuracy:0.953\nIteration: 17340, learning rate: 0.00470, Loss: 0.1783, Accuracy:0.945\nIteration: 17341, learning rate: 0.00470, Loss: 0.0673, Accuracy:0.977\nIteration: 17342, learning rate: 0.00470, Loss: 0.1105, Accuracy:0.969\nIteration: 17343, learning rate: 0.00470, Loss: 0.2194, Accuracy:0.906\nIteration: 17344, learning rate: 0.00470, Loss: 0.1335, Accuracy:0.977\nIteration: 17345, learning rate: 0.00470, Loss: 0.0953, Accuracy:0.961\nIteration: 17346, learning rate: 0.00470, Loss: 0.1566, Accuracy:0.930\nIteration: 17347, learning rate: 0.00470, Loss: 0.1617, Accuracy:0.930\nIteration: 17348, learning rate: 0.00470, Loss: 0.1157, Accuracy:0.977\nIteration: 17349, learning rate: 0.00470, Loss: 0.0775, Accuracy:0.961\nIteration: 17350, learning rate: 0.00470, Loss: 0.1202, Accuracy:0.938\nIteration: 17351, learning rate: 0.00470, Loss: 0.1628, Accuracy:0.914\nIteration: 17352, learning rate: 0.00470, Loss: 0.1094, Accuracy:0.961\nIteration: 17353, learning rate: 0.00470, Loss: 0.2195, Accuracy:0.930\nIteration: 17354, learning rate: 0.00470, Loss: 0.0769, Accuracy:0.977\nIteration: 17355, learning rate: 0.00470, Loss: 0.1879, Accuracy:0.914\nIteration: 17356, learning rate: 0.00470, Loss: 0.1850, Accuracy:0.922\nIteration: 17357, learning rate: 0.00470, Loss: 0.2249, Accuracy:0.883\nIteration: 17358, learning rate: 0.00470, Loss: 0.1415, Accuracy:0.938\nIteration: 17359, learning rate: 0.00470, Loss: 0.1224, Accuracy:0.945\nIteration: 17360, learning rate: 0.00470, Loss: 0.1795, Accuracy:0.935\nEpoch: 560, Loss: 0.1469, Accuracy:0.944, Val Loss: 0.3249, Val Accuracy: 0.860\nIteration: 17361, learning rate: 0.00470, Loss: 0.1302, Accuracy:0.945\nIteration: 17362, learning rate: 0.00470, Loss: 0.1085, Accuracy:0.953\nIteration: 17363, learning rate: 0.00470, Loss: 0.2114, Accuracy:0.938\nIteration: 17364, learning rate: 0.00470, Loss: 0.1287, Accuracy:0.961\nIteration: 17365, learning rate: 0.00470, Loss: 0.2439, Accuracy:0.898\nIteration: 17366, learning rate: 0.00470, Loss: 0.0836, Accuracy:0.977\nIteration: 17367, learning rate: 0.00470, Loss: 0.1930, Accuracy:0.930\nIteration: 17368, learning rate: 0.00470, Loss: 0.1299, Accuracy:0.945\nIteration: 17369, learning rate: 0.00470, Loss: 0.1252, Accuracy:0.953\nIteration: 17370, learning rate: 0.00470, Loss: 0.1228, Accuracy:0.938\nIteration: 17371, learning rate: 0.00470, Loss: 0.0973, Accuracy:0.969\nIteration: 17372, learning rate: 0.00470, Loss: 0.1481, Accuracy:0.945\nIteration: 17373, learning rate: 0.00470, Loss: 0.1818, Accuracy:0.922\nIteration: 17374, learning rate: 0.00470, Loss: 0.1522, Accuracy:0.953\nIteration: 17375, learning rate: 0.00470, Loss: 0.1797, Accuracy:0.898\nIteration: 17376, learning rate: 0.00470, Loss: 0.1333, Accuracy:0.953\nIteration: 17377, learning rate: 0.00470, Loss: 0.0635, Accuracy:0.992\nIteration: 17378, learning rate: 0.00470, Loss: 0.1783, Accuracy:0.945\nIteration: 17379, learning rate: 0.00470, Loss: 0.1292, Accuracy:0.961\nIteration: 17380, learning rate: 0.00470, Loss: 0.0947, Accuracy:0.953\nIteration: 17381, learning rate: 0.00470, Loss: 0.1870, Accuracy:0.938\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17382, learning rate: 0.00470, Loss: 0.0986, Accuracy:0.961\nIteration: 17383, learning rate: 0.00470, Loss: 0.1371, Accuracy:0.945\nIteration: 17384, learning rate: 0.00470, Loss: 0.0933, Accuracy:0.961\nIteration: 17385, learning rate: 0.00470, Loss: 0.1620, Accuracy:0.938\nIteration: 17386, learning rate: 0.00470, Loss: 0.1494, Accuracy:0.938\nIteration: 17387, learning rate: 0.00470, Loss: 0.1070, Accuracy:0.953\nIteration: 17388, learning rate: 0.00470, Loss: 0.1323, Accuracy:0.945\nIteration: 17389, learning rate: 0.00470, Loss: 0.1125, Accuracy:0.953\nIteration: 17390, learning rate: 0.00470, Loss: 0.1358, Accuracy:0.953\nIteration: 17391, learning rate: 0.00470, Loss: 0.1664, Accuracy:0.957\nEpoch: 561, Loss: 0.1393, Accuracy:0.947, Val Loss: 0.2783, Val Accuracy: 0.879\nIteration: 17392, learning rate: 0.00470, Loss: 0.1564, Accuracy:0.930\nIteration: 17393, learning rate: 0.00470, Loss: 0.1126, Accuracy:0.961\nIteration: 17394, learning rate: 0.00470, Loss: 0.1651, Accuracy:0.922\nIteration: 17395, learning rate: 0.00470, Loss: 0.0504, Accuracy:0.992\nIteration: 17396, learning rate: 0.00470, Loss: 0.1213, Accuracy:0.945\nIteration: 17397, learning rate: 0.00470, Loss: 0.1288, Accuracy:0.938\nIteration: 17398, learning rate: 0.00470, Loss: 0.0781, Accuracy:0.984\nIteration: 17399, learning rate: 0.00470, Loss: 0.1498, Accuracy:0.961\nIteration: 17400, learning rate: 0.00470, Loss: 0.1631, Accuracy:0.945\nIteration: 17401, learning rate: 0.00470, Loss: 0.0861, Accuracy:0.977\nIteration: 17402, learning rate: 0.00470, Loss: 0.1521, Accuracy:0.930\nIteration: 17403, learning rate: 0.00470, Loss: 0.1379, Accuracy:0.922\nIteration: 17404, learning rate: 0.00470, Loss: 0.0708, Accuracy:0.984\nIteration: 17405, learning rate: 0.00470, Loss: 0.1295, Accuracy:0.945\nIteration: 17406, learning rate: 0.00469, Loss: 0.0887, Accuracy:0.969\nIteration: 17407, learning rate: 0.00469, Loss: 0.1691, Accuracy:0.938\nIteration: 17408, learning rate: 0.00469, Loss: 0.1355, Accuracy:0.945\nIteration: 17409, learning rate: 0.00469, Loss: 0.0726, Accuracy:0.984\nIteration: 17410, learning rate: 0.00469, Loss: 0.1918, Accuracy:0.914\nIteration: 17411, learning rate: 0.00469, Loss: 0.1180, Accuracy:0.961\nIteration: 17412, learning rate: 0.00469, Loss: 0.0918, Accuracy:0.977\nIteration: 17413, learning rate: 0.00469, Loss: 0.0988, Accuracy:0.961\nIteration: 17414, learning rate: 0.00469, Loss: 0.0835, Accuracy:0.984\nIteration: 17415, learning rate: 0.00469, Loss: 0.1067, Accuracy:0.938\nIteration: 17416, learning rate: 0.00469, Loss: 0.0813, Accuracy:0.977\nIteration: 17417, learning rate: 0.00469, Loss: 0.2107, Accuracy:0.930\nIteration: 17418, learning rate: 0.00469, Loss: 0.1281, Accuracy:0.945\nIteration: 17419, learning rate: 0.00469, Loss: 0.0993, Accuracy:0.953\nIteration: 17420, learning rate: 0.00469, Loss: 0.1518, Accuracy:0.953\nIteration: 17421, learning rate: 0.00469, Loss: 0.1498, Accuracy:0.938\nIteration: 17422, learning rate: 0.00469, Loss: 0.1784, Accuracy:0.946\nEpoch: 562, Loss: 0.1245, Accuracy:0.953, Val Loss: 0.2799, Val Accuracy: 0.894\nIteration: 17423, learning rate: 0.00469, Loss: 0.1195, Accuracy:0.938\nIteration: 17424, learning rate: 0.00469, Loss: 0.1253, Accuracy:0.961\nIteration: 17425, learning rate: 0.00469, Loss: 0.0823, Accuracy:0.977\nIteration: 17426, learning rate: 0.00469, Loss: 0.1176, Accuracy:0.961\nIteration: 17427, learning rate: 0.00469, Loss: 0.1935, Accuracy:0.914\nIteration: 17428, learning rate: 0.00469, Loss: 0.1248, Accuracy:0.930\nIteration: 17429, learning rate: 0.00469, Loss: 0.1520, Accuracy:0.953\nIteration: 17430, learning rate: 0.00469, Loss: 0.1028, Accuracy:0.953\nIteration: 17431, learning rate: 0.00469, Loss: 0.1527, Accuracy:0.930\nIteration: 17432, learning rate: 0.00469, Loss: 0.1187, Accuracy:0.945\nIteration: 17433, learning rate: 0.00469, Loss: 0.1313, Accuracy:0.953\nIteration: 17434, learning rate: 0.00469, Loss: 0.1687, Accuracy:0.930\nIteration: 17435, learning rate: 0.00469, Loss: 0.1927, Accuracy:0.945\nIteration: 17436, learning rate: 0.00469, Loss: 0.1758, Accuracy:0.930\nIteration: 17437, learning rate: 0.00469, Loss: 0.1007, Accuracy:0.969\nIteration: 17438, learning rate: 0.00469, Loss: 0.1192, Accuracy:0.969\nIteration: 17439, learning rate: 0.00469, Loss: 0.1277, Accuracy:0.945\nIteration: 17440, learning rate: 0.00469, Loss: 0.1706, Accuracy:0.930\nIteration: 17441, learning rate: 0.00469, Loss: 0.1420, Accuracy:0.938\nIteration: 17442, learning rate: 0.00469, Loss: 0.1059, Accuracy:0.977\nIteration: 17443, learning rate: 0.00469, Loss: 0.1458, Accuracy:0.961\nIteration: 17444, learning rate: 0.00469, Loss: 0.2110, Accuracy:0.945\nIteration: 17445, learning rate: 0.00469, Loss: 0.1450, Accuracy:0.969\nIteration: 17446, learning rate: 0.00469, Loss: 0.1231, Accuracy:0.938\nIteration: 17447, learning rate: 0.00469, Loss: 0.1079, Accuracy:0.969\nIteration: 17448, learning rate: 0.00469, Loss: 0.1344, Accuracy:0.953\nIteration: 17449, learning rate: 0.00469, Loss: 0.1007, Accuracy:0.953\nIteration: 17450, learning rate: 0.00469, Loss: 0.1076, Accuracy:0.953\nIteration: 17451, learning rate: 0.00469, Loss: 0.1352, Accuracy:0.945\nIteration: 17452, learning rate: 0.00469, Loss: 0.1275, Accuracy:0.961\nIteration: 17453, learning rate: 0.00469, Loss: 0.1416, Accuracy:0.935\nEpoch: 563, Loss: 0.1356, Accuracy:0.949, Val Loss: 0.2462, Val Accuracy: 0.912\nIteration: 17454, learning rate: 0.00469, Loss: 0.0964, Accuracy:0.953\nIteration: 17455, learning rate: 0.00469, Loss: 0.0849, Accuracy:0.977\nIteration: 17456, learning rate: 0.00469, Loss: 0.1340, Accuracy:0.945\nIteration: 17457, learning rate: 0.00469, Loss: 0.1272, Accuracy:0.945\nIteration: 17458, learning rate: 0.00469, Loss: 0.1286, Accuracy:0.953\nIteration: 17459, learning rate: 0.00469, Loss: 0.1425, Accuracy:0.938\nIteration: 17460, learning rate: 0.00469, Loss: 0.0772, Accuracy:0.984\nIteration: 17461, learning rate: 0.00469, Loss: 0.1167, Accuracy:0.953\nIteration: 17462, learning rate: 0.00469, Loss: 0.1429, Accuracy:0.953\nIteration: 17463, learning rate: 0.00469, Loss: 0.0978, Accuracy:0.961\nIteration: 17464, learning rate: 0.00469, Loss: 0.0825, Accuracy:0.961\nIteration: 17465, learning rate: 0.00469, Loss: 0.1270, Accuracy:0.953\nIteration: 17466, learning rate: 0.00469, Loss: 0.0636, Accuracy:0.992\nIteration: 17467, learning rate: 0.00469, Loss: 0.0952, Accuracy:0.969\nIteration: 17468, learning rate: 0.00469, Loss: 0.1141, Accuracy:0.953\nIteration: 17469, learning rate: 0.00469, Loss: 0.1979, Accuracy:0.938\nIteration: 17470, learning rate: 0.00469, Loss: 0.0661, Accuracy:0.984\nIteration: 17471, learning rate: 0.00469, Loss: 0.1773, Accuracy:0.922\nIteration: 17472, learning rate: 0.00469, Loss: 0.1471, Accuracy:0.969\nIteration: 17473, learning rate: 0.00469, Loss: 0.1489, Accuracy:0.938\nIteration: 17474, learning rate: 0.00469, Loss: 0.1088, Accuracy:0.953\nIteration: 17475, learning rate: 0.00469, Loss: 0.1056, Accuracy:0.984\nIteration: 17476, learning rate: 0.00469, Loss: 0.1797, Accuracy:0.938\nIteration: 17477, learning rate: 0.00469, Loss: 0.1343, Accuracy:0.953\nIteration: 17478, learning rate: 0.00469, Loss: 0.1525, Accuracy:0.953\nIteration: 17479, learning rate: 0.00469, Loss: 0.1592, Accuracy:0.930\nIteration: 17480, learning rate: 0.00469, Loss: 0.1691, Accuracy:0.922\nIteration: 17481, learning rate: 0.00469, Loss: 0.1053, Accuracy:0.969\nIteration: 17482, learning rate: 0.00469, Loss: 0.1362, Accuracy:0.938\nIteration: 17483, learning rate: 0.00469, Loss: 0.1354, Accuracy:0.938\nIteration: 17484, learning rate: 0.00468, Loss: 0.1254, Accuracy:0.946\nEpoch: 564, Loss: 0.1251, Accuracy:0.954, Val Loss: 0.2817, Val Accuracy: 0.890\nIteration: 17485, learning rate: 0.00468, Loss: 0.1020, Accuracy:0.984\nIteration: 17486, learning rate: 0.00468, Loss: 0.1963, Accuracy:0.906\nIteration: 17487, learning rate: 0.00468, Loss: 0.1269, Accuracy:0.930\nIteration: 17488, learning rate: 0.00468, Loss: 0.1405, Accuracy:0.938\nIteration: 17489, learning rate: 0.00468, Loss: 0.1050, Accuracy:0.969\nIteration: 17490, learning rate: 0.00468, Loss: 0.1742, Accuracy:0.938\nIteration: 17491, learning rate: 0.00468, Loss: 0.1384, Accuracy:0.930\nIteration: 17492, learning rate: 0.00468, Loss: 0.1166, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17493, learning rate: 0.00468, Loss: 0.1905, Accuracy:0.953\nIteration: 17494, learning rate: 0.00468, Loss: 0.1206, Accuracy:0.945\nIteration: 17495, learning rate: 0.00468, Loss: 0.1742, Accuracy:0.922\nIteration: 17496, learning rate: 0.00468, Loss: 0.1307, Accuracy:0.961\nIteration: 17497, learning rate: 0.00468, Loss: 0.1283, Accuracy:0.953\nIteration: 17498, learning rate: 0.00468, Loss: 0.1384, Accuracy:0.930\nIteration: 17499, learning rate: 0.00468, Loss: 0.1184, Accuracy:0.961\nIteration: 17500, learning rate: 0.00468, Loss: 0.1162, Accuracy:0.961\nIteration: 17501, learning rate: 0.00468, Loss: 0.1712, Accuracy:0.930\nIteration: 17502, learning rate: 0.00468, Loss: 0.1228, Accuracy:0.953\nIteration: 17503, learning rate: 0.00468, Loss: 0.0972, Accuracy:0.961\nIteration: 17504, learning rate: 0.00468, Loss: 0.0919, Accuracy:0.969\nIteration: 17505, learning rate: 0.00468, Loss: 0.1773, Accuracy:0.938\nIteration: 17506, learning rate: 0.00468, Loss: 0.1184, Accuracy:0.961\nIteration: 17507, learning rate: 0.00468, Loss: 0.1238, Accuracy:0.961\nIteration: 17508, learning rate: 0.00468, Loss: 0.1624, Accuracy:0.945\nIteration: 17509, learning rate: 0.00468, Loss: 0.1134, Accuracy:0.953\nIteration: 17510, learning rate: 0.00468, Loss: 0.0985, Accuracy:0.969\nIteration: 17511, learning rate: 0.00468, Loss: 0.1032, Accuracy:0.961\nIteration: 17512, learning rate: 0.00468, Loss: 0.1185, Accuracy:0.953\nIteration: 17513, learning rate: 0.00468, Loss: 0.2429, Accuracy:0.906\nIteration: 17514, learning rate: 0.00468, Loss: 0.1453, Accuracy:0.953\nIteration: 17515, learning rate: 0.00468, Loss: 0.0760, Accuracy:0.989\nEpoch: 565, Loss: 0.1348, Accuracy:0.950, Val Loss: 0.2885, Val Accuracy: 0.888\nIteration: 17516, learning rate: 0.00468, Loss: 0.1123, Accuracy:0.961\nIteration: 17517, learning rate: 0.00468, Loss: 0.1273, Accuracy:0.945\nIteration: 17518, learning rate: 0.00468, Loss: 0.1617, Accuracy:0.945\nIteration: 17519, learning rate: 0.00468, Loss: 0.1083, Accuracy:0.977\nIteration: 17520, learning rate: 0.00468, Loss: 0.2215, Accuracy:0.914\nIteration: 17521, learning rate: 0.00468, Loss: 0.2197, Accuracy:0.930\nIteration: 17522, learning rate: 0.00468, Loss: 0.1147, Accuracy:0.961\nIteration: 17523, learning rate: 0.00468, Loss: 0.1034, Accuracy:0.969\nIteration: 17524, learning rate: 0.00468, Loss: 0.0843, Accuracy:0.961\nIteration: 17525, learning rate: 0.00468, Loss: 0.1461, Accuracy:0.953\nIteration: 17526, learning rate: 0.00468, Loss: 0.1440, Accuracy:0.961\nIteration: 17527, learning rate: 0.00468, Loss: 0.1197, Accuracy:0.953\nIteration: 17528, learning rate: 0.00468, Loss: 0.1511, Accuracy:0.938\nIteration: 17529, learning rate: 0.00468, Loss: 0.0909, Accuracy:0.977\nIteration: 17530, learning rate: 0.00468, Loss: 0.1656, Accuracy:0.953\nIteration: 17531, learning rate: 0.00468, Loss: 0.1119, Accuracy:0.977\nIteration: 17532, learning rate: 0.00468, Loss: 0.1910, Accuracy:0.945\nIteration: 17533, learning rate: 0.00468, Loss: 0.1331, Accuracy:0.930\nIteration: 17534, learning rate: 0.00468, Loss: 0.1461, Accuracy:0.930\nIteration: 17535, learning rate: 0.00468, Loss: 0.1663, Accuracy:0.938\nIteration: 17536, learning rate: 0.00468, Loss: 0.1439, Accuracy:0.953\nIteration: 17537, learning rate: 0.00468, Loss: 0.0970, Accuracy:0.969\nIteration: 17538, learning rate: 0.00468, Loss: 0.0918, Accuracy:0.977\nIteration: 17539, learning rate: 0.00468, Loss: 0.1383, Accuracy:0.945\nIteration: 17540, learning rate: 0.00468, Loss: 0.1129, Accuracy:0.961\nIteration: 17541, learning rate: 0.00468, Loss: 0.1149, Accuracy:0.938\nIteration: 17542, learning rate: 0.00468, Loss: 0.1145, Accuracy:0.961\nIteration: 17543, learning rate: 0.00468, Loss: 0.1481, Accuracy:0.930\nIteration: 17544, learning rate: 0.00468, Loss: 0.2152, Accuracy:0.930\nIteration: 17545, learning rate: 0.00468, Loss: 0.1446, Accuracy:0.930\nIteration: 17546, learning rate: 0.00468, Loss: 0.1087, Accuracy:0.968\nEpoch: 566, Loss: 0.1371, Accuracy:0.951, Val Loss: 0.2401, Val Accuracy: 0.901\nIteration: 17547, learning rate: 0.00468, Loss: 0.1101, Accuracy:0.953\nIteration: 17548, learning rate: 0.00468, Loss: 0.0985, Accuracy:0.977\nIteration: 17549, learning rate: 0.00468, Loss: 0.1675, Accuracy:0.938\nIteration: 17550, learning rate: 0.00468, Loss: 0.1136, Accuracy:0.945\nIteration: 17551, learning rate: 0.00468, Loss: 0.0791, Accuracy:0.977\nIteration: 17552, learning rate: 0.00468, Loss: 0.1798, Accuracy:0.930\nIteration: 17553, learning rate: 0.00468, Loss: 0.0846, Accuracy:0.984\nIteration: 17554, learning rate: 0.00468, Loss: 0.1792, Accuracy:0.930\nIteration: 17555, learning rate: 0.00468, Loss: 0.0878, Accuracy:0.961\nIteration: 17556, learning rate: 0.00468, Loss: 0.0803, Accuracy:0.977\nIteration: 17557, learning rate: 0.00468, Loss: 0.1569, Accuracy:0.938\nIteration: 17558, learning rate: 0.00468, Loss: 0.0992, Accuracy:0.969\nIteration: 17559, learning rate: 0.00468, Loss: 0.1395, Accuracy:0.938\nIteration: 17560, learning rate: 0.00468, Loss: 0.0909, Accuracy:0.977\nIteration: 17561, learning rate: 0.00468, Loss: 0.1452, Accuracy:0.930\nIteration: 17562, learning rate: 0.00467, Loss: 0.1355, Accuracy:0.945\nIteration: 17563, learning rate: 0.00467, Loss: 0.1056, Accuracy:0.953\nIteration: 17564, learning rate: 0.00467, Loss: 0.0639, Accuracy:0.977\nIteration: 17565, learning rate: 0.00467, Loss: 0.1331, Accuracy:0.938\nIteration: 17566, learning rate: 0.00467, Loss: 0.0540, Accuracy:0.992\nIteration: 17567, learning rate: 0.00467, Loss: 0.1150, Accuracy:0.953\nIteration: 17568, learning rate: 0.00467, Loss: 0.0763, Accuracy:0.969\nIteration: 17569, learning rate: 0.00467, Loss: 0.0922, Accuracy:0.984\nIteration: 17570, learning rate: 0.00467, Loss: 0.0807, Accuracy:0.977\nIteration: 17571, learning rate: 0.00467, Loss: 0.0852, Accuracy:0.977\nIteration: 17572, learning rate: 0.00467, Loss: 0.1363, Accuracy:0.945\nIteration: 17573, learning rate: 0.00467, Loss: 0.1495, Accuracy:0.945\nIteration: 17574, learning rate: 0.00467, Loss: 0.1635, Accuracy:0.922\nIteration: 17575, learning rate: 0.00467, Loss: 0.1188, Accuracy:0.969\nIteration: 17576, learning rate: 0.00467, Loss: 0.0488, Accuracy:1.000\nIteration: 17577, learning rate: 0.00467, Loss: 0.1391, Accuracy:0.946\nEpoch: 567, Loss: 0.1132, Accuracy:0.958, Val Loss: 0.3856, Val Accuracy: 0.865\nIteration: 17578, learning rate: 0.00467, Loss: 0.1306, Accuracy:0.945\nIteration: 17579, learning rate: 0.00467, Loss: 0.0824, Accuracy:0.969\nIteration: 17580, learning rate: 0.00467, Loss: 0.0720, Accuracy:0.969\nIteration: 17581, learning rate: 0.00467, Loss: 0.1433, Accuracy:0.938\nIteration: 17582, learning rate: 0.00467, Loss: 0.0897, Accuracy:0.984\nIteration: 17583, learning rate: 0.00467, Loss: 0.1572, Accuracy:0.938\nIteration: 17584, learning rate: 0.00467, Loss: 0.0951, Accuracy:0.961\nIteration: 17585, learning rate: 0.00467, Loss: 0.1010, Accuracy:0.969\nIteration: 17586, learning rate: 0.00467, Loss: 0.1448, Accuracy:0.938\nIteration: 17587, learning rate: 0.00467, Loss: 0.1069, Accuracy:0.969\nIteration: 17588, learning rate: 0.00467, Loss: 0.0987, Accuracy:0.969\nIteration: 17589, learning rate: 0.00467, Loss: 0.1656, Accuracy:0.930\nIteration: 17590, learning rate: 0.00467, Loss: 0.1192, Accuracy:0.961\nIteration: 17591, learning rate: 0.00467, Loss: 0.1111, Accuracy:0.953\nIteration: 17592, learning rate: 0.00467, Loss: 0.1295, Accuracy:0.953\nIteration: 17593, learning rate: 0.00467, Loss: 0.1113, Accuracy:0.969\nIteration: 17594, learning rate: 0.00467, Loss: 0.2144, Accuracy:0.906\nIteration: 17595, learning rate: 0.00467, Loss: 0.1304, Accuracy:0.953\nIteration: 17596, learning rate: 0.00467, Loss: 0.1143, Accuracy:0.961\nIteration: 17597, learning rate: 0.00467, Loss: 0.1052, Accuracy:0.945\nIteration: 17598, learning rate: 0.00467, Loss: 0.0870, Accuracy:0.977\nIteration: 17599, learning rate: 0.00467, Loss: 0.1222, Accuracy:0.945\nIteration: 17600, learning rate: 0.00467, Loss: 0.0863, Accuracy:0.969\nIteration: 17601, learning rate: 0.00467, Loss: 0.1400, Accuracy:0.953\nIteration: 17602, learning rate: 0.00467, Loss: 0.1541, Accuracy:0.953\nIteration: 17603, learning rate: 0.00467, Loss: 0.1634, Accuracy:0.945\nIteration: 17604, learning rate: 0.00467, Loss: 0.0865, Accuracy:0.953\nIteration: 17605, learning rate: 0.00467, Loss: 0.1665, Accuracy:0.953\nIteration: 17606, learning rate: 0.00467, Loss: 0.1213, Accuracy:0.953\nIteration: 17607, learning rate: 0.00467, Loss: 0.1050, Accuracy:0.945\nIteration: 17608, learning rate: 0.00467, Loss: 0.1171, Accuracy:0.968\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 568, Loss: 0.1217, Accuracy:0.955, Val Loss: 0.2826, Val Accuracy: 0.885\nIteration: 17609, learning rate: 0.00467, Loss: 0.0593, Accuracy:0.984\nIteration: 17610, learning rate: 0.00467, Loss: 0.1661, Accuracy:0.922\nIteration: 17611, learning rate: 0.00467, Loss: 0.1369, Accuracy:0.945\nIteration: 17612, learning rate: 0.00467, Loss: 0.0982, Accuracy:0.961\nIteration: 17613, learning rate: 0.00467, Loss: 0.0974, Accuracy:0.961\nIteration: 17614, learning rate: 0.00467, Loss: 0.1633, Accuracy:0.922\nIteration: 17615, learning rate: 0.00467, Loss: 0.0976, Accuracy:0.969\nIteration: 17616, learning rate: 0.00467, Loss: 0.1190, Accuracy:0.961\nIteration: 17617, learning rate: 0.00467, Loss: 0.2149, Accuracy:0.922\nIteration: 17618, learning rate: 0.00467, Loss: 0.0982, Accuracy:0.969\nIteration: 17619, learning rate: 0.00467, Loss: 0.1307, Accuracy:0.953\nIteration: 17620, learning rate: 0.00467, Loss: 0.1824, Accuracy:0.930\nIteration: 17621, learning rate: 0.00467, Loss: 0.0902, Accuracy:0.969\nIteration: 17622, learning rate: 0.00467, Loss: 0.1145, Accuracy:0.945\nIteration: 17623, learning rate: 0.00467, Loss: 0.1758, Accuracy:0.922\nIteration: 17624, learning rate: 0.00467, Loss: 0.1640, Accuracy:0.938\nIteration: 17625, learning rate: 0.00467, Loss: 0.1335, Accuracy:0.945\nIteration: 17626, learning rate: 0.00467, Loss: 0.1334, Accuracy:0.945\nIteration: 17627, learning rate: 0.00467, Loss: 0.1125, Accuracy:0.969\nIteration: 17628, learning rate: 0.00467, Loss: 0.0891, Accuracy:0.961\nIteration: 17629, learning rate: 0.00467, Loss: 0.1144, Accuracy:0.969\nIteration: 17630, learning rate: 0.00467, Loss: 0.0896, Accuracy:0.969\nIteration: 17631, learning rate: 0.00467, Loss: 0.1509, Accuracy:0.953\nIteration: 17632, learning rate: 0.00467, Loss: 0.1294, Accuracy:0.953\nIteration: 17633, learning rate: 0.00467, Loss: 0.1189, Accuracy:0.953\nIteration: 17634, learning rate: 0.00467, Loss: 0.1307, Accuracy:0.922\nIteration: 17635, learning rate: 0.00467, Loss: 0.1541, Accuracy:0.922\nIteration: 17636, learning rate: 0.00467, Loss: 0.1068, Accuracy:0.961\nIteration: 17637, learning rate: 0.00467, Loss: 0.1045, Accuracy:0.953\nIteration: 17638, learning rate: 0.00467, Loss: 0.0794, Accuracy:0.977\nIteration: 17639, learning rate: 0.00467, Loss: 0.1353, Accuracy:0.946\nEpoch: 569, Loss: 0.1255, Accuracy:0.951, Val Loss: 0.3277, Val Accuracy: 0.853\nIteration: 17640, learning rate: 0.00467, Loss: 0.1231, Accuracy:0.945\nIteration: 17641, learning rate: 0.00466, Loss: 0.1497, Accuracy:0.938\nIteration: 17642, learning rate: 0.00466, Loss: 0.1102, Accuracy:0.953\nIteration: 17643, learning rate: 0.00466, Loss: 0.1418, Accuracy:0.938\nIteration: 17644, learning rate: 0.00466, Loss: 0.1115, Accuracy:0.961\nIteration: 17645, learning rate: 0.00466, Loss: 0.1192, Accuracy:0.945\nIteration: 17646, learning rate: 0.00466, Loss: 0.1667, Accuracy:0.945\nIteration: 17647, learning rate: 0.00466, Loss: 0.1515, Accuracy:0.945\nIteration: 17648, learning rate: 0.00466, Loss: 0.1733, Accuracy:0.930\nIteration: 17649, learning rate: 0.00466, Loss: 0.1146, Accuracy:0.938\nIteration: 17650, learning rate: 0.00466, Loss: 0.1360, Accuracy:0.938\nIteration: 17651, learning rate: 0.00466, Loss: 0.1319, Accuracy:0.953\nIteration: 17652, learning rate: 0.00466, Loss: 0.1575, Accuracy:0.945\nIteration: 17653, learning rate: 0.00466, Loss: 0.1531, Accuracy:0.945\nIteration: 17654, learning rate: 0.00466, Loss: 0.0826, Accuracy:0.969\nIteration: 17655, learning rate: 0.00466, Loss: 0.0919, Accuracy:0.961\nIteration: 17656, learning rate: 0.00466, Loss: 0.1040, Accuracy:0.953\nIteration: 17657, learning rate: 0.00466, Loss: 0.1895, Accuracy:0.930\nIteration: 17658, learning rate: 0.00466, Loss: 0.1246, Accuracy:0.953\nIteration: 17659, learning rate: 0.00466, Loss: 0.1003, Accuracy:0.953\nIteration: 17660, learning rate: 0.00466, Loss: 0.1178, Accuracy:0.961\nIteration: 17661, learning rate: 0.00466, Loss: 0.1291, Accuracy:0.961\nIteration: 17662, learning rate: 0.00466, Loss: 0.1420, Accuracy:0.945\nIteration: 17663, learning rate: 0.00466, Loss: 0.1718, Accuracy:0.930\nIteration: 17664, learning rate: 0.00466, Loss: 0.1713, Accuracy:0.953\nIteration: 17665, learning rate: 0.00466, Loss: 0.2051, Accuracy:0.930\nIteration: 17666, learning rate: 0.00466, Loss: 0.1252, Accuracy:0.961\nIteration: 17667, learning rate: 0.00466, Loss: 0.1643, Accuracy:0.953\nIteration: 17668, learning rate: 0.00466, Loss: 0.1750, Accuracy:0.930\nIteration: 17669, learning rate: 0.00466, Loss: 0.0887, Accuracy:0.969\nIteration: 17670, learning rate: 0.00466, Loss: 0.0723, Accuracy:0.978\nEpoch: 570, Loss: 0.1353, Accuracy:0.949, Val Loss: 0.3215, Val Accuracy: 0.867\nIteration: 17671, learning rate: 0.00466, Loss: 0.1006, Accuracy:0.961\nIteration: 17672, learning rate: 0.00466, Loss: 0.1204, Accuracy:0.953\nIteration: 17673, learning rate: 0.00466, Loss: 0.0971, Accuracy:0.969\nIteration: 17674, learning rate: 0.00466, Loss: 0.1374, Accuracy:0.945\nIteration: 17675, learning rate: 0.00466, Loss: 0.1331, Accuracy:0.922\nIteration: 17676, learning rate: 0.00466, Loss: 0.1642, Accuracy:0.938\nIteration: 17677, learning rate: 0.00466, Loss: 0.1303, Accuracy:0.953\nIteration: 17678, learning rate: 0.00466, Loss: 0.0744, Accuracy:0.969\nIteration: 17679, learning rate: 0.00466, Loss: 0.0733, Accuracy:0.977\nIteration: 17680, learning rate: 0.00466, Loss: 0.1162, Accuracy:0.938\nIteration: 17681, learning rate: 0.00466, Loss: 0.2888, Accuracy:0.898\nIteration: 17682, learning rate: 0.00466, Loss: 0.1229, Accuracy:0.945\nIteration: 17683, learning rate: 0.00466, Loss: 0.1550, Accuracy:0.945\nIteration: 17684, learning rate: 0.00466, Loss: 0.1727, Accuracy:0.930\nIteration: 17685, learning rate: 0.00466, Loss: 0.1406, Accuracy:0.945\nIteration: 17686, learning rate: 0.00466, Loss: 0.1568, Accuracy:0.938\nIteration: 17687, learning rate: 0.00466, Loss: 0.1577, Accuracy:0.930\nIteration: 17688, learning rate: 0.00466, Loss: 0.1730, Accuracy:0.922\nIteration: 17689, learning rate: 0.00466, Loss: 0.1144, Accuracy:0.953\nIteration: 17690, learning rate: 0.00466, Loss: 0.1742, Accuracy:0.961\nIteration: 17691, learning rate: 0.00466, Loss: 0.1469, Accuracy:0.938\nIteration: 17692, learning rate: 0.00466, Loss: 0.1065, Accuracy:0.953\nIteration: 17693, learning rate: 0.00466, Loss: 0.0728, Accuracy:0.977\nIteration: 17694, learning rate: 0.00466, Loss: 0.0958, Accuracy:0.969\nIteration: 17695, learning rate: 0.00466, Loss: 0.1360, Accuracy:0.953\nIteration: 17696, learning rate: 0.00466, Loss: 0.1291, Accuracy:0.945\nIteration: 17697, learning rate: 0.00466, Loss: 0.1101, Accuracy:0.938\nIteration: 17698, learning rate: 0.00466, Loss: 0.1050, Accuracy:0.961\nIteration: 17699, learning rate: 0.00466, Loss: 0.0858, Accuracy:0.961\nIteration: 17700, learning rate: 0.00466, Loss: 0.1000, Accuracy:0.961\nIteration: 17701, learning rate: 0.00466, Loss: 0.1080, Accuracy:0.968\nEpoch: 571, Loss: 0.1290, Accuracy:0.949, Val Loss: 0.2419, Val Accuracy: 0.897\nIteration: 17702, learning rate: 0.00466, Loss: 0.1341, Accuracy:0.961\nIteration: 17703, learning rate: 0.00466, Loss: 0.1007, Accuracy:0.961\nIteration: 17704, learning rate: 0.00466, Loss: 0.1211, Accuracy:0.953\nIteration: 17705, learning rate: 0.00466, Loss: 0.2148, Accuracy:0.906\nIteration: 17706, learning rate: 0.00466, Loss: 0.1329, Accuracy:0.961\nIteration: 17707, learning rate: 0.00466, Loss: 0.1339, Accuracy:0.969\nIteration: 17708, learning rate: 0.00466, Loss: 0.0611, Accuracy:0.984\nIteration: 17709, learning rate: 0.00466, Loss: 0.1153, Accuracy:0.977\nIteration: 17710, learning rate: 0.00466, Loss: 0.1517, Accuracy:0.930\nIteration: 17711, learning rate: 0.00466, Loss: 0.0944, Accuracy:0.977\nIteration: 17712, learning rate: 0.00466, Loss: 0.0922, Accuracy:0.953\nIteration: 17713, learning rate: 0.00466, Loss: 0.1294, Accuracy:0.961\nIteration: 17714, learning rate: 0.00466, Loss: 0.1220, Accuracy:0.969\nIteration: 17715, learning rate: 0.00466, Loss: 0.1269, Accuracy:0.961\nIteration: 17716, learning rate: 0.00466, Loss: 0.0977, Accuracy:0.969\nIteration: 17717, learning rate: 0.00466, Loss: 0.1318, Accuracy:0.953\nIteration: 17718, learning rate: 0.00466, Loss: 0.1739, Accuracy:0.938\nIteration: 17719, learning rate: 0.00466, Loss: 0.1258, Accuracy:0.961\nIteration: 17720, learning rate: 0.00465, Loss: 0.1027, Accuracy:0.969\nIteration: 17721, learning rate: 0.00465, Loss: 0.1565, Accuracy:0.930\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17722, learning rate: 0.00465, Loss: 0.1278, Accuracy:0.961\nIteration: 17723, learning rate: 0.00465, Loss: 0.1844, Accuracy:0.945\nIteration: 17724, learning rate: 0.00465, Loss: 0.1931, Accuracy:0.930\nIteration: 17725, learning rate: 0.00465, Loss: 0.2132, Accuracy:0.938\nIteration: 17726, learning rate: 0.00465, Loss: 0.0623, Accuracy:0.984\nIteration: 17727, learning rate: 0.00465, Loss: 0.1141, Accuracy:0.953\nIteration: 17728, learning rate: 0.00465, Loss: 0.0896, Accuracy:0.953\nIteration: 17729, learning rate: 0.00465, Loss: 0.1441, Accuracy:0.938\nIteration: 17730, learning rate: 0.00465, Loss: 0.1062, Accuracy:0.961\nIteration: 17731, learning rate: 0.00465, Loss: 0.1396, Accuracy:0.953\nIteration: 17732, learning rate: 0.00465, Loss: 0.1297, Accuracy:0.935\nEpoch: 572, Loss: 0.1298, Accuracy:0.955, Val Loss: 0.4036, Val Accuracy: 0.861\nIteration: 17733, learning rate: 0.00465, Loss: 0.1164, Accuracy:0.961\nIteration: 17734, learning rate: 0.00465, Loss: 0.0907, Accuracy:0.961\nIteration: 17735, learning rate: 0.00465, Loss: 0.1113, Accuracy:0.953\nIteration: 17736, learning rate: 0.00465, Loss: 0.1535, Accuracy:0.961\nIteration: 17737, learning rate: 0.00465, Loss: 0.1418, Accuracy:0.945\nIteration: 17738, learning rate: 0.00465, Loss: 0.1553, Accuracy:0.938\nIteration: 17739, learning rate: 0.00465, Loss: 0.1145, Accuracy:0.938\nIteration: 17740, learning rate: 0.00465, Loss: 0.1372, Accuracy:0.953\nIteration: 17741, learning rate: 0.00465, Loss: 0.0789, Accuracy:0.977\nIteration: 17742, learning rate: 0.00465, Loss: 0.1182, Accuracy:0.961\nIteration: 17743, learning rate: 0.00465, Loss: 0.1206, Accuracy:0.961\nIteration: 17744, learning rate: 0.00465, Loss: 0.1086, Accuracy:0.938\nIteration: 17745, learning rate: 0.00465, Loss: 0.2115, Accuracy:0.914\nIteration: 17746, learning rate: 0.00465, Loss: 0.0927, Accuracy:0.969\nIteration: 17747, learning rate: 0.00465, Loss: 0.1654, Accuracy:0.938\nIteration: 17748, learning rate: 0.00465, Loss: 0.0739, Accuracy:0.969\nIteration: 17749, learning rate: 0.00465, Loss: 0.1292, Accuracy:0.953\nIteration: 17750, learning rate: 0.00465, Loss: 0.1418, Accuracy:0.953\nIteration: 17751, learning rate: 0.00465, Loss: 0.1055, Accuracy:0.977\nIteration: 17752, learning rate: 0.00465, Loss: 0.0601, Accuracy:0.969\nIteration: 17753, learning rate: 0.00465, Loss: 0.1606, Accuracy:0.938\nIteration: 17754, learning rate: 0.00465, Loss: 0.1950, Accuracy:0.898\nIteration: 17755, learning rate: 0.00465, Loss: 0.1477, Accuracy:0.961\nIteration: 17756, learning rate: 0.00465, Loss: 0.1184, Accuracy:0.961\nIteration: 17757, learning rate: 0.00465, Loss: 0.0981, Accuracy:0.969\nIteration: 17758, learning rate: 0.00465, Loss: 0.1243, Accuracy:0.945\nIteration: 17759, learning rate: 0.00465, Loss: 0.1005, Accuracy:0.977\nIteration: 17760, learning rate: 0.00465, Loss: 0.0481, Accuracy:0.992\nIteration: 17761, learning rate: 0.00465, Loss: 0.1118, Accuracy:0.953\nIteration: 17762, learning rate: 0.00465, Loss: 0.1326, Accuracy:0.953\nIteration: 17763, learning rate: 0.00465, Loss: 0.1020, Accuracy:0.957\nEpoch: 573, Loss: 0.1215, Accuracy:0.955, Val Loss: 0.2920, Val Accuracy: 0.878\nIteration: 17764, learning rate: 0.00465, Loss: 0.1001, Accuracy:0.977\nIteration: 17765, learning rate: 0.00465, Loss: 0.1475, Accuracy:0.953\nIteration: 17766, learning rate: 0.00465, Loss: 0.1338, Accuracy:0.930\nIteration: 17767, learning rate: 0.00465, Loss: 0.1255, Accuracy:0.953\nIteration: 17768, learning rate: 0.00465, Loss: 0.2171, Accuracy:0.930\nIteration: 17769, learning rate: 0.00465, Loss: 0.1292, Accuracy:0.953\nIteration: 17770, learning rate: 0.00465, Loss: 0.1200, Accuracy:0.953\nIteration: 17771, learning rate: 0.00465, Loss: 0.1447, Accuracy:0.953\nIteration: 17772, learning rate: 0.00465, Loss: 0.1738, Accuracy:0.922\nIteration: 17773, learning rate: 0.00465, Loss: 0.1314, Accuracy:0.961\nIteration: 17774, learning rate: 0.00465, Loss: 0.2504, Accuracy:0.922\nIteration: 17775, learning rate: 0.00465, Loss: 0.1536, Accuracy:0.961\nIteration: 17776, learning rate: 0.00465, Loss: 0.0950, Accuracy:0.961\nIteration: 17777, learning rate: 0.00465, Loss: 0.0978, Accuracy:0.953\nIteration: 17778, learning rate: 0.00465, Loss: 0.1387, Accuracy:0.961\nIteration: 17779, learning rate: 0.00465, Loss: 0.1456, Accuracy:0.953\nIteration: 17780, learning rate: 0.00465, Loss: 0.1136, Accuracy:0.945\nIteration: 17781, learning rate: 0.00465, Loss: 0.1705, Accuracy:0.922\nIteration: 17782, learning rate: 0.00465, Loss: 0.2035, Accuracy:0.914\nIteration: 17783, learning rate: 0.00465, Loss: 0.0860, Accuracy:0.977\nIteration: 17784, learning rate: 0.00465, Loss: 0.0992, Accuracy:0.969\nIteration: 17785, learning rate: 0.00465, Loss: 0.1377, Accuracy:0.953\nIteration: 17786, learning rate: 0.00465, Loss: 0.1242, Accuracy:0.961\nIteration: 17787, learning rate: 0.00465, Loss: 0.1530, Accuracy:0.938\nIteration: 17788, learning rate: 0.00465, Loss: 0.1558, Accuracy:0.961\nIteration: 17789, learning rate: 0.00465, Loss: 0.1758, Accuracy:0.922\nIteration: 17790, learning rate: 0.00465, Loss: 0.1232, Accuracy:0.922\nIteration: 17791, learning rate: 0.00465, Loss: 0.0820, Accuracy:0.984\nIteration: 17792, learning rate: 0.00465, Loss: 0.1198, Accuracy:0.945\nIteration: 17793, learning rate: 0.00465, Loss: 0.0833, Accuracy:0.977\nIteration: 17794, learning rate: 0.00465, Loss: 0.1977, Accuracy:0.914\nEpoch: 574, Loss: 0.1397, Accuracy:0.948, Val Loss: 0.3344, Val Accuracy: 0.874\nIteration: 17795, learning rate: 0.00465, Loss: 0.1240, Accuracy:0.961\nIteration: 17796, learning rate: 0.00465, Loss: 0.1264, Accuracy:0.953\nIteration: 17797, learning rate: 0.00465, Loss: 0.1180, Accuracy:0.953\nIteration: 17798, learning rate: 0.00465, Loss: 0.1018, Accuracy:0.969\nIteration: 17799, learning rate: 0.00465, Loss: 0.1180, Accuracy:0.953\nIteration: 17800, learning rate: 0.00464, Loss: 0.0776, Accuracy:0.969\nIteration: 17801, learning rate: 0.00464, Loss: 0.1226, Accuracy:0.945\nIteration: 17802, learning rate: 0.00464, Loss: 0.1264, Accuracy:0.953\nIteration: 17803, learning rate: 0.00464, Loss: 0.1018, Accuracy:0.969\nIteration: 17804, learning rate: 0.00464, Loss: 0.1544, Accuracy:0.938\nIteration: 17805, learning rate: 0.00464, Loss: 0.1435, Accuracy:0.953\nIteration: 17806, learning rate: 0.00464, Loss: 0.0983, Accuracy:0.953\nIteration: 17807, learning rate: 0.00464, Loss: 0.1885, Accuracy:0.922\nIteration: 17808, learning rate: 0.00464, Loss: 0.1625, Accuracy:0.938\nIteration: 17809, learning rate: 0.00464, Loss: 0.1491, Accuracy:0.945\nIteration: 17810, learning rate: 0.00464, Loss: 0.1114, Accuracy:0.961\nIteration: 17811, learning rate: 0.00464, Loss: 0.0843, Accuracy:0.977\nIteration: 17812, learning rate: 0.00464, Loss: 0.2031, Accuracy:0.930\nIteration: 17813, learning rate: 0.00464, Loss: 0.1126, Accuracy:0.977\nIteration: 17814, learning rate: 0.00464, Loss: 0.1030, Accuracy:0.961\nIteration: 17815, learning rate: 0.00464, Loss: 0.0833, Accuracy:0.969\nIteration: 17816, learning rate: 0.00464, Loss: 0.1448, Accuracy:0.938\nIteration: 17817, learning rate: 0.00464, Loss: 0.0932, Accuracy:0.969\nIteration: 17818, learning rate: 0.00464, Loss: 0.0527, Accuracy:1.000\nIteration: 17819, learning rate: 0.00464, Loss: 0.1397, Accuracy:0.930\nIteration: 17820, learning rate: 0.00464, Loss: 0.1049, Accuracy:0.961\nIteration: 17821, learning rate: 0.00464, Loss: 0.0899, Accuracy:0.977\nIteration: 17822, learning rate: 0.00464, Loss: 0.1578, Accuracy:0.961\nIteration: 17823, learning rate: 0.00464, Loss: 0.1400, Accuracy:0.938\nIteration: 17824, learning rate: 0.00464, Loss: 0.1380, Accuracy:0.938\nIteration: 17825, learning rate: 0.00464, Loss: 0.1143, Accuracy:0.935\nEpoch: 575, Loss: 0.1221, Accuracy:0.955, Val Loss: 0.2466, Val Accuracy: 0.902\nIteration: 17826, learning rate: 0.00464, Loss: 0.0920, Accuracy:0.984\nIteration: 17827, learning rate: 0.00464, Loss: 0.1688, Accuracy:0.945\nIteration: 17828, learning rate: 0.00464, Loss: 0.1201, Accuracy:0.953\nIteration: 17829, learning rate: 0.00464, Loss: 0.1355, Accuracy:0.945\nIteration: 17830, learning rate: 0.00464, Loss: 0.1115, Accuracy:0.961\nIteration: 17831, learning rate: 0.00464, Loss: 0.0797, Accuracy:0.969\nIteration: 17832, learning rate: 0.00464, Loss: 0.1629, Accuracy:0.953\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 17833, learning rate: 0.00464, Loss: 0.1504, Accuracy:0.945\nIteration: 17834, learning rate: 0.00464, Loss: 0.1268, Accuracy:0.969\nIteration: 17835, learning rate: 0.00464, Loss: 0.1227, Accuracy:0.945\nIteration: 17836, learning rate: 0.00464, Loss: 0.1675, Accuracy:0.945\nIteration: 17837, learning rate: 0.00464, Loss: 0.1161, Accuracy:0.969\nIteration: 17838, learning rate: 0.00464, Loss: 0.1348, Accuracy:0.953\nIteration: 17839, learning rate: 0.00464, Loss: 0.1266, Accuracy:0.961\nIteration: 17840, learning rate: 0.00464, Loss: 0.0913, Accuracy:0.984\nIteration: 17841, learning rate: 0.00464, Loss: 0.1425, Accuracy:0.961\nIteration: 17842, learning rate: 0.00464, Loss: 0.1853, Accuracy:0.953\nIteration: 17843, learning rate: 0.00464, Loss: 0.1564, Accuracy:0.922\nIteration: 17844, learning rate: 0.00464, Loss: 0.1066, Accuracy:0.969\nIteration: 17845, learning rate: 0.00464, Loss: 0.1229, Accuracy:0.961\nIteration: 17846, learning rate: 0.00464, Loss: 0.1732, Accuracy:0.945\nIteration: 17847, learning rate: 0.00464, Loss: 0.1127, Accuracy:0.969\nIteration: 17848, learning rate: 0.00464, Loss: 0.0886, Accuracy:0.961\nIteration: 17849, learning rate: 0.00464, Loss: 0.1029, Accuracy:0.961\nIteration: 17850, learning rate: 0.00464, Loss: 0.1165, Accuracy:0.969\nIteration: 17851, learning rate: 0.00464, Loss: 0.0517, Accuracy:0.984\nIteration: 17852, learning rate: 0.00464, Loss: 0.0885, Accuracy:0.961\nIteration: 17853, learning rate: 0.00464, Loss: 0.1375, Accuracy:0.953\nIteration: 17854, learning rate: 0.00464, Loss: 0.0731, Accuracy:0.969\nIteration: 17855, learning rate: 0.00464, Loss: 0.1168, Accuracy:0.961\nIteration: 17856, learning rate: 0.00464, Loss: 0.1238, Accuracy:0.946\nEpoch: 576, Loss: 0.1228, Accuracy:0.959, Val Loss: 0.3426, Val Accuracy: 0.853\nIteration: 17857, learning rate: 0.00464, Loss: 0.0960, Accuracy:0.977\nIteration: 17858, learning rate: 0.00464, Loss: 0.1027, Accuracy:0.945\nIteration: 17859, learning rate: 0.00464, Loss: 0.1130, Accuracy:0.977\nIteration: 17860, learning rate: 0.00464, Loss: 0.1147, Accuracy:0.961\nIteration: 17861, learning rate: 0.00464, Loss: 0.0887, Accuracy:0.953\nIteration: 17862, learning rate: 0.00464, Loss: 0.0793, Accuracy:0.969\nIteration: 17863, learning rate: 0.00464, Loss: 0.1176, Accuracy:0.945\nIteration: 17864, learning rate: 0.00464, Loss: 0.1573, Accuracy:0.953\nIteration: 17865, learning rate: 0.00464, Loss: 0.1606, Accuracy:0.961\nIteration: 17866, learning rate: 0.00464, Loss: 0.1411, Accuracy:0.945\nIteration: 17867, learning rate: 0.00464, Loss: 0.1952, Accuracy:0.914\nIteration: 17868, learning rate: 0.00464, Loss: 0.1210, Accuracy:0.961\nIteration: 17869, learning rate: 0.00464, Loss: 0.1510, Accuracy:0.961\nIteration: 17870, learning rate: 0.00464, Loss: 0.0967, Accuracy:0.977\nIteration: 17871, learning rate: 0.00464, Loss: 0.0783, Accuracy:0.961\nIteration: 17872, learning rate: 0.00464, Loss: 0.1432, Accuracy:0.961\nIteration: 17873, learning rate: 0.00464, Loss: 0.0911, Accuracy:0.961\nIteration: 17874, learning rate: 0.00464, Loss: 0.1109, Accuracy:0.977\nIteration: 17875, learning rate: 0.00464, Loss: 0.1477, Accuracy:0.938\nIteration: 17876, learning rate: 0.00464, Loss: 0.0927, Accuracy:0.953\nIteration: 17877, learning rate: 0.00464, Loss: 0.1100, Accuracy:0.961\nIteration: 17878, learning rate: 0.00464, Loss: 0.1162, Accuracy:0.961\nIteration: 17879, learning rate: 0.00464, Loss: 0.1630, Accuracy:0.930\nIteration: 17880, learning rate: 0.00463, Loss: 0.1224, Accuracy:0.945\nIteration: 17881, learning rate: 0.00463, Loss: 0.1582, Accuracy:0.961\nIteration: 17882, learning rate: 0.00463, Loss: 0.0773, Accuracy:0.969\nIteration: 17883, learning rate: 0.00463, Loss: 0.1178, Accuracy:0.953\nIteration: 17884, learning rate: 0.00463, Loss: 0.1340, Accuracy:0.945\nIteration: 17885, learning rate: 0.00463, Loss: 0.1347, Accuracy:0.945\nIteration: 17886, learning rate: 0.00463, Loss: 0.0983, Accuracy:0.969\nIteration: 17887, learning rate: 0.00463, Loss: 0.1167, Accuracy:0.957\nEpoch: 577, Loss: 0.1209, Accuracy:0.956, Val Loss: 0.3279, Val Accuracy: 0.868\nIteration: 17888, learning rate: 0.00463, Loss: 0.0835, Accuracy:0.969\nIteration: 17889, learning rate: 0.00463, Loss: 0.1223, Accuracy:0.953\nIteration: 17890, learning rate: 0.00463, Loss: 0.1466, Accuracy:0.961\nIteration: 17891, learning rate: 0.00463, Loss: 0.0945, Accuracy:0.961\nIteration: 17892, learning rate: 0.00463, Loss: 0.1078, Accuracy:0.977\nIteration: 17893, learning rate: 0.00463, Loss: 0.1465, Accuracy:0.930\nIteration: 17894, learning rate: 0.00463, Loss: 0.0719, Accuracy:0.977\nIteration: 17895, learning rate: 0.00463, Loss: 0.0755, Accuracy:0.953\nIteration: 17896, learning rate: 0.00463, Loss: 0.1429, Accuracy:0.930\nIteration: 17897, learning rate: 0.00463, Loss: 0.1584, Accuracy:0.938\nIteration: 17898, learning rate: 0.00463, Loss: 0.1062, Accuracy:0.969\nIteration: 17899, learning rate: 0.00463, Loss: 0.1308, Accuracy:0.945\nIteration: 17900, learning rate: 0.00463, Loss: 0.0839, Accuracy:0.969\nIteration: 17901, learning rate: 0.00463, Loss: 0.1675, Accuracy:0.930\nIteration: 17902, learning rate: 0.00463, Loss: 0.0776, Accuracy:0.961\nIteration: 17903, learning rate: 0.00463, Loss: 0.0702, Accuracy:0.977\nIteration: 17904, learning rate: 0.00463, Loss: 0.0823, Accuracy:0.969\nIteration: 17905, learning rate: 0.00463, Loss: 0.1844, Accuracy:0.930\nIteration: 17906, learning rate: 0.00463, Loss: 0.0704, Accuracy:0.977\nIteration: 17907, learning rate: 0.00463, Loss: 0.1456, Accuracy:0.930\nIteration: 17908, learning rate: 0.00463, Loss: 0.1190, Accuracy:0.961\nIteration: 17909, learning rate: 0.00463, Loss: 0.1292, Accuracy:0.953\nIteration: 17910, learning rate: 0.00463, Loss: 0.0753, Accuracy:0.969\nIteration: 17911, learning rate: 0.00463, Loss: 0.1728, Accuracy:0.938\nIteration: 17912, learning rate: 0.00463, Loss: 0.0674, Accuracy:0.984\nIteration: 17913, learning rate: 0.00463, Loss: 0.2073, Accuracy:0.922\nIteration: 17914, learning rate: 0.00463, Loss: 0.2108, Accuracy:0.945\nIteration: 17915, learning rate: 0.00463, Loss: 0.1185, Accuracy:0.938\nIteration: 17916, learning rate: 0.00463, Loss: 0.1705, Accuracy:0.930\nIteration: 17917, learning rate: 0.00463, Loss: 0.1198, Accuracy:0.961\nIteration: 17918, learning rate: 0.00463, Loss: 0.0871, Accuracy:0.968\nEpoch: 578, Loss: 0.1209, Accuracy:0.954, Val Loss: 0.3046, Val Accuracy: 0.888\nIteration: 17919, learning rate: 0.00463, Loss: 0.1262, Accuracy:0.953\nIteration: 17920, learning rate: 0.00463, Loss: 0.1695, Accuracy:0.945\nIteration: 17921, learning rate: 0.00463, Loss: 0.0840, Accuracy:0.969\nIteration: 17922, learning rate: 0.00463, Loss: 0.1377, Accuracy:0.945\nIteration: 17923, learning rate: 0.00463, Loss: 0.1354, Accuracy:0.945\nIteration: 17924, learning rate: 0.00463, Loss: 0.0765, Accuracy:0.977\nIteration: 17925, learning rate: 0.00463, Loss: 0.1121, Accuracy:0.953\nIteration: 17926, learning rate: 0.00463, Loss: 0.1094, Accuracy:0.945\nIteration: 17927, learning rate: 0.00463, Loss: 0.0944, Accuracy:0.977\nIteration: 17928, learning rate: 0.00463, Loss: 0.0550, Accuracy:0.992\nIteration: 17929, learning rate: 0.00463, Loss: 0.0888, Accuracy:0.969\nIteration: 17930, learning rate: 0.00463, Loss: 0.0962, Accuracy:0.953\nIteration: 17931, learning rate: 0.00463, Loss: 0.1218, Accuracy:0.961\nIteration: 17932, learning rate: 0.00463, Loss: 0.0943, Accuracy:0.969\nIteration: 17933, learning rate: 0.00463, Loss: 0.1322, Accuracy:0.953\nIteration: 17934, learning rate: 0.00463, Loss: 0.1334, Accuracy:0.953\nIteration: 17935, learning rate: 0.00463, Loss: 0.1199, Accuracy:0.930\nIteration: 17936, learning rate: 0.00463, Loss: 0.0728, Accuracy:0.977\nIteration: 17937, learning rate: 0.00463, Loss: 0.0982, Accuracy:0.977\nIteration: 17938, learning rate: 0.00463, Loss: 0.1024, Accuracy:0.953\nIteration: 17939, learning rate: 0.00463, Loss: 0.1283, Accuracy:0.953\nIteration: 17940, learning rate: 0.00463, Loss: 0.1297, Accuracy:0.945\nIteration: 17941, learning rate: 0.00463, Loss: 0.2101, Accuracy:0.930\nIteration: 17942, learning rate: 0.00463, Loss: 0.1348, Accuracy:0.961\nIteration: 17943, learning rate: 0.00463, Loss: 0.1204, Accuracy:0.961\nIteration: 17944, learning rate: 0.00463, Loss: 0.1311, Accuracy:0.945\nIteration: 17945, learning rate: 0.00463, Loss: 0.1308, Accuracy:0.930\nIteration: 17946, learning rate: 0.00463, Loss: 0.1370, Accuracy:0.961\nIteration: 17947, learning rate: 0.00463, Loss: 0.1887, Accuracy:0.906\nIteration: 17948, learning rate: 0.00463, Loss: 0.1114, Accuracy:0.953\nIteration: 17949, learning rate: 0.00463, Loss: 0.1197, Accuracy:0.946\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 579, Loss: 0.1194, Accuracy:0.954, Val Loss: 0.2519, Val Accuracy: 0.904\nIteration: 17950, learning rate: 0.00463, Loss: 0.1182, Accuracy:0.969\nIteration: 17951, learning rate: 0.00463, Loss: 0.1254, Accuracy:0.945\nIteration: 17952, learning rate: 0.00463, Loss: 0.1282, Accuracy:0.961\nIteration: 17953, learning rate: 0.00463, Loss: 0.1188, Accuracy:0.977\nIteration: 17954, learning rate: 0.00463, Loss: 0.1205, Accuracy:0.961\nIteration: 17955, learning rate: 0.00463, Loss: 0.1629, Accuracy:0.930\nIteration: 17956, learning rate: 0.00463, Loss: 0.1385, Accuracy:0.938\nIteration: 17957, learning rate: 0.00463, Loss: 0.1331, Accuracy:0.969\nIteration: 17958, learning rate: 0.00463, Loss: 0.0666, Accuracy:0.969\nIteration: 17959, learning rate: 0.00463, Loss: 0.1064, Accuracy:0.969\nIteration: 17960, learning rate: 0.00462, Loss: 0.1066, Accuracy:0.961\nIteration: 17961, learning rate: 0.00462, Loss: 0.0804, Accuracy:0.984\nIteration: 17962, learning rate: 0.00462, Loss: 0.1348, Accuracy:0.938\nIteration: 17963, learning rate: 0.00462, Loss: 0.1885, Accuracy:0.930\nIteration: 17964, learning rate: 0.00462, Loss: 0.0623, Accuracy:0.984\nIteration: 17965, learning rate: 0.00462, Loss: 0.1349, Accuracy:0.953\nIteration: 17966, learning rate: 0.00462, Loss: 0.2524, Accuracy:0.891\nIteration: 17967, learning rate: 0.00462, Loss: 0.1537, Accuracy:0.938\nIteration: 17968, learning rate: 0.00462, Loss: 0.1210, Accuracy:0.945\nIteration: 17969, learning rate: 0.00462, Loss: 0.0743, Accuracy:0.969\nIteration: 17970, learning rate: 0.00462, Loss: 0.1037, Accuracy:0.969\nIteration: 17971, learning rate: 0.00462, Loss: 0.1577, Accuracy:0.922\nIteration: 17972, learning rate: 0.00462, Loss: 0.1316, Accuracy:0.945\nIteration: 17973, learning rate: 0.00462, Loss: 0.0578, Accuracy:1.000\nIteration: 17974, learning rate: 0.00462, Loss: 0.0792, Accuracy:0.961\nIteration: 17975, learning rate: 0.00462, Loss: 0.1088, Accuracy:0.961\nIteration: 17976, learning rate: 0.00462, Loss: 0.1843, Accuracy:0.945\nIteration: 17977, learning rate: 0.00462, Loss: 0.1180, Accuracy:0.961\nIteration: 17978, learning rate: 0.00462, Loss: 0.1297, Accuracy:0.961\nIteration: 17979, learning rate: 0.00462, Loss: 0.1790, Accuracy:0.938\nIteration: 17980, learning rate: 0.00462, Loss: 0.0912, Accuracy:0.957\nEpoch: 580, Loss: 0.1248, Accuracy:0.955, Val Loss: 0.3224, Val Accuracy: 0.873\nIteration: 17981, learning rate: 0.00462, Loss: 0.1497, Accuracy:0.945\nIteration: 17982, learning rate: 0.00462, Loss: 0.1726, Accuracy:0.922\nIteration: 17983, learning rate: 0.00462, Loss: 0.1551, Accuracy:0.961\nIteration: 17984, learning rate: 0.00462, Loss: 0.1456, Accuracy:0.945\nIteration: 17985, learning rate: 0.00462, Loss: 0.1531, Accuracy:0.930\nIteration: 17986, learning rate: 0.00462, Loss: 0.1275, Accuracy:0.945\nIteration: 17987, learning rate: 0.00462, Loss: 0.0879, Accuracy:0.969\nIteration: 17988, learning rate: 0.00462, Loss: 0.1232, Accuracy:0.945\nIteration: 17989, learning rate: 0.00462, Loss: 0.1110, Accuracy:0.961\nIteration: 17990, learning rate: 0.00462, Loss: 0.0720, Accuracy:0.984\nIteration: 17991, learning rate: 0.00462, Loss: 0.0918, Accuracy:0.969\nIteration: 17992, learning rate: 0.00462, Loss: 0.1097, Accuracy:0.961\nIteration: 17993, learning rate: 0.00462, Loss: 0.1253, Accuracy:0.969\nIteration: 17994, learning rate: 0.00462, Loss: 0.0977, Accuracy:0.969\nIteration: 17995, learning rate: 0.00462, Loss: 0.1125, Accuracy:0.961\nIteration: 17996, learning rate: 0.00462, Loss: 0.1540, Accuracy:0.938\nIteration: 17997, learning rate: 0.00462, Loss: 0.1239, Accuracy:0.930\nIteration: 17998, learning rate: 0.00462, Loss: 0.1038, Accuracy:0.953\nIteration: 17999, learning rate: 0.00462, Loss: 0.1622, Accuracy:0.945\nIteration: 18000, learning rate: 0.00462, Loss: 0.0734, Accuracy:0.969\nIteration: 18001, learning rate: 0.00462, Loss: 0.1224, Accuracy:0.930\nIteration: 18002, learning rate: 0.00462, Loss: 0.0858, Accuracy:0.969\nIteration: 18003, learning rate: 0.00462, Loss: 0.1144, Accuracy:0.953\nIteration: 18004, learning rate: 0.00462, Loss: 0.1519, Accuracy:0.945\nIteration: 18005, learning rate: 0.00462, Loss: 0.1437, Accuracy:0.953\nIteration: 18006, learning rate: 0.00462, Loss: 0.2093, Accuracy:0.914\nIteration: 18007, learning rate: 0.00462, Loss: 0.1113, Accuracy:0.953\nIteration: 18008, learning rate: 0.00462, Loss: 0.0958, Accuracy:0.961\nIteration: 18009, learning rate: 0.00462, Loss: 0.1426, Accuracy:0.945\nIteration: 18010, learning rate: 0.00462, Loss: 0.0485, Accuracy:0.992\nIteration: 18011, learning rate: 0.00462, Loss: 0.0725, Accuracy:0.968\nEpoch: 581, Loss: 0.1210, Accuracy:0.953, Val Loss: 0.2619, Val Accuracy: 0.897\nIteration: 18012, learning rate: 0.00462, Loss: 0.1309, Accuracy:0.930\nIteration: 18013, learning rate: 0.00462, Loss: 0.1389, Accuracy:0.961\nIteration: 18014, learning rate: 0.00462, Loss: 0.1945, Accuracy:0.922\nIteration: 18015, learning rate: 0.00462, Loss: 0.1157, Accuracy:0.977\nIteration: 18016, learning rate: 0.00462, Loss: 0.0974, Accuracy:0.969\nIteration: 18017, learning rate: 0.00462, Loss: 0.0681, Accuracy:0.977\nIteration: 18018, learning rate: 0.00462, Loss: 0.0953, Accuracy:0.969\nIteration: 18019, learning rate: 0.00462, Loss: 0.0890, Accuracy:0.953\nIteration: 18020, learning rate: 0.00462, Loss: 0.1006, Accuracy:0.969\nIteration: 18021, learning rate: 0.00462, Loss: 0.1518, Accuracy:0.945\nIteration: 18022, learning rate: 0.00462, Loss: 0.0888, Accuracy:0.961\nIteration: 18023, learning rate: 0.00462, Loss: 0.0959, Accuracy:0.961\nIteration: 18024, learning rate: 0.00462, Loss: 0.0883, Accuracy:0.984\nIteration: 18025, learning rate: 0.00462, Loss: 0.0613, Accuracy:0.977\nIteration: 18026, learning rate: 0.00462, Loss: 0.2083, Accuracy:0.898\nIteration: 18027, learning rate: 0.00462, Loss: 0.0992, Accuracy:0.977\nIteration: 18028, learning rate: 0.00462, Loss: 0.1142, Accuracy:0.961\nIteration: 18029, learning rate: 0.00462, Loss: 0.1655, Accuracy:0.953\nIteration: 18030, learning rate: 0.00462, Loss: 0.1021, Accuracy:0.953\nIteration: 18031, learning rate: 0.00462, Loss: 0.0728, Accuracy:0.969\nIteration: 18032, learning rate: 0.00462, Loss: 0.1259, Accuracy:0.938\nIteration: 18033, learning rate: 0.00462, Loss: 0.1068, Accuracy:0.953\nIteration: 18034, learning rate: 0.00462, Loss: 0.1559, Accuracy:0.914\nIteration: 18035, learning rate: 0.00462, Loss: 0.1381, Accuracy:0.961\nIteration: 18036, learning rate: 0.00462, Loss: 0.0906, Accuracy:0.953\nIteration: 18037, learning rate: 0.00462, Loss: 0.1886, Accuracy:0.930\nIteration: 18038, learning rate: 0.00462, Loss: 0.0901, Accuracy:0.977\nIteration: 18039, learning rate: 0.00462, Loss: 0.1934, Accuracy:0.922\nIteration: 18040, learning rate: 0.00462, Loss: 0.1380, Accuracy:0.945\nIteration: 18041, learning rate: 0.00461, Loss: 0.0844, Accuracy:0.969\nIteration: 18042, learning rate: 0.00461, Loss: 0.1527, Accuracy:0.957\nEpoch: 582, Loss: 0.1208, Accuracy:0.954, Val Loss: 0.2751, Val Accuracy: 0.887\nIteration: 18043, learning rate: 0.00461, Loss: 0.1655, Accuracy:0.938\nIteration: 18044, learning rate: 0.00461, Loss: 0.1657, Accuracy:0.945\nIteration: 18045, learning rate: 0.00461, Loss: 0.1088, Accuracy:0.969\nIteration: 18046, learning rate: 0.00461, Loss: 0.1085, Accuracy:0.961\nIteration: 18047, learning rate: 0.00461, Loss: 0.1289, Accuracy:0.930\nIteration: 18048, learning rate: 0.00461, Loss: 0.2237, Accuracy:0.922\nIteration: 18049, learning rate: 0.00461, Loss: 0.1075, Accuracy:0.953\nIteration: 18050, learning rate: 0.00461, Loss: 0.1258, Accuracy:0.945\nIteration: 18051, learning rate: 0.00461, Loss: 0.0733, Accuracy:0.984\nIteration: 18052, learning rate: 0.00461, Loss: 0.0657, Accuracy:0.984\nIteration: 18053, learning rate: 0.00461, Loss: 0.1104, Accuracy:0.953\nIteration: 18054, learning rate: 0.00461, Loss: 0.1285, Accuracy:0.938\nIteration: 18055, learning rate: 0.00461, Loss: 0.1310, Accuracy:0.945\nIteration: 18056, learning rate: 0.00461, Loss: 0.1378, Accuracy:0.945\nIteration: 18057, learning rate: 0.00461, Loss: 0.1401, Accuracy:0.945\nIteration: 18058, learning rate: 0.00461, Loss: 0.2191, Accuracy:0.914\nIteration: 18059, learning rate: 0.00461, Loss: 0.1122, Accuracy:0.961\nIteration: 18060, learning rate: 0.00461, Loss: 0.0649, Accuracy:0.984\nIteration: 18061, learning rate: 0.00461, Loss: 0.1984, Accuracy:0.945\nIteration: 18062, learning rate: 0.00461, Loss: 0.1252, Accuracy:0.969\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 18063, learning rate: 0.00461, Loss: 0.2033, Accuracy:0.930\nIteration: 18064, learning rate: 0.00461, Loss: 0.1468, Accuracy:0.961\nIteration: 18065, learning rate: 0.00461, Loss: 0.1240, Accuracy:0.945\nIteration: 18066, learning rate: 0.00461, Loss: 0.1802, Accuracy:0.938\nIteration: 18067, learning rate: 0.00461, Loss: 0.1375, Accuracy:0.945\nIteration: 18068, learning rate: 0.00461, Loss: 0.1697, Accuracy:0.930\nIteration: 18069, learning rate: 0.00461, Loss: 0.1270, Accuracy:0.945\nIteration: 18070, learning rate: 0.00461, Loss: 0.1296, Accuracy:0.938\nIteration: 18071, learning rate: 0.00461, Loss: 0.1661, Accuracy:0.945\nIteration: 18072, learning rate: 0.00461, Loss: 0.1019, Accuracy:0.969\nIteration: 18073, learning rate: 0.00461, Loss: 0.0532, Accuracy:0.989\nEpoch: 583, Loss: 0.1349, Accuracy:0.951, Val Loss: 0.2983, Val Accuracy: 0.881\nIteration: 18074, learning rate: 0.00461, Loss: 0.0951, Accuracy:0.969\nIteration: 18075, learning rate: 0.00461, Loss: 0.1501, Accuracy:0.945\nIteration: 18076, learning rate: 0.00461, Loss: 0.2318, Accuracy:0.930\nIteration: 18077, learning rate: 0.00461, Loss: 0.0713, Accuracy:0.969\nIteration: 18078, learning rate: 0.00461, Loss: 0.1315, Accuracy:0.953\nIteration: 18079, learning rate: 0.00461, Loss: 0.0944, Accuracy:0.953\nIteration: 18080, learning rate: 0.00461, Loss: 0.1053, Accuracy:0.961\nIteration: 18081, learning rate: 0.00461, Loss: 0.1392, Accuracy:0.961\nIteration: 18082, learning rate: 0.00461, Loss: 0.1076, Accuracy:0.961\nIteration: 18083, learning rate: 0.00461, Loss: 0.0688, Accuracy:0.977\nIteration: 18084, learning rate: 0.00461, Loss: 0.0570, Accuracy:0.984\nIteration: 18085, learning rate: 0.00461, Loss: 0.1285, Accuracy:0.953\nIteration: 18086, learning rate: 0.00461, Loss: 0.1844, Accuracy:0.922\nIteration: 18087, learning rate: 0.00461, Loss: 0.1647, Accuracy:0.945\nIteration: 18088, learning rate: 0.00461, Loss: 0.0838, Accuracy:0.969\nIteration: 18089, learning rate: 0.00461, Loss: 0.0844, Accuracy:0.969\nIteration: 18090, learning rate: 0.00461, Loss: 0.1078, Accuracy:0.969\nIteration: 18091, learning rate: 0.00461, Loss: 0.0949, Accuracy:0.969\nIteration: 18092, learning rate: 0.00461, Loss: 0.0720, Accuracy:0.977\nIteration: 18093, learning rate: 0.00461, Loss: 0.1395, Accuracy:0.961\nIteration: 18094, learning rate: 0.00461, Loss: 0.0947, Accuracy:0.961\nIteration: 18095, learning rate: 0.00461, Loss: 0.1180, Accuracy:0.953\nIteration: 18096, learning rate: 0.00461, Loss: 0.0764, Accuracy:0.961\nIteration: 18097, learning rate: 0.00461, Loss: 0.1160, Accuracy:0.953\nIteration: 18098, learning rate: 0.00461, Loss: 0.1800, Accuracy:0.945\nIteration: 18099, learning rate: 0.00461, Loss: 0.2122, Accuracy:0.938\nIteration: 18100, learning rate: 0.00461, Loss: 0.1573, Accuracy:0.922\nIteration: 18101, learning rate: 0.00461, Loss: 0.2102, Accuracy:0.898\nIteration: 18102, learning rate: 0.00461, Loss: 0.1078, Accuracy:0.977\nIteration: 18103, learning rate: 0.00461, Loss: 0.0962, Accuracy:0.977\nIteration: 18104, learning rate: 0.00461, Loss: 0.1914, Accuracy:0.914\nEpoch: 584, Loss: 0.1249, Accuracy:0.955, Val Loss: 0.3007, Val Accuracy: 0.872\nIteration: 18105, learning rate: 0.00461, Loss: 0.1043, Accuracy:0.953\nIteration: 18106, learning rate: 0.00461, Loss: 0.0930, Accuracy:0.969\nIteration: 18107, learning rate: 0.00461, Loss: 0.1677, Accuracy:0.922\nIteration: 18108, learning rate: 0.00461, Loss: 0.0800, Accuracy:0.984\nIteration: 18109, learning rate: 0.00461, Loss: 0.1166, Accuracy:0.945\nIteration: 18110, learning rate: 0.00461, Loss: 0.1192, Accuracy:0.953\nIteration: 18111, learning rate: 0.00461, Loss: 0.1267, Accuracy:0.922\nIteration: 18112, learning rate: 0.00461, Loss: 0.2006, Accuracy:0.938\nIteration: 18113, learning rate: 0.00461, Loss: 0.1097, Accuracy:0.977\nIteration: 18114, learning rate: 0.00461, Loss: 0.1791, Accuracy:0.930\nIteration: 18115, learning rate: 0.00461, Loss: 0.1239, Accuracy:0.953\nIteration: 18116, learning rate: 0.00461, Loss: 0.1113, Accuracy:0.953\nIteration: 18117, learning rate: 0.00461, Loss: 0.1403, Accuracy:0.930\nIteration: 18118, learning rate: 0.00461, Loss: 0.1253, Accuracy:0.961\nIteration: 18119, learning rate: 0.00461, Loss: 0.1673, Accuracy:0.922\nIteration: 18120, learning rate: 0.00461, Loss: 0.1010, Accuracy:0.961\nIteration: 18121, learning rate: 0.00461, Loss: 0.1038, Accuracy:0.969\nIteration: 18122, learning rate: 0.00460, Loss: 0.1312, Accuracy:0.938\nIteration: 18123, learning rate: 0.00460, Loss: 0.1226, Accuracy:0.938\nIteration: 18124, learning rate: 0.00460, Loss: 0.1243, Accuracy:0.930\nIteration: 18125, learning rate: 0.00460, Loss: 0.1540, Accuracy:0.953\nIteration: 18126, learning rate: 0.00460, Loss: 0.1117, Accuracy:0.945\nIteration: 18127, learning rate: 0.00460, Loss: 0.1283, Accuracy:0.961\nIteration: 18128, learning rate: 0.00460, Loss: 0.1476, Accuracy:0.945\nIteration: 18129, learning rate: 0.00460, Loss: 0.1374, Accuracy:0.945\nIteration: 18130, learning rate: 0.00460, Loss: 0.1478, Accuracy:0.938\nIteration: 18131, learning rate: 0.00460, Loss: 0.1582, Accuracy:0.938\nIteration: 18132, learning rate: 0.00460, Loss: 0.1306, Accuracy:0.969\nIteration: 18133, learning rate: 0.00460, Loss: 0.1389, Accuracy:0.945\nIteration: 18134, learning rate: 0.00460, Loss: 0.0783, Accuracy:0.969\nIteration: 18135, learning rate: 0.00460, Loss: 0.0960, Accuracy:0.978\nEpoch: 585, Loss: 0.1283, Accuracy:0.949, Val Loss: 0.3792, Val Accuracy: 0.852\nIteration: 18136, learning rate: 0.00460, Loss: 0.1773, Accuracy:0.922\nIteration: 18137, learning rate: 0.00460, Loss: 0.1894, Accuracy:0.945\nIteration: 18138, learning rate: 0.00460, Loss: 0.1350, Accuracy:0.961\nIteration: 18139, learning rate: 0.00460, Loss: 0.0941, Accuracy:0.969\nIteration: 18140, learning rate: 0.00460, Loss: 0.1717, Accuracy:0.930\nIteration: 18141, learning rate: 0.00460, Loss: 0.1499, Accuracy:0.945\nIteration: 18142, learning rate: 0.00460, Loss: 0.1382, Accuracy:0.953\nIteration: 18143, learning rate: 0.00460, Loss: 0.0812, Accuracy:0.977\nIteration: 18144, learning rate: 0.00460, Loss: 0.1547, Accuracy:0.938\nIteration: 18145, learning rate: 0.00460, Loss: 0.1378, Accuracy:0.953\nIteration: 18146, learning rate: 0.00460, Loss: 0.0985, Accuracy:0.953\nIteration: 18147, learning rate: 0.00460, Loss: 0.1429, Accuracy:0.945\nIteration: 18148, learning rate: 0.00460, Loss: 0.1473, Accuracy:0.953\nIteration: 18149, learning rate: 0.00460, Loss: 0.1133, Accuracy:0.961\nIteration: 18150, learning rate: 0.00460, Loss: 0.0884, Accuracy:0.984\nIteration: 18151, learning rate: 0.00460, Loss: 0.1537, Accuracy:0.938\nIteration: 18152, learning rate: 0.00460, Loss: 0.1806, Accuracy:0.930\nIteration: 18153, learning rate: 0.00460, Loss: 0.1342, Accuracy:0.961\nIteration: 18154, learning rate: 0.00460, Loss: 0.1211, Accuracy:0.945\nIteration: 18155, learning rate: 0.00460, Loss: 0.1168, Accuracy:0.961\nIteration: 18156, learning rate: 0.00460, Loss: 0.0799, Accuracy:0.977\nIteration: 18157, learning rate: 0.00460, Loss: 0.1121, Accuracy:0.945\nIteration: 18158, learning rate: 0.00460, Loss: 0.1608, Accuracy:0.953\nIteration: 18159, learning rate: 0.00460, Loss: 0.1884, Accuracy:0.938\nIteration: 18160, learning rate: 0.00460, Loss: 0.1956, Accuracy:0.953\nIteration: 18161, learning rate: 0.00460, Loss: 0.0945, Accuracy:0.977\nIteration: 18162, learning rate: 0.00460, Loss: 0.1090, Accuracy:0.953\nIteration: 18163, learning rate: 0.00460, Loss: 0.1303, Accuracy:0.938\nIteration: 18164, learning rate: 0.00460, Loss: 0.1339, Accuracy:0.945\nIteration: 18165, learning rate: 0.00460, Loss: 0.1403, Accuracy:0.945\nIteration: 18166, learning rate: 0.00460, Loss: 0.1075, Accuracy:0.957\nEpoch: 586, Loss: 0.1348, Accuracy:0.952, Val Loss: 0.2775, Val Accuracy: 0.901\nIteration: 18167, learning rate: 0.00460, Loss: 0.0698, Accuracy:0.977\nIteration: 18168, learning rate: 0.00460, Loss: 0.1336, Accuracy:0.938\nIteration: 18169, learning rate: 0.00460, Loss: 0.0775, Accuracy:0.969\nIteration: 18170, learning rate: 0.00460, Loss: 0.1180, Accuracy:0.977\nIteration: 18171, learning rate: 0.00460, Loss: 0.1581, Accuracy:0.938\nIteration: 18172, learning rate: 0.00460, Loss: 0.1457, Accuracy:0.953\nIteration: 18173, learning rate: 0.00460, Loss: 0.0811, Accuracy:0.961\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 18174, learning rate: 0.00460, Loss: 0.0731, Accuracy:0.992\nIteration: 18175, learning rate: 0.00460, Loss: 0.0962, Accuracy:0.977\nIteration: 18176, learning rate: 0.00460, Loss: 0.2596, Accuracy:0.906\nIteration: 18177, learning rate: 0.00460, Loss: 0.1265, Accuracy:0.969\nIteration: 18178, learning rate: 0.00460, Loss: 0.0604, Accuracy:0.977\nIteration: 18179, learning rate: 0.00460, Loss: 0.0649, Accuracy:0.984\nIteration: 18180, learning rate: 0.00460, Loss: 0.1678, Accuracy:0.961\nIteration: 18181, learning rate: 0.00460, Loss: 0.0884, Accuracy:0.969\nIteration: 18182, learning rate: 0.00460, Loss: 0.1216, Accuracy:0.961\nIteration: 18183, learning rate: 0.00460, Loss: 0.1630, Accuracy:0.922\nIteration: 18184, learning rate: 0.00460, Loss: 0.0858, Accuracy:0.961\nIteration: 18185, learning rate: 0.00460, Loss: 0.1252, Accuracy:0.945\nIteration: 18186, learning rate: 0.00460, Loss: 0.1579, Accuracy:0.938\nIteration: 18187, learning rate: 0.00460, Loss: 0.1846, Accuracy:0.914\nIteration: 18188, learning rate: 0.00460, Loss: 0.1691, Accuracy:0.930\nIteration: 18189, learning rate: 0.00460, Loss: 0.0862, Accuracy:0.961\nIteration: 18190, learning rate: 0.00460, Loss: 0.2701, Accuracy:0.898\nIteration: 18191, learning rate: 0.00460, Loss: 0.0982, Accuracy:0.953\nIteration: 18192, learning rate: 0.00460, Loss: 0.0996, Accuracy:0.961\nIteration: 18193, learning rate: 0.00460, Loss: 0.1666, Accuracy:0.953\nIteration: 18194, learning rate: 0.00460, Loss: 0.1027, Accuracy:0.961\nIteration: 18195, learning rate: 0.00460, Loss: 0.1461, Accuracy:0.953\nIteration: 18196, learning rate: 0.00460, Loss: 0.1178, Accuracy:0.945\nIteration: 18197, learning rate: 0.00460, Loss: 0.0996, Accuracy:0.978\nEpoch: 587, Loss: 0.1263, Accuracy:0.954, Val Loss: 0.2450, Val Accuracy: 0.906\nIteration: 18198, learning rate: 0.00460, Loss: 0.0745, Accuracy:0.984\nIteration: 18199, learning rate: 0.00460, Loss: 0.1089, Accuracy:0.977\nIteration: 18200, learning rate: 0.00460, Loss: 0.0981, Accuracy:0.961\nIteration: 18201, learning rate: 0.00460, Loss: 0.1682, Accuracy:0.930\nIteration: 18202, learning rate: 0.00460, Loss: 0.1737, Accuracy:0.930\nIteration: 18203, learning rate: 0.00460, Loss: 0.1062, Accuracy:0.977\nIteration: 18204, learning rate: 0.00459, Loss: 0.1432, Accuracy:0.914\nIteration: 18205, learning rate: 0.00459, Loss: 0.1867, Accuracy:0.938\nIteration: 18206, learning rate: 0.00459, Loss: 0.1441, Accuracy:0.945\nIteration: 18207, learning rate: 0.00459, Loss: 0.0753, Accuracy:0.977\nIteration: 18208, learning rate: 0.00459, Loss: 0.1453, Accuracy:0.961\nIteration: 18209, learning rate: 0.00459, Loss: 0.1175, Accuracy:0.945\nIteration: 18210, learning rate: 0.00459, Loss: 0.1384, Accuracy:0.945\nIteration: 18211, learning rate: 0.00459, Loss: 0.1805, Accuracy:0.922\nIteration: 18212, learning rate: 0.00459, Loss: 0.1171, Accuracy:0.953\nIteration: 18213, learning rate: 0.00459, Loss: 0.1830, Accuracy:0.938\nIteration: 18214, learning rate: 0.00459, Loss: 0.1569, Accuracy:0.930\nIteration: 18215, learning rate: 0.00459, Loss: 0.1589, Accuracy:0.945\nIteration: 18216, learning rate: 0.00459, Loss: 0.1128, Accuracy:0.969\nIteration: 18217, learning rate: 0.00459, Loss: 0.0969, Accuracy:0.969\nIteration: 18218, learning rate: 0.00459, Loss: 0.1351, Accuracy:0.977\nIteration: 18219, learning rate: 0.00459, Loss: 0.1156, Accuracy:0.945\nIteration: 18220, learning rate: 0.00459, Loss: 0.1192, Accuracy:0.953\nIteration: 18221, learning rate: 0.00459, Loss: 0.1749, Accuracy:0.914\nIteration: 18222, learning rate: 0.00459, Loss: 0.1288, Accuracy:0.945\nIteration: 18223, learning rate: 0.00459, Loss: 0.1200, Accuracy:0.961\nIteration: 18224, learning rate: 0.00459, Loss: 0.1442, Accuracy:0.938\nIteration: 18225, learning rate: 0.00459, Loss: 0.1388, Accuracy:0.930\nIteration: 18226, learning rate: 0.00459, Loss: 0.1355, Accuracy:0.945\nIteration: 18227, learning rate: 0.00459, Loss: 0.1148, Accuracy:0.953\nIteration: 18228, learning rate: 0.00459, Loss: 0.0452, Accuracy:1.000\nEpoch: 588, Loss: 0.1309, Accuracy:0.951, Val Loss: 0.3098, Val Accuracy: 0.898\nIteration: 18229, learning rate: 0.00459, Loss: 0.1263, Accuracy:0.953\nIteration: 18230, learning rate: 0.00459, Loss: 0.1504, Accuracy:0.953\nIteration: 18231, learning rate: 0.00459, Loss: 0.1377, Accuracy:0.938\nIteration: 18232, learning rate: 0.00459, Loss: 0.1833, Accuracy:0.906\nIteration: 18233, learning rate: 0.00459, Loss: 0.1493, Accuracy:0.945\nIteration: 18234, learning rate: 0.00459, Loss: 0.1526, Accuracy:0.938\nIteration: 18235, learning rate: 0.00459, Loss: 0.1258, Accuracy:0.977\nIteration: 18236, learning rate: 0.00459, Loss: 0.1787, Accuracy:0.938\nIteration: 18237, learning rate: 0.00459, Loss: 0.0599, Accuracy:0.992\nIteration: 18238, learning rate: 0.00459, Loss: 0.1000, Accuracy:0.961\nIteration: 18239, learning rate: 0.00459, Loss: 0.1011, Accuracy:0.977\nIteration: 18240, learning rate: 0.00459, Loss: 0.1700, Accuracy:0.945\nIteration: 18241, learning rate: 0.00459, Loss: 0.0762, Accuracy:0.961\nIteration: 18242, learning rate: 0.00459, Loss: 0.1938, Accuracy:0.930\nIteration: 18243, learning rate: 0.00459, Loss: 0.1562, Accuracy:0.961\nIteration: 18244, learning rate: 0.00459, Loss: 0.1618, Accuracy:0.953\nIteration: 18245, learning rate: 0.00459, Loss: 0.1290, Accuracy:0.945\nIteration: 18246, learning rate: 0.00459, Loss: 0.1500, Accuracy:0.945\nIteration: 18247, learning rate: 0.00459, Loss: 0.1266, Accuracy:0.945\nIteration: 18248, learning rate: 0.00459, Loss: 0.1344, Accuracy:0.945\nIteration: 18249, learning rate: 0.00459, Loss: 0.0658, Accuracy:1.000\nIteration: 18250, learning rate: 0.00459, Loss: 0.0789, Accuracy:0.969\nIteration: 18251, learning rate: 0.00459, Loss: 0.1819, Accuracy:0.938\nIteration: 18252, learning rate: 0.00459, Loss: 0.1102, Accuracy:0.969\nIteration: 18253, learning rate: 0.00459, Loss: 0.1289, Accuracy:0.945\nIteration: 18254, learning rate: 0.00459, Loss: 0.1455, Accuracy:0.945\nIteration: 18255, learning rate: 0.00459, Loss: 0.3187, Accuracy:0.883\nIteration: 18256, learning rate: 0.00459, Loss: 0.1376, Accuracy:0.953\nIteration: 18257, learning rate: 0.00459, Loss: 0.1401, Accuracy:0.945\nIteration: 18258, learning rate: 0.00459, Loss: 0.1420, Accuracy:0.938\nIteration: 18259, learning rate: 0.00459, Loss: 0.1334, Accuracy:0.946\nEpoch: 589, Loss: 0.1402, Accuracy:0.950, Val Loss: 0.2892, Val Accuracy: 0.871\nIteration: 18260, learning rate: 0.00459, Loss: 0.0696, Accuracy:0.977\nIteration: 18261, learning rate: 0.00459, Loss: 0.1906, Accuracy:0.914\nIteration: 18262, learning rate: 0.00459, Loss: 0.1548, Accuracy:0.906\nIteration: 18263, learning rate: 0.00459, Loss: 0.0988, Accuracy:0.945\nIteration: 18264, learning rate: 0.00459, Loss: 0.0967, Accuracy:0.953\nIteration: 18265, learning rate: 0.00459, Loss: 0.1039, Accuracy:0.953\nIteration: 18266, learning rate: 0.00459, Loss: 0.1060, Accuracy:0.953\nIteration: 18267, learning rate: 0.00459, Loss: 0.1098, Accuracy:0.969\nIteration: 18268, learning rate: 0.00459, Loss: 0.1259, Accuracy:0.961\nIteration: 18269, learning rate: 0.00459, Loss: 0.1563, Accuracy:0.945\nIteration: 18270, learning rate: 0.00459, Loss: 0.1047, Accuracy:0.961\nIteration: 18271, learning rate: 0.00459, Loss: 0.1338, Accuracy:0.938\nIteration: 18272, learning rate: 0.00459, Loss: 0.1438, Accuracy:0.945\nIteration: 18273, learning rate: 0.00459, Loss: 0.1326, Accuracy:0.945\nIteration: 18274, learning rate: 0.00459, Loss: 0.1445, Accuracy:0.938\nIteration: 18275, learning rate: 0.00459, Loss: 0.1290, Accuracy:0.938\nIteration: 18276, learning rate: 0.00459, Loss: 0.1188, Accuracy:0.969\nIteration: 18277, learning rate: 0.00459, Loss: 0.1091, Accuracy:0.953\nIteration: 18278, learning rate: 0.00459, Loss: 0.2189, Accuracy:0.914\nIteration: 18279, learning rate: 0.00459, Loss: 0.1912, Accuracy:0.906\nIteration: 18280, learning rate: 0.00459, Loss: 0.2170, Accuracy:0.914\nIteration: 18281, learning rate: 0.00459, Loss: 0.1040, Accuracy:0.953\nIteration: 18282, learning rate: 0.00459, Loss: 0.1033, Accuracy:0.969\nIteration: 18283, learning rate: 0.00459, Loss: 0.1224, Accuracy:0.945\nIteration: 18284, learning rate: 0.00459, Loss: 0.1413, Accuracy:0.961\nIteration: 18285, learning rate: 0.00459, Loss: 0.1431, Accuracy:0.930\nIteration: 18286, learning rate: 0.00458, Loss: 0.1838, Accuracy:0.938\nIteration: 18287, learning rate: 0.00458, Loss: 0.1476, Accuracy:0.953\nIteration: 18288, learning rate: 0.00458, Loss: 0.2046, Accuracy:0.922\nIteration: 18289, learning rate: 0.00458, Loss: 0.1252, Accuracy:0.938\nIteration: 18290, learning rate: 0.00458, Loss: 0.0922, Accuracy:0.978\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 590, Loss: 0.1362, Accuracy:0.945, Val Loss: 0.2568, Val Accuracy: 0.900\nIteration: 18291, learning rate: 0.00458, Loss: 0.0810, Accuracy:0.969\nIteration: 18292, learning rate: 0.00458, Loss: 0.1290, Accuracy:0.969\nIteration: 18293, learning rate: 0.00458, Loss: 0.1634, Accuracy:0.930\nIteration: 18294, learning rate: 0.00458, Loss: 0.1018, Accuracy:0.961\nIteration: 18295, learning rate: 0.00458, Loss: 0.1845, Accuracy:0.922\nIteration: 18296, learning rate: 0.00458, Loss: 0.1436, Accuracy:0.961\nIteration: 18297, learning rate: 0.00458, Loss: 0.1009, Accuracy:0.977\nIteration: 18298, learning rate: 0.00458, Loss: 0.1376, Accuracy:0.930\nIteration: 18299, learning rate: 0.00458, Loss: 0.0930, Accuracy:0.977\nIteration: 18300, learning rate: 0.00458, Loss: 0.0853, Accuracy:0.992\nIteration: 18301, learning rate: 0.00458, Loss: 0.1384, Accuracy:0.930\nIteration: 18302, learning rate: 0.00458, Loss: 0.1426, Accuracy:0.938\nIteration: 18303, learning rate: 0.00458, Loss: 0.1640, Accuracy:0.945\nIteration: 18304, learning rate: 0.00458, Loss: 0.1614, Accuracy:0.945\nIteration: 18305, learning rate: 0.00458, Loss: 0.1415, Accuracy:0.930\nIteration: 18306, learning rate: 0.00458, Loss: 0.1501, Accuracy:0.938\nIteration: 18307, learning rate: 0.00458, Loss: 0.1107, Accuracy:0.961\nIteration: 18308, learning rate: 0.00458, Loss: 0.1170, Accuracy:0.953\nIteration: 18309, learning rate: 0.00458, Loss: 0.0697, Accuracy:0.984\nIteration: 18310, learning rate: 0.00458, Loss: 0.1067, Accuracy:0.977\nIteration: 18311, learning rate: 0.00458, Loss: 0.1058, Accuracy:0.945\nIteration: 18312, learning rate: 0.00458, Loss: 0.0889, Accuracy:0.961\nIteration: 18313, learning rate: 0.00458, Loss: 0.1134, Accuracy:0.945\nIteration: 18314, learning rate: 0.00458, Loss: 0.1586, Accuracy:0.922\nIteration: 18315, learning rate: 0.00458, Loss: 0.1827, Accuracy:0.945\nIteration: 18316, learning rate: 0.00458, Loss: 0.0868, Accuracy:0.961\nIteration: 18317, learning rate: 0.00458, Loss: 0.1378, Accuracy:0.914\nIteration: 18318, learning rate: 0.00458, Loss: 0.1050, Accuracy:0.953\nIteration: 18319, learning rate: 0.00458, Loss: 0.1404, Accuracy:0.945\nIteration: 18320, learning rate: 0.00458, Loss: 0.1556, Accuracy:0.953\nIteration: 18321, learning rate: 0.00458, Loss: 0.1496, Accuracy:0.946\nEpoch: 591, Loss: 0.1273, Accuracy:0.951, Val Loss: 0.3517, Val Accuracy: 0.873\nIteration: 18322, learning rate: 0.00458, Loss: 0.1117, Accuracy:0.953\nIteration: 18323, learning rate: 0.00458, Loss: 0.1335, Accuracy:0.945\nIteration: 18324, learning rate: 0.00458, Loss: 0.0695, Accuracy:0.984\nIteration: 18325, learning rate: 0.00458, Loss: 0.1581, Accuracy:0.938\nIteration: 18326, learning rate: 0.00458, Loss: 0.0916, Accuracy:0.961\nIteration: 18327, learning rate: 0.00458, Loss: 0.0667, Accuracy:0.984\nIteration: 18328, learning rate: 0.00458, Loss: 0.0855, Accuracy:0.961\nIteration: 18329, learning rate: 0.00458, Loss: 0.1699, Accuracy:0.945\nIteration: 18330, learning rate: 0.00458, Loss: 0.1371, Accuracy:0.945\nIteration: 18331, learning rate: 0.00458, Loss: 0.1257, Accuracy:0.961\nIteration: 18332, learning rate: 0.00458, Loss: 0.1943, Accuracy:0.930\nIteration: 18333, learning rate: 0.00458, Loss: 0.1110, Accuracy:0.969\nIteration: 18334, learning rate: 0.00458, Loss: 0.1354, Accuracy:0.938\nIteration: 18335, learning rate: 0.00458, Loss: 0.1399, Accuracy:0.914\nIteration: 18336, learning rate: 0.00458, Loss: 0.0969, Accuracy:0.961\nIteration: 18337, learning rate: 0.00458, Loss: 0.1386, Accuracy:0.938\nIteration: 18338, learning rate: 0.00458, Loss: 0.1230, Accuracy:0.945\nIteration: 18339, learning rate: 0.00458, Loss: 0.1672, Accuracy:0.938\nIteration: 18340, learning rate: 0.00458, Loss: 0.0731, Accuracy:0.977\nIteration: 18341, learning rate: 0.00458, Loss: 0.1078, Accuracy:0.945\nIteration: 18342, learning rate: 0.00458, Loss: 0.1072, Accuracy:0.953\nIteration: 18343, learning rate: 0.00458, Loss: 0.1125, Accuracy:0.969\nIteration: 18344, learning rate: 0.00458, Loss: 0.0648, Accuracy:0.977\nIteration: 18345, learning rate: 0.00458, Loss: 0.1303, Accuracy:0.938\nIteration: 18346, learning rate: 0.00458, Loss: 0.1640, Accuracy:0.938\nIteration: 18347, learning rate: 0.00458, Loss: 0.1342, Accuracy:0.953\nIteration: 18348, learning rate: 0.00458, Loss: 0.1716, Accuracy:0.930\nIteration: 18349, learning rate: 0.00458, Loss: 0.0609, Accuracy:0.984\nIteration: 18350, learning rate: 0.00458, Loss: 0.1499, Accuracy:0.938\nIteration: 18351, learning rate: 0.00458, Loss: 0.1198, Accuracy:0.945\nIteration: 18352, learning rate: 0.00458, Loss: 0.0889, Accuracy:0.978\nEpoch: 592, Loss: 0.1207, Accuracy:0.953, Val Loss: 0.3129, Val Accuracy: 0.891\nIteration: 18353, learning rate: 0.00458, Loss: 0.1325, Accuracy:0.953\nIteration: 18354, learning rate: 0.00458, Loss: 0.0831, Accuracy:0.961\nIteration: 18355, learning rate: 0.00458, Loss: 0.1607, Accuracy:0.945\nIteration: 18356, learning rate: 0.00458, Loss: 0.1689, Accuracy:0.945\nIteration: 18357, learning rate: 0.00458, Loss: 0.1010, Accuracy:0.953\nIteration: 18358, learning rate: 0.00458, Loss: 0.0894, Accuracy:0.969\nIteration: 18359, learning rate: 0.00458, Loss: 0.1424, Accuracy:0.953\nIteration: 18360, learning rate: 0.00458, Loss: 0.1388, Accuracy:0.953\nIteration: 18361, learning rate: 0.00458, Loss: 0.0973, Accuracy:0.961\nIteration: 18362, learning rate: 0.00458, Loss: 0.0671, Accuracy:0.969\nIteration: 18363, learning rate: 0.00458, Loss: 0.1466, Accuracy:0.922\nIteration: 18364, learning rate: 0.00458, Loss: 0.1289, Accuracy:0.969\nIteration: 18365, learning rate: 0.00458, Loss: 0.1395, Accuracy:0.953\nIteration: 18366, learning rate: 0.00458, Loss: 0.1161, Accuracy:0.961\nIteration: 18367, learning rate: 0.00458, Loss: 0.0750, Accuracy:0.977\nIteration: 18368, learning rate: 0.00457, Loss: 0.0874, Accuracy:0.961\nIteration: 18369, learning rate: 0.00457, Loss: 0.1296, Accuracy:0.945\nIteration: 18370, learning rate: 0.00457, Loss: 0.1162, Accuracy:0.953\nIteration: 18371, learning rate: 0.00457, Loss: 0.0928, Accuracy:0.969\nIteration: 18372, learning rate: 0.00457, Loss: 0.1605, Accuracy:0.945\nIteration: 18373, learning rate: 0.00457, Loss: 0.1548, Accuracy:0.938\nIteration: 18374, learning rate: 0.00457, Loss: 0.2002, Accuracy:0.922\nIteration: 18375, learning rate: 0.00457, Loss: 0.1957, Accuracy:0.914\nIteration: 18376, learning rate: 0.00457, Loss: 0.1387, Accuracy:0.938\nIteration: 18377, learning rate: 0.00457, Loss: 0.1063, Accuracy:0.977\nIteration: 18378, learning rate: 0.00457, Loss: 0.1314, Accuracy:0.961\nIteration: 18379, learning rate: 0.00457, Loss: 0.1523, Accuracy:0.938\nIteration: 18380, learning rate: 0.00457, Loss: 0.1073, Accuracy:0.969\nIteration: 18381, learning rate: 0.00457, Loss: 0.1180, Accuracy:0.953\nIteration: 18382, learning rate: 0.00457, Loss: 0.0666, Accuracy:0.969\nIteration: 18383, learning rate: 0.00457, Loss: 0.2015, Accuracy:0.935\nEpoch: 593, Loss: 0.1273, Accuracy:0.953, Val Loss: 0.3049, Val Accuracy: 0.875\nIteration: 18384, learning rate: 0.00457, Loss: 0.1342, Accuracy:0.953\nIteration: 18385, learning rate: 0.00457, Loss: 0.0893, Accuracy:0.984\nIteration: 18386, learning rate: 0.00457, Loss: 0.1325, Accuracy:0.953\nIteration: 18387, learning rate: 0.00457, Loss: 0.2022, Accuracy:0.922\nIteration: 18388, learning rate: 0.00457, Loss: 0.0983, Accuracy:0.969\nIteration: 18389, learning rate: 0.00457, Loss: 0.1154, Accuracy:0.953\nIteration: 18390, learning rate: 0.00457, Loss: 0.0949, Accuracy:0.969\nIteration: 18391, learning rate: 0.00457, Loss: 0.0716, Accuracy:0.977\nIteration: 18392, learning rate: 0.00457, Loss: 0.1518, Accuracy:0.930\nIteration: 18393, learning rate: 0.00457, Loss: 0.1599, Accuracy:0.938\nIteration: 18394, learning rate: 0.00457, Loss: 0.0975, Accuracy:0.969\nIteration: 18395, learning rate: 0.00457, Loss: 0.0858, Accuracy:0.977\nIteration: 18396, learning rate: 0.00457, Loss: 0.2248, Accuracy:0.930\nIteration: 18397, learning rate: 0.00457, Loss: 0.1872, Accuracy:0.922\nIteration: 18398, learning rate: 0.00457, Loss: 0.0788, Accuracy:0.969\nIteration: 18399, learning rate: 0.00457, Loss: 0.1742, Accuracy:0.938\nIteration: 18400, learning rate: 0.00457, Loss: 0.1160, Accuracy:0.945\nIteration: 18401, learning rate: 0.00457, Loss: 0.1380, Accuracy:0.945\nIteration: 18402, learning rate: 0.00457, Loss: 0.1535, Accuracy:0.953\nIteration: 18403, learning rate: 0.00457, Loss: 0.0979, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 18404, learning rate: 0.00457, Loss: 0.0948, Accuracy:0.953\nIteration: 18405, learning rate: 0.00457, Loss: 0.1171, Accuracy:0.938\nIteration: 18406, learning rate: 0.00457, Loss: 0.1025, Accuracy:0.977\nIteration: 18407, learning rate: 0.00457, Loss: 0.1097, Accuracy:0.969\nIteration: 18408, learning rate: 0.00457, Loss: 0.1990, Accuracy:0.914\nIteration: 18409, learning rate: 0.00457, Loss: 0.0949, Accuracy:0.969\nIteration: 18410, learning rate: 0.00457, Loss: 0.0801, Accuracy:0.977\nIteration: 18411, learning rate: 0.00457, Loss: 0.1468, Accuracy:0.945\nIteration: 18412, learning rate: 0.00457, Loss: 0.0892, Accuracy:0.953\nIteration: 18413, learning rate: 0.00457, Loss: 0.1278, Accuracy:0.953\nIteration: 18414, learning rate: 0.00457, Loss: 0.0659, Accuracy:0.968\nEpoch: 594, Loss: 0.1236, Accuracy:0.954, Val Loss: 0.2542, Val Accuracy: 0.889\nIteration: 18415, learning rate: 0.00457, Loss: 0.1690, Accuracy:0.922\nIteration: 18416, learning rate: 0.00457, Loss: 0.1132, Accuracy:0.961\nIteration: 18417, learning rate: 0.00457, Loss: 0.1065, Accuracy:0.953\nIteration: 18418, learning rate: 0.00457, Loss: 0.0919, Accuracy:0.969\nIteration: 18419, learning rate: 0.00457, Loss: 0.1207, Accuracy:0.938\nIteration: 18420, learning rate: 0.00457, Loss: 0.1172, Accuracy:0.961\nIteration: 18421, learning rate: 0.00457, Loss: 0.0794, Accuracy:0.977\nIteration: 18422, learning rate: 0.00457, Loss: 0.0786, Accuracy:0.977\nIteration: 18423, learning rate: 0.00457, Loss: 0.0843, Accuracy:0.984\nIteration: 18424, learning rate: 0.00457, Loss: 0.1004, Accuracy:0.961\nIteration: 18425, learning rate: 0.00457, Loss: 0.1491, Accuracy:0.938\nIteration: 18426, learning rate: 0.00457, Loss: 0.1065, Accuracy:0.969\nIteration: 18427, learning rate: 0.00457, Loss: 0.1556, Accuracy:0.938\nIteration: 18428, learning rate: 0.00457, Loss: 0.1227, Accuracy:0.938\nIteration: 18429, learning rate: 0.00457, Loss: 0.1400, Accuracy:0.945\nIteration: 18430, learning rate: 0.00457, Loss: 0.0964, Accuracy:0.969\nIteration: 18431, learning rate: 0.00457, Loss: 0.0823, Accuracy:0.961\nIteration: 18432, learning rate: 0.00457, Loss: 0.1663, Accuracy:0.938\nIteration: 18433, learning rate: 0.00457, Loss: 0.1472, Accuracy:0.953\nIteration: 18434, learning rate: 0.00457, Loss: 0.0685, Accuracy:0.969\nIteration: 18435, learning rate: 0.00457, Loss: 0.1493, Accuracy:0.945\nIteration: 18436, learning rate: 0.00457, Loss: 0.0893, Accuracy:0.977\nIteration: 18437, learning rate: 0.00457, Loss: 0.0943, Accuracy:0.953\nIteration: 18438, learning rate: 0.00457, Loss: 0.0741, Accuracy:0.977\nIteration: 18439, learning rate: 0.00457, Loss: 0.1195, Accuracy:0.938\nIteration: 18440, learning rate: 0.00457, Loss: 0.1559, Accuracy:0.938\nIteration: 18441, learning rate: 0.00457, Loss: 0.0936, Accuracy:0.953\nIteration: 18442, learning rate: 0.00457, Loss: 0.0635, Accuracy:0.984\nIteration: 18443, learning rate: 0.00457, Loss: 0.1055, Accuracy:0.945\nIteration: 18444, learning rate: 0.00457, Loss: 0.0881, Accuracy:0.969\nIteration: 18445, learning rate: 0.00457, Loss: 0.1362, Accuracy:0.925\nEpoch: 595, Loss: 0.1118, Accuracy:0.955, Val Loss: 0.2858, Val Accuracy: 0.885\nIteration: 18446, learning rate: 0.00457, Loss: 0.1252, Accuracy:0.930\nIteration: 18447, learning rate: 0.00457, Loss: 0.0731, Accuracy:0.969\nIteration: 18448, learning rate: 0.00457, Loss: 0.1814, Accuracy:0.930\nIteration: 18449, learning rate: 0.00457, Loss: 0.1135, Accuracy:0.938\nIteration: 18450, learning rate: 0.00457, Loss: 0.1377, Accuracy:0.969\nIteration: 18451, learning rate: 0.00456, Loss: 0.1789, Accuracy:0.938\nIteration: 18452, learning rate: 0.00456, Loss: 0.1349, Accuracy:0.953\nIteration: 18453, learning rate: 0.00456, Loss: 0.0800, Accuracy:0.977\nIteration: 18454, learning rate: 0.00456, Loss: 0.1227, Accuracy:0.953\nIteration: 18455, learning rate: 0.00456, Loss: 0.1349, Accuracy:0.969\nIteration: 18456, learning rate: 0.00456, Loss: 0.1273, Accuracy:0.953\nIteration: 18457, learning rate: 0.00456, Loss: 0.0989, Accuracy:0.961\nIteration: 18458, learning rate: 0.00456, Loss: 0.1250, Accuracy:0.961\nIteration: 18459, learning rate: 0.00456, Loss: 0.1577, Accuracy:0.945\nIteration: 18460, learning rate: 0.00456, Loss: 0.1413, Accuracy:0.953\nIteration: 18461, learning rate: 0.00456, Loss: 0.1051, Accuracy:0.953\nIteration: 18462, learning rate: 0.00456, Loss: 0.1023, Accuracy:0.938\nIteration: 18463, learning rate: 0.00456, Loss: 0.0697, Accuracy:0.977\nIteration: 18464, learning rate: 0.00456, Loss: 0.2147, Accuracy:0.930\nIteration: 18465, learning rate: 0.00456, Loss: 0.1317, Accuracy:0.953\nIteration: 18466, learning rate: 0.00456, Loss: 0.1503, Accuracy:0.938\nIteration: 18467, learning rate: 0.00456, Loss: 0.1361, Accuracy:0.930\nIteration: 18468, learning rate: 0.00456, Loss: 0.0913, Accuracy:0.977\nIteration: 18469, learning rate: 0.00456, Loss: 0.1610, Accuracy:0.938\nIteration: 18470, learning rate: 0.00456, Loss: 0.0888, Accuracy:0.961\nIteration: 18471, learning rate: 0.00456, Loss: 0.1488, Accuracy:0.961\nIteration: 18472, learning rate: 0.00456, Loss: 0.0797, Accuracy:0.977\nIteration: 18473, learning rate: 0.00456, Loss: 0.1100, Accuracy:0.969\nIteration: 18474, learning rate: 0.00456, Loss: 0.1525, Accuracy:0.945\nIteration: 18475, learning rate: 0.00456, Loss: 0.1355, Accuracy:0.930\nIteration: 18476, learning rate: 0.00456, Loss: 0.1378, Accuracy:0.946\nEpoch: 596, Loss: 0.1273, Accuracy:0.952, Val Loss: 0.2721, Val Accuracy: 0.894\nIteration: 18477, learning rate: 0.00456, Loss: 0.1443, Accuracy:0.922\nIteration: 18478, learning rate: 0.00456, Loss: 0.1283, Accuracy:0.969\nIteration: 18479, learning rate: 0.00456, Loss: 0.1193, Accuracy:0.953\nIteration: 18480, learning rate: 0.00456, Loss: 0.1455, Accuracy:0.953\nIteration: 18481, learning rate: 0.00456, Loss: 0.1720, Accuracy:0.938\nIteration: 18482, learning rate: 0.00456, Loss: 0.1421, Accuracy:0.961\nIteration: 18483, learning rate: 0.00456, Loss: 0.1087, Accuracy:0.953\nIteration: 18484, learning rate: 0.00456, Loss: 0.1728, Accuracy:0.938\nIteration: 18485, learning rate: 0.00456, Loss: 0.1949, Accuracy:0.906\nIteration: 18486, learning rate: 0.00456, Loss: 0.1667, Accuracy:0.906\nIteration: 18487, learning rate: 0.00456, Loss: 0.0550, Accuracy:1.000\nIteration: 18488, learning rate: 0.00456, Loss: 0.1033, Accuracy:0.969\nIteration: 18489, learning rate: 0.00456, Loss: 0.1582, Accuracy:0.945\nIteration: 18490, learning rate: 0.00456, Loss: 0.0795, Accuracy:0.969\nIteration: 18491, learning rate: 0.00456, Loss: 0.1098, Accuracy:0.953\nIteration: 18492, learning rate: 0.00456, Loss: 0.1044, Accuracy:0.953\nIteration: 18493, learning rate: 0.00456, Loss: 0.0959, Accuracy:0.969\nIteration: 18494, learning rate: 0.00456, Loss: 0.0892, Accuracy:0.953\nIteration: 18495, learning rate: 0.00456, Loss: 0.1097, Accuracy:0.945\nIteration: 18496, learning rate: 0.00456, Loss: 0.1319, Accuracy:0.953\nIteration: 18497, learning rate: 0.00456, Loss: 0.1128, Accuracy:0.969\nIteration: 18498, learning rate: 0.00456, Loss: 0.1088, Accuracy:0.945\nIteration: 18499, learning rate: 0.00456, Loss: 0.0927, Accuracy:0.969\nIteration: 18500, learning rate: 0.00456, Loss: 0.1445, Accuracy:0.953\nIteration: 18501, learning rate: 0.00456, Loss: 0.0896, Accuracy:0.969\nIteration: 18502, learning rate: 0.00456, Loss: 0.0922, Accuracy:0.945\nIteration: 18503, learning rate: 0.00456, Loss: 0.1217, Accuracy:0.961\nIteration: 18504, learning rate: 0.00456, Loss: 0.0969, Accuracy:0.961\nIteration: 18505, learning rate: 0.00456, Loss: 0.1368, Accuracy:0.938\nIteration: 18506, learning rate: 0.00456, Loss: 0.1138, Accuracy:0.945\nIteration: 18507, learning rate: 0.00456, Loss: 0.1564, Accuracy:0.957\nEpoch: 597, Loss: 0.1225, Accuracy:0.952, Val Loss: 0.2899, Val Accuracy: 0.888\nIteration: 18508, learning rate: 0.00456, Loss: 0.1434, Accuracy:0.953\nIteration: 18509, learning rate: 0.00456, Loss: 0.0744, Accuracy:0.969\nIteration: 18510, learning rate: 0.00456, Loss: 0.1094, Accuracy:0.930\nIteration: 18511, learning rate: 0.00456, Loss: 0.0910, Accuracy:0.945\nIteration: 18512, learning rate: 0.00456, Loss: 0.1466, Accuracy:0.953\nIteration: 18513, learning rate: 0.00456, Loss: 0.1187, Accuracy:0.961\nIteration: 18514, learning rate: 0.00456, Loss: 0.0778, Accuracy:0.977\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 18515, learning rate: 0.00456, Loss: 0.1063, Accuracy:0.953\nIteration: 18516, learning rate: 0.00456, Loss: 0.1890, Accuracy:0.922\nIteration: 18517, learning rate: 0.00456, Loss: 0.1190, Accuracy:0.961\nIteration: 18518, learning rate: 0.00456, Loss: 0.2007, Accuracy:0.938\nIteration: 18519, learning rate: 0.00456, Loss: 0.1648, Accuracy:0.953\nIteration: 18520, learning rate: 0.00456, Loss: 0.1169, Accuracy:0.961\nIteration: 18521, learning rate: 0.00456, Loss: 0.1589, Accuracy:0.938\nIteration: 18522, learning rate: 0.00456, Loss: 0.0735, Accuracy:0.977\nIteration: 18523, learning rate: 0.00456, Loss: 0.0935, Accuracy:0.961\nIteration: 18524, learning rate: 0.00456, Loss: 0.1685, Accuracy:0.938\nIteration: 18525, learning rate: 0.00456, Loss: 0.0919, Accuracy:0.961\nIteration: 18526, learning rate: 0.00456, Loss: 0.1272, Accuracy:0.961\nIteration: 18527, learning rate: 0.00456, Loss: 0.1546, Accuracy:0.953\nIteration: 18528, learning rate: 0.00456, Loss: 0.0889, Accuracy:0.961\nIteration: 18529, learning rate: 0.00456, Loss: 0.1626, Accuracy:0.945\nIteration: 18530, learning rate: 0.00456, Loss: 0.1498, Accuracy:0.953\nIteration: 18531, learning rate: 0.00456, Loss: 0.0780, Accuracy:0.977\nIteration: 18532, learning rate: 0.00456, Loss: 0.0733, Accuracy:0.969\nIteration: 18533, learning rate: 0.00456, Loss: 0.1019, Accuracy:0.953\nIteration: 18534, learning rate: 0.00456, Loss: 0.1605, Accuracy:0.953\nIteration: 18535, learning rate: 0.00455, Loss: 0.0575, Accuracy:0.984\nIteration: 18536, learning rate: 0.00455, Loss: 0.1530, Accuracy:0.938\nIteration: 18537, learning rate: 0.00455, Loss: 0.1350, Accuracy:0.945\nIteration: 18538, learning rate: 0.00455, Loss: 0.1118, Accuracy:0.957\nEpoch: 598, Loss: 0.1225, Accuracy:0.955, Val Loss: 0.2887, Val Accuracy: 0.878\nIteration: 18539, learning rate: 0.00455, Loss: 0.1192, Accuracy:0.945\nIteration: 18540, learning rate: 0.00455, Loss: 0.0774, Accuracy:0.977\nIteration: 18541, learning rate: 0.00455, Loss: 0.0568, Accuracy:0.984\nIteration: 18542, learning rate: 0.00455, Loss: 0.2294, Accuracy:0.930\nIteration: 18543, learning rate: 0.00455, Loss: 0.1356, Accuracy:0.938\nIteration: 18544, learning rate: 0.00455, Loss: 0.1119, Accuracy:0.961\nIteration: 18545, learning rate: 0.00455, Loss: 0.0707, Accuracy:0.984\nIteration: 18546, learning rate: 0.00455, Loss: 0.0957, Accuracy:0.969\nIteration: 18547, learning rate: 0.00455, Loss: 0.0945, Accuracy:0.984\nIteration: 18548, learning rate: 0.00455, Loss: 0.1431, Accuracy:0.945\nIteration: 18549, learning rate: 0.00455, Loss: 0.1319, Accuracy:0.945\nIteration: 18550, learning rate: 0.00455, Loss: 0.1257, Accuracy:0.953\nIteration: 18551, learning rate: 0.00455, Loss: 0.1669, Accuracy:0.922\nIteration: 18552, learning rate: 0.00455, Loss: 0.1084, Accuracy:0.938\nIteration: 18553, learning rate: 0.00455, Loss: 0.1341, Accuracy:0.938\nIteration: 18554, learning rate: 0.00455, Loss: 0.1287, Accuracy:0.969\nIteration: 18555, learning rate: 0.00455, Loss: 0.0930, Accuracy:0.977\nIteration: 18556, learning rate: 0.00455, Loss: 0.1449, Accuracy:0.945\nIteration: 18557, learning rate: 0.00455, Loss: 0.0691, Accuracy:0.977\nIteration: 18558, learning rate: 0.00455, Loss: 0.0895, Accuracy:0.961\nIteration: 18559, learning rate: 0.00455, Loss: 0.1295, Accuracy:0.945\nIteration: 18560, learning rate: 0.00455, Loss: 0.1139, Accuracy:0.930\nIteration: 18561, learning rate: 0.00455, Loss: 0.1136, Accuracy:0.953\nIteration: 18562, learning rate: 0.00455, Loss: 0.1482, Accuracy:0.945\nIteration: 18563, learning rate: 0.00455, Loss: 0.1618, Accuracy:0.945\nIteration: 18564, learning rate: 0.00455, Loss: 0.1177, Accuracy:0.961\nIteration: 18565, learning rate: 0.00455, Loss: 0.1899, Accuracy:0.922\nIteration: 18566, learning rate: 0.00455, Loss: 0.0732, Accuracy:0.984\nIteration: 18567, learning rate: 0.00455, Loss: 0.1100, Accuracy:0.953\nIteration: 18568, learning rate: 0.00455, Loss: 0.1255, Accuracy:0.953\nIteration: 18569, learning rate: 0.00455, Loss: 0.1114, Accuracy:0.957\nEpoch: 599, Loss: 0.1200, Accuracy:0.955, Val Loss: 0.3170, Val Accuracy: 0.881\nIteration: 18570, learning rate: 0.00455, Loss: 0.1724, Accuracy:0.938\nIteration: 18571, learning rate: 0.00455, Loss: 0.1087, Accuracy:0.953\nIteration: 18572, learning rate: 0.00455, Loss: 0.1078, Accuracy:0.953\nIteration: 18573, learning rate: 0.00455, Loss: 0.0746, Accuracy:0.984\nIteration: 18574, learning rate: 0.00455, Loss: 0.1499, Accuracy:0.938\nIteration: 18575, learning rate: 0.00455, Loss: 0.1120, Accuracy:0.953\nIteration: 18576, learning rate: 0.00455, Loss: 0.1407, Accuracy:0.938\nIteration: 18577, learning rate: 0.00455, Loss: 0.0962, Accuracy:0.969\nIteration: 18578, learning rate: 0.00455, Loss: 0.1126, Accuracy:0.945\nIteration: 18579, learning rate: 0.00455, Loss: 0.2032, Accuracy:0.938\nIteration: 18580, learning rate: 0.00455, Loss: 0.1809, Accuracy:0.914\nIteration: 18581, learning rate: 0.00455, Loss: 0.1685, Accuracy:0.930\nIteration: 18582, learning rate: 0.00455, Loss: 0.1038, Accuracy:0.961\nIteration: 18583, learning rate: 0.00455, Loss: 0.0811, Accuracy:0.969\nIteration: 18584, learning rate: 0.00455, Loss: 0.1067, Accuracy:0.961\nIteration: 18585, learning rate: 0.00455, Loss: 0.1645, Accuracy:0.930\nIteration: 18586, learning rate: 0.00455, Loss: 0.1165, Accuracy:0.961\nIteration: 18587, learning rate: 0.00455, Loss: 0.1359, Accuracy:0.930\nIteration: 18588, learning rate: 0.00455, Loss: 0.1855, Accuracy:0.891\nIteration: 18589, learning rate: 0.00455, Loss: 0.1117, Accuracy:0.961\nIteration: 18590, learning rate: 0.00455, Loss: 0.1827, Accuracy:0.914\nIteration: 18591, learning rate: 0.00455, Loss: 0.1823, Accuracy:0.930\nIteration: 18592, learning rate: 0.00455, Loss: 0.0879, Accuracy:0.977\nIteration: 18593, learning rate: 0.00455, Loss: 0.1073, Accuracy:0.969\nIteration: 18594, learning rate: 0.00455, Loss: 0.0945, Accuracy:0.984\nIteration: 18595, learning rate: 0.00455, Loss: 0.1345, Accuracy:0.938\nIteration: 18596, learning rate: 0.00455, Loss: 0.1399, Accuracy:0.953\nIteration: 18597, learning rate: 0.00455, Loss: 0.1436, Accuracy:0.914\nIteration: 18598, learning rate: 0.00455, Loss: 0.1661, Accuracy:0.930\nIteration: 18599, learning rate: 0.00455, Loss: 0.1951, Accuracy:0.922\nIteration: 18600, learning rate: 0.00455, Loss: 0.0708, Accuracy:0.978\nEpoch: 600, Loss: 0.1335, Accuracy:0.946, Val Loss: 0.2670, Val Accuracy: 0.880\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nax1 = plt.subplot(2,1,1)\nax1.plot(history['loss'], label='train_loss')\nax1.plot(history['val_loss'][1:], label='val_loss')\nax1.legend()\nax2 = plt.subplot(2,1,2)\nax2.plot(history['acc'], label='train_acc')\nax2.plot(history['val_acc'][1:], label='val_acc')\nax2.legend()\nplt.savefig('metrics.png')","execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists('logs'):\n    checkpoint = torch.load('logs')\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    exp_lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    epoch = checkpoint['epoch']\n    print('Restore model at epoch - ', epoch)\n\ntest_acc = []\ntest_loss = []\nfor batch_idx, data in enumerate(validation_loader):\n\n    img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]\n    img0, img1 , labels = img0.to(device), img1.to(device) , labels.to(device)#move to GPU\n\n    logits = model(img0, img1)\n    loss = F.cross_entropy(logits, labels, reduction = 'sum')/len(img0)\n\n    test_loss.append(loss.item())\n    _, preds = torch.max(logits, 1)\n    total = len(labels)\n    correct = torch.sum(preds==labels)\n    test_acc.append(correct.item()/total)  \n\nt_loss = np.mean(test_loss)\nt_acc = np.mean(test_acc)\nprint('Test Loss: {:.4f}, Test Accuracy: {:.3f}'.format(t_loss,  t_acc))\n","execution_count":37,"outputs":[{"output_type":"stream","text":"Restore model at epoch -  348\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:234: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"Test Loss: 0.3016, Test Accuracy: 0.871\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.lines as mlines\n\ndef cmc2(distmat, query_ids=None, gallery_ids=None,\n        query_cams=None, gallery_cams=None, topk=100,\n        separate_camera_set=False,\n        single_gallery_shot=False,\n        first_match_break=False):\n    distmat = np.array(distmat)\n    m, n = distmat.shape\n    # Fill up default values\n    if query_ids is None:\n        query_ids = np.arange(m)\n    if gallery_ids is None:\n        gallery_ids = np.arange(n)\n    if query_cams is None:\n        query_cams = np.zeros(m).astype(np.int32)\n    if gallery_cams is None:\n        gallery_cams = np.ones(n).astype(np.int32)\n    # Ensure numpy array\n    query_ids = np.asarray(query_ids)\n    gallery_ids = np.asarray(gallery_ids)\n    query_cams = np.asarray(query_cams)\n    gallery_cams = np.asarray(gallery_cams)\n    # Sort and find correct matches\n#     print(m,n)\n    indices = np.argsort(-distmat, axis=1)\n#     print(indices)\n    matches = (gallery_ids[indices] == query_ids[:, np.newaxis])\n    # Compute CMC for each query\n    ret = np.zeros(topk)\n    num_valid_queries = 0\n    for i in range(m):\n        # Filter out the same id and same camera\n        valid = ((gallery_ids[indices[i]] != query_ids[i]) |\n                 (gallery_cams[indices[i]] != query_cams[i]))\n        if separate_camera_set:\n            # Filter out samples from same camera\n            valid &= (gallery_cams[indices[i]] != query_cams[i])\n        if not np.any(matches[i, valid]): continue\n        if single_gallery_shot:\n            repeat = 10\n            gids = gallery_ids[indices[i][valid]]\n            print(gids)\n            inds = np.where(valid)[0]\n            ids_dict = defaultdict(list)\n            for j, x in zip(inds, gids):\n                ids_dict[x].append(j)\n        else:\n            repeat = 1\n        for _ in range(repeat):\n            if single_gallery_shot:\n                # Randomly choose one instance for each id\n                sampled = (valid & 1)#_unique_sample(ids_dict, len(valid)))\n                index = np.nonzero(matches[i, sampled])[0]\n            else:\n                index = np.nonzero(matches[i, valid])[0]\n            delta = 1. / (len(index) * repeat)\n            for j, k in enumerate(index):\n                if k - j >= topk: break\n                if first_match_break:\n                    print('I am here')\n                    ret[k - j] += 1\n                    break\n                ret[k - j] += delta\n        num_valid_queries += 1\n    if num_valid_queries == 0:\n        raise RuntimeError(\"No valid query\")\n    return ret.cumsum() / num_valid_queries\n\ndefault_color = ['r','g','b','c','m','y','orange','brown']\ndefault_marker = ['*','o','s','v','X','*','.','P']\n\nclass CMC:\n    def __init__(self,cmc_dict, color=default_color, marker = default_marker, name = None):\n        self.color = color\n        self.marker = marker\n        self.cmc_dict = cmc_dict\n        self.name = name\n        \n    def plot(self,title,rank=10, xlabel='Rank',ylabel='Matching Rates',show_grid=True):        \n        fig, ax = plt.subplots()\n        fig.suptitle(title)\n        x = list(range(1, rank+1, 1))\n        plt.ylim(0, 1.0)\n        plt.xlim(1, rank)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.xticks(x)\n        plt.grid(show_grid)\n\n        method_name = []\n        i = 0\n        for name in self.cmc_dict.keys():\n            if rank < len(self.cmc_dict[name]):\n                temp_cmc = self.cmc_dict[name][:rank]\n                r = list(range(1, rank+1))\n            else:\n                temp_cmc = self.cmc_dict[name]\n                r = list(range(1, len(temp_cmc)+1))\n                \n            if name == list(self.cmc_dict.keys())[-1]:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[0], marker=self.marker[0], label= name)\n            else:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[i+1], marker=self.marker[i+1], label=name)\n                i = i+1\n            ax.add_line(globals()[name])\n            method_name.append(globals()[name])\n\n        plt.legend(handles=method_name)\n        plt.savefig(self.name)\n        #plt.show()\n    \n    def save(self, title, filename, \n             rank=20, xlabel='Rank',\n             ylabel='Matching Rates (%)', show_grid=True,\n             save_path=os.getcwd(), format='png', **kwargs):\n        fig, ax = plt.subplots()\n        fig.suptitle(title)\n        x = list(range(0, rank+1, 5))\n        plt.ylim(0, 1.0)\n        plt.xlim(1, rank)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.xticks(x)\n        plt.grid(show_grid)\n\n        method_name = []\n        i = 0\n        for name in self.cmc_dict.keys():\n            if rank < len(self.cmc_dict[name]):\n                temp_cmc = self.cmc_dict[name][:rank]\n                r = list(range(1, rank+1))\n            else:\n                temp_cmc = self.cmc_dict[name]\n                r = list(range(1, len(temp_cmc)+1))\n                \n            if name == list(self.cmc_dict.keys())[-1]:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color='r', marker='*', label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n            else:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[i], marker=self.marker[i], label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n                i = i+1\n            ax.add_line(globals()[name])\n            method_name.append(globals()[name])\n\n        plt.legend(handles=method_name)\n        plt.show()\n\ndef score(img1,img2):\n\n    image1 = cv2.imread(img1)\n    image1 = cv2.resize(image1, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB).astype(float)\n    image1 = val_transform(image=image1)['image']/255\n    image1 = torch.reshape(image1, (1, 3, IMAGE_HEIGHT, IMAGE_WIDTH)).float().cuda()\n    image2 = cv2.imread(img2)\n    image2 = cv2.resize(image2, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB).astype(float)\n    image2 = val_transform(image=image2)['image']/255.\n    image2 = torch.reshape(image2, (1,3, IMAGE_HEIGHT, IMAGE_WIDTH)).float().cuda()\n    out = model(image1, image2)\n\n    return out[0][1].item()\n\n    \ntest_idx = np.arange(0,256)\nprint('len of iestidx - ', len(test_idx))\n\n\nscore_matrix=np.zeros((256,256))\nfor i in range(len(test_idx)):\n    img1=random.choice(test_list[i])\n    for j in range(len(test_idx)):\n        img2=random.choice(test_list[j])\n        score_matrix[i][j]=score(img1,img2)\n        #print(score_matrix[i][j])\nprint('completed computing score matrix')\n#calculating cmc score\ncmc_score=cmc2(score_matrix,gallery_ids=test_idx,query_ids=test_idx, topk = 256)\nprint(cmc_score)\nnp.save('cmc_score1', cmc_score)\ncmc_dict ={\n\n'simaese_face_with_32X32': cmc_score,\n}\ncurve=CMC(cmc_dict, name = 'Siamese_face_32X32_torch_cmc')\ncurve.plot(title = \"\", show_grid=False)","execution_count":46,"outputs":[{"output_type":"stream","text":"len of iestidx -  256\ncompleted computing score matrix\n[0.4453125  0.52734375 0.5546875  0.609375   0.63671875 0.6640625\n 0.6796875  0.71875    0.7265625  0.7421875  0.75       0.765625\n 0.76953125 0.7734375  0.7890625  0.796875   0.80078125 0.80859375\n 0.8125     0.81640625 0.82421875 0.83984375 0.8515625  0.85546875\n 0.86328125 0.8671875  0.8671875  0.87109375 0.87890625 0.88671875\n 0.89453125 0.90234375 0.91015625 0.9140625  0.921875   0.92578125\n 0.92578125 0.92578125 0.92578125 0.9296875  0.9296875  0.9296875\n 0.93359375 0.93359375 0.93359375 0.94140625 0.94140625 0.94140625\n 0.94921875 0.94921875 0.94921875 0.94921875 0.94921875 0.94921875\n 0.94921875 0.953125   0.95703125 0.95703125 0.95703125 0.95703125\n 0.95703125 0.95703125 0.96484375 0.96484375 0.96484375 0.96484375\n 0.96484375 0.96484375 0.96484375 0.96484375 0.96484375 0.96484375\n 0.96484375 0.96875    0.97265625 0.97265625 0.9765625  0.98046875\n 0.98046875 0.98046875 0.984375   0.984375   0.984375   0.984375\n 0.984375   0.984375   0.984375   0.98828125 0.98828125 0.98828125\n 0.98828125 0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n 0.98828125 0.98828125 0.98828125 0.9921875  0.9921875  0.9921875\n 0.9921875  0.9921875  0.9921875  0.9921875  0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375 0.99609375\n 0.99609375 0.99609375 0.99609375 0.99609375 1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.         1.         1.\n 1.         1.         1.         1.        ]\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}